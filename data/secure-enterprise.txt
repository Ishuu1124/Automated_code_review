IBM Cloud

Running secure
workloads
Solution guide

Edition notices
This PDF was created on 2025-04-15 as a supplement to Running secure workloads in the IBM Cloud docs. It might not be a complete set of information or the latest
version. For the latest information, see the IBM Cloud documentation at https://cloud.ibm.com/docs/secure-enterprise.

What are modules and deployable architectures?
Creating secure, compliant, and scalable application infrastructure can be difficult to set up and costly to maintain. Instead of figuring out how to assemble
a compliant infrastructure architecture on your own, you can take advantage of modules and deployable architectures. Modules and deployable
architectures can help you to create a framework around how resources are deployed in your organization's accounts. By working with these reusable
configurations, you can define the standard for deployment once and ensure that it is easily repeatable for each member of your organization.
For example, think about an architect who is building an apartment complex. These designs are typically executed in a modular way. There are patterns for
standard one-bedroom, two, or three-bedroom apartments. The builder can combine the standard apartments, each functional in their own way, into a
larger, more complex, but functional living arrangement. IBM applied this same analogy to deploying solutions on the cloud. Rather than your organization
spending months figuring out how to get services and software to work together, you can use IBM Cloud's well-architected patterns. Each pattern is
packaged as composable, automated building blocks known as modules and deployable architectures.

What is a module?
A module is a stand-alone unit of automation code that can be reused by developers and shared as part of a larger system. Similar to Node.js or Python
packages, modules are a convenience to developers who are managing related resources. While it is possible to use modules alone, they're more powerful
when you combine them to build a deployable architecture. Modules that are created by IBM Cloud are made available in the IBM Terraform modules
public GitHub org. For example, the Red Hat® OpenShift® VPC cluster on IBM Cloud module installs and configures a Red Hat OpenShift cluster on IBM
Cloud.

What is a deployable architecture?
A deployable architecture is cloud automation for deploying a common architectural pattern that combines one or more cloud resources. It is designed to
provide simplified deployment by users, scalability, and modularity. A deployable architecture incorporates one or more modules. Deployable
architectures are coded in Terraform, which you configure with input variables to achieve the behavior that you want. In the case of a deployable
architecture stack, it incorporates one or more deployable architectures that are grouped without requiring Terraform code.

Deployable architecture that contains modules

For example, VPC landing zone is a deployable architecture that provisions several virtual private clouds in a hub-and-spoke networking pattern that is
connected by a transit gateway. It includes a number of supporting services that are used for the monitoring and security of the workloads that run on the
VPCs.
Deployable architectures that are built and maintained by experts at IBM Cloud are made available to you in the

IBM Cloud catalog. If you choose to create

your own version of those deployable architectures, or build one from scratch, you can onboard your deployable architecture to a private catalog and share
your ready-to-deploy solution with your organization through the catalog.
A deployable architecture might include variations, have dependencies, or be stacked together to create more complex solutions.

Variations
A variation is a type of deployable architecture that applies differing capabilities or complexity to an existing deployable architecture. For example,
there might be a Quick start variation to your deployable architecture that has basic capabilities for simple, low-cost deployment to test internally.
And, you might have a Standard variation that is a bit more complex that is ready for use in production.
Dependencies
A deployable architecture is considered dependent upon another architecture when it has inputs that require the outputs from the other architecture
to properly deploy.

Running secure workloads 3

Deployable architecture with a dependency on another deployable architecture

Stacks

Experimental

A deployable architecture stack links together multiple architectures to create an end-to-end solution. This linking is achieved by specifying
references in the configuration of each architecture's inputs. You do not need to be an expert in Terraform, or have any Terraform coding skills, to
create and deploy a stack.
Deployable architecture stacks are created with IBM Cloud Projects and can be shared with others through a private catalog. A stacked deployable
architecture has independent configuration states for each of the architectures in the stack. This allows each component deployable architecture to
be individually deployed, updated, or undeployed independently. The deployable architecture stack derives much of its cost, compliance, support,
and quality assurances from its included deployable architectures. However, each stack is uniquely versioned and has its own descriptions and
architecture diagram. The following diagram shows how a deployable architecture stack can be made of multiple deployable architectures to create
a single deployable architecture.

Deployable architecture stack

For an example, see the Retrieval Augmented Generation Pattern deployable architecture , which is assembled from separate deployable
architectures. For more information, see stacking deployable architectures.

What are projects and how do they work with deployable architectures?
An IBM Cloud project is a management tool that is designed to organize and provide visibility into a real-world project that exists in your organization. A
project manages all of the configured instances of a deployable architecture and the resources that are related to the real-world reasons that they are
deployed. Projects store versioned deployable architecture instances and organize the instances and resources into environments to help improve visibility
into the development lifecycle. An environment is a group of related deployable architecture instances that share values for easier deployments. For

Running secure workloads 4

example, development, test, or prod.
Projects are responsible for ensuring that only approved deployable architectures can be deployed. Additionally, they can help to ensure that the
architectures and the resources that they created are up-to-date, compliant, and that drift does not occur over time. For example, you might have an
account management application project. This project is designed to manage all of the resources that the account management application needs to
deploy into a development, test, or production environment. Each environment has the same variables, such as a region or prefix, but has different values.
When a deployable architecture is assigned to an environment through a project, their input values can automatically reference any of the environment's
properties that have the same name. While IBM Cloud projects are easy to create and update, they are not templatized or optimized for replication or
sharing.

How do I know which solution to create?
If you plan to create your own solution, the scope, coupling, whether it's deployable, and the purpose of your solution should all be taken into account. For
guidance and use cases to help you decide what you plan to build, see Planning and researching for designing an architecture and How do I decide what
kind of component to create.
The following table provides a high-level overview of why you might want to create the different components.
Purpose

Recommended

Why?

component
Creating a library of sharable
automation components

Module

Modules provide reusable, curated automation to speed up the process for those who are
creating and configuring deployable architectures.

Ensuring that your organization's
cloud environment is secure and
compliant

Deployable
architecture

Deployable architectures are packaged in a way that you can define a secure and compliant
deployment once and ensure that all members of your organization are repeating the
deployment in the same way.

Architecting your own solutions

Deployable
architecture
stack

By combining architectures, you can create a more complex end-to-end solution for your
organization.

Understanding for automated deployments use-cases

Running secure workloads 5

Learn about access management
How IBM Cloud IAM works
Learn about what IBM Cloud Identity and Access Management (IAM) is, how IAM works, what features are available, and how to access the console, CLI,
and APIs to work with IAM in your account.
IAM enables you to securely authenticate users for platform services and control access to resources consistently across IBM Cloud. A set of IBM Cloud
services is enabled to use IBM Cloud IAM for access control, and are organized into resource groups within your account so you can give users access
quickly to more than one resource at a time. Each of these services is labeled as "IAM-enabled" in the catalog. You can use IAM access policies to assign
users, service IDs, and trusted profiles access to resources within your account. And, you can group users, service IDs, and trusted profiles into an access
group to easily give all members of the group the same level of access.
You can use trusted profiles to automate the grouping and granting of access to users, services, and app identities. By specifying conditions based on
SAML attributes for users whose identity is federated from your external identity provider (IdP), users can be granted access to resources without having to
be invited to the account if they meet those conditions. For service and app identities, you can define fine-grained authorization for all applications that are
running in a compute resource without creating service IDs or managing the API key lifecycle for applications.

How IAM access works in an account by using access groups. Service IDs and select IBM Cloud can also asssume trusted profiles.

Note: For classic infrastructure that doesn't support the use of IBM Cloud IAM policies for managing access, you can use the

classic infrastructure

permissions documentation.

What features are provided?
IBM Cloud IAM provides a wide range of features for your identity and access management needs.

User management
With unified user management, you can add and delete users in an account for both platform and classic infrastructure services. You can organize a group
of users in an access group to make assigning access for more than one user or service ID at a time a quick and easy task.

Fine-grained access control
Running secure workloads 6

Access for users, service IDs, access groups, and trusted profiles are defined by a policy. Within the policy, the scope of access can be assigned to a set of
resources in a resource group, a single resource, or account management services. After the target is set, you can define what actions are allowed by the
subject of the policy by selecting access roles. Roles provide a way to tailor the level of access that is granted for the subject of the policy to perform
actions on the target of policy, whether it is platform management tasks within the account or accessing a service's UI or completing API calls.
You can also add time-based conditions to a policy that defines when the policy grants access, whether you want to grant temporary access to resources in
your account or allow access during recurring time windows. For more information, see Limiting access with time-based conditions.

Access groups for streamlined access management
Quickly and easily assign access for a group of users, service IDs, or trusted profiles that are organized in an access group by assigning access to the group,
and then add or remove identities as needed to grant or deny access to account resources. Access groups enable you to manage a minimal number of
policies in the account. For more information, see Setting up access groups .

Trusted profiles for eliminating the need to manage credentials
Automatically grant federated users access to your account with conditions based on SAML attributes from your corporate directory. Trusted profiles can
also be used to set up fine-grained authorization for applications that are running in compute resources. This way, you aren't required to create service IDs
or API keys for the compute resources. Assign access to the profile by adding it to an access group or by assigning individual policies, and then add or
remove conditions as needed to grant or deny access to account resources. By using trusted profiles, you can centrally manage the access lifecycle to
multiple IBM Cloud assets. For more information, see Creating trusted profiles .

Federated users
Your users might already have identities outside of IBM Cloud in your corporate directory. If your users need to work with IBM Cloud resources or work
with applications that access those resources, then those users also need IBM Cloud credentials. You can use a trusted profile to specify permissions for
users whose identity is federated from your organization or an external IdP. By using your IdP, you can provide a way for users in your company to use
single sign-on (SSO). To connect your federated users with IBM Cloud resources, see Federating users to IBM Cloud.

View video: Introducing IBM Cloud trusted profiles

Video transcript
We are excited to introduce the latest and greatest identity type: IBM Cloud trusted profiles. You expect the most reliable and efficient way to manage
access to your account, so let’s learn about how you can use trusted profiles.
Previously, organizing identities and assigning access was limited to access groups, where each user is added to the account manually.
As an account owner, you can save time and automatically grant federated users access to your accounts by leveraging the attributes that already exist in
your corporate directory.
Simply add conditions based on SAML attributes to define which federated users can apply a profile. This way, changes in your directory immediately affect
access to resources.
As a federated user, you might have the option to apply one of many trusted profiles. After you log in, you can apply a profile, or continue to the console.
Imagine a scenario where you want to complete developer-related tasks, like working with the service instances from your application components. You
can select the Developer profile when logging in to ensure that you have the access you need.
Similarly, if you want to complete an administrator-related task, you can select the Admin profile that has privileged permissions. This way, you reduce the
risk of taking privileged actions by mistake.
You also have the option to log in to the account without applying a profile by continuing to the console.
To learn more about how trusted profiles work check out our IBM Cloud Identity and Access Management documentation which includes tutorials and
other helpful resources to get started!

Compute resources
By using trusted profiles, you can define fine-grained authorization for all applications that are running in a compute resource without creating service IDs
or managing the API key lifecycle for applications. The trusted profiles provide better control for granting access to compute resources.

Running secure workloads 7

Application developers can programmatically retrieve a token that is associated with the compute resource identity that they are running on. That
token is used to get the trusted profile identity token, which is used to access services and resources on IBM Cloud.
Applications running on a compute resource can have a flexible, but secure way to access other IBM Cloud services from within compute resources.
For example, it's more secure not having to store API keys.
All compute resource instances that share certain conditions such as name, namespace, tags, or location, their identities are mapped to a common
profile and can share access to IBM Cloud resources. This common identity makes it possible to give the applications within various compute
resources access to an external resource one time rather than cluster-by-cluster.

Enterprise-managed IAM templates for centrally managing access in enterprises
Your enterprise can easily scale access management and ensure consistent account security settings throughout the organizaiton by using enterprisemanaged IAM templates. You can create templates for IAM resources like access groups, trusted profiles, and account security settings that you assign
throughout the enterprise. When you assign an IAM template to child accounts, enterprise-managed IAM resources are created in the child accounts you
select.
For example, there might be a certain job role in every child account that requires the same permissions. You can create an access group template with the
necessary access polices and assign the template to all of the child accounts in your enterprise. This way, you reduce policy drift and can be certain that
users with that job role have only the access that is necessary in each account.
For more information, see How enterprise-managed IAM works .

API keys for user authentication
You can create multiple API keys for a user to support key rotation scenarios, and the same key can be used for accessing multiple services. IBM Cloud API
keys enable users who use two-factor authentication or a federated ID to automate authentication to the console from the command line. A user can also
have a single classic infrastructure API key that can be used to access classic infrastructure APIs; however, this is not required as you can use IBM Cloud
API keys to access the same APIs. For more information, see Understanding API keys.

Service IDs
A service ID identifies a service or application similar to how a user ID identifies a user. These are IDs that can be used by applications to authenticate with
an IBM Cloud service. Policies can be assigned to each service ID to control the level of access that is allowed by an application that uses the service ID,
and an API key can be created to enable the authentication. For more information, see Creating and working with service IDs .
Note: Infrastructure-as-a-Service (IaaS) doesn't support operations that are made by service IDs. If an account includes IaaS and PaaS,
administrative functions that are made by a service ID might not work as intended if the operation depends on API calls to IaaS. In an account that
includes IaaS, be sure that account administrators complete the administrative functions. For example, functional IDs can be used for
administrative functions. In some cases, IBM support might be able to assist with some administrative functions that span both IaaS and PaaS.

Multifactor authentication
You can require multifactor authentication (MFA) for every user in the account or just users with non-federated IDs who do not use SSO. All users with an
IBMid use a time-based one-time passcode (TOTP) MFA factor, and any users with a different type of ID must be enabled to use the TOTP, security
questions, or external authentication factor separately. For more information, see Types of multifactor authentication .

Service to service authorizations
In a scenario that you need to provide one service access to another, you can create a policy by using a service to service authorization. For more
information, see Using authorizations to grant access between services .

Related access management controls
IAM is the foundation for identity and access management in IBM Cloud, but you can extend your security strategy by building on IAM access controls with
context-based restriction. These restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. For
more information, see What are context-based restrictions? .

How do I use IBM Cloud IAM?
You can access and use IBM Cloud IAM through the Access (IAM) UI, CLI, or API.
To access IBM Cloud IAM by using the console, go to Manage > Access (IAM).
Go to Managing IAM access, API keys, service IDs, and access groups to review the available CLI commands.
Go to the following API docs to review the available APIs:
IAM Identity Services API
Running secure workloads 8

IAM Access Groups API
IAM Policy Management API

Identities in IBM Cloud
The two major concepts of IBM Cloud® IAM are identity and access management. For more information, review the following sections and

Access

management concepts.
The identity concept consists of user identities, service and app identities, API keys for users and service IDs, trusted profiles, and resource identities.
Users are identified by their IBMid, SoftLayer ID, App ID user ID, or federated user attributes.
IBM Cloud IAM grants access to individual identities or a group of identities by using policies. The policies allow for users to grant access while adhering to
the principle of least privilege by utilizing roles and scoped resources. Except for account owners, user identities do not have any access grants by default.
Each access grant is independent of other access grants, and users with permission can access resources by using the console and APIs. The actions that
are allowed can be for a single API or a group of APIs depending on customer needs. Access can be granted at a high level for a grouping of resources or
scoped to a single resource depending on customer needs.
Tip: Removing access for inactive identities can reduce the risk of unauthorized access to your IBM Cloud resource and help you manage access
more efficiently. For more information, see Identifying inactive identities.

Users
User IDs are best used when a person needs a digital identity in an account. Users are invited to the account and given access to the resources in the
account. Users log in by using their IBMid, SoftLayer ID, App ID user ID, or federated user ID. Each user is also identified by a generated ID called an IAM
ID.
IAM IDs always include a realm to identify the provider of the user, such as IBMid or an external identity provider. In the IAM ID, the realm is followed by a
series of numbers that is a unique identifier. For example, the IAM ID for a user with an IBMid would look like IBMid-20000AB1C .
IAM IDs are most commonly used when you assign access to others by using the API. They are used to identify a user, service ID, trusted profile, or
resource. The IAM ID is included in the token when used in the console, CLI, or API. Access policies are defined by using IAM IDs since it is the identity that
can be verified in the IAM token.
To find your IAM ID, go to Manage > Access (IAM). You can see your IAM ID in the My user details section. To view other users' IAM IDs, go to Manage >
Access (IAM) > Users, then select a user's name from the list and click Details.

User API keys
IBM Cloud API keys are credentials that are associated with a user's identity. The access that the user is assigned can be from policies across multiple
accounts that the user is a member of. User API key credentials can be used to make API and CLI calls. The user API key can be used directly or used to
generate a token.
For more information about using an API key associated with your user identity, see Managing user API keys.

Federating users to IBM Cloud
IBM Cloud offers two ways for you to federate your corporate identity provider (IdP), which simplifies login by giving your employees access to IBM Cloud
with their company username and password. You can federate with IBMid, or you have the option to create an IBM Cloud App ID service instance and use
that as a way to federate users into an IBM Cloud account. For more information, see Enabling authentication from an external identity provider .
Both federation options require that the user is a member of the account, or has access to the account by a trusted profile to be able to complete
operations. If trusted profiles are not configured, the account owner or administrator must invite individual IBMids into the IBM Cloud account. Only if the
invited IBMid accepts the invitation is the user added the account as an active user. In the case of App ID, the user is automatically onboarded to IBM
Cloud without a need to invite each user to the account. In both types of federation, the users are active IBM Cloud account users that can access the
platform, including IAM-enabled resources and classic infrastructure all depending on their assigned access.
Trusted profiles deal with federated users differently. If the customer federates their corporate IdP, users from that IdP aren't added to an account as what
we might consider a typical user. Instead, users' SAML-based IdP attributes are evaluated at login and if they meet all of the conditions for a trusted profile,
they are prompted to apply one or more trusted profiles. Trusted profiles grant users the level of access that they need to complete specialized and specific
tasks in a limited time-period, for example, 1 - 4 hours. Time-based access allows frequent authentication checks for reduced security risks. These are
usually critical tasks that you would want to avoid doing unintentionally in daily work. Users don't need to onboard to IBM Cloud, they're automatically
added through the trust relationship. If a user leaves your company, you can delete the user's corporate identity in your directory, which revokes access to
IBM Cloud.

Functional IDs
Running secure workloads 9

Functional IDs are most commonly used when an application or service needs a digital identity and access to IAM-enabled resources or Classic
infrastructure resources. Some services require a functional ID when you create service instances, for example the Kubernetes Service.
A functional ID is a type of user ID that exists in your Identity Provider's (IdP) user directory, but it's not tied to a specific user. To create a functional ID, you
must create a new user in the user directory and invite them to your IBM Cloud account.
The functional ID is used to create service instances, like Kubernetes Service clusters. This way, instances aren't linked to a specific person that might
leave the company, which would leave the instance without an owner. Generally, functional IDs can do more in IBM Cloud than a service ID. For example,
functional IDs, like user IDs, can be granted access to services and applications through access policies.
IBM Cloud API keys for users can be created and associated with a functional ID. If a service requires a user API key for interacting with other services or
applications, use the functional ID API key. By using the API key that is associated with the functional ID, you can provide only the access that is needed for
that service.
Tip: If you're using a functional ID as the account owner, instead consider Setting an alternative account owner . This is available only for classic
infrastructure accounts.

Service IDs
Service IDs are another type of identity that is used in an account. Service IDs are used to provide a separate identity for services and applications. Service
IDs are best used when an application or service needs a digital identity and needs access to only IAM-enabled resources. You can create a service ID to
be used by an application that needs access to your IBM Cloud services so that individual user credentials don't need to be used.

Service ID API keys
You can also create API keys that are associated with service IDs to authenticate applications as a particular service ID. This way, the applications can
access resources that are assigned to that specific service ID. Service ID API key credentials can be used to make API and CLI calls. For more information
about creating API keys associated with a service ID, see Managing service ID API keys .

Trusted profiles
Similar to other identities within IAM, trusted profiles are treated as a subject that is granted access in IAM policies.
Usually, for a user to take an action on a resource within an account, that identity must explicitly be added to the account. With trusted profiles, it is possible
for a user to complete the actions without being invited to an account. Instead, they are automatically granted access to resources when they apply the
trusted profile identity during login. Only users federated by an external IdP can be mapped to trusted profiles during login by evaluating SAML-based
attributes to determine which profiles their identity can apply.
Similarly, instead of creating a service ID, generating an API key, and getting the application to store and validate that key, you can create

trusted profiles

for compute resources to define fine-grained authorization for all applications that are running in a compute resource. Compute resources become
identities when used as part of a trusted profile. Trust with compute resources is established by conditions based on resource attributes, or creating a
direct link to a specific resource.
You can also establish trust with IBM Cloud services that need to run an operation in your account. Or, use trusted profiels to give a service ID from
another account access in your account.

Resource identities
The final piece of the identity concept in IAM is IBM Cloud resources, which are identified by their

cloud resource names (CRN). All resources that are

created from the catalog are identified by their CRN. These CRNs are used for service-to-service authorizations in IAM. Additionally, you use a CRN to
assign access to specific resources when you use the API. For more information, see Cloud Resource Names and Using authorizations to grant access
between services.
For more information, see Cloud Resource Names and Using authorizations to grant access between services .

IAM access concepts
The concept of access management consists of a few interrelated components, including users, service IDs, access groups, trusted profiles, resources,
policies, roles, actions, and the IBM Cloud IAM control system, which allows users to take actions on resources within an account.
IBM Cloud IAM follows an eventually consistent pattern that is common to many cloud-native services. As a result, IAM remains highly available and
performant across multiple global regions. Changes that are made to IAM access policies, authorizations, service IDs, API keys, access groups, trusted
profiles, resource groups, users, or any other access controls are recorded and propagated across all IAM components and IAM-enabled services
worldwide. Access changes might not take effect until the propagation process is complete.

Running secure workloads 10

Access groups
A group of users and service IDs can be organized so that the same access can be assigned to all members within the group by using one or more policies.
With access groups, you can streamline the access assignment process so that you can manage fewer policies and reduce the number of policies in an
account, which in turn increases performance. Access groups allow you to grant and revoke access by simply adding or removing users or service IDs in
the access group. After your groups are set up, you can start assigning policies by selecting an access group as the subject of the policy. For more
information, see Access groups for streamlined access management .

Trusted profiles
With trusted profiles, you manage the identities of your users within your own corporate directory. And, you can centrally manage the access lifecycle to
multiple IBM Cloud accounts and assets for federated users without the need to configure access policies for each entity within each account. You don't
need to invite users to your account to give them to access your IBM Cloud resources.
You can also define fine-grained authorization for all applications that are running in a compute resource without creating service IDs or managing the API
key lifecycle for applications. To start creating trusted profiles for your organization, see Trusted profiles for eliminating the need to manage credentials .

Resources
Account resources are the service instances that are selected from the catalog or finer-grained resources within a service instance, such as an IBM Cloud®
Object Storage bucket. IAM-enabled resources are added to a resource group when they are created from the catalog.
IAM access management enables fine-grained access, which means that a policy can be set on a wide scale to all resources in a resource group, for
example, or to a specific service instance in the account and even a resource type like a IBM Cloud Object Storage bucket within a specific instance.

Access policies
Access policies are how users, service IDs, access groups, and trusted profiles in the account are given permission to access and take actions on account
resources. Policies include a subject, target, and role. The subject is the user, service ID, or access group that you are providing access. The target of the
policy is the resource to which you want to provide access. And, the IAM roles define the level of access or allowed actions on the target of the policy.
A policy assigns the subject one or more roles that define the level of access and one or more attributes that define the target that the policy allows access
to. The policy can provide access to a single service at the instance level, to a set of resources that are organized together in a resource group or to any set
of resources that can be defined by a set of attributes such as location or resource type. A policy can also provide access to account management services.
Depending on the IAM roles that you assign, the subject is allowed varying levels of access for completing account management tasks, working with
service instances, or accessing a service by using the console or completing API calls.
There are different types of policies that allow access to account resources for users and service IDs: a resource group policy, a resource instance policy,
an account-wide policy for access to all IAM-enabled services or all instances of a specified service, and a policy on all or one account management
services. Depending on your selections, custom configuration options, such as defining access to resources in a specific location or defining access to the
granular level of a service-specific resource within an instance, might be available.
In addition to access policies for users and service IDs, there is a policy type that is called an authorization that allows specific services or instances of
services access to other services. You can learn more about assigning access between services in the Using authorizations to grant access between
services documentation.

Roles
IBM Cloud access roles are a group of actions. Access roles allow users and service IDs to complete specific tasks within the context of the target resources
that are defined in the policy. There are two types of predefined access roles: platform management and service access. The third type of access role is a
custom role that you can create for a service to combine any set of available actions to meet your organizational needs.
Platform management roles define allowable actions, such as assigning user access and creation of service instances, for managing resources at the
platform level. Platform roles also apply to actions that can be taken within the context of account management services, such as inviting and removing
users, managing access groups, managing service IDs, and private catalog products.
Service access roles define allowable actions, such as calling service APIs or accessing a service's dashboard. These roles are customized based on the
service that is selected within the policy.
Tip: When you assign access within the console, next to the role you can see the number of actions that are mapped to each role and drill down
into that list to see exactly what each role allows.
For more information, see IAM roles.

Actions
Running secure workloads 11

Actions are mapped to IBM Cloud IAM roles so that users can perform only specific tasks when they are assigned the different roles. Sometimes actions
are also referred to as permissions or operations. Allowable actions for each role change based on the service that is being accessed because each service
defines how that role maps to the use of the service. For more information, see IAM roles and actions .

Enterprise-managed IAM templates
Enterprise-managed IAM templates are a useful tool for standardizing access management and account security settings across an enterprise. Templates
allow you to define commonly used access groups, trusted profiles, and security settings in a consistent manner, ensuring that your security policies are
applied uniformly throughout the enterprise. This can be especially important for compliance with organizational standards, which may require that certain
access management and security settings are configured consistently across all or some accounts. By using IAM templates, you can simplify the
management of your security policies, reduce the risk of misconfiguration or human error, and improve overall security posture. For more information, see
How enterprise-managed IAM works .
Note: Enterprise-managed IAM resources in your child account have the tag

enterprise-managed

.

Action controls
Action controls enforce your preferences on which operations child account administrators can take on the enteprise-managed IAM resources in their
accounts. You might want to allow child account administrators to add members to an enterprise-managed access group that you assign in their account.
In this case, you can enable the action control for adding members. Or, you might want to prohibit child account administrators from adding new policies to
a trusted profile. By default, action controls restrict child account administrators from making changes to enterprise managed IAM resources in their
account.

Access management system
The IBM Cloud IAM control system allows or denies actions by users or service IDs within the context of a service based on their assigned access policies.
By default, every user and service ID has no access. Each access policy that is added enables the user or service ID to perform an action within the account
based on the specified target and role that is selected in the access policy. When a user tries to complete a specific action, the control system uses the
attributes that are defined in the policy to determine whether the user has permission to perform that task. For more information, see How IBM Cloud IAM
works.

What is ABAC and RBAC?
There are two common types of IAM systems in cloud providers and understanding each of these models can help you gain a better understanding of how
IAM works in IBM Cloud.
Attribute-based access control (ABAC) uses attributes from identities, such as users and service IDs, environments, and resources. These attributes
are used by an access decision engine to determine whether an access request should be permitted or denied. ABAC provides more flexibility,
control, and features than role-based access control systems. ABAC is typically used when fine-grained access control is needed, or if a wide variety
of access control use cases needs to be solved by the same decision engine. ABAC helps reduce security risks by providing fine-grained access
control and is typically more complex, especially during initial setup.
Role-based access control (RBAC) uses a mapping from an identity, such as a user or service ID, to a role. The RBAC role defines the type of access
that an identity with the RBAC role can take against a resource. Typically access can be granted for a resource type or a grouping of resources. RBAC
roles are usually defined based on job responsibilities within an organization. The RBAC role grants the access that is needed for an identity to do its
job. This is a simple model because IAM administrators manage the mapping of RBAC roles to an identity. RBAC roles setup can be simpler than
ABAC initial setup.
IBM Cloud IAM uses an ABAC model by using identity and resource attributes. IBM Cloud IAM uses access policies to store the attribute information that is
needed by the IAM access decision engine. And, the access policies tell the IAM decision engine, which attributes the author of the policy requires to grant
access to a resource.
The supported attributes for identities are iam_id and access group ID. The supported attributes for resources belong to one of the following categories:
Fields defined in the resource CRN, for example the service name.
System-wide defined resource attributes, such as resource groups.
Service-specific resource attributes such as namespaces or buckets.
Note: Each service defines the supported attributes for resources it manages. For more information, see the documentation for the service you're
using.
A best practice in IBM Cloud IAM is to use access groups to manage access for identities. After the access group access policies are defined, granting, and
revoking access is simply a matter of adding and removing identities to or from access groups. A user or service ID can belong to as many access groups as

Running secure workloads 12

the administrator wants, and the members of the group inherit all access that is assigned to the access group. This approach provides the fine-grained
access benefits of ABAC with the simplicity of RBAC.
Tip: IAM administrators familiar with RBAC might use access groups to mimic an RBAC model. Conceptually an access group is similar to an RBAC
role. If you're more familiar with using traditional RBAC roles like system administrator, network administrator, or storage administrator, these can
be defined in IBM Cloud IAM by using access groups with specific access policies that are assigned to each. For more information about using
access groups and the best practices for assigning access, see Best practices for organizing resources and assigning access .
For example, you can create an access group called Storage Administrators . When it is first created, no access is granted to any members of the
access group. The access group can then be assigned policies granting the Administrator role to all storage resources in the current account as well as any
that will be created in the future. If a new user joins the team and their job in the organization is a storage administrator for the account, then they can
simply be added to the access group and have all of the access that they need to do their job.
This is a simple example, but the approach can be applied to any job, role, or responsibility in an organization. The access policies assigned to the access
group can be fine-grained allowing for use cases like storage administrator of all storage in a specific resource group, and even for only a specific storage
type.
For more information about getting up and running quickly with IBM Cloud IAM by setting up access groups for quick access assignments, inviting users to
your account, and managing their access, see Assigning access to resources.

What are IAM policies and who can assign them?
A policy grants a subject one or multiple roles to a set of resources so that specific actions can be taken within the context of the specified target resources.
The following graphic helps to explain how the IAM policy is created. Policies are always created by specifying the subject first. The subject is a specific
user, service ID, access group, or a trusted profile. Next, the target of the policy is selected which is what you are allowing the user to access, for example:
all services in a resource group, all IAM-enabled services in the account, account management services, or a particular service instance. Finally, you
complete your access policy by selecting from the available roles. These roles define exactly what actions that a user can complete. More configuration
options might be available, depending on the service you select.

How IAM access policies are created by using a subject, target, and role

You can assign and manage policies if you have the proper role. The following table shows policy management tasks and the role that is required for each.
Action

Required role

Create a policy in an account
for all services and instances

Account owner or administrator on all account management services and all Identity and Access enabled services

Create a policy on a service
in an account

Account owner, administrator on all Identity and Access enabled services, or administrator on the service in the
account

Create a policy on a service
instance

Account owner, administrator on all Identity and Access enabled services, administrator on the service in the
account, administrator on all services in the relevant resource group, or administrator on the service instance
Users allowed to create access policies

Common access policy types
You can provide fine-grained access for users, service IDs, or access groups by assigning the following types of access policies:
All Account Management services
A specific account management service
All IAM Account Management services, which are a subset of account management services that includes IAM Identity, IAM Access Management,

Running secure workloads 13

IAM User Management, and IAM Groups
A specific IAM service
All resources within the account
All resources within all services that belong to an individual resource group with the ability to manage the resource group
All resources within a single service in a resource group with the ability to manage the resource group
All resources within a single service across the account, regardless of the resource group they're assigned to
Resources in an individual instance
A single resource type within an instance, for example, a bucket in an Object Storage instance
If you want to enable a user full administrator access to complete the account management tasks, such as inviting and removing users, viewing billing and
usage, managing service IDs, managing access groups, managing user access, and access to all account resources, you must assign a user the following
access:
A policy for All Identity and Access enabled services within the account with the administrator and manager roles assigned.
A policy with the administrator role assigned on All Account Management services.

Groups of services
You can assign access to a group of services so that you need only a single policy to assign access to multiple services. This way, you decrease the number
of policies in your account and reduce the time and effort to manage access.
All Identity and Access enabled services : All catalog services that use IAM for access management.
All Account Management services: Platform services, such as billing and usage, license and entitlements, enterprises, and more. For more
information, see Assigning access to account management services .
All IAM Account Management services: A subset of account management services that includes the IAM platform services IAM Identity, IAM
Access Management, IAM Users, IAM Groups, and future IAM services.

Assigning IBM Cloud access policies
To help you further understand how access is assigned by using access policies in IBM Cloud in relation to other cloud providers that you might be familiar
with, check out the following details and example of an access policy.
IBM Cloud IAM policies consist of the identity who (subject) is being given access, such as the user or service ID, the specific resources or services (target)
to which they are being given access, and roles that define what actions are allowed within the context of the selected resource or service.
In IBM Cloud, a user, service ID, or the members of an access group don't have any access by default. The IBM Cloud access model is simple when it
comes to understanding how you get permitted or denied completing specific actions. It isn't until an administrator assigns an access policy with a
particular access role that access is granted. The IAM system doesn't have to evaluate permit and deny policies to determine what actions are allowed,
instead the system just evaluates what resources you have policies for and what level of access is allowed by your assigned roles.
Tip: To reduce the number of policies in the account and keep only the minimum access that is required for each user, you can identify and remove
the infrequently used access policies. For more information, see Managing inactive policies.
When you specify a resource in a policy because IBM Cloud is attribute-based, you can specify a broad set of resources for a user to have access to, for
example all resources in a resource group. Or, you can narrow the user's access to a specific instance of a single service or even a subresource type, such
as a Object Storage bucket. IBM Cloud IAM provides a high level of flexibility and granularity to help you assign only the type of access that is required. A
few examples of the different levels of access that you can assign by using attributes in an access policy are the following:
All Account Management services
A specific account management service
All Identity and Access Enabled services within the account, which includes all catalog services that use IAM for access management
All resources that belong to a resource group
All resource types of a single service across the entire account, regardless of resource group assignment
A specific instance of a service in the account
A single subresource type within an instance, for example, a bucket in an Object Storage instance
Tip: If a specific predefined platform or service role doesn't fit what you're looking for when assigning the level of access, you can create a

custom

role for a specific service and then choose from the available actions to create a role that fits your organization's needs.

Policy example
Running secure workloads 14

This policy example gives access to all service resources that belong to a resource group named default with an ID of
abcd2e6fg1h74i44j5kl467m701n5289 with the Viewer platform role assigned. This policy can be assigned to a user, service ID, or access group. In this

case, it is assigned to a user with an iam_id of IBMid-3IAMISBEST1 .
Note: Access groups are not identities like a user or service ID; however, they are a grouping mechanism for identities. An access group can be
defined as a subject of an access policy, and the assigned access on the group applies to all members added to it.

{
"type": "access",
"subjects": [
{
"attributes": [
{
"name": "iam_id",
"value": "IBMid-3IAMISBEST1"
}
]
}
],
"roles": [
{
"role_id": "crn:v1:bluemix:public:iam::::role:Viewer"
}
],
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "7e522a19eb77477e88e96a600c44fb22"
},
{
"name": "resourceGroupId",
"value": "abcd2e6fg1h74i44j5kl467m701n5289"
}
]
}
]
}

In addition to an access policy for a user, service ID, or access group that can provide access to a service, specific resource, or resource group in the
account, IBM Cloud also provides the capability to assign an access policy that is called a service to service authorization, which provides access between
services. For an example of this policy type, see Creating an authorization by using the API .

IBM Cloud IAM roles
All services that are organized in a resource group in your account are managed by using IBM Cloud Identity and Access Management (IAM). Account
owners are automatically assigned the account administrator role. As the account administrator, you can assign and manage access for users, create
resource groups, create access groups, create trusted profiles, view billing details and track usage, and create service instances. You provide access for
users, service IDs, access groups, and trusted profiles by creating policies that set a target for the subject of the policy to access and a role that defines
what type of access that is allowed.

IAM roles
You can manage and define access based on specific roles for users and resources in your account.
Platform management roles cover a range of actions, including the ability to create and delete instances, manage credentials, and manage access.
The platform roles are administrator, editor, operator, viewer. Platform management roles also apply to account management services that enable
users to invite users, manage service IDs, access policies, catalog entries, and track billing and usage depending on their assigned role on an account
management service.
Service access roles define a user or service’s ability to perform actions on a service instance, such as accessing the console or performing API calls.
The most common service access roles are manager, writer, and reader. Each service maps particular actions for working with the service to each of
these roles.
Note: You might not see all of the roles that are listed here as options when you assign policies in the UI because only the roles available for
Running secure workloads 15

the service that you chose are displayed. For more information on what roles are enabled and what actions each access role allows for each
service, see the documentation for that service.
Custom roles for a service can be created on the IAM Roles page by the account owner or a user assigned the administrator role on the role
management service.
Note: You can review the available roles and associated actions for a particular service by going to the

Roles page, and selecting the service

that you want to learn more about. This is the same page where you can create a custom role in the console.

Platform management roles
With platform management roles, users can be assigned varying levels of permission for performing platform actions within the account and on a service.
For example, platform management roles that are assigned for catalog resources enable users to complete actions such as creating, deleting, editing, and
viewing service instances. And, the platform management roles that are assigned for account management services enable users to complete actions such
as inviting and removing users, working with resource groups, and viewing billing information. For more information about the account management
services, see Assigning access to account management services .
Tip: Select all roles that apply when you create a policy. Each role allows separate actions to be completed and doesn't inherit the actions of the
lesser roles.
The following table provides examples for some of the platform management actions that users can take within the context of catalog resources and
resource groups. See the documentation for each catalog product to understand how the roles apply to users within the context of the service that is being
used.
Platform

One or all IAM-enabled services

Selected service in a resource group

Resource group access

Viewer role

View instances and credentials

View only specified instances in the resource group

View resource group

Operator role

View instances and manage
credentials

Not applicable

Not applicable

Editor role

Create, delete, edit, and view
instances. Manage credentials

Create, delete, edit, suspend, resume, view, and bind
only specified instances in the resource group

View and edit name of
resource group

Administrator
role

All management actions for
services

All management actions for the specified instances in the
resource group

View, edit, and manage
access for the resource group

management
role

Example platform management roles and actions for services in an account

For information about the specific actions users can take based on their assigned role on account management services, see

Assigning access to account

management services.
Some services might map specific actions to the platform management roles that are related to the management of the service rather than to the access of
the service. As an example, see the following table that details the Kubernetes Service service actions that are mapped to these roles.
Platform

Actions

management

Example actions for Kubernetes
Service

role
Viewer

Can view service instances, but can't modify them

List clusters
View details for a cluster

Editor

Perform all platform actions except for managing the account and assigning access
policies

Bind a service to a cluster
Create a webhook

Running secure workloads 16

Operator

Perform platform actions required to configure and operate service instances, such
as viewing a service's dashboard

Add or remove worker nodes
Restart or reload worker nodes
Bind a service to a cluster

Administrator

Perform all platform actions based on the resource this role is being assigned,
including assigning access policies to other users

Remove a cluster
Create a cluster
Update user access policies
All actions a viewer, editor, and
operator can perform

Example platform management roles and actions for Kubernetes Service service

Service access roles
Service access roles enable users to be assigned different levels of permission for calling the service's API and accessing the UI for the service. The
following table provides example actions that can be taken depending on the assigned roles based on using the Object Storage service.
Note: The actions that can be taken based on each assigned role vary based on the service that you selected for the policy. Not all services use
these types of roles. See the documentation for the service for more details.

Service

Actions

Example actions for Object Storage service

Reader

Perform read-only actions within a service, such as viewing service-specific
resources

List and download objects

Writer

Permissions beyond the reader role, including creating and editing service-specific
resources

Create and destroy buckets and objects

Manager

Permissions beyond the writer role to complete privileged actions as defined by the
service, plus create and edit service-specific resources

Manage all aspects of data storage, create,
and destroy buckets and objects

access
role

Example service access user roles and actions

Custom access roles
An account owner or a user assigned the Administrator role on the Role management service can create custom roles for a service on the IAM Roles page.
Any number of actions that are available for a service for any platform or service role can be combined and added to a custom named role.
After the role is created, any user who can assign access for that service sees the new custom role as an option. For more information, see

Creating

custom roles.

Mapping IBM Cloud IAM concepts to other cloud providers
Identity and access management is used to securely authenticate users and provide access to cloud resources. While IAM across cloud providers is a
consistent way of securing authentication and access, the concepts within each cloud provider and how they apply might differ. Review the following
information in the table to learn more about how concepts in IBM Cloud IAM relate or compare to those of other cloud providers to help you onboard
smoothly with IBM Cloud.

Comparing IAM concepts
The following mappings of IBM Cloud IAM concepts to those of other cloud providers, such as Amazon Web Services (AWS), Google Cloud Platform, and
Microsoft Azure, might not be an exact one-to-one match. However, if you are familiar with a particular concept within another provider, this mapping is
intended to help you find the closest related concept in IBM Cloud.

Running secure workloads 17

IBM Cloud

IBM Cloud description

AWS

Azure

Google Cloud Platform

Identities

Users and service IDs

Users, groups, and
roles

User, group, service
principal, managed
identity

User accounts and service accounts.
Supported identity types: Google
Account, Service account, Google
group, G Suite domain, Cloud
Identity domain

Users

Managed outside IAM. Users are
uniquely identified in IBM Cloud
with the iam_id value, but can
come from IBMid, App ID, or
SoftLayer

Managed in IAM.
Identity federated to
external identity
management system.

Managed in Active
Directory

Managed outside IAM. Identity
federated to external identity
management system.

Service
IDs

An ID for an app or service.

Roles that are
assigned to an app

User-assigned identity

Service accounts

API key

A credential that is used for a user
or service ID

Access Key

api-key

API key

Access
groups

A way to organize users and service
IDs where all members of the
group are assigned the same
access.

Groups, roles

Active Directory groups

Google Groups

Trusted
profiles

A way to assign access to
federated users based on SAML
attributes or for all applications
running in a compute resource
without the need of managing and
rotating credentials.

Roles

Managed identity

Workload identity

Policy

Access assignment made up of a
subject, target, and role.

Policy

Role assignment

Policy

Policy
subject

A user, service ID, or access group

An IAM user, group, or
a role

Security principal

A resource

Roles

A role is a collection of actions for a
specific resource that are used as a
building block to make an access
policy.

AWS-managed policy

Role definition

Predefined roles

Custom
roles

Customer-defined and named role,
including only the actions chosen
by the user.

Customer-managed
policies

Custom roles

Custom roles

Actions

What is allowed to be completed
within the context of the platform
or service

Actions

Permissions

Permissions

Resources

Target of an access policy

Resources

Resources

Resources

Resource
groups

Logical organization container for
IAM-enabled services

Tags

Resource groups

Projects

concept

Running secure workloads 18

Public
access

Public access to specific resources
is enabled through a default access
group called Public Access. This
feature can be disabled on each
account.

Feature of Amazon S3
that can be enabled
for specific resources,
and can be disabled at
the account or bucket
level.

Public read access can be
enabled for specific
account types or
resources. It can be
disabled at the storage
account or container level.

Google has an identifier for
allAuthenticatedUsers that
represents all service accounts and
all users who are authenticated with
a Google Account, which can also be
granted access.

Auditing

Audit with Activity Tracker

Audit with AWS
CloudTrail

Azure Logging and
Auditing Activity logs

Audit with Audit logging

Enterprisemanaged
IAM

Centrally administer access and
security settings for an IBM Cloud
multi-account environment.

AWS Control Tower

IBM Cloud IAM concept comparison

Federating users to IBM Cloud
IBM Cloud offers two ways for you to federate your corporate identity provider (IdP), which simplifies login by giving your employees access to IBM Cloud
with their company username and password. You can federate with IBMid, or you have the option to create an IBM Cloud App ID service instance and use
that as a way to federate users into an IBM Cloud account. For more information, see Enabling authentication from an external identity provider .
Both federation options require that the user is a member of the account, or has access to the account by a trusted profile to be able to complete
operations. If trusted profiles are not configured, the account owner or administrator must invite individual IBMids into the IBM Cloud account. Only if the
invited IBMid accepts the invitation is the user added the account as an active user. In the case of App ID, the user is automatically onboarded to IBM
Cloud without a need to invite each user to the account. In both types of federation, the users are active IBM Cloud account users that can access the
platform, including IAM-enabled resources and classic infrastructure all depending on their assigned access.
Trusted profiles deal with federated users differently. If the customer federates their corporate IdP, users from that IdP aren't added to an account as what
we might consider a typical user. Instead, users' SAML-based IdP attributes are evaluated at login and if they meet all of the conditions for a trusted profile,
they are prompted to apply one or more trusted profiles. Trusted profiles grant users the level of access that they need to complete specialized and specific
tasks in a limited time-period, for example, 1 - 4 hours. Time-based access allows frequent authentication checks for reduced security risks. These are
usually critical tasks that you would want to avoid doing unintentionally in daily work. Users don't need to onboard to IBM Cloud, they're automatically
added through the trust relationship. If a user leaves your company, you can delete the user's corporate identity in your directory, which revokes access to
IBM Cloud.

What are context-based restrictions?
Context-based restrictions give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud® resources based on
a rule's criteria. The criteria include the network location of access requests, the endpoint type from where the request is sent, the multifactor
authentication level of an identity, and sometimes the API that the request tries to access. These restrictions work with traditional IAM policies, which are
based on identity, to provide another layer of protection. Since both IAM policies and context-based restrictions enforce access, context-based restrictions
offer protection even in the face of compromised or mismanaged credentials.

A diagram that shows how context-based restrictions work.

For an example scenario on creating context-based restrictions, follow the tutorial for Leveraging context-based restrictions to secure your resources .
For more information about implementing context-based restrictions in your security strategy, see the solution tutorial Enhance cloud security by applying
Running secure workloads 19

context-based restrictions.

Rules
A rule associates an IBM Cloud resource with a set of contexts:
The cloud resource is specified by resource attributes similar to IAM access policies.
A context is a combination of network zones and endpoint types.
The contexts that you configure define the boundary for the associated resources.
The necessary resource attributes in context-based restrictions rules are accountId and serviceName . Rules must be scoped to an account and a
specific service.
Context-based restriction rules are applied by the following logic:
Access is granted by a rule only when at least one of the rule's contexts allows access.
If multiple rules are applicable to a particular resource, access is granted only when all applicable rules allow access.
If no rules are applicable to a particular resource, access is determined exclusively by IAM policies.
Unlike IAM policies, context-based restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed
context that you configure.
Note: The interface that you use to access a resource, such as the console, CLI, or API, doesn't affect how a rule applies to that resource. The rule
applies the same way across all interfaces and is based on the client IP address.

Rule enforcement
You can decide how you want to enforce a rule upon creation and update the rule enforcement at any time.

Enabled
Enforce the rule. Depending on the service that you select, monitoring denied access attempts through Activity Tracker might be available. Review
each service's documentation to learn about how they integrate with context-based restrictions.
Disabled
No restrictions apply to your account resources. Select this option if you're not ready to enable the rule.
Report-only
Depending on the service that you select, you can monitor how a rule affects access without enforcing it. With report-only mode, all attempts to
access resources in the account are logged in Activity Tracker. If available, monitoring is recommended for 30 days before you enforce a rule.

Report-only mode is not available for all services, so review each service's documentation to learn about how they integrate with context-based
restrictions.
Tip: You can monitor the impact of your enabled and report-only rules. For more information, see

Monitoring context-based restrictions.

Defining the scope of a rule
Define the APIs that you want to protect to narrow the scope of a rule's restrictions. This way, you can specify granular protections for different APIs that
have distinct access requirements.
For example, you might create a rule that targets a data plane API so that it is only accessible from a Kubernetes cluster, or wherever your compute
infrastructure exists. Then, you can create a rule that targets your control plane API and all platform APIs to protect interactions with the cloud console so
that it is only accessible from behind your organization's VPN.
Note: Only some services support the ability to scope a rule by API.
With some services, you can restrict the actions of all service APIs on your resources by default, which includes all current and future APIs that the service
might support. Or, select specific APIs. For example, Kubernetes has custom service APIs that you can restrict access to based on the context of the
request. Review each service's documentation to learn more about how they integrate with context-based restrictions.

Running secure workloads 20

Select services support the ability to scope a rule to protect all platform APIs, which include all current and future platform APIs that a service might
support. The addition of platform APIs to the scope of a rule ensures that platform operations like resource provisioning, service credential management,
and attaching tags are only accessible from locations that you define.
Tip: Context-based restrictions default to protect all of the service and platform APIs the target service supports.

Contexts
Contexts define where your resource can be accessed. A context is made up of the allowed endpoint types and network zones that you configure.
If a context includes network zones, then access is granted only when the request is created from within one of those zones.
If a context includes service endpoint types, then access is granted only when the request is received over a connection that matches one of those
types.
If a context includes multifactor authentication (MFA), then access is granted only when the requesting identity has an MFA level equal to or
exceeding the required MFA level.
If a context includes multiple restrictions, for example, both zones and endpoint types, then all restrictions must be satisfied for access to be
granted.

Network zone
A network zone represents an allowlist of IP addresses where an access request is created. It defines a set of one or more network locations that are
specified by the following attributes:
IP addresses, which include individual addresses, ranges, or subnets.
VPCs
Service references, which allow access from other IBM Cloud® services.

IP addresses
Customers can specify the IP addresses they know that they want to be able to send traffic from. Anything outside of the specified IP addresses is denied.

VPCs
If you have apps that are deployed in a VPC that need access to a context-based restricted resource, you can include the VPC IP addresses in your network
zone. To do so, select the target VPC in your network zone and add that network zone to your rule. This way, you don’t must find the IP addresses that the
VPC uses. Resources that are contacted see that the request is coming from a set of allowed IP addresses.

Service references
A service reference represents the network locations of a service or service instance. Including a service reference in a network zone adds the IP
addresses associated with the service to your allowlist without requiring you to know the service's underlying IP addresses. Service references are helpful
since the network locations of cloud services are unknown to the context-based restriction administrator and can change over time.
The following is a list of services that you can add to a network zone as a service reference:
Service

Service type

service_name

All Account Management services

Account Management

iam-access-management

IAM Access Groups Service

Account Management

iam-groups

IAM User Management

Account Management

user-management

Activity Tracker

IAM-enabled

logdnaat

App Configuration

IAM-enabled

apprapp

Catalog Management Service

IAM-enabled

globalcatalog-collection

Cloud Block Storage for VPC

IAM-enabled

Running secure workloads 21

Cloud Object Storage

IAM-enabled

cloud-object-storage

Code Engine

IAM-enabled

codeengine

Databases for DataStax

IAM-enabled

databases-for-cassandra

Databases for EnterpriseDB

IAM-enabled

databases-for-enterprisedb

Databases for Elasticsearch

IAM-enabled

databases-for-elasticsearch

Databases for etcd

IAM-enabled

databases-for-etcd

Databases for MongoDB

IAM-enabled

databases-for-mongodb

Databases for MySQL

IAM-enabled

databases-for-mysql

Databases for PostgreSQL

IAM-enabled

databases-for-postgresql

Databases for Redis

IAM-enabled

databases-for-redis

Direct Link

IAM-enabled

directlink

Event Notifications

IAM-enabled

event-notifications

Event Streams

IAM-enabled

messagehub

Kubernetes Service / Red Hat OpenShift

IAM-enabled

containers-kubernetes

Messages for RabbitMQ

IAM-enabled

messages-for-rabbitmq

Secrets Manager

IAM-enabled

secrets-manager

VPC Infrastructure Services

IAM-enabled

Schematics

IAM-enabled

schematics

Toolchain

IAM-enabled

toolchain

Services that are compatible with service references.

Note: In table 1, All Account Management services refers to the grouping of Account Management type services that are listed in the table. For
example, if there are two Account Management services that are listed in table 1, All Account Management services includes those two services.
As more Account Management services become available as service references, network zones that specify All Account Management services as
a service reference automatically include the newly added account management services.

Important: Refer to each service offering's documentation for more information about which services to add as a service reference for the service
offering that you target in a rule.

Endpoint types
An endpoint type represents the connection over which an access request is received. It corresponds to the endpoint that receives the connection. You can
allow access from all endpoint types that are supported by the service or specific service endpoint types.
The three common endpoint types are as follows:
Public endpoints can accept requests from anywhere.
Private endpoints are available for most requests that originate from within IBM Cloud®.
Direct endpoints are used in Bring-Your-Own-IP scenarios, generally for requests that originate from resources within VPCs.
Running secure workloads 22

Note: Some endpoint types might not be supported by the selected service.

Note: To access virtual private endpoints, the CLI users must log in using the command

ibmcloud login -a private.cloud.ibm.com --vpc ​.

For more information, see Creating a private endpoint gateway (required for VPC use) .

Multifactor authentication
Multifactor authentication (MFA) requires identities to authenticate by using another authentication factor beyond an ID and password. By setting a lower
MFA level requirement, you’re allowing users who meet or exceed that requirement to authenticate. For example, if your rule requires users to
authenticate with MFA LEVEL1, users that have MFA LEVEL2 are still compliant since LEVEL2 exceeds the security criteria for LEVEL1. The following MFA
levels name the minimum MFA factor for each level. For more information, see IBM Cloud multifactor authentication .
LEVEL1: Email-based MFA
LEVEL2: TOTP MFA
LEVEL3: U2F MFA
In addition to LEVEL1, LEVEL2, and LEVEL3 MFA, the context-based restrictions rule also supports the value

IAM_ACCOUNT_SETTING , which means that the

rule's MFA value matches whatever you define as the MFA requirement for your account. This way, any changes to your account's MFA settings
automatically applies to the rule. For more information, see MFA options.
Note: If an option is selected from the MFA for users with an IBMid section in the IAM authentication settings, the MFA value from IAM is mapped
to LEVEL2 MFA in context-based restrictions. MFA is applied to both federated and nonfederated users, even if Non-federated user is selected.

Note: Only some services support the ability to specify MFA in a rule.

Access requirements
To complete rule actions, you must be assigned an IAM policy on the target service. To complete network zone actions, you must be assigned an IAM policy
on the context-based restrictions service.
To create a context-based restriction for a service, you must be assigned an IAM policy with the Administrator role the service you are creating a rule
against. For example, if you want to create a rule to protect a Key Protect instance, you must be assigned the Administrator role on the Key Protect service
and the Viewer role or higher on the context-based restrictions service.
Tip: The Viewer role on the context-based restrictions service authorizes you to add network zones to your rule.

Context-based restrictions roles and actions
To manage network zones, you must be assigned an IAM policy with a specific role for the Context-based restrictions account management service. The
following table shows the possible access roles and actions for account management.
Roles

Actions

Viewer

View network zones

Editor

View network zones
Create network zones
Update network zones
Remove network zones

Administrator

View network zones
Create network zones
Update network zones
Remove network zones
Roles and actions for the context-based restrictions service
Running secure workloads 23

Roles and actions for the context-based restrictions service

For more information, see Actions and roles for account management services .
Note: You can also use network zones to restrict access at the account level. To set account-level restrictions by using network zones, go to
Manage > IAM > Settings in the IBM Cloud console and enter the name of your network zone.

Target service roles and actions
To manage rules, you must be assigned an IAM policy with the Administrator role for the service that you are creating the rule against. The following table
shows the possible access roles and actions for services.
Roles

Actions

Viewer

View rules

Editor

View rules

Administrator

View rules
Create rules
Update rules
Remove rules
Roles and example actions for target service

Services integrated with context-based restrictions
Specific IBM Cloud services are integrated with context-based restrictions, and only these services can apply rules to their resources. The way that rules
apply to individual services is determined by the service, so be sure to review the documentation for each service to understand how context-based
restrictions apply.
You can create context-based restrictions for the following services if you are granted the correct access on the service:
Service

Service type

Scope to APIs

service_name

Catalog Management Service

IAM-enabled

Yes

globalcatalog-collection

Context-based restrictions Service

Account Management

No

context-based-restrictions

IAM Access Groups Service

Account Management

No

iam-groups

IAM Access Management Service

Account Management

No

iam-access-management

IAM Identity Service

Account Management

No

iam-identity

IAM User Management

Account Management

No

user-management

Activity Tracker

IAM-enabled

Yes

logdnaat

App Configuration

IAM-enabled

No

apprapp

Cloud Object Storage

IAM-enabled

No

cloud-object-storage

Code Engine

IAM-enabled

No

codeengine

Container Registry

IAM-enabled

No

container-registry

Databases for DataStax

IAM-enabled

Yes

databases-for-cassandra

Running secure workloads 24

Databases for EnterpriseDB

IAM-enabled

Yes

databases-for-enterprisedb

Databases for Elasticsearch

IAM-enabled

Yes

databases-for-elasticsearch

Databases for etcd

IAM-enabled

Yes

databases-for-etcd

Databases for MongoDB

IAM-enabled

Yes

databases-for-mongodb

Databases for MySQL

IAM-enabled

Yes

databases-for-mysql

Databases for PostgreSQL

IAM-enabled

Yes

databases-for-postgresql

Databases for Redis

IAM-enabled

Yes

databases-for-redis

Direct Link

IAM-enabled

No

directlink

DNS Services

IAM-enabled

No

dns-svcs

Event Notifications

IAM-enabled

No

event-notifications

Event Streams

IAM-enabled

No

messagehub

Key Protect

IAM-enabled

No

kms

Kubernetes Service / Red Hat OpenShift

IAM-enabled

Yes

containers-kubernetes

Messages for RabbitMQ

IAM-enabled

Yes

messages-for-rabbitmq

Secrets Manager

IAM-enabled

No

secrets-manager

Security and Compliance Center

IAM-enabled

No

compliance

Transit Gateway

IAM-enabled

No

transit

IBM Cloud® Virtual Private Cloud

IAM-enabled

No

is

Schematics

IAM-enabled

No

schematics

Services that are compatible with context-based restrictions.

Important: Context-based restrictions that are defined for IAM-enabled services do not apply to platform actions like create or delete. For more
information, see IAM roles and actions .

Note: Check back regularly to see what services are added as more services integrate with context-based restrictions.

Context-based restrictions limits
The following table lists the maximum limits for context-based restrictions. These limits apply to any user who can create context-based restrictions rules
or network zones. For more information, see What are context-based restrictions? .
Note: If you have a specific use case that requires an extended limit, you can request an increase. For more information, see

Increasing account

limits.

Resource

Max

Running secure workloads 25

Context-based restriction rules per account [1]

4020

Network zones per account

500

IP addresses per network zone

1000

IP addresses per rule

1000
Context-based restrictions limits

Note: A context-based restriction rule that includes multiple network zones can have a maximum of 1000 IP addresses indirectly associated with
it. For example, in a rule that includes two network zones, one of the zones might have 800 IP addresses and the other might have a maximum of
200 IP addresses.
If you want to check the number of rules in your account, see Viewing the total number of rules per account . To request an increase in the account limit,
see Requesting a policy and rule shared limit increase .

Eventual consistency
Context-based restrictions follow an eventually consistent pattern that is common to many cloud-native services. As a result, context-based restrictions
remain highly available and performant across multiple global regions. Changes that are made to context-based restrictions rules and network zones are
recorded and propagated worldwide. Access changes might not take effect until the propagation process is complete, usually within a few minutes.
1. IAM policies and context-based restrictions rules share a combined limit of 4020. ↩︎

Running secure workloads 26

Learn about deploying compliant workloads
Achieving continuous compliance as an enterprise
With continuous security and compliance at the core of IBM Cloud®'s platform, you can find compliant-by-default infrastructure for hosting your regulated
workloads in the cloud. From deployable architectures for secure infrastructure and DevSecOps pipelines to continuous validation through Security and
Compliance Center, you can be sure that your organization is secure and compliant through every stage of development.

View video: Security and compliance for regulated workloads on IBM Cloud

Video transcript
Hi, I’m Chris Mitchell, an STSM and Architect for IBM Cloud.
Today’s enterprises are challenged to manage risk and compliance, contain costs, and unlock innovation.
Here at IBM Cloud, we understand the complexity and challenges in optimizing for security and compliance, reducing lead time for deploying new systems,
and successfully running secure and compliant infrastructure.
IBM Cloud is the first secure and compliant-by-default cloud for regulated industries. It is specifically designed to reduce risk and has been architected to
be the hub for enterprise IT security and compliance.
With the integration of security and compliance through our catalog of deployable architectures and other tools, you can streamline the process of defining
compliance profiles, implementing secure infrastructure, and assessing the compliance of your enterprise workloads.
To define your goals for assessing your workloads, you can use one of IBM Cloud’s predefined compliance profiles, like IBM Cloud Framework for Financial
Services, or you can create your own custom profile in the IBM Cloud Security and Compliance Center.
Then, depending on your defined compliance standards and infrastructure needs, you can take advantage of automated well-documented architecture
patterns available in the catalog that are based on the IBM Cloud Framework for Financial Services.
The IBM Cloud Framework for Financial Services reference architectures are based on a set of best practices for cloud infrastructure and software as a
service.
When you provision infrastructure using these deployable architectures, you meet the defined controls and stay within the constraints of the IBM Cloud
Framework for Financial Services profile. This can help take the guesswork out of creating secure and compliant patterns for infrastructure in your
enterprise.
Each deployable architecture can be deployed and configured by using an IBM Cloud project. Projects support a simplified process for deploying
repeatable infrastructure patterns with integrated compliance checks.
With projects, you can review changes to infrastructure costs and review compliance checks based on your configuration of the architecture prior to
deployment, which helps build in transparency and trust along your journey.
Finally, when you’re ready to assess the compliance of your deployed cloud resources against your defined standards, you can use the Security and
Compliance Center to evaluate resources in your accounts.
Whether it’s a one-time evaluation or recurring scans, you can prepare for audits by having a clear view of the security and compliance posture of your
enterprise.
And, to ensure continuous compliance of your cloud resources, you can set up notifications to get alerted when an issue is found so your team can stay on
top of remediating any issues.
With the architectures and security tools available through IBM Cloud, you can define your compliance goals from the start, deploy secure solutions with
automation, and stay compliant, all while managing your resources at scale.
To learn more about achieving continuous compliance as an enterprise, visit the documentation. https://cloud.ibm.com/docs/secure-enterprise

Reviewing available controls
As a regulated business, there are specific standards that apply to your industry that you need to prove compliance to. In Security and Compliance Center,
Running secure workloads 27

you can view the profiles that are offered by IBM® that can meet your requirements. For example, if you are a financial institution, you might want to use
the IBM Cloud for Financial Services library. If you don't see the control set that you are looking for, you can always create a custom one. After you have
reviewed the libraries, you can pull specific compliance controls into a profile that can be evaluated.
During your investigation phase, you might also want to review the available infrastructure deployable architectures in the catalog. IBM Cloud has created
automation for the deployment of common architectural patterns that combine one or more cloud resources and designed for easy scalability and
modularity. You can review the components of the architecture and the level of compliance each deployable architecture meets by reviewing the details
directly in the catalog detail pages, and you can customize these architectures to meet your exact needs.

IBM Cloud catalog showing deployable architecture tiles

Deploying your infrastructure and applications
Now that you've evaluated what is available to you on IBM Cloud and you know what needs to be customized or what can be used as is, it's time to start
working! The engineers on your teams can start by getting your infrastructure and application workloads ready to deploy.
Your team can use projects to help organize your enterprise deployments and ensure that commit checks, vulnerability scans, and cost estimations are
completed as deployable architectures are configured. Within the context of a project, you can easily deploy infrastructure resources from approved,
compliant IBM Cloud or private catalog offerings by using a deployable architecture. By using a predefined deployable architecture, you can be sure that
you are meeting the compliance standards that the architecture is associated with. Or, you can onboard your own and specify the controls within Security
and Compliance Center that your architecture is compliant with.
Before you deploy an architecture, a validation check is run on your configuration for both compliance and risk so that you can address any issues that are
found. You can view the logs through the IBM Cloud® Schematics service to determine which resources are affected and consider whether to fix or override
the flagged issue and move forward.
After your infrastructure is deployed and your DevSecOps toolchains are configured, you're ready to deploy your app by using the DevSecOps continuous
integration and continuous deployment pipelines. These pipelines can help your enterprise to shift left and reduce the possibility of human error or
introduction of new vulnerabilities before code ever reaches production to help mitigate any major security or financial risks.

Continuous integration, deployment, and compliance

Running secure workloads 28

Staying compliant
After you deploy resources that you know are compliant, you can ensure that you remain compliant in two ways. First, by validating your resource
configurations with Security and Compliance Center. Security and Compliance Center regularly scans your configurations of the resources in your account
to ensure that there hasn't been a drift in compliance.

Example Security and Compliance Center dashboard

Second, you can ensure that you're deploying your code by using DevSecOps pipelines. When you use the continuous compliance toolchain, scans are
reexecuted against your current production code artifacts. This continuous scanning helps to ensure that any code that is deployed in to production is
checked for the latest known vulnerabilities allowing for regular revalidation of deployed code and remediation of any new issues that are discovered since
the last scan.
Staying compliant and audit-ready is of the utmost importance. Security and Compliance Center allows you to define the controls you need to meet by
using pre-defined or custom profiles, attach the profiles to a group of resources, or scope, and perform regularly scheduled evaluations. As evaluations are
completed, the results are displayed in a dashboard so you can get an overarching view of your current compliance posture against the controls that are
important for your use case and download compliance reports. Your security and compliance managers can also choose to set up notifications to get
alerted when an issue is found so that it can be remediated quickly. In addition, Security and Compliance Center can collect evidence from your DevSecOps
pipeline runs on your application code so that it can show a complete view of your compliance on IBM Cloud.

Using projects for IaC deployments
IBM Cloud® projects are a named collection of configurations that are used to manage related resources and deployments across accounts, embracing an
Infrastructure as Code (IaC) approach to deployments. They enable teams to configure, deploy, and monitor deployments by using DevOps best practices.
Each project includes tools to scan for potentially harmful resource changes, compliance, security, and cost, as well as tracking configuration versioning
and governance. They're designed with an IaC and a compliance-first approach that helps to ensure that a project is managed, secure, and always
compliant.

Running secure workloads 29

Understanding the projects workflow.

After choosing a deployable architecture from the catalog, you can add its configuration to a new or existing project, and configure it to your enterprise's
needs. Before you use the configuration to deploy resources to a specific environment, validation is performed on your code by completing commit checks,
vulnerability scans, and cost estimations, so that your team has all of the essential information that it needs before deploying. And, if the validation fails, the
team can work to update the configuration and run the validation again until it passes. With an approval, resources can be deployed and monitored by using
IBM Cloud® Schematics. Then, if an update to the deployable architecture becomes available, your team is notified within your project and can update the
version on your schedule.

Benefits of projects
Projects help manage deployments at scale. They help ensure that your configured architectures are always valid, secure, and compliant. Because a single
project can deploy to different accounts, projects allow users to group related resources across accounts for better collaboration, organization, and user
management. Users can get started more efficiently on IBM Cloud by using projects to create resources by using deployable architectures that help build
complex cloud infrastructures that are designed to meet high-availability, scalability, resiliency, and business continuity and disaster recovery (BC/DR)
requirements. A project is a useful tool for many reasons:
You can associate a set of deployable architectures, their configurations, and the resulting resources in a single interface. This helps you to manage
your resources in a more secure and repeatable way, while simultaneously managing cost, status, and team activity.
Projects offer a secure solution supply chain by ensuring that only approved deployable architectures are used to deploy resources and by leveraging
trusted profiles to provide secure authorization that doesn't require key rotation and can't be misplaced.
Projects provide governance over your infrastructure by ensuring that configuration changes are tracked, approved, and subject to automated
validation and compliance checks.
Projects help ensure that security and compliance issues are addressed by notifying project users of new versions and helping them get deployed in
a timely manner.
Projects allow infrastructure to be managed as code across accounts, allowing all infrastructure that is related to a project to be managed from a
single place. This makes it easy to monitor that development and test infrastructure is aligned with production infrastructure by avoiding surprises as
applications move through to production.
Projects help with accounting and configuration management by ensuring that all resources that are associated with the project can be tracked back
to the project by tagging and resource reports. Projects can also be tagged to provide a higher level of organization.

Exploring popular use cases
Projects help organize and secure the configurations that you create from a deployable architecture as well as the resulting resources. If you are a large
organization or enterprise, there are several advantages to using IBM Cloud projects. Explore these popular use cases to learn how you can adapt projects
to your business needs.

Shift-left compliance and governance
As you deploy and operate shared infrastructure, projects help to organize and bundle the related configurations and deployments in a single
location - even across different environments. Projects run predeployment security and compliance checks to ensure that your deployable
architecture still meets its claimed compliance at the point of deployment. A separate project administrator or editor must review and approve
changes, providing an additional layer of governance.
Automated deployment across accounts
Projects can deploy to any account, which makes it much easier to isolate your environments in separate accounts. This enables you to organize and
manage configurations across environments from a single view. Because projects deploy changes through automation, they reduce the chance of
human error or deviations between environments. You can even lock down access to your most sensitive accounts and require changes to be made
by using projects.
Tracking ongoing maintenance and updates
Projects help you to manage architecture updates and maintain compliance. In addition to conducting continuous compliance scans, projects notify
you of architecture version updates, validation failures, and required cluster updates. Because projects are integrated with IBM Cloud’s Event
Notifications service, you can route project notifications to Slack, PagerDuty, and other third-party tools.
Building and sharing custom architectures by using private catalogs
Deployable architectures are built to be modular and flexible. You can create custom deployable architectures and share them with your team by
using private catalogs by adding the architecture to a new project. You can download a code bundle from the deployable architecture's catalog page,
customize it if needed, and then upload it to any repo that you specify. After the custom architecture is deployed, CI and CD pipelines check any
changes for compliance and allows you to share the architecture directly into a private catalog. Private catalogs make it easy to consume and push
version updates to your team.
Managing the lifecycle of your infrastructure
Running secure workloads 30

Projects help you manage, track, and maintain your infrastructure from start to finish. As the lifecycle of your infrastructure changes, you can use
projects to easily clean up the project resources that are no longer needed. If a project is complete and is no longer needed, the whole project and all
associated resources in all envionments can be deleted. In addition, a project can be paused by deleting the associated resources while retaining the
project and its configurations. This makes it easy to resume the project later.
Reporting and cost management
Projects assist with cost management and other types of reporting by automatically tagging all created resources and by providing a resource
inventory within the project. For example, when a usage report is generated the project tags will be included, allowing the accounting team to
allocate costs to projects without any additional effort. Other types of configuration management tasks such as determining an inventory of particular
types of applications or resources can also be accomplished by project tagging and resource views.

Essential concepts
Review the following concepts and processes to help you learn about working with projects in your account.

Configurations
A single project typically manages configurations for one or more templates called deployable architectures in IBM Cloud. The set of input values and the
architecture that you are configuring together become a configuration. In addition to providing review and approval work flows, projects monitor each
configuration for cost, compliance, and version updates from the catalog.
Typically, a project holds several configurations of each architecture. An architecture might have separate configurations for the development, test, and
production environments, or for three separate regions, all of which are in the production environment.

Deployable architectures
Projects provide governance and management for deployable architectures, which are templates designed to embrace an infrastructure as code approach
to managing deployments. Custom deployable architectures can be developed by using the tooling of your choice and can be added to a private catalog in
the IBM Cloud console. You must select Deployable Architecture as the type of product that you are onboarding for it to be used with projects.

Project tooling
Projects have internal versioned configuration storage and validation pipelines to support project governance. Projects also leverage Schematics
workspaces to store the Terraform state for each configuration and to run the automation. These workspaces are in the region and resource group that you
specify when you create the project. The Schematics workspace is also tagged with the project name, making it easier to identify that workspace among
other ones.
Note: Don't delete or directly modify these workspaces. This can cause projects to lose track of the configuration state that can lead to creation of
duplicate resources and other issues. To prevent users from modifying workspaces, administrators on the Projects service should not grant users
access to the Schematics service.

Trusted profiles
Trusted profiles authorize cross-account access for applications. Because trusted profiles can generate temporary service ID API keys that exist only
during the lifecycle of the operation, projects use them as the secure and compliant way to authorize a configuration to deploy. Unlike other authentication
methods, trusted profiles don't require key rotation. Create a trusted profile that can manage API keys for the service ID in your account, which deploys
deployable architecture.

Secrets Manager
With Secrets Manager, you can create and centrally manage secrets that are used in IBM Cloud deployable architectures. Secrets are an easy and
compliant way to store sensitive information, like API keys, SSH keys, database credentials, and more. Create a Secrets Manager service instance in your
project home account that you can use for all projects within that account.
Secrets Manager can also be used to store API keys that are used to authorize a project to deploy resources into an account, although there are other
options too. For more information, see Using an API key or secret to authorize a project to deploy an architecture .

Project costs
While there is no charge for a project, there can be costs for any resources created by a deployable architecture. These resources are billed as normal
within IBM Cloud. As you customize the configuration for your deployable architecture, a starting cost is estimated based on the available data. For more
information about project cost estimation, see Cost estimation.

Running secure workloads 31

Important: You're not charged while customizing a deployable architecture. You begin to incur charges after it is deployed.

Needs attention items
Projects monitor configurations by checking to ensure that it passes various automated tests, receives approval, and is updated when new versions are
available from the catalog. When the project needs attention from the user for one of these reasons, the key operational information is displayed on the
project dashboard as a needs attention item. For more information on how to address each type of needs attention notification, see Viewing needs
attention items.
Note: Projects support sending the needs attention notifications to the IBM Cloud® Event Notifications service, allowing them to be filtered and
routed as wanted to Slack, email, and other systems.

Getting started with projects
Now that you've learned about the basics of a project, check out how to Configure and deploy a deployable architecture to start building and review the
Enterprise account architecture white paper to ensure that your account is set up according to IBM Cloud best practices.

Using DevSecOps to build a secure software supply chain
With the DevSecOps tools and services available through IBM Cloud®, you can take advantage of using a verified secure software supply chain for
developing and deploying your application code. Your agile development practices require rapid application deployment, but at the same time, you need to
ensure that your applications are secure. Learn more about the background of agile, DevOps, and DevSecOps.
You can use the DevSecOps Application Lifecycle Management deployable architecture, which is a solution available from the IBM Cloud catalog that uses
Continuous Delivery and others tools to help you automate the integration of security at every phase of the application software development lifecycle,
from development through integration, testing, deployment, and software delivery. Evidence is also collected so that you can easily demonstrate to
auditors that necessary controls are being met. By using DevSecOps Application Lifecycle Management, you can implement a shift-left approach by
preventing new vulnerabilities from reaching production, ensuring frequent updates to production with quality and control, and collecting evidence for
handling security audits.
DevSecOps Application Lifecycle Management uses Continuous Delivery (Git Repos and Issue Tracking, Tekton Pipelines, DevOps Insights, and Code Risk
Analyzer), Secrets Manager, Key Protect, Object Storage, Container Registry, and Vulnerability Advisor. Aligned with the requirements of the Financial
Services industry, Continuous Delivery provides a reference implementation of NIST Configuration Management controls as a service.
Out of the box, DevSecOps with Continuous Delivery also uses scanning tools such as SonarQube, Gosec, OWASP Zap (dynamic scan), any unit test
framework, and GPG signing. It can also be used with more tools such as external Git providers and artifact stores. DevSecOps supports hybrid
deployments, in particular by using pipeline private workers, and can be interfaced with other deployment tools such as Satellite Config and ArgoCD. For
more information, see DevSecOps with Continuous Delivery .
You can configure this deployable architecture from the catalog by adding it to a project, configuring the input variables, validating your updates, and
deploying it in just a short time. Learn about how you can Deploy DevSecOps Application Lifecycle Management with projects .

Running secure workloads 32

Best practices
Best practices for organizing and managing projects
These best practices provide you with the basic building blocks to manage successful and secure projects in IBM Cloud®. Projects are beneficial to
regulated enterprises as a way to best manage code-based deployments while maintaining compliance and collaborating with team members across
accounts.

Creating a primary project account
A key benefit of IBM Cloud projects is the ability to centrally manage and collaborate your Infrastructure as Code deployments. If you are using an
enterprise, establishing a primary or home account to store all of your projects helps manage and track your projects in one location.
The usefulness of establishing a primary account depends on your enterprise structure. Projects can be created in an account and deploy resources to
other accounts. Users can view only the projects that are within the account that they're currently logged in to. In addition, reports for multiple projects can
be generated only for projects within the same account. This is another useful benefit of establishing a common home account for all projects in an
enterprise or all projects with a similar line of business. By keeping your project in a primary account, and deploying to separate accounts for each
environment (dev, test, and production) to simplify enterprise management.
To make the account easier to identify the purpose and projects within the account by all users, give the account a human-readable name. For example
Front-end UI team and Back-end API team .

Defining an authentication method
When you configure your deployable architecture, you are required to add an authentication method. You can choose to authenticate through a trusted
profile or an existing secret.

Using trusted profiles
Important: Some services cannot fully configure and deploy architectures by using trusted profiles. For more information, see Known issues and
limitations for projects.
You can deploy an architecture in your own account or in another account by using trusted profiles. Depending on your organization, deploying an
architecture might require access to another account by using a trusted profile and coordinating with administrators in multiple accounts. If the IBM Cloud
Projects service in another account needs access to your account to deploy an architecture, use trusted profiles and service IDs to authorize deployments
in your account. For more information about creating a trusted profile for your project, see Using trusted profiles to authorize a project to deploy an
architecture.

Using IBM Cloud® Secrets Manager
When deploying Infrastructure as Code (IaC), there are often secrets that are required to configure the infrastructure, like API keys, SSH keys, and SSL
certificates. In these cases, it's recommended to store these secrets within a Secrets Manager instance. Storing secrets directly in the configuration of a
project is not recommended as they are exposed to any user with access to the project. Projects directly support referencing API keys that are stored in
Secrets Manager as an input to a deployable architecture.
Important: Create a Secrets Manager service instance in your primary project account that you can use for all projects within that account before
you create your project.
There are a few different secret types that you can create. Use an arbitrary secret instance to store API Keys for your project. For more information, see
Creating arbitrary secrets in the UI .
Typically a single Secrets Manager instance is used for all projects in an account. Secrets in that instance can be organized into secrets groups that align
with access restrictions. For example, you might want to use a secrets group per project or for a set of related projects.

Controlling deployments by using environments
Within a project, you can group related configurations together by using an environment. An environment can also contain properties such as input values,
authentication details, and Security and Compliance Center attachments. These properties are automatically added to a configuration when you select an
environment, which helps ensure accurate deployments to your target account. When you edit a configuration, you can select an environment for the
configuration to use in the Define details section.

Benefits to using environments
Running secure workloads 33

Environments make it easier to control deployments. By specifying an environment and adding properties, you know that the same values are shared
across configurations that are using that environment. Within a configuration, you can override any values that are automatically provided by an
environment.
Environments provide a way to group related configurations together within a project. Let's say you have a set of configurations that you want to deploy to
the same target account that's your development account. You can create a Development environment and add the authentication details for the target
account to that environment. The authentication method is added to each configuration that's using the Development environment.
Though you can create as many environments as you want, it's recommended that you keep the number of environments in your project low. Using a
standard set of environments for your deployments across accounts makes it easier to configure and deploy architectures.
For more information, see Creating an environment.

Organizing your configurations
Consider organizing all of the related configurations into a single project. This way, you can manage the deployments from one location and help ensure
they're secure and compliant. This might consist of one or more deployable architectures to create the necessary infrastructure, which then needs to be
replicated to support multiple regions and environments such as development, test, and production.
Use a naming convention for your configurations so that users can understand the function of each configuration. For example, in a deployment that uses a
VPC Base deployable architecture and a Kubernetes Cluster deployable architecture that relies on the VPC Base, you might name your configurations as
follows:
Name

Deployable architecture

Environment

Notes

Dev-VPC-Global

VPC Base

Development

Create the base VPC for the development environment

Dev-Kub-Dallas

Kubernetes Cluster

Development

Create the cluster in Dallas for development

Dev-Kub-London

Kubernetes Cluster

Development

Create the cluster in London for development

Prod-VPC-Global

VPC Base

Production

Create the base VPC for the production environment

Prod-Kub-Dallas

Kubernetes Cluster

Production

Create the cluster in Dallas for production

Prod-Kub-London

Kubernetes Cluster

Production

Create the cluster in London for production

Prod-Kub-Tokyo

Kubernetes Cluster

Production

Create the cluster in Tokyo for production

Prod-Kub-Sydney

Kubernetes Cluster

Production

Create the cluster in Sydney for production

Configuration name examples

Tip: You can duplicate the development configuration in the project.json file and modify it as needed to quickly creating production
deployments from their tested development deployments.

Creating access groups for projects
Access to projects is controlled by Identity and Access Management (IAM). It's recommended to create two or three access groups per project and assign
users that work on the project to one of those access groups. For example, you might create a ProjectName-Reader access group that provides read-only
access to the project for users who need to monitor costs or availability and a ProjectName-Writer access group for operations users who need to make
changes to a project and deploy resources. If needed, you can create two writer access groups, one for users who can add configs and complete input
values and a second for users who can deploy resources.
Access group

Roles

ProjectName-Reader

Reader, Viewer

ProjectName-Writer

Manager, Operator
Project access groups and roles

Running secure workloads 34

Note: To create new projects, users must be assigned specific access. For more information, see Assigning users access to projects .

Monitoring needs attention items
Needs attention items are best used to monitor validation, approvals, failures, and version updates. By checking the needs attention items regularly, you
can ensure that your project and configuration are up-to-date and compliant.

Adding tags to projects
You can apply tags to organize, track, and manage your projects. It can be useful to add tags to related projects, or even an extra tag to projects that are
temporary, such as infrastructure used for a customer demo or a prototype that's no longer needed. This allows temporary projects to be easily located and
managed.
Tags are not case-sensitive, and the maximum length of a tag is 128 characters. The permitted characters are A-Z, 0-9, spaces, underscore, hyphen,
period, and colon.
Note: Resources in a project are automatically given service tags with the project ID and configuration ID with which they are associated. For more
information, see Tracking usage and spend for projects .

Undeploying resources created by projects
When you deploy your configuration, resources that are created can be managed as a group within your project. These resources are created based on the
Terraform plan and can be managed individually in your Schematics workspace.
Although you can destroy individual resources from the Schematics workspace, doing so is not recommended for resources that are created by using a
project, as it leads to drift. Instead, you can undeploy all of the resources that are associated with a configuration at once from the project UI with a single
click. Doing so removes the deployment from whatever target environment that your configuration was deployed to. Undeploying resources without
deleting the configuration can be helpful if you need to deploy your configuration again in the future.
By default, when you delete a project or a configuration, any resources that were deployed are undeployed automatically. It's recommended to keep this
setting enabled, but you can disable it by opening your project and going to Manage > Settings. If you disable that setting, resources remain deployed
when you delete a configuration or a project, but you lose the ability to easily manage those resources within the project. Deployed resources can continue
accruing costs to your target account if they remain available after a project or configuration is deleted. For more information, see Undeploying resources.

Best practices for creating deployable architectures
A deployable architecture is a self-contained, modular unit of cloud automation that combines one or more cloud resources to provide a common
architectural pattern. It enables simplified deployment, scalability, and modularity, allowing users to easily provision and manage infrastructure resources.
This guide outlines best practices for building well-designed and maintainable deployable architectures that are written in Terraform. Focusing on key
attributes such as scope, composability, consumability, and quality checks help ensure robust and reliable solutions. The final section of this guide
provides references to tools and templates that help implement these practices.
Note: These best practices apply to creating deployable architectures with Terraform. For more information, see Creating a deployable
architecture.

Design principles
Scope, composability, and consumability are the three main design principles that you need to consider when you are creating a deployable architecture.
In the planning and researching phase, you should evaluate the current ecosystem of offerings and evaluate the business use case and requirements. Use
the Well-Architected Framework and the Architecture Design Framework to plan and design the required components for the architecture.

Scope
A well-defined scope for the deployable architecture is crucial, as it should be comprehensive enough to include all necessary resources, yet focused
enough to avoid unnecessary complexity.
A best practice is to include infrastructure resources that are typically deployed together as a unit, require similar access rights and permissions, and have
the same lifecycle. For example, let's consider the VPC landing zone deployable architecture . This deployable architecture has a well-defined scope that
includes the following infrastructure resources:

Running secure workloads 35

Resource

Description

VPCs

Creates a secure VPC topology

Network infrastructure

Includes subnets, public gateways, ACLs, transit gateways, and security groups

Edge networking

Isolates traffic to the public internet

Monitoring and logging

Integrates Flow Logs for observability and auditing of the VPC traffic
Resources in the VPC landingn zone DA

These resources are typically deployed together as a unit, require similar network administrative rights and permissions, and have the same lifecycle,
meaning that they:
Are created together, such as when a new VPC is provisioned with its associated subnets, public gateways, and security groups.
Are updated together, such as when a change is made to the VPC's network configuration, which requires updates to the subnets, public gateways,
and security groups.
Are deleted together, such as when a VPC is decommissioned and all its associated resources, including subnets, public gateways, and security
groups, are removed.

Composability
A fundamental principle of a deployable architecture is composability, which enables the creation of a broader deployable architecture stack by combining
multiple deployable architectures. This modular approach allows for maximum flexibility and reusability of automation resources.
To achieve composability, a deployable architecture should be designed to:
Maximize the amount of information surfaced through the output values, yet keep the output types simple. This practice enables the deployable
architecture automation to be reused in a wide range of scenarios, and makes it a versatile building block for various automated solutions.
Allow optional references to existing deployed resources, such as resource groups, IBM® Key Protect for IBM Cloud® or Hyper Protect Crypto
Services instances, and IBM Cloud Secrets Manager instances, among others. Users can then configure existing instances or deploy into existing
resource groups, increasing the versatility of your automation. The Secrets Manager deployable architecture is a great example of this principle in
action. By allowing users to reuse existing Secrets Manager instances, resource groups, and KMS encryption key, this automation provides a high
degree of flexibility and adaptability. For example, you can:
Configure an existing Secrets Manager instance by passing its ID, and create secret groups in the existing instance.
Integrate with an existing key management system like Key Protect or Hyper Protect Crypto Services.
Deploy in an existing resource group or create a new one with customizable naming conventions.
Alternatively, this deployable architecture also allows creating a new Secrets Manager instance, a new resource group, and other resources from scratch,
providing a stand-alone solution.
By embracing composability, a deployable architecture can be easily integrated into a more complex solution architecture, such as a

deployable

architecture stack. For example, the Retrieval Augmented Generation Pattern demonstrates how multiple deployable architectures, including the Secrets
Manager deployable architecture, can be combined to build a complex solution. Deployable architectures that are designed with composability in mind
provide the foundation for these more complex solutions.
In a deployable architecture stack, each member deployable architecture maintains its independent configuration state, allowing for individual
deployment, update, or undeployment. This modular approach enables cost, compliance, support, and quality assurances to be derived from the included
deployable architectures, while each stack remains uniquely versioned with its own descriptions and reference architecture.

Consumability
A deployable architecture should be designed with consumability in mind, making it easy for users to understand and deploy. To achieve this, the
deployable architecture should provide comprehensive documentation that includes the following:

Prerequisites
Software dependencies and infrastructure requirements necessary for deployment.
Detailed input variables and output values descriptions
Including purpose, data type, and default values.

Running secure workloads 36

Necessary minimal permissions
Required permissions to run the deployable architecture automation.
Diagrams and architecture maps
Visual representations of the deployable architecture's components and relationships.
Simplified configuration
Easy to deploy and manage.
Reduced resource requirements
Optimize the deployable architecture to minimize hardware and resource requirements, such as lower CPU and memory requirements, making it
more affordable and efficient.
Streamlined deployment
Faster and easier to get started.

Another facet of ensuring the deployable architecture is easily consumable is by providing multiple variations, including a quick start variation. A quick start
version of the deployable architecture should be provided, which is cheaper and faster to run with. For example, the QuickStart variation of the Red Hat
OpenShift Container Platform on VPC landing zone deployable architecture creates a fully customizable Virtual Private Cloud (VPC) environment in a single
region, providing a single Red Hat OpenShift cluster in a secure VPC for workloads. This quick start variation is designed for demonstration and
development purposes, and costs less than $400 per month to run.
In contrast, the standard version of the Red Hat OpenShift Container Platform on VPC landing zone deployable architecture, based on the IBM Cloud
Framework for Financial Services reference architecture, creates secure and compliant Red Hat OpenShift Container Platform workload clusters on a
Virtual Private Cloud (VPC) network, but costs over $4,000 per month to run. And, it includes advanced features such as management VPC service,
workload VPC service, isolation of management VPC and workload VPC, and advanced network security architecture decisions.

Input variables
Make it easier for users to configure the deployable architecture's input variables by using the following best practices:

Expose only commonly modified arguments
Expose only the variables that most users will need to change, avoiding deployable architectures with a large number of input variables that would
overwhelm users. For advanced users, consider providing a single JSON input field for further customization. As an example, the VPC Landing zone
deployable architecture surfaces a single field that is named override_json_string that gives full control to advanced users on the deployed
topology. For more information, see the VPC Landing zone deployment guide .
Use clear and descriptive naming for existing resources
When referring to existing resources, use names that clearly indicate what they refer to, such as

existing_cluster_name instead of

cluster_name , to avoid ambiguity.

Prefer names over IDs
When referring to existing resources, use names instead of IDs for better user consumability.
Avoid acronyms
Instead of using acronyms, use full product names to make it easier for people not familiar with the products or services to understand what they
refer to. For example, secrets_manager instead of sm , or key_management instead of kms .
Use advanced typing capabilities
To enable the IBM Cloud Projects service to render appropriate input widgets for variables, which makes it easier for users to configure values. For
example:
VPC Region: a dropdown list of all available VPC regions on IBM Cloud.
VPC SSH Key: a secure input field for SSH key management.
Cluster: a dropdown list of available clusters on IBM Cloud.
For more information, see Locally editing the catalog manifest values .

Running secure workloads 37

By following these guidelines, the deployable architecture can be made more consumable, allowing users to quickly understand and deploy it.

Quality
To ensure the deployable architecture is reliable and consistent, it is essential to implement and automate quality checks. These checks should cover
various aspects of the deployable architecture, including code quality, configuration validation, testing, and continuous integration.

Code quality
Leverage linting and code formatting. Enforce consistent coding styles and formatting to make the code easy to read and maintain. Detect errors and
warnings in the code to prevent issues during deployment. Consider going beyond just the Terraform code, but incorporate any tools relevant to all
resources in your deployable architecture, such as Bash scripts, Python scripts, YAML and JSON files, and Golang.
Examples:
terraform_fmt to format Terraform code.
go-fmt to format Go code.
black to format Python code.
isort to sort Python imports.
flake8 to check Python code for errors and warnings.
shellcheck to check shell scripts for errors and warnings.
golangci-lint to check Go code for errors and warnings.

Configuration validation
Use static validation to check the deployable architecture's syntax and configuration to ensure it is correct and consistent. Validate the deployable
architecture's configuration to prevent errors during deployment. Again, consider going beyond just the Terraform code, and incorporate any tools relevant
to all resources in your deployable architecture, such as Bash scripts, Python scripts, YAML and JSON files, and Golang.
Examples:
terraform_validate to validate Terraform configuration.
checkov to check for security and compliance issues in Terraform code.
tflint to check for errors and warnings.
detect-secrets to detect secrets in code.
hadolint to check Docker files for errors and warnings.
helmlint to check Helm charts for errors and warnings.

Testing
When it comes to testing infrastructure code, there is no pure unit testing in the way that you might think of it for application code. Instead, the test
strategy involves deploying the infrastructure to a real environment, validating that it works, and then undeploying it.

Automated validation test suite
The recommendation is to have a basic automated test suite that covers the following fundamentals:

Deployment tests
Verify that the infrastructure code can be successfully deployed to a real environment. Create all necessary resources, such as virtual machines,
databases, and networks. These tests help ensure that the infrastructure code is correct and can be successfully applied to a real environment. It is
recommended to vary the input parameters of the deployable architecture in these tests to ensure broad coverage aligned with common usage.
Destruction tests
Verify that the infrastructure code can be successfully undeployed or destroyed, removing all created resources. These tests ensure that the
infrastructure code can be safely removed from a real environment, without leaving behind orphaned resources or causing unintended
consequences.
Idempotency tests
Verify that the infrastructure code can be reapplied multiple times without causing unintended changes or errors. In other words, the code should
produce the same result regardless of how many times it is applied. These tests are critical in environments like IBM Cloud, where the platform
periodically checks for changes to detect drift between the deployed infrastructure and the source of truth, which is the automation code.
Idempotency tests help ensure that the infrastructure code can handle repeated deployments or updates without causing issues. These tests also
Running secure workloads 38

help ensure that drift detection capabilities can accurately identify and remediate any discrepancies between the intended state and the actual state
of the infrastructure. For more information, see Managing drift.
Version upgrade tests
Verify that the infrastructure code can be successfully upgraded from one version to another, without causing errors or unintended changes. These
tests ensure that the infrastructure code can be safely upgraded, without disrupting or destroying existing resources or causing unintended
consequences.

Advanced test cases
The advanced test cases include scenarios such as:

Deploying the deployable architecture multiple times in the same account
Verify that the infrastructure code can handle multiple deployments in the same account, without causing resource name clashes or other issues.
Deploying the deployable architecture with a trusted profile
Verify that the infrastructure code can be deployed with an Cloud Identity and Access Management trusted profile. For more information, see
Defining an authentication method .

By including these tests in your automated testing suite, you can ensure that your infrastructure code is reliable, robust, and safe to deploy to production.

Continuous integration
To ensure the reliability, consistency, and maintainability of the deployable architecture, a shift-left approach is recommended, where quality checks and
testing are integrated early in the development cycle. This approach helps catch errors and defects early, reducing the likelihood of downstream problems
and improving overall quality.
As part of this approach, the following quality checks are recommended:

Client-side quality control
Client-side Git commit hooks should be used to run checks on the developer machine before committing code. This includes checks for coding
standards, syntax errors, and sensitive data. Tools like Pre-commit can be used to automate this process.
CI practices
Best practices for continuous integration (CI) should be followed. The general practices for any software engineering product applies to deployable
architecture development, including:
Working with small, focused pull requests (PRs) to facilitate timely reviews and reduce merge conflicts.
Integrating code changes into the main branch on a regular basis to prevent long-lived feature branches and reduce merge complexity.
Implementing automated testing and code reviews to ensure code quality and consistency.
Continuously validating the deployable architecture's configuration and syntax to ensure correctness and consistency.
CI Pipeline
A CI pipeline should be set up to automate these practices, ensuring that every code change in the deployable architecture is systematically tested
and validated. This pipeline ensures that the deployable architecture works correctly and consistently, and that any errors or defects are caught
early.

Tools and resources
A comprehensive set of tools and resources is provided to facilitate the creation of high-quality deployable architectures. Curated Terraform modules are a
key piece, with over 60+ reusable, secure, and validated modules that cover a wide range of infrastructure needs. These modules are available on GitHub
and are supported and kept current through an open source contribution model, and backed by contributions from the IBM Cloud development
organization.
In addition to the curated Terraform modules, best practices and templates are also provided to help with deployable architecture and module authoring.
This includes documentation, a GitHub deployable architecture repository template that is aligned with authoring best practices, and module authoring
Running secure workloads 39

guidelines that apply to both Terraform modules and Terraform-based deployable architectures. These resources can be used to quickly get started on a
new deployable architecture.
An automated testing framework is also provided, and based on the Terratest library, with tests written in Go. The framework covers idempotency tests,
upgrade tests, and GitHub, and uses test helper functions from the https://github.com/terraform-ibm-modules/ibmcloud-terratest-wrapper library. For
more information, see our testing documentation.
To support CI pipeline development, a range of tools and resources are available, including:
Reusable GitHub Actions.
Automated generation of documentation.
Automated onboarding to IBM Cloud.
Automated dependency updates by using custom renovate.
Local development setup tooling and pre-commit hooks configuration, see our local development setup documentation for more information.
These tools and resources are designed to accelerate and facilitate the creation of high-quality deployable architectures.

Next steps
Now that you understand the best practices for building a deployable architecture, you can use the tools and resources and review the following IBM Cloud
documentation before developing your automation code. This helps ensure that you thoroughly planned and designed your solution to share in IBM Cloud:
Planning and researching for designing an architecture to ensure that you're designing an architecture that is a viable reusable pattern that meets
your business requirements.
How do I decide what type of component to create? to make sure you understand the differences between a module, deployable architecture, and
deployable architecture stack.
How do I decide where to share my solution? to ensure you're meeting the requirements depending on where you plan to share or publish your
solution.

Best practices for working with Security and Compliance Center
As you start working with Security and Compliance Center, there are a few best practices that you can follow to have the best experience meeting your goal
of continuous compliance and being audit ready.

Providing the correct access to the correct people
There are several people in your organization who might require varying levels of access to Security and Compliance Center or integrations. To ensure that
you're following best practices, be sure that you create access groups and assign only the minimum required permissions for team members to perform
their duties. To manage compliance for an individual account, a compliance focal needs access to the Security and Compliance Center service, Event
Notifications, and Cloud Object Storage by using IAM access policies assign to the access group. To manage compliance for an enterprise, additional
permissions are required. For more information, see Assigning access.

Managing profiles
In Security and Compliance Center, a profile is the collection of controls that you use to evaluate your compliance. When you work with Security and
Compliance Center, you have the option to use a predefined profile or create a custom profile. There are pros and cons to both.

Working with predefined profiles
Predefined profiles are versioned and periodically updated with bug fixes, more checks, or changes to the compliance program. If you are monitoring
compliance for a specific program, such as IBM Cloud Framework for Financial Services, it is recommended that you work with a predefined profile. This
way you can take advantages of new versions of the profile as they become available. Learn more about versioning.
To avoid having to create and maintain a fully customized profile, you can customize a predefined profile by using

parameters. A parameter is the actual

value that your resource is evaluated against. Each parameter is assigned a default value that can be edited at the time of attachment. Each attachment can
be assigned a different parameter value, which then changes the evaluation that is completed. However, when a new version of a profile is released, you
need to ensure that your customizations are made for the new profile version.

Working with custom profiles
If you want total control over your profile - the number of assessments, versioning, or naming, you might want to create a custom profile. With custom
profiles, you can mix and match controls from different libraries or only select the assessments that apply to your use case. Or, you can create your own
controls.
Although it is possible to add both custom and predefined controls to a profile, it is recommended that you create a separate profile for any controls that
Running secure workloads 40

you want to add. By keeping predefined and custom controls separate, you are able to update to new versions of the predefined profiles more easily as you
won't need to redo your customizations.
Tip: You cannot create custom profiles from deprecated control library versions. To get started, work with the most recent version.

Defining scopes in enterprise accounts
When you work with Security and Compliance Center through an enterprise account, your experience is a bit different when it comes to your set up options.
As an enterprise, you have more scope options than an account. You can choose to evaluate your entire enterprise, specific account groups, or single
accounts. It is recommended that if you want to evaluate a single account that you do so from that account.
Note: If you are working in an enterprise account, you must have additional permissions for the enterprise to manage and see results. For more
information, see Assigning access.
A scope defines which resources in your accounts are evaluated. It is defined when you create an attachment by selecting the parent account or resource
group that you want to evaluate. Anything that exists within that account or group is evaluated. So, for example, if you create an attachment at the
enterprise account level, then all of the account groups and accounts within them are included in your evaluation. If you don't want to evaluate an account,
you can always exclude it from your scope when you create the attachment. When an account is excluded, any of its child accounts are also excluded.
However, as new accounts are added to your enterprise, they are automatically evaluated according to the parent account's attachment.
Check out the following diagram to see how three attachments can co-exist within an enterprise.

Attachment hierarchy

Attachment A
In Attachment A, the target scope is the full enterprise. As you can see, all account groups and accounts that exist within the enterprise are
evaluated. That is, unless they have been purposefully excluded.
Attachment B
The target scope of Attachment B is a specific account group within an enterprise. As you can see, the resources in the account group are now being
evaluated against the profile that is selected during Attachment A and are evaluated according to the profile selected when Attachment B was
created.
Attachment C
The target scope of Attachment C is a child account. This attachment was created in the account, outside of the context of the enterprise. As you can
see, Attachment A is monitoring the resources in the same account, but because Attachment C is created at the account level, resource groups are
able to be seen and excluded.

To view the results of an evaluation, you look in the account where the attachment was created. If you use the previous image as an example, attachment

Running secure workloads 41

A and B's results would exist within the enterprise account, and the enterprise account is charged for the evaluation. However, attachment C's results
would exist within the child account.

Defining scopes in accounts outside of an enterprise
When you work with Security and Compliance Center outside of the enterprise account structure, your set up options for scopes are different. Because you
can scan and evaluate your resources across accounts, you must use the cross-account access policy to access resources in other accounts.
You can select a single Security and Compliance Center instance in your main account to monitor a list of other target accounts (and their resources) and
environments. This Security and Compliance Center instance in your main account must have access to scan resources in multiple target accounts for IBM
Cloud resources. You can define multiple scopes for each target account in an attachment.
You can create multiple attachments that distribute accounts across multiple attachments. For example, you can select 1 to 200 accounts in a single
attachment scope. Then, you can select 201 to 400 accounts in the next attachment scope.

Running secure workloads 42

Planning and designing an architecture
Planning and researching for designing an architecture
When you're planning to create a module, deployable architecture, or deployable architecture stack, you need to research and come up with a plan for
designing the architecture before creating the automation. Evaluating what exists and how your proposed solution fits into the current ecosystem of
offerings, thoroughly planning the architecture around your business requirements, and determining what you plan to build and where you will share or
publish the solution are all key parts of the planning phase.

Researching existing offerings and user needs
As part of the research phase you need to understand what's currently available and what business use cases and requirements you plan to solve.

Researching current offerings
Evaluate the currently available modules and deployable architectures from IBM Cloud® to determine whether other similar solutions exist or how much
automation your team needs to develop. For example, if the existing architectures in the catalog can help build the solution you're planning, you might
have to build only a single deployable architecture that you group into a stack with other existing deployable architectures to build the full solution. So,
instead of building all of the pieces yourself, you can use existing deployable architectures. Similarly, if you're building a deployable architecture that is
composed of modules, you can review the existing modules to identify any that you might want to use in your architecture.
You can explore existing modules and deployable architectures in the following locations:
terraform-ibm-modules public GitHub org is the IBM Cloud Terraform modules project. This collection of Terraform modules follows best practices

and simplifies the provisioning of IBM Cloud services and instances.
IBM Cloud module registry is a collection of assets that is separate from the IBM Cloud catalog and is governed and maintained by the process in the
terraform-ibm-modules repository. Discover public modules that have been confirmed to work with deployable architectures for your

customization and building needs.
IBM Cloud catalog includes generally available deployable architectures that are covered by the IBM Cloud terms and conditions.
Community registry includes a collection of real world examples of coded industry solutions to jumpstart your building needs. This collection is
maintained based on specifications in the originating Github repository that might change frequently or be discontinued at short notice.

Determining a viable reusable architecture pattern
The second part of the research phase is to understand the business requirements and use cases that the solution will be built to address and how you can
build a viable, reusable pattern. Many of the existing architectures are based on customer use cases for digital transformation, application modernization,
and more. Knowing which use cases you're meeting will help determine which technologies you choose to build your architecture.
Use the Well-Architected Framework and the Architecture Design Framework to plan and design the required components for the architecture. Follow the
steps for Designing a cloud solution by using the Architecture Design Framework . The decisions that you make during this process for the requirements
and components that will be used to build your architecture pattern will be the design for your development team to build the pattern.

Designing the architecture
Based on the decisions reached during the research phase, many teams start documenting the pattern by using a Word document where they can track
changes and provide comments to collaborate on what the team plans to build.
As the plan for your architecture gets solidified, you can refer to the reference architecture template as a guide for documenting your pattern. This includes
creating an architecture diagram, design requirements heatmap, and documenting requirements and the architecture decisions for the chosen
components.

Next steps: Choosing what to create
It's important to understand the key differences between modules and types of deployable architectures to determine which you plan to create. The scope,
coupling, whether it's deployable, and the purpose of your solution should all be taken into account. For guidance and use cases to help you decide what
you plan to build, see How do I decide what kind of component to create .

How do I decide what kind of component to create?
How do you decide whether you should create a module, a deployable architecture, or stack deployable architectures together? Let's compare the
differences and evaluate the use cases in the following sections to help you decide.

Comparing deployable architectures and modules
Running secure workloads 43

The following table provides a comparison and quick summary of the key differences between modules and types of deployable architectures.
Method

Scope

Coupling

Deployable

Author

Create a module

Narrow

Tight

No

Developer

Create a deployable architecture

Medium to broad

Tight

Yes

Developer

Stack deployable architectures

Broad

Loose

Yes

Anyone

Comparison of concepts

The following table can help you decide whether to use a module, a deployable architecture, or stack deployable architectures together depending on your
use case.
Purpose

Recommended

Notes

method
Accelerate
coding
automation

Use modules

Modules provide reusable, curated automation to get developers of deployable architectures coding faster.
Modules are for developers, not consumers.

Ensure that
the cloud is
secure and
compliant

Use a
deployable
architecture

Deployable architectures enforce security and compliance for an architecture. If a deployable architecture is too
small in scope, it cannot enforce compliance. For example, a deployable architecture that deploys only a virtual
server instance can't ensure network security.

Give users a
choice with
guardrails

Stack
deployable
architectures
together

By stacking deployable architectures, you can swap deployable architectures or add on deployable architectures
and give users more choices. Since deployable architectures enforce security and compliance, stacking helps
ensure the overall solution remains compliant. Stacking deployable architectures is an excellent approach for
things like selecting which database to use.

Usercreated
solutions or
architectures

Stack
deployable
architectures
together

Stacking deployable architectures allow users to create and publish their own repeatable patterns that are still
safe, as they are composed of secure and compliant deployable architectures.

Decoupled
architecture
components

Stack
deployable
architectures
together

Deployable architectures can be independently developed and versioned, but then stacked together for
deployment.

Simplified
user
experience

Use a
deployable
architecture

Deployable architectures can provide a small or simple list of inputs to the user even for large or complex
architectures. Deployable architectures are simple to understand and deploy. In comparison, stacking
deployable architectures is a little more complex as the deployable architectures are exposed.
Help me choose the component to use

IBM Cloud projects ensure that resources are deployed through deployable architectures from the catalog and operate within the security and compliance
guardrails of the organization. They also ensure that these resources are kept up to date and do not drift.

Dependencies for deployable architectures
Dependencies arise when resources that are provisioned by one deployable architecture are required by another. That is, the resources that one
deployable architecture provisions are used during the deployment of another architecture, as illustrated in the following image.

Running secure workloads 44

Deployable architecture dependencies

One way to work with dependencies is to stack deployable architectures and add references between them in a project . For example, the VSI on VPC
landing zone deployable architecture includes a variation that extends the Red Hat OpenShift Container Platform on VPC landing zone deployable
architecture. Consider stacking these architectures together in a project. This approach works well if the prerequisite architecture isn't deployed yet. You
also don't need to edit code to stack deployable architectures.
Tip: Many deployable architectures are stand-alone and aren't extensions of other architectures, but you can choose to extend some deployable
architectures in the Architecture section of the catalog details page. Select an option from the How do you want to build this architecture? menu.
However, if you already deployed Red Hat OpenShift Container Platform and you need to deploy VSI, the resources that are required for VSI are already
provisioned. You don't need to deploy the Red Hat OpenShift Container Platform architecture again. Since the VSI architecture is an extension of the Red
Hat OpenShift Container Platform, you can deploy VSI and the architecture uses the resources from the Red Hat OpenShift Container Platform as needed.

Optional and swappable components
This is an experimental feature that is available for evaluation and testing purposes and might change without notice.
Some architectures might work well with a deployable architecture that you're onboarding without being a required prerequisite for your product. If that's
the case for the product that you're onboarding, you can specify other architectures as optional components, also known as optional dependencies in the
catalog manifest file. When a user adds your deployable architecture to a project from a catalog, they can customize it by adding the optional component if
they want to. Any dependency, whether it's optional or required for your product, can be swappable with other architectures. Swappable components
provide the same function, and the user can select the architecture that best meets their needs.
For more information, see Specifying dependencies.

Terraform versus Ansible
In IBM Cloud, a deployable architecture must use Terraform to declare the inputs and outputs of the deployable architecture (the interface) as Ansible
does not have a machine-readable interface definition. Otherwise, the author of a deployable architecture might use any combination of Ansible pre- or
post-scripts and Terraform to run the work of the deployable architecture. So, how does a developer decide which technology to use and for what?
Terraform

Ansible

Language

Declarative

Procedural

Syntax

HCL (similar to JSON)

YAML (and callouts to other scripts)

Default approach

Mutable infrastructure

Immutable infrastructure

Focus

Infrastructure

Configuration

Drift

Comparison with wanted state

Idempotent tasks

Comparison of configuration languages

Terraform is excellent at creating and managing infrastructure, whereas Ansible is excellent at configuring the software and operating systems that are
running on that infrastructure. Because Ansible is procedural, you can also script one-time operations. Maintenance tasks, like restoring from backup, are
easy in Ansible.

Running secure workloads 45

Purpose

Recommended

Notes

configuration
language
Deploy cloud
infrastructure
or services

Terraform

Terraform targets this use case and is better at handling changing infrastructure. IBM Cloud provides Terraform
modules and supported deployable architectures to accelerate secure and compliant infrastructure patterns.
The Terraform state model allows developers to preview the changes. Those changes can be scanned for
compliance.

Install or
configure
software

Ansible

If a pre-built container or virtual machine image is not suitable for the use case, Ansible is better at handling the
software installation and configuration. Ansible has extensive support for automated operations such as
configuration edits, package management, and process restarts. A large library of Ansible modules and
playbooks are available to ease the configuration of thousands of commonly used software packages.

CCDB
integration

Ansible

Making a dynamic call to an on-premises service like a CCDB can be done in Terraform or Ansible but is easier
to accomplish in a procedural or scripting language.

Input
validation

Terraform or
Ansible

Terraform has limited ability to do input validation, but it is declarative and can be used by user interfaces.
Ansible adds the ability to do dynamic input validation where inputs to a deployable architecture are checked
against a remote service.

Day 2
maintenance
actions

Ansible

Day 2 maintenance is generally procedural in nature and best completed in Ansible. Examples include manual
backup, restore, or key rotations.

Drift
management

Terraform

Terraform can be used to determine whether drift occurred and what that drift is, which can help you

Ansible

decide how to manage the drift. The drift information is powerful because it might indicate that you can
add a change to automation.
Ansible can't detect drift. But by regularly reapplying an idempotent ansible script, you can prevent drift.

Help me choose the configuration language to use

For more information about including pre- or post-scripts with your deployable architectures, see Creating scripts for deployable architecture.

Next steps: Deciding where to publish
After you've planned out your architecture and decided what type of component to create, you should

consider where you plan to share or publish your

solution, so that other users can take advantage of the solution that you create. Depending on where you plan to share or publish, you might have different
levels of requirements or approvals to complete.

How do I decide where to share my solution?
The options for sharing and publishing differ based on whether you have a module or deployable architecture, who you want to share the solution with, and
the level of support that is available for the solution.

Sharing and publishing options
First, you need to know whether you're creating a module or deployable architecture. It's important to note that deployable architectures can be deployed
from private catalogs or the IBM Cloud® catalog by using projects, but modules can't be deployed from private catalogs. Let's look at the available options
for each.
Component

Sharing and publishing options

Module

Private catalog

Deployable architecture

Private catalog
IBM Cloud catalog
Publishing options

Let's learn a little more about each of these options.
Running secure workloads 46

Private catalog
Private catalogs provide a way to centrally manage access to products in the IBM Cloud catalog and your own catalogs. You can customize the public
catalog and your private catalogs to make specific solutions available to users in your account. By doing so, you can ensure that your catalogs are
relevant to your business. You can share products in your private catalog with users in your account, account groups within your enterprise, the entire
enterprise, and even other enterprises that you have access to. By sharing your offering, any user within the account, enterprise, or account groups
can configure and deploy an instance.
IBM Cloud catalog
The IBM Cloud catalog is the official collection of generally available supported products and offerings from IBM Cloud and approved third-party
partners. All products onboarded and published to the catalog must complete the requirements in Partner Center.

Choosing where to share or publish deployable architectures
If you plan to build a deployable architecture, you might choose to share it with just people in your enterprise or the wider cloud community in the IBM
Cloud catalog.
Scenario

Publishing location

I'm a development team in an enterprise that's building a proprietary solution for my company

Private catalog

I'm creating an experimental type of pattern

Private catalog

The pattern applies broadly to a larger customer base

IBM Cloud catalog

My team has development resources to provide support and ongoing maintenance

IBM Cloud catalog

Scenarios for publishing location

If you plan to offer your deployable architecture in the IBM Cloud catalog, there are required tasks and approvals that must be completed in Partner
Center. For more information, see the Checklist for selling deployable architectures.

Next steps: Creating the solution automation
Now that you have a plan and architecture design and you know where you want to share or publish your solution, you can get started creating the
automation. Use the following resources to help you get started creating your solution.
Creating a module
Creating a deployable architecture
Stacking deployable architectures

Running secure workloads 47

Preparing your account to scan for security and compliance
With IBM Cloud® Security and Compliance Center, as a security focal within your enterprise, you can scan your account resources to evaluate whether they
meet your enterprise's regulatory compliance requirements.
This tutorial walks you through the process of setting up the automatic evaluation of your

VSI on VPC landing zone deployable architecture resources

against the IBM Cloud Framework for Financial Services profile. This workflow requires you to set up an attachment to target a resource group in your
account that is to contain the resources for the deployable architecture.
You can follow the Using IBM Cloud deployable architectures to build a deployable architecture tutorial to customize the deployable architecture to meet
your needs and offer it through a private catalog to your enterprise users. Or, you can use the unedited deployable architecture from the catalog. Either
way, with this tutorial, you can scan your account resources on a recurring schedule to get ready for audits.

Before you begin
Before you get started, be sure that you have the following prerequisites.
Check whether you are part of the relevant access group in your enterprise's account. The access group must have the required permissions to
select a profile, set up attachments, run scans, view detailed results, and more.
To manage your security and compliance evaluations, you need to make sure that you have the Editor platform role or higher .
Make sure that you have an authorization with Writer access permissions in place to enable communication between Security and Compliance
Center and IBM Cloud Object Storage.

Step 1: Setting up storage for your scan results
You must connect the Security and Compliance Center service to a Object Storage bucket to store your results. Then, you can create an attachment.
1. In the IBM Cloud Dashboard, go to Resource list and select the Security and Compliance Center instance that you want to work with.
2. In the Security and Compliance Center console, go to the Settings page.
3. In the Storage section, click Connect.
4. Select the correct Object Storage instance from the dropdown list.
5. Select the Object Storage bucket where you want to store your scan results.
6. Click Connect.

Step 2: Creating an attachment
In this scenario, your solution architect and development team plan to customize and deploy the VSI on VPC landing zone architecture . Working as a team,
you can determine which specific deployable architecture resources are to be contained in the resource group that you plan to use. Then, you can set up an
attachment between the resource group and the profile that best meets your enterprise's regulatory objectives.
The attachment that you're creating validates the group of specific deployable architecture resources in your account against the IBM Cloud Framework for
Financial Services profile. The IBM Cloud Framework for Financial Services profile evaluates the deployable architecture resources that the resource group
contains, whether they're created already or are planned to be in the future.
1. In the IBM Cloud Dashboard, go to Resource list and select the Security and Compliance Center instance that you want to work with.
2. In the Security and Compliance Center console, navigate to the Attachments page and click Create.
3. Provide a name and description for your attachment. Click Next.
4. Select the IBM Cloud Framework for Financial Services profile in the Profile dropdown list. Then, click Next.
5. Define a scope by selecting the resource group that you created with your team and specify the resources that you want to exclude from your scope.
Click Next.
6. Select Weekly as the frequency at which you want to evaluate your resources. With this interval, the scan starts as soon as the attachment is
created. Click Next.
Note: If your development team hasn't deployed the deployable architecture resources to the resource group yet, select Never. When the
team adds the resources to the resource group, you can return and update the frequency of the scans.
7. Review your choices and click Create.

Running secure workloads 48

Note: When you create your attachment, a scan is scheduled. When the scan completes, your results are available in the Security and Compliance
Center dashboard. If your results are not updated, review the troubleshooting guide.

Next Steps
Now that you set up the attachment to scan the resource group that is to contain the VSI on VPC landing zone deployable architecture resources, you can
view scan results and prepare for audits. For more information, check out Viewing results.
When your development team is ready to customize the architecture, they can use the Security and Compliance Center attachment that you just created to
validate the architecture before they deploy it.

Running secure workloads 49

Creating deployable architectures
Using IBM Cloud deployable architectures to build a deployable architecture
This tutorial walks you through how to create a new deployable architecture from an existing IBM Cloud® deployable architecture to fit your business
needs. By completing this tutorial, you learn how to download the Terraform files of a deployable architecture, update the variables, and then test the new
deployable architecture.
By starting with an IBM Cloud deployable architecture, you don't need to worry about creating compliant infrastructure architecture from the ground up.
You can get a jump-start by using an IBM Cloud deployable architecture and configuring it to meet your specific needs.
Imagine you are the infrastructure architect for the fictitious company Example Corp and you have been given certain infrastructure requirements. You
browse the IBM Cloud catalog and discover that the VSI on VPC landing zone deployable architecture meets most of your requirements. However, you
want to make the following changes to meet your business needs:
Remove unwanted variables
Constrain IBM Cloud regions to US deployment regions
Use an existing SSH key instead of a personal SSH key
Use a specific Virtual Server Instance profile called example-profile
This tutorial uses a fictitious scenario to help you learn and understand a few of the configuration options for a deployable architecture. As you complete
the tutorial, adapt each step to match your organization's needs.

Before you begin
1. To build an architecture, you must have familiarity with Terraform.
2. Verify that you're using a Pay-As-You-Go or Subscription account by going to Manage > Account > Account settings in the IBM Cloud console.
3. Create a repository to store your new configuration. For the purposes of this tutorial, GitHub is used. For more information, see

Create a repo.

4. Make sure that you have an editor of your choice set up, for example, Visual Studio Code.
5. Verify that you're assigned the following IBM Cloud Identity and Access Management (IAM) roles:
Administrator on all account management services and all IAM services
Editor on the Catalog management service
Manager service access role for Schematics
Other roles that are required for specific resources in your configured deployable architecture

Step 1: Downloading the deployable architecture files
To begin, you need to download the deployable architecture files. The files include a

main.tf file that invokes the root Terraform module in VSI on VPC

landing zone.
1. In the IBM Cloud console, click Catalog.
2. Select Deployable architectures from the list of Type filters > VSI on VPC landing zone .
3. Click Review deployment options from the summary panel.
4. Select Work with code > Download bundle to download the bundle.
5. Open the downloaded bundle on your local computer.
6. If needed, extract the .tar.gz bundle to access and edit the files.
After successfully downloading and extracting the bundle, you'll see the following files and folders:
$ - automation folder
- ibm_catalog.json
- main.tf
- outputs.tf
- provider.tf
- README.md
- variables.tf
- version.tf

7. Rename the bundle Example-corp-architecture for findability and ease-of-use.

Running secure workloads 50

Step 2: Editing your list of variables
When you researched VSI on VPC landing zone, you determined that you wanted to modify the region, SSH key, IBM Cloud API key, and VSI profile
variables. The other variables that are included in the architecture aren't needed for your purposes, and you would like to remove them by using your
favorite editor Visual Studio Code.
1. In Visual Studio Code, open the variables.tf file.
2. Move the following variables to the start of the variables.tf file.
existing_ssh_key_name
ibmcloud_api_key
region
prefix

Tip: The order of the variables does not matter.
3. Delete all the other variables and save the file.

Step 3: Updating the main.tf file
Now that you updated the variables.tf file, make sure that the configuration information in the main.tf file is correct. Since you want to use an
existing SSH key and a specific VSI profile, replace the ssh_public_key variable and add the vsi_instance_profile variable.
1. Open the main.tf file.
2. Replace ssh_public_key = var.ssh_public_key with the following text to indicate that you want users to use an existing SSH key and not a public
or personal SSH key.
existing_ssh_key_name

= var.existing_ssh_key_name

3. To hardcode the architecture to use the example-profile VSI profile, add vsi_instance_profile = "example-profile" as the last variable.
4. Confirm that the ibmcloud_api_key , prefix , and region variables are as shown in the following example.
module "deploy-arch-ibm-slz-vsi" {
source

= "https://cm.globalcatalog.cloud.ibm.com/api/v1-beta/offering/source//patterns/vsi?

archive=tgz&flavor=standard&installType=fullstack&kind=terraform&name=deploy-arch-ibm-slz-vsi&version=v4.0.0"
ibmcloud_api_key
prefix

= var.ibmcloud_api_key

= var.prefix

existing_ssh_key_name
region

= var.existing_ssh_key_name

= var.region

vsi_instance_profile

= "example-profile"

}

5. Save the file.
Your architecture is now hardcoded to use the specific example-profile VSI profile and configured to use the variables for IBM Cloud API key, prefix, and
existing SSH key.

Step 4: Updating the ibm_catalog.json file
The ibm_catalog.json file is a manifest JSON file that is used to automatically import version information when you onboard to a private catalog.
Because you changed the deployable architecture, you created a brand new architecture for your needs. Update the following information in the
ibm_catalog.json file to reflect your changes.

For more information on the manifest file and what it contains, see Locally editing the catalog manifest .

Updating the product information
Now that you updated the configuration and created your own architecture, you must also update the name and the programmatic name. For the purposes
of this tutorial, update the name to Example Corps' architecture and the programmatic name to deploy-arch-example-corp .
1. Open the ibm_catalog.json file.
2. Find the label field and update the name of your deployable architecture to Example Corps' architecture .
3. Find the name field and update the programmatic name of your architecture to deploy-arch-example-corp .
Running secure workloads 51

4. Find the version field and enter 0.0.1 to update the version number.
5. Save the file.

Updating the configuration information
Now, you want to make sure that users of your new configuration must specify an existing SSH key and can deploy it from only US regions. To do so, update
the variable information in the configuration section of the ibm_catalog.json file.
1. In the configuration section of the ibm_catalog.json file, find the following variables and move them to the beginning of the configuration
section.
existing_ssh_key_name
ibmcloud_api_key
region
prefix

2. To require users to specify an existing_SSH_key , change the required field to true .
3. To restrict the regions to only US regions, you must add each region as an option for the region variable, for example:
{
"key": "region",
"type": "string",
"default_value": "__NOT_SET__",
"description": "Region where VPC is created. To find your VPC region, use `ibmcloud is regions` command to find
available regions.",
"required": true,
"custom_config": {},
"options": [
{
"displayname": "us-east",
"value": "us-east"
},
{
"displayname": "us-south",
"value": "us-south"
}
]
}

4. Delete the rest of the variables in the configuration section.
Note: When users deploy your architecture, they can choose between the region options that you listed. For a list of available regions, see
Regions.
5. Save the ibm_catalog.json file.

Step 5: Testing your deployable architecture
Before you onboard your configured deployable architecture to a private catalog and make it available for use, test your configuration to ensure that the
architecture runs as intended. To test your architecture with the Terraform command line, complete the following steps:
1. Create or update a .netrc file that is needed to use Terraform modules from the IBM Cloud. For more information, see ibmcloud catalog utility
netrc.
ibmcloud catalog utility netrc

2. Initialize the Terraform CLI. For more information, see Initializing Working Directories .
$ terraform init

3. Provision the resources. For more information, see Provisioning Infrastructure with Terraform.
a. Run terraform plan to generate a Terraform execution plan to preview the proposed actions.

Running secure workloads 52

$ terraform plan

b. Run terraform apply to create the resources that are defined in the plan.
$ terraform apply

Next steps
If your deployable architecture ran as expected, you successfully created your own deployable architecture from VSI on VPC landing zone. You are now
ready to move your updated files to the GitHub repository that you created and onboard your product to a private catalog .

Sharing your deployable architecture to your enterprise
This tutorial walks you through how to share a deployable architecture that you created from an IBM Cloud® pre-built deployable architecture. By
completing this tutorial, you learn about sending a share request, viewing the status of your share request, and sharing your deployable architecture.
When you send a share request to an enterprise, you are requesting to add the enterprise to an allowlist. After the enterprise accepts the request, you can
share individual products and deployable architectures to enterprise users who can create instances of any version that is in the ready state. A product is
in the ready state when it is validated and you've marked it as ready . Versions that are not validated are in the draft state and are not shared with
users. However, unvalidated draft versions are available to users who have access to the private catalog that contains the version.
Imagine you are a product manager for the fictitious company Example Corp. Your enterprise needs a deployable architecture to provide secure and
customizable compute resources for running your applications and services. You browse the IBM Cloud catalog and discover the VSI on VPC landing zone
option, a deployable architecture that provides the foundation that you need. However, your team of developers decided to modify the architecture to fully
meet your business needs. You name your new deployable architecture Example Corp architecture and onboarded it to the private catalog Example
Corp catalog . Now, you are ready to share Example Corp architecture to the rest of your enterprise account Example Corp enterprise .

This tutorial uses a fictitious scenario to help you learn and understand how to share a deployable architecture. As you complete the tutorial, adapt each
step to match your organization's needs.

Before you begin
1. You must be assigned the Publisher and Viewer access roles for the Catalog Management service to share products with other accounts. For more
information, see Assigning users access.
2. Verify that at least one version of your deployable architecture is validated and in the

Ready state. For more information, see Validating the version.

Step 1: Send a share request
To send a request to share deployable architectures and products to the enterprise, complete the following steps:
1. In the IBM Cloud console, click Manage > Catalogs > Private catalogs.
2. Select Example Corp catalog, which is where your deployable architecture is located.
3. Select Example Corp architecture .
4. Click Actions... > Share.
5. Review the list of affected versions. If you don't see the version that you want to share, make sure that the version is in the

ready state.

6. Select Share to this enterprise or account groups to see the enterprise and its account groups.
7. Select Example Corp enterprise to share to the enterprise and all account groups.
8. Click Share.
In the version list, the Visibility status is now Pending . Next, the enterprise needs to accept the share request. For more information, see Accepting share
requests for private catalog products.

Step 2: Check the share request status
You can check the share request status by completing the following steps:
1. In the IBM Cloud console, select Manage > Catalogs > Share requests.
2. Click Sent requests to show the table of all your requests.
If the enterprise accepted the request, the request state is Accepted .
If the enterprise denied the request, the request state is Rejected .
After the enterprise accepts the request, you need to share the deployable architecture to the enterprise. If your request is rejected, you will need to reach

Running secure workloads 53

out to the enterprise.

Step 3: Contact the enterprise
You need to complete this step only if your share request was rejected. Since you are part of the enterprise you are sharing to, you can reach out to the
enterprise owner to discuss the share request and discover if changes need to be made.
1. Log in to the enterprise account.
2. Click Manage > Enterprise > Accounts.
3. In the Accounts table, find the email of the owner of the enterprise account.
4. Send an email to the owner with details about the share request.

Step 4: Share your deployable architecture
Now that you have permission to share to the enterprise, you can share your deployable architecture. To share the deployable architecture, you need to
complete the same steps as sending a share request. To share the deployable architecture, complete the following steps:
1. In the IBM Cloud console, click Manage > Catalogs > Private catalogs.
2. Select Example Corp catalog, which is where your deployable architecture is located.
3. Select Example Corp architecture .
4. Click Actions... > Share.
5. Review the list of affected versions. If you don't see the version that you want to share, make sure that the version is in the

ready state.

6. Select Share to this enterprise or account groups to see the enterprise and its account groups.
7. Select Example Corp enterprise to share to the enterprise and all account groups.
8. Click Share.
In the version list, the Visibility status is now Shared .

Running secure workloads 54

Using projects to deploy a deployable architecture to multiple regions
This tutorial walks you through how to use projects to deploy two slightly different configurations of the same deployable architecture to two different
regions.
Imagine you are a member of the Example Corp enterprise. You discovered the VSI on VPC landing zone deployable architecture and want to use it for your
business. However, you need to deploy the deployable architecture to multiple regions for local data storage and performance or high availability reasons.
This tutorial uses a fictitious scenario to help you learn and understand how to use projects to deploy to multiple regions. As you complete the tutorial,
adapt each step to match your organization's needs.

Before you begin
1. Set up your IBM Cloud account .
2. Make sure you have the following access roles to create a project and permission to create the project tool resources within the account:
The Editor role on the IBM Cloud Projects service.
The Editor and Manager role on the IBM Cloud® Schematics service
The Viewer role on the resource group for the project
For more information about access and permissions, see Assigning users access to projects .
3. Set up an authentication method.
a. Create a Secrets Manager service instance in your IBM Cloud account. To create a secret, you must have the Writer role or higher on the
Secrets Manager service.
b. After you create your secret instance, make sure that you select Other secret type to add an arbitrary secret. For information about creating an
arbitrary secret, see Creating arbitrary secrets in the UI . Your arbitrary secret must contain the API key. The API key must be created in the
target account that you want to deploy to.
For more information, see Using an API key with Secrets Manager to authorize a project to deploy an architecture .

Step 1: Add a deployable architecture to a project
Before you can configure VSI on VPC landing zone, you need to find the deployable architecture in the IBM Cloud catalog and add it to a project.
1. In the IBM Cloud console, click Catalog.
2. Search for VSI on VPC landing zone and select the deployable architecture from the search results.
3. Select Review deployment options > Add to project to be redirected to the Projects space.
4. In the Name field, enter VSI on VPC landing zone regions to name the project.
5. Add the following description to your project: Project to manage the different configurations and deployments of VSI on VPC landing
zone.

6. Change the configuration name to landing-zone-us to indicate that you want to deploy the configuration in the US.
7. Select Dallas as the region where the project data is stored.
8. Keep Default for the resource group.
9. Click Create.
You successfully added the deployable architecture to a project and are ready to define the configuration.

Step 2: Configure the deployable architecture
1. In the Define details section, review the information.
2. From the Security tab in the Configure section, select API key using Secrets Manager as the authentication method.
3. Click Select from Secrets Manager .
4. Choose the service instance, secret group, and secret that you previously created in the before you begin steps.
5. Click Save.
6. During validation, a Code Risk Analyzer scan is run on your architecture. In the Security and compliance area, select Architecture default to use the
default controls that the owner of the deployable architecture added when they onboarded it. For more information about using Architecture default

Running secure workloads 55

controls, see Configuring the architecture.
7. Select the Required tab to enter values for the required fields for the deployable architecture configuration.
8. Enter existing_ssh_key_name in the ssh_public_key field to use an existing key.
9. Select us-south as the region to deploy the resources.
10. Enter us as the prefix to use for naming conventions.
11. Keep the Optional values as-is.
12. Click Save.
13. Click Validate. The modal that is displayed provides more details about your in-progress validation.
If the validation fails, you can troubleshoot the failure . Or, an administrator on the IBM Cloud Projects service can review the results through the
Schematics service and override the failure and approve the configuration to deploy anyway. However, make sure that the pipeline failed due to the
Code Risk Analyzer scan and not because of a validation or plan failure. It is not recommended to override a failure that is flagged due to a validation
or plan failure as the configuration cannot deploy successfully. For more information about security and compliance in projects, see Achieving
continuous compliance as an enterprise.
During the configuration and deployment process, monitor your Needs attention items. The widget reflects any issue that occurs in your configurations.

Step 3: Approve and deploy your first configuration
As an Editor on the IBM Cloud® Projects service, you can approve the configuration changes and deploy the configuration. It can be beneficial to deploy
your first configuration to make sure your changes work as expected. Then, if the deployment is successful, you can continue to create your second
configuration.
Tip: You must address any outstanding Needs attention items on the Overview tab before you can approve and deploy your configurations.
1. From the VSI on VPC landing zone regions project dashboard, select the Configurations tab of one of the configurations.
2. Click Edit > View last validation.
3. Add a comment with more details about the approval, and click Approve.
4. From the Configurations tab in your project, click the name of your deployable architecture configuration > Edit.
5. Review the input changes, click Deploy, and wait for the deployment to finish.

Step 4: Create an environment
If you successfully deployed your first configuration, you can now use it to create an environment to share values across configurations for easier
deployments. The properties that you add to an environment are automatically added to configurations that are using that environment. For more
information, see the benefits to using environments .
1. In the IBM Cloud console, click the Navigation menu icon

> Projects and select a project.

2. From the Manage tab, select Environments.
3. Click Create.
4. Name your environment VSI on VPC landing zone regions dev .
5. Click Add > Add from a configuration…
6. Select landing-zone-us to use the configuration you previously configured.
7. Since we want to keep the configuration the same but deploy to a different region, select all properties except

region and prefix .

8. Click Add > Save.

Step 5: Add a second deployable architecture to a project
Now that you created an environment, you can use it to configure the second deployable architecture.
1. From the VSI on VPC landing zone regions project dashboard, select the Configurations tab.
2. Click Create.
3. Select VSI on VPC landing zone from the catalog.
4. Click Review deployment options.
5. Click Add to project.
Running secure workloads 56

6. Make sure Add to existing is selected.
7. Choose VSI on VPC landing zone regions as the project.
8. Update the configuration name to landing-zone-eu to indicate that you want to deploy the configuration in Europe.
9. Select landing zone dev as the environment.
10. Click Add.

Step 6: Configure the second deployable architecture
1. From the Define details section, review the information and make sure the landing zone dev environment is selected.
2. From the Security tab in the Configure section, review the information that was pulled in from the environment that you created.
3. Select the Required tab to enter values for the region and prefix variables. The value for ssh_public_key is pulled in from the environment
that you created.
4. Select eu-de as the region to deploy resources.
5. Enter eu as the prefix to use for naming conventions.
6. Select the Optional tab to review the optional values that were pulled in from the environment.
7. Click Save.
8. Click Validate. The modal that is displayed provides more details about your in-progress validation.
If the validation fails, you can troubleshoot the failure . Or, an administrator on the IBM Cloud Projects service can review the results through the
Schematics service and override the failure and approve the configuration to deploy anyway. However, make sure that the pipeline failed due to the
Code Risk Analyzer scan and not because of a validation or plan failure. It is not recommended to override a failure that is flagged due to a validation
or plan failure as the configuration cannot deploy successfully. For more information about security and compliance in projects, see Achieving
continuous compliance as an enterprise.
During the configuration and deployment process, monitor your Needs attention items. The widget reflects any issue that occurs in your configurations.

Step 7: Approve and deploy your second configuration
After the validation completes, you can deploy your second configuration.
Tip: You must address any outstanding Needs attention items on the Overview tab before you can approve and deploy your configurations.
1. From the VSI on VPC landing zone regions project dashboard, select the Configurations tab of one of the configurations.
2. Click Edit > View last validation.
3. Add a comment with more details about the approval, and click Approve.
4. From the Configurations tab in your project, click the name of your deployable architecture configuration > Edit.
5. Review the input changes and click Deploy.
After the deployment successfully completes, you have two slightly different configurations based on a single deployable architecture that is deployed in
two separate regions.

Running secure workloads 57

Automating projects actions in your Git repository
In this tutorial, you learn how to set up a pipeline to trigger an update in your project when configuration changes are merged to the main branch in your
repository. By completing this tutorial, you learn how to automate common tasks in a project, such as validating a configuration, by using the pipelines and
toolchains of your choosing.
This is an experimental feature that is available for evaluation and testing purposes and might change without notice.
This tutorial focuses on a simple use case of updating a configuration in a project when changes are merged to the main branch in your repository, as
illustrated in the following image:

Automatically updating your project after changes are merged into your main branch

Since pipelines and toolchains are customizable, the principles in this tutorial can help you automate other common actions within a project, such as
validating and deploying configuration changes after they are merged to the main branch in your repository. This tutorial uses GitHub actions and
workflows to automate a pipeline between the repository and the project. As you complete the tutorial, adapt each step to match your repository's CI and
CD pipelines and processes.
Important: You can validate and deploy draft configurations only after they are merged to the branch in your repository that manages your CD
pipelines. You must also sync the updates from your repository into your project by updating configurations before you can validate and deploy
those configurations. You can automate this update by using the project.config.update API method (as described in this tutorial) or by using the
ibmcloud project config-update CLI command.

Before you begin
1. Make sure you have the Editor role on the IBM Cloud Projects service.
2. Complete the steps to connect your project to a Git repository . For the purposes of this tutorial, connect an empty project to a GitHub repository.

Step 1: Adding secrets and variables to GitHub
Create secrets and variables in the GitHub repository that you connected to your project. These secrets and variables are used in the GitHub workflow. Add
the following secrets and variables:
1. To authenticate with your project, you must include an IBM Cloud API key in your GitHub workflow. To keep the API key secure, complete the steps
to create a secret for a repository to save the API key as a secret in GitHub. For the purposes of this tutorial, name the secret

IBM_CLOUD_API_KEY .

2. Next, complete the steps to create configuration variables for your GitHub repository. Save the following variables:
Variable name

Value

Description

CONFIG_FOLDER_PATH

configs

The path to the repository folder that is connected to your project. This
folder contains the configuration files from your project.

IAM_URL

https://iam.cloud.ibm.com

The URL to Cloud Identity and Access Management.

PROJECTS_API_BASE_URL

https://projects.api.cloud.ibm.com

The URL to the projects API.

List of variables to save to your GitHub repository

Running secure workloads 58

Step 2: Creating a workflow in GitHub
Complete the steps to write a workflow in the GitHub repository that you connected to your project.
Tip: Get started with an example workflow file that you can modify as needed in GitHub.
You can customize the workflow with any number of jobs that you require. However, the following code needs to be included to successfully update
configurations in your project when changes are merged from a side branch into the main branch of your repository:
1. Add types: [closed] to the on section of the workflow to trigger the workflow when a pull request to the main branch is closed:
# Controls when the workflow will run
on:
# Triggers the workflow on push or pull request events but only for the "main" branch
# push:
#

branches: [ "main" ]

pull_request:
branches: [ "main" ]
types: [closed]

2. Add an if statement that triggers this workflow when changes are merged to the main branch:
jobs:
update-config:
if: github.event.pull_request.merged == true
runs-on: ubuntu-latest

3. Include the following code in the workflow so your repository can connect to your project, where

IBM_CLOUD_API_KEY is the name of the secret you

added to GitHub:
IAM_TOKEN=$(curl -X POST "https://iam.test.cloud.ibm.com/identity/token" \
-H "Content-Type: application/x-www-form-urlencoded" \
-H "Accept: application/json" \
-d "grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey=${{ secrets.IBM_CLOUD_API_KEY }}" | jq -r .access_token)

4. Include the following code to identify which configurations were edited:
# get files changed in the PR
changed_files=$(git diff --name-only HEAD^ HEAD)
echo "Changed files: $changed_files"
for file in $changed_files; do
# find config files that were changed
if [[ "${file}" == ${{ vars.CONFIG_FOLDER_PATH }}/* ]] && [ -s "${file}" ]; then
echo "Config file updated: ${file}"
# extract data from config files
PROJECT_ID=$(jq -r '.project_id' $file)
CONFIG_ID=$(jq -r '.config_id' $file)
DEF=$(jq '.definition' $file)
echo "Project ID: ${PROJECT_ID}"
echo "Config ID: ${CONFIG_ID}"

5. Include the following code to update the edited configurations in your project:
# update config definition
RESPONSE=$(curl -X PATCH "${BASE_URL}/v1/projects/${PROJECT_ID}/configs/${CONFIG_ID}" \
--header "Authorization: Bearer ${IAM_TOKEN}" \
--header "Accept: application/json" \
--header "Content-Type: application/json" \
--data "{ \"definition\": ${DEF} }")

Example workflow file
The following code snippet can be used as a template for your workflow file:
Running secure workloads 59

name: Projects Git Integration Workflow
# Controls when the workflow will run
on:
# Triggers the workflow on push or pull request events but only for the "main" branch
pull_request:
branches: [ "main" ]
types: [closed]
# Allows you to run this workflow manually from the Actions tab
workflow_dispatch:
jobs:
update-configs:
if: github.event.pull_request.merged == true
runs-on: ubuntu-latest
steps:
# Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
- uses: actions/checkout@v4
with:
fetch-depth: 0
- name: Update Project Configs
run: |
IAM_TOKEN=$(curl -X POST "${{ vars.IAM_URL }}/identity/token" \
-H "Content-Type: application/x-www-form-urlencoded" \
-H "Accept: application/json" \
-d "grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey=${{ secrets.IBM_CLOUD_API_KEY }}" | jq -r .access_token)
BASE_URL=${{ vars.PROJECTS_API_BASE_URL }}
# get files changed in the PR
changed_files=$(git diff --name-only HEAD^ HEAD)
echo "Changed files: $changed_files"
for file in $changed_files; do
# find config files that were changed
if [[ "${file}" == ${{ vars.CONFIG_FOLDER_PATH }}/* ]] && [ -s "${file}" ]; then
echo "Config file updated: ${file}"
# extract data from config files
PROJECT_ID=$(jq -r '.project_id' $file)
CONFIG_ID=$(jq -r '.config_id' $file)
DEF=$(jq '.definition' $file)
echo "Project ID: ${PROJECT_ID}"
echo "Config ID: ${CONFIG_ID}"
# update config definition
RESPONSE=$(curl -X PATCH "${BASE_URL}/v1/projects/${PROJECT_ID}/configs/${CONFIG_ID}" \
--header "Authorization: Bearer ${IAM_TOKEN}" \
--header "Accept: application/json" \
--header "Content-Type: application/json" \
--data "{ \"definition\": ${DEF} }")
echo $RESPONSE
ERR_CODE=$(echo $RESPONSE | jq '.code')
if [ "${ERR_CODE}" != "null" ]; then
exit 1
fi
else
echo "Not a project configuration file: ${file}"
fi
done

Step 3: Testing the workflow
Now that your workflow is created in GitHub, make sure that the workflow runs successfully by adding a configuration to the project. Complete the
following steps:

Running secure workloads 60

1. In the IBM Cloud console, click the Navigation menu icon

> Projects and select the project that is connected to your GitHub

repository.
2. Click Create to add a configuration to your project. Make sure to select a side branch where your configuration will be saved.
3. Edit the configuration. For example, add an authentication method in the Configure panel.
4. Select the side branch where you want to commit your changes.
5. Click Commit.
6. Go to your GitHub repository, and open a pull request to merge the side branch into the main branch of your repository.
7. Verify that your workflow runs when the side branch is merged into the main one. You can verify in the GitHub repository and the project:
a. In the GitHub repository, go to the Actions tab and select the workflow. Verify that the update ran successfully.
b. In your project, click the Options icon

> Edit for the configuration you added and switch to the main branch. Verify that your

update is applied. For example, the authentication method that you added earlier is included in the Configure panel.

Running secure workloads 61

Managing access
Assigning access
Assigning access to projects
Projects are controlled by IBM Cloud® Identity and Access Management (IAM). As an administrator on a project, you can grant users access to view and
edit projects, approve changes, and deploy or destroy configuration resources. Projects also requires authorization with other IBM Cloud services in order
for users to validate and deploy configurations.
Tip: Assigning users access to projects is different than authorizing a project to deploy into an account. To authorize a project to deploy, you can
use either a trusted profile or an API key in IBM Cloud Secrets Manager .

Actions and roles for the IBM Cloud Projects service
The following table includes the actions that users can take when they are assigned a specific role on the IBM Cloud Projects service. Review the following
information to make sure that you are assigning the correct level of access to your users.
Role

Definition

Project permissions

Viewer

Viewers can perform read-only actions within a project.

View a project (including
the project.json)
Find a project by using
Global Search

Operator

Operators can perform the same actions as viewers, with more permissions beyond the viewer role,
including planning project deployments

All viewer project
permissions
Validate a configuration
Edit a configuration

Editor

Editors can perform the same actions as operators, with more permissions beyond the operator role,
including creating projects and deploying resources.

All viewer and operator
project permissions
Create a project
Edit a project
Edit project settings
Delete a project
Create a configuration
Discard a draft
configuration
Approve configuration
changes
Deploy configuration
changes
Destroy resources
Create an environment
Edit an environment
Delete an environment

Running secure workloads 62

Administrator

Administrators can perform the same actions as editors, with more permissions beyond the editor
role, including updating project statuses and planning new or changed project deployments.

All viewer, operator, and
editor project
permissions
Force approve changes
that failed validation

Access roles for projects

In addition to access on the IBM Cloud Projects service, you must be assigned the following IAM privileges on the project tooling resources within the
account:
The Viewer role on the resource group for the project, which allows a resource group for the project to be selected to deploy the tooling services.

Assigning access in the console
To assign access to the IBM Cloud Projects service, complete the following steps:
1. In the IBM Cloud console, click Manage > Access (IAM), and then select Access groups.
2. Select the access group that you want to assign access to, then go to Access > Assign access.
3. For the service, select IBM Cloud Projects. Then, click Next.
4. Scope the access to All resources or Specific resources. Then, click Next.
5. Select any combination of roles or permissions, and click Next.
6. Optionally, add conditions to the policy. Then, click Review.
7. Click Add to add your policy configuration to your access summary.
8. Click Assign.
Tip: It's a best practice to assign access to an access group and then add users to the access group, instead of assigning access to users one by
one. However, you can assign access to a single user by going to Manage > Access (IAM) > Users and selecting the user you want to assign access
to. For more information, go to Setting up access groups .

Granting access between the Projects service and other IBM Cloud services
Before a project can validate or deploy configurations, the Projects service must be authorized in your account to communicate with other IBM Cloud
services. The following table lists the required authorizations. This authorization is only required once.
Tip: An IAM administrator or a user with the required roles on those services can automatically grant authorizations by creating a project in your
account, or they can create the service to service authorizations manually .

Role

Source

Target

Source account

Manager and Administrator

IBM Cloud Projects service

Schematics service

This account

Viewer

IBM Cloud Projects service

Resource group only

This account

All resource groups in the account
Viewer

IBM Cloud Projects service

Catalog Management service

This account

Viewer and SecretsReader

IBM Cloud Projects service

Secrets Manager service

This account

Projects service to service authorizations

Assigning access to catalogs
As the account owner, you assign users specific catalog management access depending on what tasks they are performing. To streamline the process of
assigning access, you can use access groups to organize a set of users into a single entity. That way, you can assign a single policy to the group one time,
and then add or remove users from the group as needed.
For more details, see Managing access in IBM Cloud .

Setting up your access groups in the console
Running secure workloads 63

See the following sections for details about creating your access groups and assigning specific IAM policies to each one.

Administrator access in the console
Administrator access is required for setting account-level filters to the IBM Cloud catalog.
1. Log in to your IBM Cloud account.
2. Go to Manage > Access (IAM) > Access groups in the IBM Cloud console.
3. Click Create.
4. Enter private-catalog-admins as the group name, and click Create.
5. Click Access > Assign access.
6. Select Catalog Management from the list of services.
7. Select the catalog that you want users to access.
8. In the Platform access section, select the Administrator role.
9. Click Add > Assign.

Editor access in the console
Editor access is required for creating private catalogs, setting filters at the private catalog level, adding your software to your private catalog, and updating,
deprecating, and restoring your software.
1. Go to Access groups, and click Create.
2. Enter private-catalog-editors as the group name, and click Create.
3. Click Access > Assign access.
4. Select Catalog Management from the list of services.
5. Select the catalog that you want users to access.
6. In the Platform access section, select the Editor role.
7. Click Add.
8. Select Kubernetes Service from the list of services.
9. Select your cluster, and then select the Administrator and Manager roles.
10. Click Add.
11. Select Schematics from the list of services.
12. Select the Manager role.
13. Click Add > Assign.

Viewer access in the console
Viewer access is required for viewing private catalogs, the filtered IBM Cloud catalog, and the filter settings.
1. Go to Access groups, and click Create.
2. Enter private-catalog-viewers as the group name, and click Create.
3. Click Access > Assign access.
4. Select Catalog Management from the list of services.
5. Select the catalog that you want users to access.
6. In the Platform access section, select the Viewer role.
7. Click Add > Assign.
You also need to have viewer access on the resource group to which your private catalog is assigned. You can assign your private catalog to a resource
group when you complete the steps for creating your private catalog. For more information, see Customizing the IBM Cloud catalog for all account users .
To assign viewer access to your private catalog's resource group, use the following steps:
1. Go to Users and select the user.
2. Select Access > Assign access.
3. Select All Identity and Access enabled services from the list of services.
4. Scope the access to Specific resources based on selected attributes, and select your private catalogs resource group.
5. For Platform access, select the Viewer role.
6. Click Add > Assign.

Running secure workloads 64

Add users to your access groups in the console
After you set up your access groups, complete the following steps to add users to the groups:
1. Go to Users, and click Invite users.
2. Specify the email addresses of the users. If you are inviting more than one user with a single invitation, they are all assigned the same access.
3. Select one of the three access groups you previously created, and click Add > Invite.
4. Repeat the steps to add users to your other access groups.
Or, you can give users access by adding trusted profiles to your access groups. For more information, see

What makes a good trusted profiles strategy?

and Creating trusted profiles .

Setting up your access groups by using the CLI
To assign access, run the ibmcloud iam user-policy-create command.

Administrator access by using the CLI
Run the following command to assign administrator access:
ibmcloud iam user-policy-create USER_NAME --roles Administrator --service-name globalcatalog-collection

Editor access by using the CLI
Run the following command to assign editor access:
ibmcloud iam user-policy-create USER_NAME --roles Editor --service-name globalcatalog-collection

Viewer access by using the CLI
Run the following command to set viewer access:
ibmcloud iam user-policy-create USER_NAME --roles Viewer --service-name globalcatalog-collection

Add users to your access groups by using the CLI
To add users to an access group by using the CLI, run the ibmcloud iam access-group-user-add command.
ibmcloud iam access-group-user-add GROUP_NAME USER_NAME [USER_NAME2...]

For example the following command adds user name@example.com to the example_group access group.
ibmcloud iam access-group-user-add example_group name@example.com

Or, you can give users access by adding trusted profiles to your access groups. For more information, see

What makes a good trusted profiles strategy?

and Creating trusted profiles .

Setting up your access groups by using the API
To assign access, call the IAM Policy Management API as shown in the follwing example. Replace the role_id vaiable with the role you want to assign:
Viewer , Editor , or Administrator .

Curl
curl -X POST 'https://iam.cloud.ibm.com/v1/policies' -H 'Authorization: Bearer $TOKEN' -H 'Content-Type: application/json' -d '{
"type": "access",
"description": "Editor role for SERVICE_NAME RESOURCE_NAME",
"subjects": [
{
"attributes": [
{
"name": "iam_id",
"value": "IBMid-123453user"
}
]
}
Running secure workloads 65

],
"roles":[
{
"role_id": "crn:v1:bluemix:public:iam::::role:Editor"
}
],
"resources":[
{
"attributes": [
{
"name": "accountId",
"value": "$ACCOUNT_ID"
},
{
"name": "serviceName",
"value": "$SERVICE_NAME"
},
{
"name": "resource",
"value": "$RESOURCE_NAME",
"operator": "stringEquals"
}
]
}
]
}'

Java
SubjectAttribute subjectAttribute = new SubjectAttribute.Builder()
.name("iam_id")
.value(EXAMPLE_USER_ID)
.build();
PolicySubject policySubjects = new PolicySubject.Builder()
.addAttributes(subjectAttribute)
.build();
PolicyRole policyRoles = new PolicyRole.Builder()
.roleId("crn:v1:bluemix:public:iam::::role:Viewer")
.build();
ResourceAttribute accountIdResourceAttribute = new ResourceAttribute.Builder()
.name("accountId")
.value(exampleAccountId)
.operator("stringEquals")
.build();
ResourceAttribute serviceNameResourceAttribute = new ResourceAttribute.Builder()
.name("serviceType")
.value("service")
.operator("stringEquals")
.build();
ResourceTag policyResourceTag = new ResourceTag.Builder()
.name("project")
.value("prototype")
.operator("stringEquals")
.build();
PolicyResource policyResources = new PolicyResource.Builder()
.addAttributes(accountIdResourceAttribute)
.addAttributes(serviceNameResourceAttribute)
.addTags(policyResourceTag)
.build();
CreatePolicyOptions options = new CreatePolicyOptions.Builder()
.type("access")
.subjects(Arrays.asList(policySubjects))
.roles(Arrays.asList(policyRoles))

Running secure workloads 66

.resources(Arrays.asList(policyResources))
.build();
Response<Policy> response = service.createPolicy(options).execute();
Policy policy = response.getResult();
System.out.println(policy);

Node
const policySubjects = [
{
attributes: [
{
name: 'iam_id',
value: exampleUserId,
},
],
},
];
const policyRoles = [
{
role_id: 'crn:v1:bluemix:public:iam::::role:Viewer',
},
];
const accountIdResourceAttribute = {
name: 'accountId',
value: exampleAccountId,
operator: 'stringEquals',
};
const serviceNameResourceAttribute = {
name: 'serviceType',
value: 'service',
operator: 'stringEquals',
};
const policyResourceTag = {
name: 'project',
operator: 'stringEquals',
value: 'prototype',
};
const policyResources = [
{
attributes: [accountIdResourceAttribute, serviceNameResourceAttribute],
tags: [policyResourceTag],
},
];
const params = {
type: 'access',
subjects: policySubjects,
roles: policyRoles,
resources: policyResources,
};
iamPolicyManagementService.createPolicy(params)
.then(res => {
examplePolicyId = res.result.id;
console.log(JSON.stringify(res.result, null, 2));
})
.catch(err => {
console.warn(err)
});

Python
policy_subjects = PolicySubject(
attributes=[SubjectAttribute(name='iam_id', value=example_user_id)])
policy_roles = PolicyRole(
role_id='crn:v1:bluemix:public:iam::::role:Viewer')
account_id_resource_attribute = ResourceAttribute(
name='accountId', value=example_account_id)
Running secure workloads 67

service_name_resource_attribute = ResourceAttribute(
name='serviceType', value='service')
policy_resource_tag = ResourceTag(
name='project', value='prototype')
policy_resources = PolicyResource(
attributes=[account_id_resource_attribute,
service_name_resource_attribute],
tags=[policy_resource_tag])
policy = iam_policy_management_service.create_policy(
type='access',
subjects=[policy_subjects],
roles=[policy_roles],
resources=[policy_resources]
).get_result()
print(json.dumps(policy, indent=2))

Go
subjectAttribute := &iampolicymanagementv1.SubjectAttribute{
Name:

core.StringPtr("iam_id"),

Value: &exampleUserID,
}
policySubjects := &iampolicymanagementv1.PolicySubject{
Attributes: []iampolicymanagementv1.SubjectAttribute{*subjectAttribute},
}
policyRoles := &iampolicymanagementv1.PolicyRole{
RoleID: core.StringPtr("crn:v1:bluemix:public:iam::::role:Viewer"),
}
accountIDResourceAttribute := &iampolicymanagementv1.ResourceAttribute{
Name:

core.StringPtr("accountId"),

Value:

core.StringPtr(exampleAccountID),

Operator: core.StringPtr("stringEquals"),
}
serviceNameResourceAttribute := &iampolicymanagementv1.ResourceAttribute{
Name:

core.StringPtr("serviceType"),

Value:

core.StringPtr("service"),

Operator: core.StringPtr("stringEquals"),
}
policyResourceTag := &iampolicymanagementv1.ResourceTag{
Name:

core.StringPtr("project"),

Value:

core.StringPtr("prototype"),

Operator: core.StringPtr("stringEquals"),
}
policyResources := &iampolicymanagementv1.PolicyResource{
Attributes: []iampolicymanagementv1.ResourceAttribute{
*accountIDResourceAttribute, *serviceNameResourceAttribute},
Tags: []iampolicymanagementv1.ResourceTag{*policyResourceTag},
}
options := iamPolicyManagementService.NewCreatePolicyOptions(
"access",
[]iampolicymanagementv1.PolicySubject{*policySubjects},
[]iampolicymanagementv1.PolicyRole{*policyRoles},
[]iampolicymanagementv1.PolicyResource{*policyResources},
)
policy, response, err := iamPolicyManagementService.CreatePolicy(options)
if err != nil {
panic(err)
}
b, _ := json.MarshalIndent(policy, "", "

")

fmt.Println(string(b))

Setting up access expected response
Curl
{
Running secure workloads 68

"id": "12345678-abcd-1a2b-a1b2-1234567890ab",
"type": "access",
"description": "Viewer role access for all instances of SERVICE_NAME in the account.",
"subjects": [
{
"attributes": [
{
"name": "iam_id",
"value": "IBMid-123453user"
}
]
}
],
"roles": [
{
"roles_id": "crn:v1:bluemix:public:iam::::role:Viewer"
}
],
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "ACCOUNT_ID",
"operator": "stringEquals"
},
{
"name": "serviceName",
"value": "SERVICE_NAME",
"operator": "stringEquals"
}
]
},
{
"tags": [
{
"name": "project",
"value": "moonshot",
"operator": "stringEquals"
},
{
"name": "pipeline",
"value": "test",
"operator": "stringEquals"
}
]
}
],
"href": "https://iam.cloud.ibm.com/v1/policies/12345678-abcd-1a2b-a1b2-1234567890ab",
"created_at": "2018-08-30T14:09:09.907Z",
"created_by_id": "USER_ID",
"last_modified_at": "2018-08-30T14:09:09.907Z",
"last_modified_by_id": "USER_ID",
"state": "active"
}

Java
{
"id": "12345678-abcd-1a2b-a1b2-1234567890ab",
"type": "access",
"description": "Viewer role access for all instances of SERVICE_NAME in the account.",
"subjects": [
{
"attributes": [
{
"name": "iam_id",
"value": "IBMid-123453user"
}
]

Running secure workloads 69

}
],
"roles": [
{
"roles_id": "crn:v1:bluemix:public:iam::::role:Viewer"
}
],
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "ACCOUNT_ID",
"operator": "stringEquals"
},
{
"name": "serviceName",
"value": "SERVICE_NAME",
"operator": "stringEquals"
}
]
},
{
"tags": [
{
"name": "project",
"value": "moonshot",
"operator": "stringEquals"
},
{
"name": "pipeline",
"value": "test",
"operator": "stringEquals"
}
]
}
],
"href": "https://iam.cloud.ibm.com/v1/policies/12345678-abcd-1a2b-a1b2-1234567890ab",
"created_at": "2018-08-30T14:09:09.907Z",
"created_by_id": "USER_ID",
"last_modified_at": "2018-08-30T14:09:09.907Z",
"last_modified_by_id": "USER_ID",
"state": "active"
}

Node
{
"id": "12345678-abcd-1a2b-a1b2-1234567890ab",
"type": "access",
"description": "Viewer role access for all instances of SERVICE_NAME in the account.",
"subjects": [
{
"attributes": [
{
"name": "iam_id",
"value": "IBMid-123453user"
}
]
}
],
"roles": [
{
"roles_id": "crn:v1:bluemix:public:iam::::role:Viewer"
}
],
"resources": [
{
"attributes": [
{

Running secure workloads 70

"name": "accountId",
"value": "ACCOUNT_ID",
"operator": "stringEquals"
},
{
"name": "serviceName",
"value": "SERVICE_NAME",
"operator": "stringEquals"
}
]
},
{
"tags": [
{
"name": "project",
"value": "moonshot",
"operator": "stringEquals"
},
{
"name": "pipeline",
"value": "test",
"operator": "stringEquals"
}
]
}
],
"href": "https://iam.cloud.ibm.com/v1/policies/12345678-abcd-1a2b-a1b2-1234567890ab",
"created_at": "2018-08-30T14:09:09.907Z",
"created_by_id": "USER_ID",
"last_modified_at": "2018-08-30T14:09:09.907Z",
"last_modified_by_id": "USER_ID",
"state": "active"
}

Python
{
"id": "12345678-abcd-1a2b-a1b2-1234567890ab",
"type": "access",
"description": "Viewer role access for all instances of SERVICE_NAME in the account.",
"subjects": [
{
"attributes": [
{
"name": "iam_id",
"value": "IBMid-123453user"
}
]
}
],
"roles": [
{
"roles_id": "crn:v1:bluemix:public:iam::::role:Viewer"
}
],
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "ACCOUNT_ID",
"operator": "stringEquals"
},
{
"name": "serviceName",
"value": "SERVICE_NAME",
"operator": "stringEquals"
}
]
},

Running secure workloads 71

{
"tags": [
{
"name": "project",
"value": "moonshot",
"operator": "stringEquals"
},
{
"name": "pipeline",
"value": "test",
"operator": "stringEquals"
}
]
}
],
"href": "https://iam.cloud.ibm.com/v1/policies/12345678-abcd-1a2b-a1b2-1234567890ab",
"created_at": "2018-08-30T14:09:09.907Z",
"created_by_id": "USER_ID",
"last_modified_at": "2018-08-30T14:09:09.907Z",
"last_modified_by_id": "USER_ID",
"state": "active"
}

Go
{
"id": "12345678-abcd-1a2b-a1b2-1234567890ab",
"type": "access",
"description": "Viewer role access for all instances of SERVICE_NAME in the account.",
"subjects": [
{
"attributes": [
{
"name": "iam_id",
"value": "IBMid-123453user"
}
]
}
],
"roles": [
{
"roles_id": "crn:v1:bluemix:public:iam::::role:Viewer"
}
],
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "ACCOUNT_ID",
"operator": "stringEquals"
},
{
"name": "serviceName",
"value": "SERVICE_NAME",
"operator": "stringEquals"
}
]
},
{
"tags": [
{
"name": "project",
"value": "moonshot",
"operator": "stringEquals"
},
{
"name": "pipeline",
"value": "test",
"operator": "stringEquals"

Running secure workloads 72

}
]
}
],
"href": "https://iam.cloud.ibm.com/v1/policies/12345678-abcd-1a2b-a1b2-1234567890ab",
"created_at": "2018-08-30T14:09:09.907Z",
"created_by_id": "USER_ID",
"last_modified_at": "2018-08-30T14:09:09.907Z",
"last_modified_by_id": "USER_ID",
"state": "active"
}

Add users to your access groups by using the API
To add users to an access group by using the API, call the IAM Access Groups API as shown in the following example.
Curl
curl -X PUT -H "Authorization: {iam_token}" -H "Accept: application/json" -H "Content-Type: application/json" -d '{"members": [
{"iam_id": "IBMid-user1", "type": "user"}, {"iam_id": "iam-ServiceId-123", "type": "service"} ]}' "
{base_url}/groups/{access_group_id}/members"

Java
AddGroupMembersRequestMembersItem member1 = new AddGroupMembersRequestMembersItem.Builder()
.iamId("IBMid-user1")
.type("user")
.build();
AddGroupMembersRequestMembersItem member2 = new AddGroupMembersRequestMembersItem.Builder()
.iamId("iam-ServiceId-123")
.type("service")
.build();
AddMembersToAccessGroupOptions addMembersToAccessGroupOptions = new AddMembersToAccessGroupOptions.Builder()
.accessGroupId(testGroupId)
.addMembers(member1)
.addMembers(member2)
.build();
Response<AddGroupMembersResponse> response = service.addMembersToAccessGroup(addMembersToAccessGroupOptions).execute();
AddGroupMembersResponse addGroupMembersResponse = response.getResult();
System.out.println(addGroupMembersResponse);

Node
const groupMember1 = {
iam_id: 'IBMid-user1',
type: 'user',
};
const groupMember2 = {
iam_id: 'iam-ServiceId-123',
type: 'service',
};
const params = {
accessGroupId: testGroupId,
members: [groupMember1, groupMember2],
};
iamAccessGroupsService.addMembersToAccessGroup(params)
.then(res => {
console.log(JSON.stringify(res.result, null, 2));
})
.catch(err => {
console.warn(err)
});

Python
member1 = AddGroupMembersRequestMembersItem(

Running secure workloads 73

iam_id='IBMid-user1', type='user')
member2 = AddGroupMembersRequestMembersItem(
iam_id='iam-ServiceId-123', type='service')
members = [member1, member2]
add_group_members_response = iam_access_groups_service.add_members_to_access_group(
access_group_id=test_group_id,
members=members
).get_result()
print(json.dumps(add_group_members_response, indent=2))

Go
groupMembers := []iamaccessgroupsv2.AddGroupMembersRequestMembersItem{
iamaccessgroupsv2.AddGroupMembersRequestMembersItem{
IamID: core.StringPtr("IBMid-user1"),
Type:

core.StringPtr("user"),

},
iamaccessgroupsv2.AddGroupMembersRequestMembersItem{
IamID: core.StringPtr("iam-ServiceId-123"),
Type:

core.StringPtr("service"),

},
}
addMembersToAccessGroupOptions := iamAccessGroupsService.NewAddMembersToAccessGroupOptions(testGroupID)
addMembersToAccessGroupOptions.SetMembers(groupMembers)
addGroupMembersResponse, response, err := iamAccessGroupsService.AddMembersToAccessGroup(addMembersToAccessGroupOptions)
if err != nil {
panic(err)
}
b, _ := json.MarshalIndent(addGroupMembersResponse, "", "

")

fmt.Println(string(b))

Or, you can give users access by adding trusted profiles to your access groups. For more information, see

What makes a good trusted profiles strategy?

and Creating trusted profiles .

Adding users expected response
Curl
{
"members": [
{
"iam_id": "$IBM_ID",
"type": "user",
"created_at": "2019-01-01T01:01:00Z",
"created_by_id": "CREATOR_ID",
"status_code": 200
},
{
"iam_id": "$SERVICE_ID",
"status_code": 400,
"trace": "12345678-abcd-1a2b-a1b2-1234567890ab",
"errors": [
{
"code": "error_occurred",
"message": "The service id is missing or incorrect"
}
]
}
]
}

Java
{
"members": [
{
"iam_id": "$IBM_ID",
Running secure workloads 74

"type": "user",
"created_at": "2019-01-01T01:01:00Z",
"created_by_id": "CREATOR_ID",
"status_code": 200
},
{
"iam_id": "$SERVICE_ID",
"status_code": 400,
"trace": "12345678-abcd-1a2b-a1b2-1234567890ab",
"errors": [
{
"code": "error_occurred",
"message": "The service id is missing or incorrect"
}
]
}
]
}

Node
{
"members": [
{
"iam_id": "$IBM_ID",
"type": "user",
"created_at": "2019-01-01T01:01:00Z",
"created_by_id": "CREATOR_ID",
"status_code": 200
},
{
"iam_id": "$SERVICE_ID",
"status_code": 400,
"trace": "12345678-abcd-1a2b-a1b2-1234567890ab",
"errors": [
{
"code": "error_occurred",
"message": "The service id is missing or incorrect"
}
]
}
]
}

Python
{
"members": [
{
"iam_id": "$IBM_ID",
"type": "user",
"created_at": "2019-01-01T01:01:00Z",
"created_by_id": "CREATOR_ID",
"status_code": 200
},
{
"iam_id": "$SERVICE_ID",
"status_code": 400,
"trace": "12345678-abcd-1a2b-a1b2-1234567890ab",
"errors": [
{
"code": "error_occurred",
"message": "The service id is missing or incorrect"
}
]
}
]
}

Running secure workloads 75

Go
{
"members": [
{
"iam_id": "$IBM_ID",
"type": "user",
"created_at": "2019-01-01T01:01:00Z",
"created_by_id": "CREATOR_ID",
"status_code": 200
},
{
"iam_id": "$SERVICE_ID",
"status_code": 400,
"trace": "12345678-abcd-1a2b-a1b2-1234567890ab",
"errors": [
{
"code": "error_occurred",
"message": "The service id is missing or incorrect"
}
]
}
]
}

Add users to your access groups by using Terraform
Before you can add users to your access groups by using Terraform, make sure that you have completed the following:
Install the Terraform CLI and configure the IBM Cloud Provider plug-in for Terraform. For more information, see the tutorial for

Getting started with

Terraform on IBM Cloud®. The plug-in abstracts the IBM Cloud APIs that are used to complete this task.
Create a Terraform configuration file that is named main.tf . In this file, you define resources by using HashiCorp Configuration Language. For more
information, see the Terraform documentation.
Use the following steps to add users to your access groups
1. In your Terraform configuration file, find the Terraform code that you used to create the access group and note the access_group_id assigned to
your access group.
2. Add a member to the access group.
resource "ibm_iam_access_group_members" "accgroupmem" {
access_group_id = ibm_iam_access_group.accgroup.id
ibm_ids = ["test@in.ibm.com"]
}

For more information, see the argument reference details on the Terraform Identity and Access Management (IAM) page.
3. After you finish building your configuration file, initialize the Terraform CLI. For more information, see Initializing Working Directories .
$ terraform init

4. Provision the resources from the main.tf file. For more information, see Provisioning Infrastructure with Terraform.
a. Run terraform plan to generate a Terraform execution plan to preview the proposed actions.
$ terraform plan

b. Run terraform apply to create the resources that are defined in the plan.
$ terraform apply

Controlling context-based restrictions
Creating context-based restrictions
Context-based restrictions allow you to manage user and service access to specific cloud resources. You can define restrictions to the resources based on
Running secure workloads 76

contexts, such as network zones and endpoint types. For more information, see What are context-based restrictions .
Note: User and account-level IP address restrictions can also affect users' ability to access resources. You can view account-level IP address
restrictions on the Settings page. To view individual user settings, go to the Users page and view each user's IP address restrictions in the details
tab.

Before you begin
To complete rule actions, you must be assigned an Identity and Access Management (IAM) policy on the target service.
To complete network zone actions, you must be assigned an IAM policy on the context-based restrictions service.
For more information, see Context-based restrictions roles and actions .

Creating network zones
By creating network zones, you establish a list of allowed locations where an access request originates. A set of one or more network locations can be
specified by IP addresses such as individual addresses, ranges or subnets, and VPC IDs. After you create a network zone, you can add it to a rule.
To create a network zone, complete the following steps.
1. In the IBM Cloud console, click Manage > Context-based restrictions, and select Network zones.
2. Click Create.
Note: Instead of creating a zone by using UI inputs, you can use the JSON code form to directly enter JSON to create a zone by clicking

Enter

as JSON code.
3. Enter a unique name and a description.
4. Enter the allowed IP addresses where an access request can originate. Include IP address exceptions in the deny list, if necessary.
5. Enter the allowed VPCs.
Important: If you want to allow access from the VPC to public endpoints in your rule, include any public gateway IP addresses in the zone
definition along with the VPC.
6. Reference a service. Select the service type and then select a service. Click Add to associate the service's IP addresses with your network zone.
Tip: If you're not sure what the service type is, view the table Services integrated with context-based restrictions.
7. Click Next to review your network zone.
8. Click Create.
You can continue by creating more network zones, or by creating rules.

Creating network zones by using the CLI
By creating network zones, you establish a list of allowed locations where an access request originates. A set of one or more network locations can be
specified by IP addresses such as individual addresses, ranges or subnets, and VPC IDs. After you create a network zone, you can add it to a rule.
1. Install the Context-based restrictions CLI plug-in by running the following command:
$ ibmcloud plugin install cbr

2. To create a network zone, use the cbr zone-create command.
The following example creates a network zone with a list of allowed network locations.
$ ibmcloud cbr zone-create --name example-zone --description "Example zone description" --addresses 192.0.2.1,192.2.3.5192.2.3.10

The following example creates a network zone with a service reference. For more information, see Service references.
$ ibmcloud cbr zone-create --name example-zone-1 --description "Kube zone" --service-ref service_name=containers-kubernetes
Running secure workloads 77

Tip: To find a list of available service references, run the ibmcloud cbr service-ref-targets command.

Creating network zones by using the API
By creating network zones, you establish a list of allowed locations where an access request originates. A set of one or more network locations can be
specified by IP addresses such as individual addresses, ranges or subnets, VPC IDs, and service references. After you create a network zone, you can add it
to a rule.
To create a network zone, call the Context-based restrictions API as shown in the following example:
Curl
curl -X POST --location --header "Authorization: Bearer {iam_token}" --header "Accept: application/json" --header "Content-Type:
application/json" --data '{ "name": "an example of zone", "description": "this is an example of zone", "account_id":
"12ab34cd56ef78ab90cd12ef34ab56cd", "addresses": [ { "type": "ipAddress", "value": "169.23.56.234" }, { "type": "ipRange",
"value": "169.23.22.0-169.23.22.255" }, { "type": "subnet", "value": "192.0.2.0/24" }, { "type": "vpc", "value":
"crn:v1:bluemix:public:is:us-south:a/12ab34cd56ef78ab90cd12ef34ab56cd::vpc:r134-d98a1702-b39a-449a-86d4-ef8dbacf281e" }, {
"type": "serviceRef", "ref": { "account_id": "12ab34cd56ef78ab90cd12ef34ab56cd", "service_name": "cloud-object-storage" } } ],
"excluded": [ { "type": "ipAddress", "value": "169.23.22.127" } ] }' "{base_url}/v1/zones"

Java
AddressIPAddress ipAddressModel = new AddressIPAddress.Builder()
.type("ipAddress")
.value("169.23.56.234")
.build();
AddressIPAddressRange ipRangeAddressModel = new AddressIPAddressRange.Builder()
.type("ipRange")
.value("169.23.22.0-169.23.22.255")
.build();
AddressSubnet subnetAddressModel = new AddressSubnet.Builder()
.type("subnet")
.value("192.0.2.0/24")
.build();
AddressVPC vpcAddressModel = new AddressVPC.Builder()
.type("vpc")
.value(vpcCRN)
.build();
ServiceRefValue serviceRefValueModel = new ServiceRefValue.Builder()
.accountId(accountID)
.serviceName("cloud-object-storage")
.build();
AddressServiceRef serviceRefAddressModel = new AddressServiceRef.Builder()
.type("serviceRef")
.ref(serviceRefValueModel)
.build();
AddressIPAddress excludedIPAddressModel = new AddressIPAddress.Builder()
.type("ipAddress")
.value("169.23.22.127")
.build();
CreateZoneOptions createZoneOptions = new CreateZoneOptions.Builder()
.name("an example of zone")
.accountId(accountID)
.description("this is an example of zone")
.addresses(java.util.Arrays.asList(ipAddressModel, ipRangeAddressModel, subnetAddressModel, vpcAddressModel,
serviceRefAddressModel))
.excluded(java.util.Arrays.asList(excludedIPAddressModel))
.build();
Response<Zone> response = contextBasedRestrictionsService.createZone(createZoneOptions).execute();
Zone zone = response.getResult();
System.out.println(zone);

Node
// Request models needed by this operation.

Running secure workloads 78

// AddressIPAddress
const ipAddressModel = {
type: 'ipAddress',
value: '169.23.56.234',
};
// AddressIPAddressRange
const ipRangeAddressModel = {
type: 'ipRange',
value: '169.23.22.0-169.23.22.255',
};
// AddressSubnet
const subnetAddressModel = {
type: 'subnet',
value: '192.0.2.0/24',
};
// AddressVPC
const vpcAddressModel = {
type: 'vpc',
value: vpcCRN,
};
// AddressServiceRef
const serviceRefAddressModel = {
type: 'serviceRef',
ref: {
account_id: accountId,
service_name: 'cloud-object-storage',
},
};
// AddressIPAddress
const excludedIPAddressModel = {
type: 'ipAddress',
value: '169.23.22.127',
};
const params = {
name: 'an example of zone',
accountId,
addresses: [ipAddressModel, ipRangeAddressModel, subnetAddressModel, vpcAddressModel, serviceRefAddressModel],
excluded: [excludedIPAddressModel],
description: 'this is an example of zone',
};
try {
const res = await contextBasedRestrictionsService.createZone(params);
zoneId = res.result.id;
zoneRev = res.headers.etag;
console.log(JSON.stringify(res.result, null, 2));
} catch (err) {
console.warn(err);
}

Python
ip_address_model = {
'type': 'ipAddress',
'value': '169.23.56.234',
}
ip_range_address_model = {
'type': 'ipRange',
'value': '169.23.22.0-169.23.22.255',
}
subnet_address_model = {
'type': 'subnet',
'value': '192.0.2.0/24',
}
vpc_address_model = {
'type': 'vpc',
'value': vpc_crn,
}
service_ref_address_model = {

Running secure workloads 79

'type': 'serviceRef',
'ref': {
'account_id': account_id,
'service_name': 'cloud-object-storage',
}
}
excluded_ip_address_model = {
'type': 'ipAddress',
'value': '169.23.22.127',
}
zone = context_based_restrictions_service.create_zone(
name='an example of zone',
account_id=account_id,
addresses=[ip_address_model, ip_range_address_model, subnet_address_model, vpc_address_model, service_ref_address_model],
excluded=[excluded_ip_address_model],
description='this is an example of zone',
).get_result()
print(json.dumps(zone, indent=2))

Go
ipAddressModel := &contextbasedrestrictionsv1.AddressIPAddress{
Type:

core.StringPtr("ipAddress"),

Value: core.StringPtr("169.23.56.234"),
}
ipRangeAddressModel := &contextbasedrestrictionsv1.AddressIPAddressRange{
Type:

core.StringPtr("ipRange"),

Value: core.StringPtr("169.23.22.0-169.23.22.255"),
}
subnetAddressModel := &contextbasedrestrictionsv1.AddressSubnet{
Type:

core.StringPtr("subnet"),

Value: core.StringPtr("192.0.2.0/24"),
}
vpcAddressModel := &contextbasedrestrictionsv1.AddressVPC{
Type:

core.StringPtr("vpc"),

Value: core.StringPtr(vpcCRN),
}
serviceRefAddressModel := &contextbasedrestrictionsv1.AddressServiceRef{
Type: core.StringPtr("serviceRef"),
Ref: &contextbasedrestrictionsv1.ServiceRefValue{
AccountID:

core.StringPtr(accountID),

ServiceName: core.StringPtr("cloud-object-storage"),
},
}
excludedIPAddressModel := &contextbasedrestrictionsv1.AddressIPAddress{
Type:

core.StringPtr("ipAddress"),

Value: core.StringPtr("169.23.22.127"),
}
createZoneOptions := contextBasedRestrictionsService.NewCreateZoneOptions()
createZoneOptions.SetName("an example of zone")
createZoneOptions.SetAccountID(accountID)
createZoneOptions.SetDescription("this is an example of zone")
createZoneOptions.SetAddresses([]contextbasedrestrictionsv1.AddressIntf{ipAddressModel, ipRangeAddressModel, subnetAddressModel,
vpcAddressModel, serviceRefAddressModel})
createZoneOptions.SetExcluded([]contextbasedrestrictionsv1.AddressIntf{excludedIPAddressModel})
zone, response, err := contextBasedRestrictionsService.CreateZone(createZoneOptions)
if err != nil {
panic(err)
}
b, _ := json.MarshalIndent(zone, "", "

")

fmt.Println(string(b))

Tip: To find a list of available service references, call the ListAvailableServicerefTargets method.

Running secure workloads 80

Creating network zones by using Terraform
By creating network zones, you establish a list of allowed locations where an access request originates. A set of one or more network locations can be
specified by IP addresses such as individual addresses, ranges or subnets, VPC IDs, and service references. After you create a network zone, you can add it
to a rule.
To create a network zone, use the Terraform resource cbr_zone.
1. To install the Terraform CLI and configure the IBM Cloud Provider plug-in for Terraform, follow the tutorial for

Getting started with Terraform on IBM

Cloud®. The plug-in abstracts the IBM Cloud APIs that are used to complete this task.
2. Create a Terraform configuration file that is named main.tf . In this file, you add the configuration to create a network zone by using HashiCorp
Configuration Language. For more information, see the Terraform documentation.
The following example creates a network zone that allows a single IP address and explicitly excludes a signle IP address.
resource "ibm_cbr_zone" "cbr_zone" {
account_id = "12ab34cd56ef78ab90cd12ef34ab56cd"
addresses {
type = "ipAddress"
value = "169.23.56.234"
}
description = "this is an example of zone"
excluded {
type = "ipAddress"
value = "202.38.89.897"
}
name = "an example of zone"
}

Creating rules
Define restrictions to your cloud resources by creating rules.
To create a rule, complete the following steps.
1. In the IBM Cloud console, click Manage > Context-based restrictions, and select Rules.
2. Click Create.
3. Select the service that you want to target in your rule. Then, click Next.
Note: When you create context-based restriction for the IAM Access Groups service, users who don't satisfy the rule can't view any groups in
the account, including the public access group.
4. (Optional) Select the scope of APIs whose operations are restricted by your rule. For more information, see

Defining the scope of a rule .

Note: Not all services support the ability to scope a rule by API.
5. Scope the restriction to All resources or Specific resources based on selected attributes.
6. Click Review > Continue.
7. Add one or more contexts. Select endpoint types and network zones, and click Add.
By default, access is allowed from all service-supported endpoint types when the toggle is set to No. Set the toggle to Yes to allow only specific
endpoint types.
Important: If you want to allow access from a VPC to public endpoints in your rule, include any public gateway IP addresses in the zone
definition along with the VPC.
You can add existing network zones to your rule or create new zones to add to your rule. For more information, see

Creating network zones .

8. Click Continue.
9. Provide a unique description.
10. Select how you want to enforce the rule. You can decide how you want to enforce a rule upon creation and update the rule enforcement at any time.
Running secure workloads 81

Enable: Enforce the rule. Denied access attempts are reported in Activity Tracker.
Disable: Don't enforce the rule. Restrictions don't apply to your account resources. Select this option if you're not ready to enable the rule.
Report-only: Monitor how the rule affects users without enforcing it. All attempts to access resources in the account are logged in Activity
Tracker. Monitoring is recommended for 30 days before you enforce the rule.
11. Click Create.

Creating rules by using the CLI
To define restrictions to your cloud resources by creating rules, use the ibmcloud cbr rule-create command. The following example creates a rule that
targets the Kubernetes Service and allows only private endpoints from the specified network zone to access the service.
$ ibmcloud cbr rule-create --description 'Example Rule Description' --service-name kms --context-attributes endpointType=private
--zone-id 93de8d3f588ab2c457ff576c364d1145 --enforcement-mode report

Tip: For the enforcement-mode option, the CLI accepts the values enabled , disabled , and report . If no enforcement is specified, the rule is
enabled by default. For more informaiton, see Rule enforcement.

Creating rules by using the API
To create restrictions to your cloud resources by creating rules, call the Context-based restrictions API. The following example creates an enabled rule
that targets the Kubernetes Service and allows requests only from the specified network zone to access the service.
Curl
curl -X POST --location --header "Authorization: Bearer {iam_token}" --header "Accept: application/json" --header "Content-Type:
application/json" --data '{ "description": "this is an example of rule", "resources": [ { "attributes": [ { "name": "accountId",
"value": "12ab34cd56ef78ab90cd12ef34ab56cd" }, { "name": "serviceName", "value": "kms" } ] } ], "contexts": [ { "attributes": [ {
"name": "networkZoneId", "value": "65810ac762004f22ac19f8f8edf70a34" } ] } ], "enforcement_mode": "enabled" }' "
{base_url}/v1/rules"

Java
RuleContextAttribute ruleContextAttributeModel = new RuleContextAttribute.Builder()
.name("networkZoneId")
.value(zoneID)
.build();
RuleContext ruleContextModel = new RuleContext.Builder()
.attributes(java.util.Arrays.asList(ruleContextAttributeModel))
.build();
ResourceAttribute resourceAttributeModelAccountID = new ResourceAttribute.Builder()
.name("accountId")
.value(accountID)
.build();
ResourceAttribute resourceAttributeModelServiceName = new ResourceAttribute.Builder()
.name("serviceName")
.value(serviceName)
.build();
ResourceTagAttribute resourceTagAttributeModel = new ResourceTagAttribute.Builder()
.name("tagName")
.value("tagValue")
.build();
Resource resourceModel = new Resource.Builder()
.addAttributes(resourceAttributeModelAccountID)
.addAttributes(resourceAttributeModelServiceName)
.tags(java.util.Arrays.asList(resourceTagAttributeModel))
.build();
CreateRuleOptions createRuleOptions = new CreateRuleOptions.Builder()
.description("this is an example of rule")
.addContexts(ruleContextModel)
.addResources(resourceModel)
.enforcementMode("enabled")
.build();
Response<Rule> response = contextBasedRestrictionsService.createRule(createRuleOptions).execute();
Rule rule = response.getResult();

Running secure workloads 82

System.out.println(rule);
ruleID = rule.getId();
ruleRev = response.getHeaders().values("Etag").get(0);

Node
// Request models needed by this operation.
// RuleContextAttribute
const ruleContextAttributeModel = {
name: 'networkZoneId',
value: zoneId,
};
// RuleContext
const ruleContextModel = {
attributes: [ruleContextAttributeModel],
};
// ResourceAttribute
const resourceAttributeAccountIdModel = {
name: 'accountId',
value: accountId,
};
// Resource Attribute
const resourceAttributeServiceNameModel = {
name: 'serviceName',
value: serviceName,
operator: 'stringEquals',
};
// Resource
const resourceModel = {
attributes: [resourceAttributeAccountIdModel, resourceAttributeServiceNameModel],
};
const params = {
contexts: [ruleContextModel],
resources: [resourceModel],
description: 'this is an example of rule',
enforcementMode: 'enabled',
};
try {
const res = await contextBasedRestrictionsService.createRule(params);
ruleId = res.result.id;
ruleRev = res.headers.etag;
console.log(JSON.stringify(res.result, null, 2));
} catch (err) {
console.warn(err);
}

Python
rule_context_attribute_model = {
'name': 'networkZoneId',
'value': zone_id,
}
rule_context_model = {
'attributes': [rule_context_attribute_model],
}
resource_attribute_account_id_model = {
'name': 'accountId',
'value': account_id,
}
resource_attribute_service_name_model = {
Running secure workloads 83

'name': 'serviceName',
'value': service_name,
}
resource_model = {
'attributes': [resource_attribute_account_id_model, resource_attribute_service_name_model],
}
rule = context_based_restrictions_service.create_rule(
contexts=[rule_context_model],
resources=[resource_model],
description='this is an example of rule',
enforcement_mode='enabled'
).get_result()
print(json.dumps(rule, indent=2))

Go
ruleContextAttributeModel := &contextbasedrestrictionsv1.RuleContextAttribute{
Name:

core.StringPtr("networkZoneId"),

Value: core.StringPtr(zoneID),
}
ruleContextModel := &contextbasedrestrictionsv1.RuleContext{
Attributes: []contextbasedrestrictionsv1.RuleContextAttribute{*ruleContextAttributeModel},
}
resourceModel := &contextbasedrestrictionsv1.Resource{
Attributes: []contextbasedrestrictionsv1.ResourceAttribute{
{
Name:

core.StringPtr("accountId"),

Value: core.StringPtr(accountID),
},
{
Name:

core.StringPtr("serviceName"),

Value: core.StringPtr(serviceName),
},
},
Tags: []contextbasedrestrictionsv1.ResourceTagAttribute{
{
Name:

core.StringPtr("tagName"),

Value: core.StringPtr("tagValue"),
},
},
}
createRuleOptions := contextBasedRestrictionsService.NewCreateRuleOptions()
createRuleOptions.SetDescription("this is an example of rule")
createRuleOptions.SetContexts([]contextbasedrestrictionsv1.RuleContext{*ruleContextModel})
createRuleOptions.SetResources([]contextbasedrestrictionsv1.Resource{*resourceModel})
createRuleOptions.SetEnforcementMode(contextbasedrestrictionsv1.CreateRuleOptionsEnforcementModeEnabledConst)
rule, response, err := contextBasedRestrictionsService.CreateRule(createRuleOptions)
if err != nil {
panic(err)
}
b, _ := json.MarshalIndent(rule, "", "

")

fmt.Println(string(b))

Creating rules by using Terraform
To define restrictions to your cloud resources by creating rules, use the Terraform resource

cbr_rule.

1. To install the Terraform CLI and configure the IBM Cloud Provider plug-in for Terraform, follow the tutorial for

Getting started with Terraform on IBM

Cloud®. The plug-in abstracts the IBM Cloud APIs that are used to complete this task.
2. Create a Terraform configuration file that is named main.tf . In this file, you add the configuration to create a context-based restrictions rule by
using HashiCorp Configuration Language. For more information, see the Terraform documentation.
The following example creates a rule that targets a specific Kubernetes Service API and allows only private endpoints from the specified network
Running secure workloads 84

zone to call the operations associated with that API.
resource "ibm_cbr_rule" "cbr_rule" {
contexts {
attributes {
name = "endpointType"
value = "private"
}
}
description = "this is an example of rule"
enforcement_mode = "enabled"
operations {
api_types {
api_type_id = "api_type_id"
}
}
resources {
attributes {
name = "serviceName"
value = "containers-kubernetes"
operator = "equals"
}
}
}

Managing context-based restrictions
You can manage context rules at any time by updating the description, which helps identifying the purpose of the rule, or selecting a new list of resources
and network environments. You can also remove context-based restrictions to delete restrictions that are defined by the contexts in a rule.
Context-based restrictions can define and enforce access restrictions for its own IBM Cloud® resources. You can define these restrictions based on
contexts, such as network zones and endpoint types. For more information, see What are context-based restrictions .
The context-based restriction service manages rules and network zones, so it is possible to lose all ability to manage these resources if you cannot satisfy a
rule on the context-based restriction service. Attempts to create or update such a rule are permitted only if the context of the request satisfies the new or
modified rule.
Tip: If you can no longer satisfy a rule that targets the Context-based restrictions service, open a support case and provide a context that you can
satisfy to restore your access.

Before you begin
To manage a context-based restrictionss, you must be assigned the administrator role on the account management service.

Updating rules by using the console
To edit the context-based restrictions on your cloud resources, complete the following steps:
1. In the IBM Cloud console, click Manage > Context-based restrictions, and select Rules.
2. Select the Actions icon

on the rule you want to update, and select Edit.

3. To update the scope of APIs whose operations are restricted by your rule, select All APIs or Specific APIs. Then, click Apply or Continue.
4. To update the scope of resources for the restriction, you can select All resources or Specific resources based on the available attributes, such as
resource group or location. Then, click Apply or Continue.
5. Click the Edit icon

in the summary panel to update an existing context.

a. Update the allowed endpoint types.
Set the toggle to No to allow all service supported endpoint types.
Set the toggle to Yes to allow only specific endpoint types.
b. Update the nework zones. You can select new network zones or deselect network zones to remove them.
6. Then, click Apply.
7. Click the Remove icon

in the summary panel to remove a context.

8. Configure a new context by selecting all endpoints or a specific endpoint, and by selecting your network zones. Then, click Add.
9. Click Apply or Continue.
10. Provide a new description for your rule. Click Apply to update the description, or click Continue.
Running secure workloads 85

11. To update the enforcement of a rule, click the Edit icon

. You can Enable, Disable, or set the rule to Report-only.

12. Click Apply to finish.

Updating rules by using the CLI
To update the context-based restrictions on your cloud resources, use the ibmcloud cbr rule-update command. The following example updates
description, allowed endpoint type, and network zone for a rule with the ID 30fd58c9b75f40e854b89c432318b4a2 .
$ ibmcloud cbr rule-update 30fd58c9b75f40e854b89c432318b4a2 --description 'Example rule description' --service-name kms -context-attributes endpointType=private --zone-id 93de8d3f588ab2c457ff576c364d1145

Updating rules by using the API
To update restrictions to your cloud resources by creating rules, call the Context-based restrictions API.
1. Get the rule that you want to replace. In in response body, copy the rule ID and in the response headers copy the ETag header.
Curl
curl -X GET --location --header "Authorization: Bearer {iam_token}" --header "Accept: application/json"
"https://cbr.cloud.ibm.com/v1/rules/{rule_id}"

Java
GetRuleOptions getRuleOptions = new GetRuleOptions.Builder()
.ruleId(ruleID)
.build();
Response<Rule> response = contextBasedRestrictionsService.getRule(getRuleOptions).execute();
Rule rule = response.getResult();
System.out.println(rule);

Node
const params = {
ruleId,
};
try {
const res = await contextBasedRestrictionsService.getRule(params);
console.log(JSON.stringify(res.result, null, 2));
} catch (err) {
console.warn(err);
}

Python
rule = context_based_restrictions_service.get_rule(
rule_id=rule_id
)
rule = rule.get_result()
print(json.dumps(rule, indent=2))

Go
getRuleOptions := contextBasedRestrictionsService.NewGetRuleOptions(
ruleID,
)
rule, response, err := contextBasedRestrictionsService.GetRule(getRuleOptions)
if err != nil {
panic(err)
}
b, _ := json.MarshalIndent(rule, "", "

")

fmt.Println(string(b))

2. The following example replaces a rule with an updated version. The ETag value is required in the replace request’s

If-Match header.

Curl

Running secure workloads 86

curl -X PUT --location --header "Authorization: Bearer {iam_token}" --header "Accept: application/json" --header "If-Match:
{if_match}" --header "Content-Type: application/json" --data '{ "description": "this is an example of rule", "resources": [
{ "attributes": [ { "name": "accountId", "value": "12ab34cd56ef78ab90cd12ef34ab56cd" }, { "name": "serviceName", "value":
"kms" } ] } ], "contexts": [ { "attributes": [ { "name": "networkZoneId", "value": "76921bd873115033bd2a0909fe081b45" } ] }
], "enforcement_mode": "disabled" }' "{base_url}/v1/rules/{rule_id}"

Java
RuleContextAttribute ruleContextAttributeModel = new RuleContextAttribute.Builder()
.name("networkZoneId")
.value("76921bd873115033bd2a0909fe081b45")
.build();
RuleContext ruleContextModel = new RuleContext.Builder()
.attributes(new java.util.ArrayList<RuleContextAttribute>(java.util.Arrays.asList(ruleContextAttributeModel)))
.build();
ResourceAttribute resourceAttributeModel = new ResourceAttribute.Builder()
.name("accountId")
.value("12ab34cd56ef78ab90cd12ef34ab56cd")
.build();
Resource resourceModel = new Resource.Builder()
.attributes(new java.util.ArrayList<ResourceAttribute>(java.util.Arrays.asList(resourceAttributeModel)))
.build();
ReplaceRuleOptions replaceRuleOptions = new ReplaceRuleOptions.Builder()
.ruleId("testString")
.ifMatch("testString")
.description("this is an example of rule")
.enforcementMode("disabled")
.contexts(new java.util.ArrayList<RuleContext>(java.util.Arrays.asList(ruleContextModel)))
.resources(new java.util.ArrayList<Resource>(java.util.Arrays.asList(resourceModel)))
.build();
Response<OutRule> response = contextBasedRestrictionsService.replaceRule(replaceRuleOptions).execute();
OutRule outRule = response.getResult();
System.out.println(outRule);

Node
// Request models needed by this operation.
// RuleContextAttribute
const ruleContextAttributeModel = {
name: 'networkZoneId',
value: '76921bd873115033bd2a0909fe081b45',
};
// RuleContext
const ruleContextModel = {
attributes: [ruleContextAttributeModel],
};
// ResourceAttribute
const resourceAttributeModel = {
name: 'accountId',
value: '12ab34cd56ef78ab90cd12ef34ab56cd',
};
// Resource
const resourceModel = {
attributes: [resourceAttributeModel],
};
const params = {
ruleId: 'testString',
ifMatch: 'testString',
contexts: [ruleContextModel],
resources: [resourceModel],
description: 'this is an example of rule',
enforcementMode: 'disabled',
};
contextBasedRestrictionsService.replaceRule(params)
.then(res => {
console.log(JSON.stringify(res.result, null, 2));
})
.catch(err => {
console.warn(err)

Running secure workloads 87

});

Python
rule_context_attribute_model = {
'name': 'networkZoneId',
'value': '76921bd873115033bd2a0909fe081b45',
}
rule_context_model = {
'attributes': [rule_context_attribute_model],
}
resource_attribute_model = {
'name': 'accountId',
'value': '12ab34cd56ef78ab90cd12ef34ab56cd',
}
resource_model = {
'attributes': [resource_attribute_model],
}
out_rule = context_based_restrictions_service.replace_rule(
rule_id='testString',
if_match='testString',
contexts=[rule_context_model],
resources=[resource_model],
description='this is an example of rule',
enforcement_mode='disabled'
).get_result()
print(json.dumps(out_rule, indent=2))

Go
ruleContextAttributeModel := &contextbasedrestrictionsv1.RuleContextAttribute{
Name: core.StringPtr("networkZoneId"),
Value: core.StringPtr("76921bd873115033bd2a0909fe081b45"),
}
ruleContextModel := &contextbasedrestrictionsv1.RuleContext{
Attributes: []contextbasedrestrictionsv1.RuleContextAttribute{*ruleContextAttributeModel},
}
resourceAttributeModel := &contextbasedrestrictionsv1.ResourceAttribute{
Name: core.StringPtr("accountId"),
Value: core.StringPtr("12ab34cd56ef78ab90cd12ef34ab56cd"),
}
resourceModel := &contextbasedrestrictionsv1.Resource{
Attributes: []contextbasedrestrictionsv1.ResourceAttribute{*resourceAttributeModel},
}
replaceRuleOptions := contextBasedRestrictionsService.NewReplaceRuleOptions(
"testString",
"testString",
)
replaceRuleOptions.SetDescription("this is an example of rule")
replaceRuleOptions.SetContexts([]contextbasedrestrictionsv1.RuleContext{*ruleContextModel})
replaceRuleOptions.SetResources([]contextbasedrestrictionsv1.Resource{*resourceModel})
replaceRuleOptions.SetEnforcementMode(contextbasedrestrictionsv1.ReplaceRuleOptionsEnforcementModeDisabledConst)
outRule, response, err := contextBasedRestrictionsService.ReplaceRule(replaceRuleOptions)
if err != nil {
panic(err)
}
b, _ := json.MarshalIndent(outRule, "", "

")

fmt.Println(string(b))

Updating network zones by using the console
You can modify the list of allowed locations where an access request can originate. A set of one or more network locations can be specified by IP addresses
(individual addresses, ranges, or subnets), VPCs, or service references. You can update a network zone that is used in a rule, or integrate the new updated
network zones into your rules later.
1. In the IBM Cloud console, click Manage > Context-based restrictions, and select Network zones.
2. Select the Actions icon

on the network zone that you want to update, and select Edit.

3. You can update your zone name and description.

Running secure workloads 88

4. You can edit the list of allowed IP addresses where an access request can originate. Include exceptions in the deny list, if necessary.
5. You can add or remove allowed VPCs.
6. You can add or remove service references. Select a service to associate its IP addresses with your network zone.
7. Click Next to review your new configuration.
8. To apply changes, click Update.

Updating network zones by using the CLI
To update a network zone, complete the following steps.
1. Retrieve the zone ID for the network zone that you want to update by using the

ibmcloud cbr zones command to list all zones in the account.

$ ibmcloud cbr zones

2. Update the network zone by using the ibmcloud cbr zone-update command. The following example updates the zone name, allowed addresses, and
excluded addresses for a network zone with the ID 65810ac762004f22ac19f8f8edf70a34 .
$ ibmcloud cbr zone-update 65810ac762004f22ac19f8f8edf70a34 --name 'Example Zone Name' --addresses 166.22.23.0-166.22.23.108
--excluded 166.22.23.100

Updating network zones by using the API
To update a network zone, complete the following steps.
1. Get the zone that you want to replace. In the response body, copy the zone ID and in the response headers copy the ETag header.
Curl
curl -X GET --location --header "Authorization: Bearer {iam_token}" --header "Accept: application/json"
"https://cbr.cloud.ibm.com/v1/zones/{zone_id}"

Java
GetZoneOptions getZoneOptions = new GetZoneOptions.Builder()
.zoneId(zoneID)
.build();
Response<Zone> response = contextBasedRestrictionsService.getZone(getZoneOptions).execute();
Zone zone = response.getResult();
System.out.println(zone);

Node
const params = {
zoneId,
};
try {
const res = await contextBasedRestrictionsService.getZone(params);
console.log(JSON.stringify(res.result, null, 2));
} catch (err) {
console.warn(err);
}

Python
get_zone_response = context_based_restrictions_service.get_zone(
zone_id=zone_id
)
zone = get_zone_response.get_result()
print(json.dumps(zone, indent=2))

Go
getZoneOptions := contextBasedRestrictionsService.NewGetZoneOptions(
zoneID,
)

Running secure workloads 89

zone, response, err := contextBasedRestrictionsService.GetZone(getZoneOptions)
if err != nil {
panic(err)
}
b, _ := json.MarshalIndent(zone, "", "

")

fmt.Println(string(b))

2. Update the network zone by using the Replace zone method. The ETag value is required in the replace request’s If-Match header.
Curl
curl -X PUT --location --header "Authorization: Bearer {iam_token}" --header "Accept: application/json" --header "If-Match:
{if_match}" --header "Content-Type: application/json" --data '{ "name": "new zone name", "description": "new zone
description", "account_id": "12ab34cd56ef78ab90cd12ef34ab56cd", "addresses": [ { "type": "ipAddress", "value":
"169.23.56.234" }, { "type": "ipRange", "value": "169.23.22.0-169.23.22.255" }, { "type": "vpc", "value":
"crn:v1:bluemix:public:is:us-south:a/12ab34cd56ef78ab90cd12ef34ab56cd::vpc:r134-d98a1702-b39a-449a-86d4-ef8dbacf281e" } ] }'
"{base_url}/v1/zones/{zone_id}"

Java
AddressIPAddress addressModel = new AddressIPAddress.Builder()
.type("ipAddress")
.value("169.23.56.234")
.build();
ReplaceZoneOptions replaceZoneOptions = new ReplaceZoneOptions.Builder()
.zoneId("testString")
.ifMatch("testString")
.name("an example of zone")
.accountId("12ab34cd56ef78ab90cd12ef34ab56cd")
.description("this is an example of zone")
.addresses(new java.util.ArrayList<Address>(java.util.Arrays.asList(addressModel)))
.build();
Response<OutZone> response = contextBasedRestrictionsService.replaceZone(replaceZoneOptions).execute();
OutZone outZone = response.getResult();
System.out.println(outZone);

Node
// Request models needed by this operation.
// AddressIPAddress
const addressModel = {
type: 'ipAddress',
value: '169.23.56.234',
};
const params = {
zoneId: 'testString',
ifMatch: 'testString',
name: 'an example of zone',
accountId: '12ab34cd56ef78ab90cd12ef34ab56cd',
addresses: [addressModel],
description: 'this is an example of zone',
};
contextBasedRestrictionsService.replaceZone(params)
.then(res => {
console.log(JSON.stringify(res.result, null, 2));
})
.catch(err => {
console.warn(err)
});

Python
address_model = {
'type': 'ipAddress',
'value': '169.23.56.234',
}
out_zone = context_based_restrictions_service.replace_zone(
zone_id='testString',

Running secure workloads 90

if_match='testString',
name='an example of zone',
account_id='12ab34cd56ef78ab90cd12ef34ab56cd',
addresses=[address_model],
description='this is an example of zone'
).get_result()
print(json.dumps(out_zone, indent=2))

Go
addressModel := &contextbasedrestrictionsv1.AddressIPAddress{
Type: core.StringPtr("ipAddress"),
Value: core.StringPtr("169.23.56.234"),
}
replaceZoneOptions := contextBasedRestrictionsService.NewReplaceZoneOptions(
"testString",
"testString",
)
replaceZoneOptions.SetName("an example of zone")
replaceZoneOptions.SetAccountID("12ab34cd56ef78ab90cd12ef34ab56cd")
replaceZoneOptions.SetDescription("this is an example of updated zone")
replaceZoneOptions.SetAddresses([]contextbasedrestrictionsv1.AddressIntf{addressModel})
outZone, response, err := contextBasedRestrictionsService.ReplaceZone(replaceZoneOptions)
if err != nil {
panic(err)
}
b, _ := json.MarshalIndent(outZone, "", "

")

fmt.Println(string(b))

Removing a rule by using the console
Deleting rules removes context-based restrictions from the given resource, and requests from any context are allowed if the user has the correct
permissions. You can remove a rule on your cloud resources by completing the following steps:
1. In the IBM Cloud console, go to Manage > Context-based restrictions, and select Rules.
2. Click the Actions icon

in the row that contains the rule, and click Remove.

Removing a rule by using the CLI
You can remove a rule on your cloud resources by completing the following steps:
1. Retrieve the rule ID for the rule that you want to delete by using the

context-based restrictions rules command. You can narrow the results of the list

by specifying attributes as command options.
$ ibmcloud cbr rules --serviceName "iam-identity"

2. Delete the rule for the specified rule ID by using the cbr rule-delete command.
$ ibmcloud cbr rule-delete 30fd58c9b75f40e854b89c432318b4a2

Removing a rule by using the API
You can remove a rule on your cloud resources by completing the following steps:
1. Retrieve the rule ID for the rule that you want to delete by using the

context-based-restrictions list rules method.

Curl
curl -X GET --location --header "Authorization: Bearer {iam_token}" --header "Accept: application/json" "
{base_url}/v1/rules?account_id={account_id}"

Java
ListRulesOptions listRulesOptions = new ListRulesOptions.Builder()
.accountId("testString")
.build();

Running secure workloads 91

Response<OutRulePage> response = contextBasedRestrictionsService.listRules(listRulesOptions).execute();
OutRulePage outRulePage = response.getResult();
System.out.println(outRulePage);

Node
const params = {
accountId: 'testString',
};
contextBasedRestrictionsService.listRules(params)
.then(res => {
console.log(JSON.stringify(res.result, null, 2));
})
.catch(err => {
console.warn(err)
});

Python
out_rule_page = context_based_restrictions_service.list_rules(
account_id='testString'
).get_result()
print(json.dumps(out_rule_page, indent=2))

Go
listRulesOptions := contextBasedRestrictionsService.NewListRulesOptions(
"testString",
)
ruleList, response, err := contextBasedRestrictionsService.ListRules(listRulesOptions)
if err != nil {
panic(err)
}
b, _ := json.MarshalIndent(ruleList, "", "

")

fmt.Println(string(b))

2. Delete the rule for the specified rule ID.
Curl
curl -X DELETE --location --header "Authorization: Bearer {iam_token}" "{base_url}/v1/rules/{rule_id}"

Java
DeleteRuleOptions deleteRuleOptions = new DeleteRuleOptions.Builder()
.ruleId("testString")
.build();
Response<Void> response = contextBasedRestrictionsService.deleteRule(deleteRuleOptions).execute();

Node
const params = {
ruleId: 'testString',
};
contextBasedRestrictionsService.deleteRule(params)
.then(res => {
done();
})
.catch(err => {
console.warn(err)
});

Running secure workloads 92

Python
response = context_based_restrictions_service.delete_rule(
rule_id='testString'
)

Go
deleteRuleOptions := contextBasedRestrictionsService.NewDeleteRuleOptions(
"testString",
)
response, err := contextBasedRestrictionsService.DeleteRule(deleteRuleOptions)
if err != nil {
panic(err)
}
if response.StatusCode != 204 {
fmt.Printf("\nUnexpected response status code received from DeleteRule(): %d\n", response.StatusCode)
}

Removing a network zone by using the console
Removing a network zone removes the set of allowed network locations from which an access request is created. If a network zone is added to a rule, you
first have to remove the zone from the rule. Complete the following steps to remove a network zone:
1. In the IBM Cloud console, go to Manage > Context-based restrictions, and select Network zones.
2. Click the Actions icon

in the row that contains the network zone, and click Remove.

Removing a network zone by using the CLI
Removing a network zone removes the set of allowed network locations from which an access request is created. If a network zone is added to a rule, you
first have to remove the zone from the rule. For more information about removing a zone from a rule, see Updating context-based restrictions . Then,
complete the following steps:
1. Retrieve the zone ID for the network zone that you want to delete by using the

contxt-based restrictions zones command. You can narrow the results

of the list by specifying the name of the zone.
$ ibmcloud cbr zones --name "Example zone"

2. Delete the network zone for the specified zone ID by using the cbr zone-delete command.
$ ibmcloud cbr zone-delete 65810ac762004f22ac19f8f8edf70a34

Removing a network zone by using the API
Removing a network zone removes the set of allowed network locations from which an access request is created. If a network zone is added to a rule, you
first have to remove the zone from the rule. See Updating context-based restrictions for more information about removing a zone from a rule. Then,
complete the following steps:
1. Retrieve the rule ID for the rule that you want to delete by using the

Context-based restrictions list zones method.

Curl
curl -X GET --location --header "Authorization: Bearer {iam_token}" --header "Accept: application/json" "
{base_url}/v1/zones?account_id={account_id}"

Java
ListZonesOptions listZonesOptions = new ListZonesOptions.Builder()
.accountId("testString")
.build();
Response<OutZonePage> response = contextBasedRestrictionsService.listZones(listZonesOptions).execute();
OutZonePage outZonePage = response.getResult();
System.out.println(outZonePage);

Running secure workloads 93

Node
const params = {
accountId: 'testString',
};
contextBasedRestrictionsService.listZones(params)
.then(res => {
console.log(JSON.stringify(res.result, null, 2));
})
.catch(err => {
console.warn(err)
});

Python
out_zone_page = context_based_restrictions_service.list_zones(
account_id='testString'
).get_result()
print(json.dumps(out_zone_page, indent=2))

Go
listZonesOptions := contextBasedRestrictionsService.NewListZonesOptions(
"testString",
)
outZonePage, response, err := contextBasedRestrictionsService.ListZones(listZonesOptions)
if err != nil {
panic(err)
}
b, _ := json.MarshalIndent(outZonePage, "", "

")

fmt.Println(string(b))

2. Delete the network zone for the specified zone ID.
Curl
curl -X DELETE --location --header "Authorization: Bearer {iam_token}" "{base_url}/v1/zones/{zone_id}"

Java
DeleteZoneOptions deleteZoneOptions = new DeleteZoneOptions.Builder()
.zoneId("testString")
.build();
Response<Void> response = contextBasedRestrictionsService.deleteZone(deleteZoneOptions).execute();

Node
const params = {
zoneId: 'testString',
};
contextBasedRestrictionsService.deleteZone(params)
.then(res => {
done();
})
.catch(err => {
console.warn(err)
});

Python
response = context_based_restrictions_service.delete_zone(
zone_id='testString'
Running secure workloads 94

)

Go
deleteZoneOptions := contextBasedRestrictionsService.NewDeleteZoneOptions(
"testString",
)
response, err := contextBasedRestrictionsService.DeleteZone(deleteZoneOptions)
if err != nil {
panic(err)
}
if response.StatusCode != 204 {
fmt.Printf("\nUnexpected response status code received from DeleteZone(): %d\n", response.StatusCode)
}

Restricting the ability to manage rules and network zones by using the console
Note: To configure this rule, target the Context-based restrictions service. For more information about the steps to set up a rule, see Creating
rules. A rule scoped to All resources is applicable to all current and future resources that are managed by the service. If you want to restrict
operations for a specific resource, scope the rule to Specific resources > Resource type. To complete any rule or network zone management
operation, a user must be assigned the correct role with an IAM access policy and they must satisfy the context-based restrictions rule.

Restricting the ability to manage rules and network zones by using the API
The following example shows a rule in JSON format that protects rule and network zone management operations:
Curl
{
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "my-AccountID"
},
{
"name": "serviceName",
"value": "context-based-restrictions"
}
]
}
],
"description": "",
"contexts": [
{
"attributes": [
{
"name": "networkZoneId",
"value": "my-zoneID"
}
]
}
],
"enforcement_mode": "report"
}

A rule that specifies only the accountId and serviceName resource attributes is applicable to all current and future resources that are managed by the
service. If you want to restrict operations for a specific resource, include the corresponding resourceType resource attribute. Valid resourceType
values for the Context-based restrictions service are rule and zone .
Note: To complete any rule or network zone management operation, a user must be assigned the correct role with an IAM access policy and they
must satisfy the context-based restrictions rule.

Running secure workloads 95

Protecting IAM services with context-based restrictions
Context-based restrictions give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud® resources based on
the context of access requests. Access to IAM resources can be controlled with context-based restrictions and identity and access management (IAM)
policies. Since both IAM access and context-based restrictions enforce access, context-based restrictions offer protection even in the face of compromised
or mismanaged credentials. For more information, see What are context-based restrictions .
These restrictions work with traditional IAM policies, which are based on identity, to provide another layer of protection. Unlike IAM policies, context-based
restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed context that you configure.
Note: A user must have the Administrator role on the specific IAM service that you want to target to create, update, or delete rules. A user must
also have at least the Viewer role on the Context-based restrictions service to view and add network zones to a rule. The Editor or Administrator
roles on the Context-based restrictions service grants users access to create, update, or delete network zones.
Any IBM Cloud Activity Tracker or audit log events generated come from the context-based restrictions service, not the IAM service. For more information,
see Monitoring context-based restrictions.
To begin protecting your IAM resources with context-based restrictions, see the tutorial for Leveraging context-based restrictions to secure your
resources.

How IAM integrates with context-based restrictions
To protect a specific IAM service or the group of all IAM Account Management services, complete the following steps:
1. In the IBM Cloud console, click Manage > Context-based restrictions , and select Rules.
2. Click Create.
3. Select an individual IAM service, or the grouping of all IAM Account Management services.
IAM Access Groups service
IAM Access Management service
IAM Identity service
User Management service
All IAM Account Management services
4. Then, click Next.
5. To protect the entire service or group of services, scope the restriction to All resources.
6. To protect only a specific set of actions, scope the restriction to Specific resources.
a. Select an attribute and select or enter a value. To learn more about restricting a specific set of actions, review the section for the service that
you target in step 3.
7. Click Review > Continue.
8. Add one or more contexts. Select endpoint types and network zones, and click Add. For more information, see Creating rules.
9. Click Continue.
10. Provide a unique description.
11. Select how you want to enforce the rule. You can decide how you want to enforce a rule upon creation and update the rule enforcement at any time.
For more information, see Rule enforcement.
Let's say that you create a rule that targets the IAM Access Groups service. To complete any IAM Access Groups service action, a user must be assigned
the correct role with an IAM access policy and they must satisfy the context-based restricitons rule. For example, a user with the Viewer role on the IAM
Access Groups service can complete the action iam-groups.members.read if they send the request from the correct network zone and satisfy the rule. If
the same user with the Viewer role tries to add a member to the group ( iam-groups.members.add ), they can't complete that request even though they
satisfy the rule because they aren't an Editor or Administrator.
Tip: To view the actions associated with a service, go to the Roles page in the IBM Cloud® console.

How IAM integrates with context-based restrictions
To protect a specific IAM service or the group of all IAM Account Management services, use the following attributes to build your rule:
Service

Name

Value

IAM Access Groups service

serviceName

iam-groups

Running secure workloads 96

IAM Access Management service

serviceName

iam-access-management

IAM Identity service

serviceName

iam-identity

User Management service

serviceName

user-management

All IAM Account Management services

service_group_id

IAM

Attribute name value pairs that identify a service

To protect all actions associated with the service, create a rule without scoping it to specific resources or APIs. For more information, see

Creating rules.

To protect only a specific set of actions, review the following sections, which are linked in Table 1.

Protecting the IAM Access Groups service
The IAM Access Groups service includes the ability to create, edit, and delete access groups. The capabilities extend to adding or removing users from
groups, assigning access to the group, and managing access for others to work with access groups. You can protect the whole service, which includes all
actions associated with the service.

Restricting the ability to manage a specific access group
You can protect the ability to manage a specific access group by scoping a rule to the the

Resource ID attribute. Creating a rule that is scoped to the

Resource ID attribute protects all actions associated with the service for that specific access group.

To configure this rule, target the IAM Access Groups service, scope the rule to Specific resources, and select the Resource ID attribute. Then, enter the
ID of the access group that you want to protect. For more information about the steps to set up a rule, see How IAM integrates with context-based
restrictions.
Tip: To find the access group ID, go to Manage > Access (IAM) > Access groups . Click the access group that you want to protect in your rule.
Then, click Details. The value that you want begins with AccessGroupId .

Restricting the ability to manage a specific access group by using the API
You can protect the ability to manage a specific access group by scoping a rule to the the

resource attribute. Creating a rule that is scoped to the

resource attribute protects all actions associated with the service for that specific access group.

The following example shows a rule in JSON format that protects a specific access group:
Curl
{
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "alphanumericAccoutnID"
},
{
"name": "serviceName",
"value": "iam-groups"
},
{
"name": "resource",
"value": "AccessGroupId1234",
"operator": "stringEquals"
}
]
}
],
"description": "",
"contexts": [],
"enforcement_mode": "enabled"
}

Running secure workloads 97

Tip: To find the access group ID, use the List access groups method.

Protecting the IAM Access Management service
The IAM Access Management service includes the ability to manage custom roles, assign access policies, manage IAM settings, and more. You can protect
the whole service, or restrict a specific set of actions based on the context of the request.

Restricting the ability to manage custom roles in the console
You can protect the ability to manage custom roles by scoping a rule to the

Role Management resource type. Creating a rule that is scoped to the

Role

Management resource type protects the following actions:
iam-access-management.customRole.create
iam-access-management.customRole.update
iam-access-management.customRole.delete
iam-access-management.customRole.read

To configure this rule, target the IAM Access Management service, scope the restriction to Specific resources > Resource type, and then select Role
management. For more information about the steps to set up a rule, see How IAM integrates with context-based restrictions .
Note: To complete any Role Management action, a user must be assigned the correct role with an IAM access policy and they must satisfy the
context-based restricitons rule. For example, a user with the Viewer role on the IAM Access Management service can complete the action iamaccess-management.customRole.read if they send the request from the correct network zone and satisfy the rule. If the same user tries to create

a custom role, they can't complete that request even though they satisfy the rule because they aren't an Administrator.

Restricting the ability to manage policies in the console
You can protect the ability to manage IAM policies by scoping a rule to the

Policy Management resource type. Creating a rule that is scoped to the

Policy

Management resource type protects the following actions:
iam.delegationPolicy.create
iam.delegationPolicy.update
iam.policy.read
iam.policy.create
iam.policy.update
iam.policy.delete

To configure this rule, target the IAM Access Management service, scope the restriction to Specific resources > Resource type, and then select Policy
management. For more information, see Creating rules.
Note: To complete any Policy Management action, a user must be assigned a role on the service with an IAM access policy and they must satisfy
the context-based restrictions rule. For example, a user with the Viewer role on the IAM Access Management service can complete the action
iam.policy.read if they send the request from the correct network zone and satisfy the rule. If the same user tries to create a policy, they can't

complete that request even though they satisfy the rule because they aren't an Administrator.

Restricting the ability to view insights in the console
You can protect the ability to view insights, like the Inactive identities and Inactive policies reports, by scoping a rule to the

insights resource type.

Creating a rule that is scoped to the insights resource type protects the following actions:
iam-access-management.insight.get

To configure this rule, target the IAM Access Management service, scope the restriction to Specific resources > Resource type, and then select AM
Insights. For more information, see Creating rules.
Note: To complete any settings action, a user must be assigned the correct role with an IAM access policy and they must satisfy the context-based
restrictions rule. For example, a user with the Editor role on the IAM Access Management service can complete the action iam-accessmanagement.insight.get if they send the request from the correct network zone and satisfy the rule. A users with the Viewer role can't complete

that request even if they satisfy the rule because they aren't an Editor or Administrator.

Restricting the ability to manage custom roles by using the API
Running secure workloads 98

You can protect the ability to manage custom roles by scoping a rule to the

customRole resource type. Creating a rule that is scoped to the

customRole

resource type protects the following actions:
iam-access-management.customRole.create
iam-access-management.customRole.update
iam-access-management.customRole.delete
iam-access-management.customRole.read

The following example shows a rule in JSON format that protects custom role actions:
Curl
{
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "alphanumericAccoutnID"
},
{
"name": "serviceName",
"value": "iam-access-management"
},
{
"name": "resourceType",
"value": "customRole"
}
]
}
],
"description": "",
"contexts": [],
"enforcement_mode": "enabled"
}

Note: To complete any Role Management action, a user must be assigned the correct role with an IAM access policy and they must satisfy the
context-based restrictions rule. For example, a user with the Viewer role on the IAM Access Management service can complete the action iamaccess-management.customRole.read if they send the request from the correct network zone and satisfy the rule. If the same user tries to create

a custom role, they can't complete that request even though they satisfy the rule because they aren't an Administrator..

Restricting the ability to manage policies by using the API
You can protect the ability to manage IAM policies by scoping a rule to the

policy resource type. Creating a rule that is scoped to the

Policy

Management resource type protects the following actions:
iam.delegationPolicy.create
iam.delegationPolicy.update
iam.policy.read
iam.policy.create
iam.policy.update
iam.policy.delete
iam.service.read
iam.role.read
iam.role.assign

The following example shows a rule in JSON format that protects policy actions:
Curl
{
"resources": [
{
"attributes": [

Running secure workloads 99

{
"name": "accountId",
"value": "alphanumericAccoutnID"
},
{
"name": "serviceName",
"value": "iam-access-management"
},
{
"name": "resourceType",
"value": "policy"
}
]
}
],
"description": "",
"contexts": [],
"enforcement_mode": "enabled"
}

Restricting the ability to view insights by using the API
You can protect the ability to view insights, like the Inactive identities and Inactive policies reports, by scoping a rule to the

insights resource type.

Creating a rule that is scoped to the insights resource type protects the following actions:
iam-access-management.insight.get

The following example shows a rule in JSON format that protects policy actions:
Curl
{
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "8293c49bc2724a07999910b1da94c4d6"
},
{
"name": "serviceName",
"value": "iam-access-management"
},
{
"name": "resourceType",
"value": "insight"
}
]
}
],
"description": "",
"contexts": [],
"enforcement_mode": "enabled"
}

Note: To complete any settings action, a user must be assigned the correct role with an IAM access policy and they must satisfy the context-based
restrictions rule. For example, a user with the Editor role on the IAM Access Management service can complete the action iam-accessmanagement.insight.get if they send the request from the correct network zone and satisfy the rule. A users with the Viewer role can't complete

that request even if they satisfy the rule because they aren't an Editor or Administrator.

Protecting the IAM Identity service
The IAM Identity service includes the ability to view, update and delete service IDs, API keys, identity providers (IdPs), and trusted profiles. You can also
assign access to service IDs and trusted profiles. All users can create service IDs, so the service actions apply to service IDs, API keys, and IdPs within the
account created by other users.
You can protect the whole service, or restrict a specific set of actions based on the context of the request. To protect only a specific set of actions, review
the following sections.
Running secure workloads 100

Important: The IAM Token API is not subject to context-based restrictions. Any rules that target the IAM Identity service are not enforced on the
Token API. The Token API uses a different mechanism to set IP address restrictions for users logging in to an account, during which users aquire a
token. For more information, see Allowing specific IP addresses for an account .

Restricting the ability to manage service IDs and their API keys in the console
You can protect the ability to manage service IDs and their API keys by scoping a rule to the

serviceid resource type. Creating a rule that is scoped to the

serviceid resource type protects the following actions:
iam-identity.serviceid.get
iam-identity.serviceid.update
iam-identity.serviceid.delete
iam-identity.apikey.manage
iam-identity.apikey.get
iam-identity.apikey.list
iam-identity.apikey.create
iam-identity.apikey.update
iam-identity.apikey.delete

To configure this rule, target the IAM Identity service, scope the rule to Specific resources, and select the Resource type attribute. Then, enter the
value serviceid . For more information about the steps to set up a rule, see How IAM integrates with context-based restrictions .

Restricting the ability to manage service IDs and their API keys by using the API
You can protect the ability to manage service IDs and their API keys by scoping a rule to the

serviceid resource type. Creating a rule that is scoped to the

serviceid resource type protects the following actions:
iam-identity.serviceid.get
iam-identity.serviceid.update
iam-identity.serviceid.delete
iam-identity.apikey.manage
iam-identity.apikey.get
iam-identity.apikey.list
iam-identity.apikey.create
iam-identity.apikey.update
iam-identity.apikey.delete

The following example shows a rule in JSON format that protects serviceid resource type actions:
Curl
{
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "alphanumericAccoutnID"
},
{
"name": "serviceName",
"value": "iam-identity"
},
{
"name": "resourceType",
"value": "serviceid"
}
]
}
],
"description": "",
"contexts": [],
"enforcement_mode": "enabled"
Running secure workloads 101

}

Restricting the ability to manage user API keys in the console
You can protect the ability to manage user API keys by scoping a rule to the

apikey resource type. Creating a rule that is scoped to the

apikey resource

type protects the following actions:
iam-identity.apikey.manage
iam-identity.apikey.get
iam-identity.apikey.list
iam-identity.apikey.create
iam-identity.apikey.update
iam-identity.apikey.delete

To configure this rule, target the IAM Identity service, scope the rule to Specific resources, and select the Resource type attribute. Then, enter the
value apikey . For more information about the steps to set up a rule, see How IAM integrates with context-based restrictions .

Restricting the ability to manage user API keys by using the API
You can protect the ability to manage user API keys by scoping a rule to the

apikey resource type. Creating a rule that is scoped to the

apikey resource

type protects the following actions:
iam-identity.apikey.manage
iam-identity.apikey.get
iam-identity.apikey.list
iam-identity.apikey.create
iam-identity.apikey.update
iam-identity.apikey.delete

The following example shows a rule in JSON format that protects apikey resource type actions:
Curl
{
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "alphanumericAccoutnID"
},
{
"name": "serviceName",
"value": "iam-identity"
},
{
"name": "resourceType",
"value": "apikey"
}
]
}
],
"description": "",
"contexts": [],
"enforcement_mode": "enabled"
}

Restricting the ability to manage trusted profiles in the console
You can protect the ability to manage trusted profiles by scoping a rule to the

profile resource type. Creating a rule that is scoped to the

profile

resource type protects the following actions:
iam-identity.profile.create
iam-identity.profile.update
iam-identity.profile.delete

Running secure workloads 102

iam-identity.profile.get
iam-identity.profile.get_session
iam-identity.profile.revoke_session
iam-identity.profile.linkToResource

To configure this rule, target the IAM Identity service, scope the rule to Specific resources, and select the Resource type attribute. Then, enter the
value profile . For more information about the steps to set up a rule, see How IAM integrates with context-based restrictions .

Restricting the ability to manage trusted profiles by using the API
You can protect the ability to manage trusted profiles by scoping a rule to the

profile resource type. Creating a rule that is scoped to the

profile

resource type protects the following actions:
iam-identity.profile.create
iam-identity.profile.update
iam-identity.profile.delete
iam-identity.profile.get
iam-identity.profile.get_session
iam-identity.profile.revoke_session
iam-identity.profile.linkToResource

The following example shows a rule in JSON format that protects profile resource type actions:
Curl
{
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "alphanumericAccoutnID"
},
{
"name": "serviceName",
"value": "iam-identity"
},
{
"name": "resourceType",
"value": "profile"
}
]
}
],
"description": "",
"contexts": [],
"enforcement_mode": "enabled"
}

Restricting the ability to manage account settings in the console
You can protect the ability to manage account settings by scoping a rule to the

settings resource type. Creating a rule that is scoped to the

settings

resource type protects the following actions:
iam-identity.account.get
iam-identity.account.create
iam-identity.account.update
iam-identity.account.create
iam-identity.account.update
iam-identity.account.enable_idp
iam-identity.account.disable_idp
iam-identity.account.delete
iam-identity.session.manage

Running secure workloads 103

To configure this rule, target the IAM Identity service, scope the rule to Specific resources, and select the Resource type attribute. Then, enter the
value settings . For more information about the steps to set up a rule, see How IAM integrates with context-based restrictions .

Restricting the ability to manage account settings by using the API
You can protect the ability to manage account settings by scoping a rule to the

settings resource type. Creating a rule that is scoped to the

settings

resource type protects the following actions:
iam-identity.account.get
iam-identity.account.create
iam-identity.account.update
iam-identity.account.create
iam-identity.account.update
iam-identity.account.enable_idp
iam-identity.account.disable_idp
iam-identity.account.delete
iam-identity.session.manage

The following example shows a rule in JSON format that protects settings resource type actions:
Curl
{
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "alphanumericAccoutnID"
},
{
"name": "serviceName",
"value": "iam-identity"
},
{
"name": "resourceType",
"value": "settings"
}
]
}
],
"description": "",
"contexts": [],
"enforcement_mode": "enabled"
}

Restricting the ability to manage Identity Providers in the console
You can protect the ability to manage Identity Providers (IdPs) by scoping a rule to the

idp resource type. Creating a rule that is scoped to the

ipd

resource type protects the following actions:
iam-identity.idp.get
iam-identity.idp.list
iam-identity.idp.create
iam-identity.idp.update
iam-identity.idp.delete
iam-identity.idp.test
iam-identity.idp.metadata

To configure this rule, target the IAM Identity service, scope the rule to Specific resources, and select the Resource type attribute. Then, enter the
value idp . For more information about the steps to set up a rule, see How IAM integrates with context-based restrictions .

Restricting the ability to manage Identity Providers by using the API
You can protect the ability to manage Identity Providers (IdPs) by scoping a rule to the

idp resource type. Creating a rule that is scoped to the

idp

Running secure workloads 104

resource type protects the following actions:
iam-identity.idp.get
iam-identity.idp.list
iam-identity.idp.create
iam-identity.idp.update
iam-identity.idp.delete
iam-identity.idp.test
iam-identity.idp.metadata

The following example shows a rule in JSON format that protects idp resource type actions:
Curl
{
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "alphanumericAccoutnID"
},
{
"name": "serviceName",
"value": "iam-identity"
},
{
"name": "resourceType",
"value": "idp"
}
]
}
],
"description": "",
"contexts": [],
"enforcement_mode": "enabled"
}

Protecting the User Management service
The User Management service includes the ability to view users in an account, invite and remove users, and view and update user profile settings. You can
create a rule that protects all actions associated with this service.
Tip: The viewer role on the User Management service is commonly assigned for users assigned a role to view or manage support cases. If an
account owner restricts the visibility of the user list in the IAM settings, users can't see support cases that are opened by other users in the
account. However, if they are assigned the viewer role for the user management service, the user list visibility setting doesn't affect the ability to
view cases in the account.
To configure this rule, target the User Management service. For more information about the steps to set up a rule in the console, see

How IAM integrates

with context-based restrictions.
The following example shows a rule in JSON format that protects all user-management actions:
Curl
{
{
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "alphanumericAccoutnID"
},
{
"name": "serviceName",

Running secure workloads 105

"value": "user-management"
}
]
}
],
"description": "",
"contexts": [],
"enforcement_mode": "enabled"
}
}

Protecting All IAM Account Management services
All IAM Account Management services is the grouping of a subset of account management services, which includes IAM Identity, IAM Access
Management, IAM User Management, and IAM Groups. You can create a rule that protects all actions associated with these services.
To configure this rule, target the All IAM Account Management services. For more information about the steps to set up a rule in the console, see

How

IAM integrates with context-based restrictions.
The following example shows a rule in JSON format that protects all actions associated with the

IAM service grouping:

Curl
{
{
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "alphanumericAccoutnID"
},
{
"name": "service_group_id",
"value": "IAM"
}
]
}
],
"description": "",
"contexts": [],
"enforcement_mode": "enabled"
}
}

Running secure workloads 106

Creating automated solutions
Creating a module
A module is a stand-alone unit of automation code that can be reused by developers and shared in a larger system. Modules are not independently
deployable and usually manage a smaller number of related resources and are used to build deployable architectures. Typically coded in Terraform or
Ansible, modules are a convenience for developers similar to Node.js or Python packages. Think of modules as building blocks that can be used in
combination with other modules to build a complete deployable architecture that solves a complex infrastructure need.
Modules that are created by IBM® are created and sourced in terraform-ibm-modules, a public GitHub org. Modules include usage information and one or
more runnable examples. This enables users who you share your modules with to copy the usage code to get started with any module, but they are not
deployable from a private catalog.

Guidelines and requirements for creating a module
The guidelines and requirements for creating a module are available in the IBM Cloud Terraform modules documentation. You can refer to the following
resources for creating your own modules:
Authoring guidelines
Module structure

Next steps: Sharing modules
Modules can be used to create a deployable architecture. You have a couple of options for sharing your module with others in your organization or external
users.
You can share with users in your account or other accounts by using a private catalog, if you have a Git release.
You might also choose to contribute your modules to the terraform-ibm-modules public GitHub org. For more information, see Contributing to the
IBM Cloud Terraform modules project.

Running secure workloads 107

Creating deployable architectures
Creating a deployable architecture
After going through the steps to plan and design your architecture and decide what type of component to create , you can start creating the automated
code that brings the architecture to life. This topic guides you through creating a deployable architecture that is made of modules.
To create a deployable architecture, you must define the required files, create a release in GitHub, and then onboard it to a private catalog so that you can
share it with others inside or outside of your organization.
You have a few options for creating a deployable architecture:
Build your own: Use the following instructions to build your own deployable architecture from scratch.
Modify existing code: Download the code from an existing architecture , modify it to fit your needs, and create a new deployable architecture with
your changes.
Stack architectures: You can also stack deployable architectures together in a project if those architectures are already available to you in a catalog.

Learn about the structure of a deployable architecture
A deployable architecture, which this documentation describes, is made up of 1 or more modules. A deployable architecture is composed of the following
in the source repo:

Anatomy of a terraform-based deployable architecture

Terraform code
Your source repo includes Terraform files. These files declare the desired infrastructure (end-state) and rely on Terraform providers that perform the
actual API requests to create, update, and delete the infrastructure. Some of the most common providers used are IBM Cloud® Terraform provider
and Helm/Kubernetes/Rest API provider.
Scripts (optional)
Used as a stop gap for functions that might not exist (Bash/Python) or for ad hoc operational tasks (Ansible). For more information, see

Creating

scripts for deployable architectures.
Automated tests
Validation tests that are used to deploy, verify, and destroy infrastructure. For an example, see the tests directory in the sample-deployablearchitectures sample repo.
Documentation
An architecture diagram and readme file need to be included in your source repo.
Catalog manifest file
Defines how the deployable architecture is exposed in the IBM Cloud catalog. In addition to the general catalog details like the name, description,
and features, it includes the variation definitions that point to the underlying Terraform configuration, compliance claims that are verified during
onboarding to the catalog by using IBM Cloud® Security and Compliance Center, and necessary IAM permissions for running the deployable
architecture. For more information, see Locally editing the catalog manifest .
Variations

Running secure workloads 108

A deployable architecture can include variations of capability or complexity. For example, you might create a quick start variation with basic
capabilities for a simple, low-cost deployment, and then you might have a standard variation with a more complex architecture that would be used in
production. Each of these variations is itself a deployable architecture, which is onboarded and configured to appear together in a catalog. These
variations are sourced in the same repo in different working directories and are defined in your ibm_catalog.json file. For more information, see
Creating a variation.

Specifying dependencies
There are two install_type options that you can specify when creating your deployable architecture. One specifies that dependent deployable
architectures that must be deployed first, and one specifies that it can be deployed without any prerequisites.

fullstack

It is a full end-to-end solution that is always deployed as-is. The fullstack value is set in the ibm_catalog.json manifest file for install_type
to specify that the deployable architecture does not have any dependencies (prerequisites).
extension

A deployable architecture that depends on another deployable architecture being deployed first. The prerequisite deployable architecture is the base
on which the extension deployable architecture is built. This dependency, or prerequisite, must be met to deploy the extension. The extension
value is set in the ibm_catalog.json manifest file for the install_type , and the dependencies array must be completed to specify the
dependent deployable architecture in the manifest file.

Note: If your deployable architecture is compatible with other architectures, but doesn't require them to deploy, you can include those
architectures as optional components for your users. To include optional components, set dependency_version_2 to true in the catalog
manifest file. If you do so, the install_type option is ignored. Then, use the dependencies or swappable_dependencies array to specify
required and optional components.
For more information and setting these values, see Locally editing the catalog manifest .

Creating a deployable architecture
You can expect to complete the following high-level tasks while creating your deployable architecture:
1. Create your source repo and add your code.
2. Create your ibm_catalog.json manifest file to prepare for creating a tile in the catalog.
3. Create a release.
4. Onboard your code to a create a catalog tile in a private catalog by reviewing and validating it.
5. Choose where you want to share or publish your deployable architecture.
Note: The following instructions for creating a deployable architecture use a public sample repo to teach by example.

Creating your source repo
By using the requirements that are defined by your organization, create a GitHub repository that you can use to hold the source code for your deployable
architecture. For help with creating a repository, see the GitHub documentation. If you already have a repository that you want to use, you can skip this
step. You can choose to use another organization to host your source code, such as GitLab, but for purposes of this documentation, GitHub is used.

Creating the required Terraform files
Review the following sections to understand which base Terraform files are required in your GitHub source repo to create the

.tgz file that is required as

part of onboarding your deployable architecture to a private catalog.

main.tf
The main.tf file is where you place the code that provisions the resources that you want to create. You can call a module from

terraform-ibm-modules

or an external module or a provider resource directly.
See examples:

Running secure workloads 109

Deployable architecture without dependencies main.tf
Deployable architecture with dependencies main.tf

outputs.tf
The outputs.tf file contains output values that you can include in your deployable architecture.
See examples:
Deployable architecture without dependencies outputs.tf
Deployable architecture with dependencies outputs.tf

provider.tf
The provider.tf file contains the provider configuration such as the provider name, API key, and region that the code expects.
See examples:
Deployable architecture without dependencies provider.tf
Deployable architecture with dependencies provider.tf

README.md
The readme file contains background and usage information about the deployable architecture, including a requirements, modules, resources, required
access, inputs, and outputs sections.
Tip: If you're source repo is in the terraform-ibm-modules org, most of the readme file is generated. So you don’t manually add the information
like the inputs and outputs. Variable names and descriptions are generated into the readme file from the variables.tf file.
See examples:
Deployable architecture without dependencies README.md
Deployable architecture with dependencies README.md

variables.tf
The variables.tf file includes the required and optional variables for the deployable architecture.
See examples:
Deployable architecture without dependencies variables.tf
Deployable architecture with dependencies variables.tf

version.tf
The version.tf file stores information about the Terraform version and provider version that is needed to run the deployable architecture.
Important: Any required Terraform providers for the deployable architecture should be locked into an exact version instead of using a range to
ensure consistent results with the deployable architecture.
See examples:
Deployable architecture without dependencies version.tf
Deployable architecture with dependencies version.tf

Creating a catalog manifest file
The catalog manifest is a file in the root of your repository that is called the

ibm_catalog.json . This file defines the required metadata for creating a tile in

a catalog, for example the name, description, features, variation definitions that point to the underlying Terraform configuration, compliance claims that
will be verified during onboarding by using Security and Compliance Center, and necessary IAM permissions for deploying the architecture. It also defines
the configurations that you want to be selected by default when a user attempts to deploy your architecture from the catalog. For more information, see
mapping catalog details to the manifest file .

Running secure workloads 110

Tip: Check out the example from the sample repo that shows a fullstack and extension type variation.
You can create your catalog manifest file by using two different methods:
1. You can create this file from scratch by using the template.
2. You can start the onboarding process with the following basic sample in your source repo, and then download the manifest file after you make
changes during onboarding in the console to add the updated file to your source repo.
The following is a basic manifest file that you can add to your repository and edit to help to get you started with this option.
{
"products": [
{
"flavors": [
{
"architecture": {},
"compliance": {},
"install_type": "fullstack"
}
],
"label": "catalog-create-sample-da-0.0.1",
"name": "catalog-create-sample-da-0.0.1",
"offering_icon_url": "url",
"product_kind": "solution",
"provider_name": "Community",
"short_description": "A simple deployable architecture.",
"tags": [
"dev_ops"
],
"version": "0.0.1"
}
]
}

Next steps: Onboard your deployable architecture to a private catalog
With a Git release created that includes the required files in your source repo, you can onboard a version of your deployable architecture and all included
variations. Onboarding is the process of creating a catalog tile in a private catalog by reviewing the catalog details and validating a test deployment and the
compliance claims in IBM Cloud. For the step-by-step process, see Onboarding deployable architectures.

Creating a deployable architecture from an existing offering
You can take advantage of an IBM®-curated customization bundle to extend and customize an IBM Cloud® deployable architecture. Each deployable
architecture provides its own customization bundle. With the bundle, you can edit the deployable architecture on your local computer, use your own
pipelines to test, and extend your own products to fit your enterprise's needs. To customize an architecture, you must have familiarity with Terraform.
The customization bundle also includes an automation directory that includes starter scripts to help you manage the lifecycle of your customized
deployable architecture from onboarding and validation to publishing it to a private catalog on IBM Cloud. Currently, two pipeline methods are included in
this directory: GitHub actions or a Toolchain from IBM Cloud.
The following guidance provides an overview of the customization bundle and some examples of customization that you can do. It is not all inclusive and
you can make any changes that you need. After you modify the architecture, you can add it to a private catalog and use IBM's tools to check for
vulnerabilities, ensure security and compliance, and share the architecture with your enterprise. For a more in-depth walkthrough, see Using IBM Cloud
deployable architectures to build a deployable architecture.
Important: Depending on your changes, IBM Cloud might not support the deployable architecture. The components of the architecture that are
supplied in the bundle are supported by IBM Cloud, but any modified code that's used to extend is not.

Before you begin
1. Create a repository to store the customized deployable architecture, for example, a GitHub repository. For more information, see Creating a new
repository.
2. Make sure that you have an editor of your choice to modify the deployable architecture, for example, Visual Studio Code. For more information, see
Visual Studio Code.

Running secure workloads 111

3. Make sure that you have tools of your choice to test your deployable architecture and ensure that it works. For example, you can use Terraform
runtime, which supplies the Terraform command line.

Finding a deployable architecture
IBM Cloud provides multiple deployable architectures that you can use as-is or you can customize. To find an architecture, complete the following steps:
1. In the IBM Cloud catalog, select a deployable architecture.
2. Download the customization bundle by selecting Review deployment options > Work with code > Download bundle.

Customizing the deployable architecture
When you download the bundle, you receive a set of files that are designed to help you get started with customization.

ibm_catalog.json
The ibm_catalog.json file is a manifest JSON file that is used to automatically import version information into a private catalog. With a catalog manifest
file, you can avoid manually entering version metadata through the console. To view how to set up an ibm_catalog.json file and the values that you can
include, see Locally editing the catalog manifest .

main.tf
The main.tf file is where configuration information about each deployable architecture that you want to use is stored. Depending on the deployable
architecture, you can use this file to specify specific regions, API keys, and source code locations. You can also use this file to add other modules and
update the architecture's Terraform parameters.

Example of main.tf with specifications
The following example shows Secure infrastructure on VPC for regulated industries using a specific region,

us-south :

module "landing-zone" {
source

= "https://cm.globalcatalog.cloud.ibm.com/api/v1-beta/offering/source//examples/power-sap?

archive=tgz&catalogID=7df1e4ca-d54c-4fd0-82ce-3d13247308cd&flavor=power&kind=terraform&name=slz-vpc-with-vsis&version=0.0.22"
ibmcloud_api_key = var.ibmcloud_api_key
ssh_public_key

= var.ssh_public_key

region

= "us-south"

prefix

= "slz"

}

outputs.tf
The outputs.tf file contains available output values that you can include in your deployable architecture. The values are commented out, but you can
include the values by removing the # symbol from the value. Also, you can add more output variables to the file. To include certain values, complete the
following steps.
1. Open the outputs.tf file.
2. Remove the # s from any output value that you want to include.

Example of outputs.tf
The following example includes the vsi_names value and excludes the transit_gateway_name value:
output "vsi_names" {
value

= var.vsi_names

description = "A list of the vsis names provisioned within the VPCs"
}

#output "transit_gateway_name" {
#

value

= var.transit_gateway_name

#

description = "The name of the transit gateway"

#}

provider.tf
The provider.tf file contains required information about which provider, API key, and region that users are required to use.

Running secure workloads 112

Important: This information is pulled in from the variables.tf file. If you need to make changes, update the variables.tf file.

Example of a provider.tf file
The following example lists IBM as the provider:
provider "ibm" {
ibmcloud_api_key = var.ibmcloud_api_key
region

= var.region

}

README.md
The readme file contains background and usage information about the deployable architecture. You can customize the readme file to help members of
your enterprise use the deployable architecture.

variables.tf
The variables.tf file includes the required variables for the deployable architecture. You can add any additional variables that you need.

version.tf
The version.tf file stores information about the Terraform version and provider version that is needed to run the deployable architecture. If you are
running the deployable architecture as-is, no updates are necessary. Your configuration might require you to update this file. If you need to specify a
particular Terraform or provider version, complete the following steps:
1. Open the versions.tf file.
2. Update required_version to the Terrafrom version that users need to use.
3. Update version to the provider version that users need to use.

Testing your deployable architecture
Before you onboard your deployable architecture to a private catalog, test your customization and ensure that the architecture runs as intended. To test
your architecture with the Terraform command line, complete the following steps:
1. After you customize the architecture, initialize the Terraform CLI. For more information, see Initializing Working Directories .
$ terraform init

2. Provision the resources. For more information, see Provisioning Infrastructure with Terraform.
a. Run terraform plan to generate a Terraform execution plan to preview the proposed actions.
$ terraform plan

b. Run terraform apply to create the resources that are defined in the plan.
$ terraform apply

Creating a release
If your tests were successful, you can prepare to onboard your architecture to a private catalog by making sure that your files are in the repository and
creating a release. For more information, see Creating a release .

Leveraging automation to share to a private catalog
The customization bundle has an automation directory that includes a couple of options for starter pipelines. These pipelines can be used to automate
the lifecycle of your customized products that you share by using a private catalog on IBM Cloud. This includes managing the onboarding, validation, and
sharing of the deployable architecture version to a private catalog. README files are included for each pipeline option that provide details on how to
leverage it. For more information about each one, see GitHub Actions and Creating a toolchain.

Using the console to onboard to a private catalog
If you'd like to use the console to onboard your deployable architecture, see onboarding your customized deployable architecture to a private catalog for
step-by-step guidance.
Running secure workloads 113

Next steps
The scripts that are provided in the customization bundle help you to automate the onboarding process to a private catalog for sharing your product with
other users. However, if you'd like to use the console or CLI to onboard your deployable architecture, see onboarding your customized deployable
architecture to a private catalog for step-by-step guidance. By using private catalogs, members of your enterprise are required to use approved
architectures that they can deploy by using projects.

Creating deployable architecture stacks
Stacking deployable architectures
You can stack deployable architectures together in a project to create a robust end-to-end solution architecture. You don't need to code Terraform to
connect the member deployable architectures within the stack. As you configure input values in a member deployable architecture, you can reference
inputs or outputs from another member to link the deployable architectures together. After you deploy the deployable architectures in your stack, you can
add the stack to a private catalog to easily share it with others in your organization.
This is an experimental feature that is available for evaluation and testing purposes and might change without notice.

Before you begin
Make sure that you have the following access. For more information about access and permissions, see Assigning access to projects .
The Editor role on the IBM Cloud Projects service.
The Editor and Manager role on the IBM Cloud® Schematics service.
The Viewer role on the resource group for the project.
Add the deployable architectures that you'd like to stack together to your project. For more information, see Adding deployable architectures to a project.
Tip: When you add deployable architectures to your project, provide meaningful names to help identify them. For example, if your stack contains
an infrastructure deployable architecture that creates the base for an application, that infrastructure needs to be deployed first. Otherwise, the
application can't deploy onto that infrastructure. Name your infrastructure deployable architecture 1 - infrastructure when you add it to your
project. Name the application 2 - application to indicate it needs to be deployed second.

Stacking architectures together by using the CLI
After you add the deployable architectures to your project, stack them together by running the following

ibmcloud project config-create command.

In the Definition option, specify the members by providing a name and the configuration ID for the existing deployable architectures that you want to
include in your stack:
ibmcloud project config-create --project-id PROJECT-ID [--definition DEFINITION]

For example, the following command creates a deployable architecture stack that is named StackDev in your project. The stack contains two deployable
architectures, custom-apache and test-slz that were already added as configurations to the project:
$ ibmcloud project config-create \
--project-id 0e13c360-45c4-4b68-a53f-bb8f6ac04161 \
--definition '{"name": "StackDev", "members": [{"name": "custom-apache", "config_id": "caff3a49-0bf4-40c4-b348-47e5da6e2274"},
{"name": "test-slz", "config_id": "fc7fa3d1-33db-4c40-9570-7604348ab3c4"} ]}' --output json

For more information about the command parameters, see ibmcloud project config-create .

Creating the stack definition by using the CLI
To onboard your deployable architecture stack to a private catalog, you must create a stack definition. It defines how the member deployable architectures
within the stack relate to each other. Provide this information so users can deploy the entire stack successfully when they add it to a project from the
private catalog.
The stack definition contains inputs and outputs at the stack level that can be referenced in the member deployable architectures within the stack. You can
also include references between members of the stack, which links the member deployable architectures together for users. Inputs that require a specific
value or reference to deploy the stack successfully need to be included in the stack definition.

Running secure workloads 114

A deployable architecture stack with references

Note: Currently, members can't reference outputs from the stack level.
Run the following ibmcloud project stack-definition-create command to create the stack definition and provide the inputs:
$ ibmcloud project stack-definition-create --project-id PROJECT-ID --id

Where id is the configuration ID of the StackDev deployable architecture stack that you just added to your project.
For example, the following command adds the following three inputs at the stack level. These inputs are required strings that are not hidden from users, so
users must configure these input values to deploy the stack:
prefix input with stackDemo as the default value.
ssh_key input with no default value.
ssh_private_key with a default value provided to assist users as they configure the input.

The command also includes input names for the two members of the stack. These inputs will be populated with values as references and saved for users
who add the stack to a project from the private catalog:
The test-slz deployable architecture contains a prefix input and an ssh_key input.
The custom-apache deployable architecture contains an ssh_private_key input and a prerequisite_workspace_id input.
For more information about writing references, see referencing values.
$ ibmcloud project stack-definition-create \
--project-id 0e13c360-45c4-4b68-a53f-bb8f6ac04161 \
--id 4d69cee6-0fb2-4621-96c6-16d987f3d9d7 \
--stack-definition '{"inputs": [{"name": "prefix", "type": "string", "hidden": false, "required": true, "default": "stackDemo"},
{"name": "ssh_key", "type": "string", "hidden": false, "required": true}, {"name": "ssh_private_key", "type": "string", "hidden":
false, "required": true, "default": "<<-EOF\nINSERT YOUR KEY HERE\nEOF"}], "members": [{"name": "test-slz", "inputs": [{"name":
"prefix"}, {"name": "ssh_key"}]}, {"name": "custom-apache", "inputs": [{"name": "ssh_private_key"}, {"name":
"prerequisite_workspace_id"}]} ]}' --output json

Running secure workloads 115

For more information about the command parameters, see ibmcloud project stack-definition-create .

Referencing inputs from the stack level within member deployable architectures by using the CLI
Now that the inputs are added at the stack level, update the member deployable architectures in the stack to reference those inputs by running the
ibmcloud project config-update command for each member of the stack:
$ ibmcloud project config-update --project-id PROJECT-ID --id

For example, the following command updates the test-slz deployable architecture to reference the inputs that were added at the stack level:
$ ibmcloud project config-update \
--project-id 0e13c360-45c4-4b68-a53f-bb8f6ac04161 \
--id fc7fa3d1-33db-4c40-9570-7604348ab3c4 \
--definition '{"inputs": {"prefix": "ref:../../inputs/prefix", "ssh_key": "ref:../../inputs/ssh_key"}}' --output json

Since the custom-apache architecture uses the ssh_private_key value from the stack definition, update the custom-apache deployable architecture
to reference that value. The custom-apache architecture also uses the schematics_workspace_id input value as one of its inputs, so include a reference
to that value:
$ ibmcloud project config-update \
--project-id 0e13c360-45c4-4b68-a53f-bb8f6ac04161 \
--id caff3a49-0bf4-40c4-b348-47e5da6e2274 \
--definition '{"inputs": {"ssh_private_key": "ref:../../inputs/ssh_private_key", "prerequisite_workspace_id": "ref:../testslz/outputs/schematics_workspace_id"}}' --output json

For more information about the command parameters, see ibmcloud project config-update .

Updating input values at the stack level by using the CLI
Now that the member deployable architectures are configured to reference the values you want, update the input values at the stack level by running
ibmcloud project config-update for the StackDev deployable architecture stack. For example, the following command updates the prefix input

value that is referenced by the test-slz deployable architecture within the stack. Values are also provided for the ssh_key and ssh_private_key
inputs:
$ ibmcloud project config-update

\

--project-id 0e13c360-45c4-4b68-a53f-bb8f6ac04161 \
--id 4d69cee6-0fb2-4621-96c6-16d987f3d9d7 \
--definition '{"inputs": {"prefix": "kb-stack-0327", "ssh_key": "<publicKey>", "ssh_private_key": "<privateKey>"}}' --output json

For more information about the command parameters, see ibmcloud project config-update .
Now that the input value is configured at the stack level, validate and deploy each member deployable architecture within the stack.
For example, the following command validates the test-slz deployable architecture:
$ ibmcloud project config-validate \
--project-id 0e13c360-45c4-4b68-a53f-bb8f6ac04161 \
--id fc7fa3d1-33db-4c40-9570-7604348ab3c4

While the following command approves the test-slz deployable architecture for deployment:
$ ibmcloud project config-approve \
--project-id 0e13c360-45c4-4b68-a53f-bb8f6ac04161 \
--id fc7fa3d1-33db-4c40-9570-7604348ab3c4 \
--comment 'I approve'

And the following command deploys the test-slz deployable architecture:
$ ibmcloud project config-deploy \
--project-id 0e13c360-45c4-4b68-a53f-bb8f6ac04161 \
--id fc7fa3d1-33db-4c40-9570-7604348ab3c4

Onboarding a deployable architecture stack to a private catalog by using the CLI
After each member deployable architecture in your stack is validated and deployed, you can onboard your stack to a private catalog for others to access.
Running secure workloads 116

Run the following ibmcloud project stack-definition-export command:
$ ibmcloud project stack-definition-export --project-id PROJECT ID

You can create a new product or add a version to an existing product. For example, the following command creates a new product in your private catalog
named My Apache Stack :
$ ibmcloud project stack-definition-export --project-id 0e13c360-45c4-4b68-a53f-bb8f6ac04161 --id 4d69cee6-0fb2-4621-96c616d987f3d9d7 --settings '{"catalog_id": "702ff97a-e35a-45a4-a0c0-a04e2e052bc8", "label": "My Apache Stack"}' --output json

While the following command creates a new version of an existing product:
$ ibmcloud project stack-definition-export \
--project-id 0e13c360-45c4-4b68-a53f-bb8f6ac04161 \
--id 4d69cee6-0fb2-4621-96c6-16d987f3d9d7 \
--settings '{"catalog_id": "702ff97a-e35a-45a4-a0c0-a04e2e052bc8", "product_id": "1bf57631-27a2-42cc-ac87-733cca67e8a5",
"target_version": "1.0.1"}' --output json

For more information about the command parameters, see ibmcloud project stack-definition-export .
Your stack is now a draft in the private catalog that is not yet published, but available to anyone who has Editor access to the private catalog.
To finish onboarding your deployable architecture stack to your private catalog, edit the catalog details and provide information like an architecture
diagram and a category.

Stacking architectures together by using the console
After you add and configure the deployable architectures to your project, stack them together by completing the following steps:
1. Select the checkbox for the deployable architectures that you want to stack.
2. Select Stack.
3. Provide a name for the new stack, or select an existing stack.
4. Click Continue.

Defining stack variables by using the console
The input variables that you define for the stack are configured by users after the stack is added to a project from a catalog. Similarly, the output variables
that you select display for users at the stack level. Don't select variables that users shouldn't configure. For example, if your stack requires a specific value
for an input variable, such as a storage plan, don't select the storage plan input. Don't select references that link the deployable architectures together
within your stack. If you do so, the connection between those architectures might break and the stack might not successfully deploy.
Tip: To make it easier for users to configure a deployable architecture stack, minimize the number of required input values that users must
configure to deploy the architectures. Review the required inputs for each architecture within the stack and make sure that those inputs are
configured by adding references to stack level input values, or referencing output values of other architectures.
Complete the following steps:
1. On the Configurations tab in your project, click the Options icon

for the stack and select Define variables.

2. On the Security tab, select any variables that users need to configure.
3. Go to the Required inputs tab and select any required inputs that users need to configure.
4. Go to the Optional inputs tab and select any optional inputs that users need to configure.
5. Go to the Outputs tab and select any output variables that you want displayed at the stack level.
Tip: Make it easier for users of the stack to find important output values after deploying the stack, such as application URLs or credential
names. Select the important output values from member deployable architectures to display them for users at the stack level.
6. Click Next and continue selecting variables for the remaining architectures in your stack.
7. When you're done, click Finish and configure the stack for deployment.

Onboarding a deployable architecture stack to a private catalog by using the console
Running secure workloads 117

After you validate and deploy each of the deployable architectures in your stack, you can add the stack to a private catalog to easily share it with others in
your organization. For more information, see deploying an architecture.
Complete the following steps:
1. On the Configurations tab in your project, click the Options icon

for the stack and select Add to private catalog.

2. Select or create the private catalog that you want to add the deployable architecture stack to.
3. Select whether this stack is a new product, or a new version of an existing product.
4. Provide the details like a product name, if applicable, the category, variation, and version.
5. Click Next.
6. Review the variables that users can configure after they add the stack to a project from the private catalog. If you need to make any changes, you can
define the stack variables .
7. Click Add.
Your stack is now a draft in the private catalog that is not yet published, but available to anyone who has Editor access to your private catalog.
To finish onboarding your deployable architecture stack to your private catalog, edit the catalog details and provide information like an architecture
diagram and a category.

Locally editing the deployable architecture stack definition
The stack definition file defines the member deployable architectures that are grouped in the deployable architecture stack. It specifies information about
how those deployable architectures are supposed to relate to each other, like input references that connect architectures together within the stack. If you
plan to share the stack with others through a private catalog, a stack definition is required to ensure that the stack can be deployed successfully.
The stack definition contains stack variables. These variables are inputs that users can configure and outputs from deployable architectures within the
stack that display at the stack level. Those input values are referenced in the member deployable architectures within the stack, as illustrated in the
following image. The stack definition also includes inputs from member deployable architectures within the stack. These inputs can be references that link
the member deployable architectures together. Inputs that require a specific value or reference to deploy the stack successfully need to be included in the
stack definition. For an example, see Creating the stack definition by using the CLI .

Visualizing the stack definition

Using the console to create the stack definition in a project
In a project, your stack definition is created automatically when you stack deployable architectures together and define stack variables. Using the console
to stack deployable architectures and define stack variables provides the following benefits:
You can use the reference picker in the console to create references between deployable architectures in the stack, as opposed to writing the
references from scratch.

Running secure workloads 118

Deploying the stack from a project helps verify the stack works as designed before others configure and deploy it.
Since the stack definition is created automatically based on the selections in the console, information like version locator IDs of member deployable
architectures is accurate and updated automatically.
In the project, you can select which inputs you want included at the stack level. These inputs are included in the

inputs section of the stack definition and

are configured as references in the member deployable architecture in your project. In the following image, the prefix input is highlighted within the
Custom Apache member deployable architecture. If this input is selected, the Default value changes to a reference to the stack level input. When a

user adds the stack to a project from a catalog, they can configure the prefix input and the Custom Apache member architecture will reference that
value. The fp_vsi_floating_ip_address input references an output from another member deployable architecture. That input shouldn't be selected, as
that reference links the member architectures together within the stack. Such inputs from member architectures are included in the members section of
the stack definition file.

Defining stack variables in a project

Editing your stack definition
To edit your stack definition locally, complete the following steps:
1. Complete the steps to stack the deployable architectures, define stack variables, and onboard the stack to a private catalog .
Important: Configure and deploy the stack to verify that it works as designed before adding the stack to a private catalog.
2. After the deployable architecture stack is added to your private catalog, you are taken to the Configure version page in the catalog. From there, click
the Actions menu > Export as code.
Tip: You can also use the projects API Get a stack definition method or the projects CLI ibmcloud project stack-definition command to
export the stack definition.
3. Open the stack_definition.json file.
4. Using the example definition as a guide, edit the input and output variables.
5. Add the file into the root folder of your source code repository.
The next time that you add a new version of your stacked deployable architecture to the catalog, your updates will be included.

Example definition file
Though it's recommended to use a project to create the stack definition to help ensure accuracy, the following code snippet can be used as a template to
create the stack definition from scratch.
{
"inputs": [
{
"name": "Stack input 1",
Running secure workloads 119

"type": "string",
"hidden": false,
"required": true,
"default" : "Default value"
},
{
"name": "Stack input 2",
"type": "string",
"hidden": false,
"required": true
}
],
"outputs": [
{
"name": "Output 1 name",
"value": "The reference to this output value"
},
{
"name": "Output 2 name",
"value": "The reference to this output value"
}
],
"members": [
{
"Name": "Deployable architecture 1 name",
"Version_locator": "",
"inputs": [
{
"name": "Input 1 name",
"value": "reference"
},
{
"name": "Input 2 name",
"value": "reference"
}
]
},
{
"Name": "Deployable architecture 2 name",
"Version_locator": "",
"inputs": [
{
"name": "Input 1 name",
"value": "reference"
},
{
"name": "Input 2 name",
"value": "reference"
}
]
}
]
}

Stack inputs
The inputs value indicates an array of the input variables that are required for the stack to successfully deploy. When a user adds the deployable
architecture stack to a project from a catalog, they must configure these inputs before they deploy. The following values can be included at the inputs
level.
"inputs": [
{
"name": "Stack input 1",
"type": "string",
"hidden": false,
"required": true,
"default" : "Default value"
},
{
"name": "Stack input 2",
Running secure workloads 120

"type": "string",
"hidden": false,
"required": true
}
]

name

The name of your input variable.
type

The Terraform primitive data type of the variable. For example, boolean or string .
hidden

A boolean that indicates whether the parameter should be hidden from users during installation.
required

A boolean that indicates whether users are required to specify the parameter during installation.
default

The default value that should be set in the catalog.

Stack outputs
The outputs value indicates an array of the output variables that are created when the stack is deployed. The following values can be included at the
outputs level.
"outputs": [
{
"name": "Output 1 name",
"value": "The reference to this output value"
},
{
"name": "Output 2 name",
"value": "The reference to this output value"
}
]

name

The name of your output variable.
value

The reference to where the value can be found. For more information about references, see Referencing values.

Member inputs
The members value indicates an array of the inputs and outputs for each deployable architecture in the stack. The following values can be included at the
members level.
"members": [
{
"Name": "Deployable architecture 1 name",
"Version_locator": "",
"inputs": [
{
"name": "Input 1 name",
"value": "reference"
},
{
"name": "Input 2 name",
"value": "reference"
}

Running secure workloads 121

]
}
]

name

The programmatic name of the deployable architecture included in the stack.
version_locator

Identifies the version of the member deployable architecture within the stack. To find the version locator, select the product in the catalog to open
the catalog details page. Make sure that the correct version is selected. Then, click View details.
inputs

Inputs to the member deployable architectures within the stack. Include inputs with specific values that are required for the deployable architecture
stack to deploy. If the member architectures within the stack depend on one another, then include those values here as references. For more
information, see Referencing values. For example, if one of your architectures requires an output from another architecture within the stack, add a
reference to the output as the value.

name

The name of your input variable. Don't edit the name as it must match the input that is used in the member deployable architecture.
value

The value of your input variable. A default value or a reference needs to be provided.

Creating deployable architecture variations
A deployable architecture can include variations of capability or complexity. For example, you might create a quick start variation with basic capabilities for
simple, low-cost deployment, and then you might have a standard variation with a more complex architecture that would be used in production. Each of
these variations is itself a deployable architecture, which is onboarded and configured to appear as options for the same tile in the catalog.
Tip: If you're working in the ibm_catalog.json catalog manifest file, variations are referred to as flavors . However, in the catalog details
page, they are referred to as variations.
The variations of the core architecture often vary in the following key areas:
Cost
Compliance
Complexity in time and use
It deploys something different for a specific use case, but solves the same overall business problem.
Here's an example of a deployable architecture with two variations in the catalog. These are two variations that use the same source URL, product name,
and version during onboarding to the catalog to ensure that they show up side by side after a user selects the catalog tile:

Running secure workloads 122

Deployable architecture with two variations

Adding a variation to an existing deployable architecture
To create another variation of the deployable architecture that you already created, complete the following steps:
1. In your source code repo, create a working directory and add the required Terraform files for a deployable architecture .
2. In the manifest file, add the following code snippet into the flavors section. This array defines the offering as part of the same deployable
architecture, but allows it to be listed as a variation within the catalog. If you downloaded your manifest from a previously onboarded version in the
catalog, the file will already have a minimal definition in place for a new variation.
For example, if your deployable architecture is called Dinner and you want to create a variation of that, you might call it

steak as shown in the

following example.
"flavors": [
{
"label": "Steak",
"name": "steak-variation",
"working_directory": "./steak",
"install_type": "fullstack"
}
]

Tip: The updated catalog manifest file that you upload as part of your release auto-fills most of the configurations for your new variation.
However, it is a best practice to validate the configuration before you share the product with your organization.
You can repeat these steps if you have more variations to add. When you're done, you can create your Git release and start

onboarding to a private catalog

to create a catalog tile that you can share with others.

Adding a deployable architecture stack as a variation
You can add a deployable architecture stack as a variation in the catalog. If a quick start variation of a deployable architecture is simple and low-cost, a
deployable architecture stack is typically more complex and creates more resources than that quick start variation.
To add a deployable architecture stack as a variation, complete the following steps:
1. Create the deployable architecture stack in a project. For more information, see Stacking deployable architectures.
Important: Configure and deploy the stack to verify that it works as designed before adding the stack as a variation.
2. Define the variables that users need to configure to deploy the stack. For more information, see Defining stack variables.
3. Create a stack definition file. The stack definition specifies how the deployable architectures within a stack relate to each other. The stack variables
that you defined in the previous step are included in your stack definition file as well.

Running secure workloads 123

4. In your source code repo, create a working directory and add the stack_definition.json file to that directory. For more information, see Creating
your source repo.
5. In your ibm_catalog.json manifest file, add the following code snippet into the flavors section:
For example, if your deployable architecture is called Dinner and you want to create a variation of that, you might call it

Steak and potatoes with

broccoli as shown in the following example.
"flavors": [
{
"label": "Steak and potatoes with broccoli",
"name": "steak-potatoes-broccoli-variation",
"working_directory": "./steak-potatoes-broccoli",
"install_type": "fullstack"
}
]

If you haven't done so already, create your Git release and start onboarding to a private catalog to create a catalog tile that you can share with others.

Locally editing the catalog manifest
The catalog manifest file specifies the information about your onboarded solution that you want to share with users through a catalog. You can provide
licensing and compliance information, make specific settings, and provide descriptions about the intended purpose of your product.
Tip: Prefer to use the console to edit your catalog details? You can make the selections by following the

provided wizard and then export the

manifest file to add to your source repo. If you are stacking deployable architectures, the catalog manifest is created for you when you add the
stack to a private catalog from your project.

Mapping catalog details to the manifest file
To help visualize how the content added to the manifest file is displayed to users, see the following examples that show the relationship between the
ibm_catalog.json and the catalog details page.

Let's look at how the deployable architecture name, description, features, and variations are defined in the catalog manifest file and how the user sees the
information on the catalog details page.

Deployable architecture title, description, features text mapping to the source file

Let's look at how the variation features list is used to help users compare variations based on how it's defined in the catalog manifest file.

Running secure workloads 124

Deployable architecture variation feature comparison

Let's look at where the permissions and architecture diagram details are specified in the catalog manifest file and how it's displayed on the catalog details
page.

Deployable architecture permissions and architecture text mapping to the source file
Running secure workloads 125

And, if your architecture meets a specific level of compliance that is verified with a scan by using the Security and Compliance Center, you can add a
compliance claim per variation. You define how your architecture meets a certain level of compliance in the ibm_catalog.json file by specifying the
Security and Compliance Center profile. You must also run a scan on the resources that your architecture creates before onboarding to IBM Cloud. For
more information, see Managing compliance information for your deployable architecture .
See in the following example how the compliance information that is defined in the manifest file is displayed to users.

Deployable architecture compliance

Editing your manifest
To edit your manifest locally, you can use the following steps.
1. Copy the following example manifest file into a local editor.
2. Name the file ibm_catalog.json .
3. Add your preferred configurations into the file by using the example manifest as a guide. To learn more about each value, view the

available values.

4. Add the file into the root folder of your source code repository.
5. Add your deployable architecture to your catalog .
Tip: If your deployable architecture is already onboarded to a private catalog, you can download the manifest from the console.

Example manifest file
The following code snippet can be used as a template.
{
"products": [
{
"name": "",
"label": "",
"product_kind": "",
"tags": [
"tag 1",
"tag 2"
],
"keywords": [
"keyword 1",
"keyword 2",
"keyword 3"
],
"short_description": "Short description of your product.",
"long_description": "A longer description of your product.",
"offering_docs_url": "URL",
"offering_icon_url": "URL or emebbed image",
"provider_name": "Community",
"module_info": {
"works_with": [
Running secure workloads 126

{
"catalog_id": "",
"name": "module name",
"kind": "terraform",
"version": "0.1.0",
"flavor": "Variation name"
}
]
},
"support_details": "Explanation of support.",
"features": [
{
"title": "Feature 1 title"
"description": "Feature 1 description"
},
{
"title": "Feature 2 title"
"description": "Feature 2 description"
}
],
"flavors": [
{
"label": "Display name",
"name": "Programatic name",
"install_type": "Install type",
"working_directory": "Directory path",
"usage_template": "template",
"scripts": [
{
"type": "ansible",
"short_description": "Short description of what your script is intended to do.",
"path": "Path to script location.",
"stage": "The stage. For example, pre.",
"action": "The action. For example, validate."
}
],
"change_notices": {
"breaking": [
{
"title": "Title of breaking change",
"description": "Description of the change."
}
],
"new": [
{
"title": "Title of new feature",
"description": "Description of the new feature or capability."
}
],
"update": [
{
"title": "Title of general update",
"description": "Description of the general update."
}
]
},
"compliance": {
"authority": "scc-v3",
"controls": [
{
"profile": {
"name": "Security and Compliance Center profile name",
"version": "Profile version"
},
"names": [
"Control name 1 e.g. AC-2(a)",
"Control name 2",
"Control name 3"
]
}
]
Running secure workloads 127

},
"configuration": [
{
"key": "key type e.g. ssh_key",
"required": true
},
{
"key": "Key type e.g. ibmcloud_api_key",
"required": true,
"type": "The data type"
}
],
"outputs": [
{
"description": "Output description",
"key": "key"
},
{
"description": "Output description",
"key": "key"
}
],
"dependencies": [
{
"catalog_id": "ID",
"id": "ID",
"name": "Product programmatic name",
"kind": "Format kind",
"version": "Versions or range of versions",
"flavors": [
"Variation name 1",
"Variation name 2",
"Variation name 3"
],
"install_type": "fullstack or extension",
}
],
"iam_permissions" [
{
"role_crns": [
"CRN 1 e.g. crn:v1:bluemix:public:iam::::serviceRole:Manager",
"CRN 2 e.g. crn:v1:bluemix:public:iam::::role:Administrator"
],
"service_name": "Programatic service name e.g. is.vpc"
}
],
"licenses": [
{
"name": "License name",
"smref": "Link to the license"
}
],
"schematics_env_values": {
"value": "value",
"smref": " "
},
"architecture": {
"descriptions": " ",
"features": [
{
"title": "Feature 1 title",
"description": "Feature 1 description"
},
{
"title": "Feature 1 title",
"description": "Feature 1 description"
}
],
"diagram": {
"caption": "Diagram caption",
"url": "Link to diagram or embedded image",
Running secure workloads 128

"metadata": []
},
"description": "Description of the diagram"
}
}
]
}
]
}

Available values
The following sections include information about each value that can be referenced in your manifest file.

Products
The products value indicates an array of products with size one or more. If a catalog manifest file exists at the root of your repository, only the products
within the file can be imported. Products are imported one at a time. The following values can be included at the products level:

label

The product display name. This value must match the display name that you provide during onboarding.
name

The programmatic name of the product.
version

The version of the product in SemVer format, including the major version, minor version, and revision, for example, 1.0.0. This value can also be
specified when the product is onboarded to a catalog.
product_kind

The kind of product that you are onboarding. Valid values are software, module, or solution. A solution is otherwise known as a deployable
architecture.
tags

An array of predefined values that can help users to filter the catalog to identify and learn more about your product. To view the available options, run
the following command: ibmcloud catalog filter options --all .
keywords

An array of specific words or phrases that a user might try to search for.
short_description

A concise summary of what your product is and its value.
long_description

A detailed description of your product that explains the product's value and benefits to users.
provider_name

Users can filter the catalog by the provider of a product. When you onboard a product to a private catalog, the provider name is set to

Community by

default. However, you can customize this field to display your company or organization name. IBM is a reserved value and can be used for IBM build
products only.
offering_docs_url

A link to documentation about the product that users can access.
offering_icon_url

A link to the URL where the icon that you want to appear on the product's catalog entry page is located.
support_details

Support information in markdown format that can include support contacts, support locations, and support methods.
features

Running secure workloads 129

Section header for details that highlight the processes, abilities, and results of the product. These product-level features are listed on your catalog
entry page with your product description. For example, features might include CPU requirements, security features, or more. Each entry is defined as
an array as shown in the example manifest in the previous section.

title

The name of the feature.
description

A concise description of the feature.

Modules
The module_info value indicates information about other products that the deployable architecture is compatible with. The following values can be
included at the module_info level:

works_with

Section header for information about a singular product that is compatible with the deployable architecture.

catalog_id (optional)

ID of the catalog that houses the product. If not specified, the IBM Cloud catalog is the default.
id (optional)

ID of the product. The ID is not required if the

name value is set.

name (optional)

Programmatic name of the product that works with the deployable architecture.
kind

The format of the module that works with your deployable architecture. Most often this is terraform .
version

Version or range of product versions that work with the deployable architecture in SemVer format.
flavors (optional)

The programmatic names of the compatible variations. Variations are onboarded individually to a catalog and are given a version number. An
example variation name might be standard or advanced .

Flavors
Section header for information about the deployable architecture variations. Flavors are now known as variations in the console. The following values can
be included at the flavors level:

label

Variation display name.
name

Variation programmatic name.
working_directory

For a working directory that is at the root level of your repo, you don't need to specify the working directory. If it is not at the root, then list the path
from the root of your repository. For example, ./examples/ .

Running secure workloads 130

usage

Information on how to embed the architecture or run it locally through Terraform.
usage_template

Similar to usage . With a template you can use variables as a place holder where the values can be substituted. The string is stored in the

usage

property.
Template variable

Replacement value

${{version}}

The version string of this variation or flavor.

${{flavor}}

The programmatic name of the variation or flavor.

${{kind}}

The implementation kind. I.e. terraform.

${{id}}

The offering or product ID.

${{name}}

The programmatic name of the offering or product.

${{catalogID}}

The ID of the catalog where the offering or product is located.

${{workingDirectory}}

The working directory of the flavor or variation.
Usage template values and descriptions

licenses

Information about the end user license agreements that users are required to accept when they install the product. The license agreements are in
addition to the IBM Cloud Services Agreement.
{
"id": "string, license id",
"name": "string, license display name",
"type": "string, type of license, e.g. Apache xxx",
"url": "string, URL for the license text",
"description": "string, license description"
}

id

The license ID.
name

The name of the license.
type

The type of license. For example, Apache.
url

A URL to where the user can access the license agreement.
description

A description of the license.

compliance

Section header that indicates which compliance controls that the architecture satisfies with the default installation settings. The evaluation and
validation of the claims made is completed by IBM Cloud® Security and Compliance Center.
"compliance": {
"authority": "scc-v3",
"profiles": [

Running secure workloads 131

{
"profile_name": "",
"profile_version": ""
}
]
}

Important: You can list multiple profiles in your catalog manifest JSON file, but only the first profile is added to your compliance information
in a private catalog.

authority

IBM Cloud Security and Compliance Center v3 is the only authority accepted. This is programmatically written as

scc-v3 .

profiles

Section header that indicates the profile that contains the controls that are being claimed. You can view predefined profiles in Security and
Compliance Center.

profile_name

The name of the profile. For example, NIST . You can find the profile name in Security and Compliance Center.
profile_version

The version of the profile. For example, 1.0.0 . You can find the profile name in Security and Compliance Center.

controls

Section header that indicates that the variation has claimed controls. The catalog manifest accepts an array of controls that you can claim on
your variation by specifying a control's profile_name , profile_version , and control_name . You can view predefined profiles in Security
and Compliance Center.

profile

Section header that indicates that you are adding controls from a specific profile.

name

The profile name of the claimed control. For example, NIST . You can find the profile name in Security and Compliance Center.
version

The version of the profile. For example, 1.0.0 . You can find the profile name in Security and Compliance Center.

names

Section header to indicate a list of claimed controls. For example:

"names": [
"CM-7(b)",
"AC-2(a)"
]

Note: If you have included controls in your readme and your catalog manifest file, the manifest file takes precedence. It is best practice to
make sure the controls that are listed in your catalog manifest file match the controls in your readme file.
change_notices (optional)

Running secure workloads 132

A list of the three types of changes that you might want to alert your users to when releasing a new version of your deployable architecture. You can
specify breaking changes , new features , and general updates . Breaking changes are those updates that break functionality that was
available through a previous version. New features highlight any new functionality that a user might encounter with the new version. Updates
encompass any changes that you want to highlight to a user such as a modified behavior that doesn't necessarily break existing functionality or
changes that make the deployable architecture easier for them to use.
"change_notices": {
"breaking": [
{
"title": "",
"description": ""
}
],
"new_features": [
{
"title": "",
"description": ""
}
],
"updates": [
{
"title": "",
"description": ""
}
]
}
iam_permissions (optional)

Section header for a list of all IAM permissions that are required for a user to work with your deployable architecture version. IAM permission
information includes the programmatic name of the service that is required and a list of CRNs for roles that are needed. If you build your catalog
manifest file from the UI, the CRNs are already included.
{
"service_name": "IAM defined service name",
"role_crns" [
""
],
"resources": [
{
"name": "",
"description": "",
"role_crns: [
""
]
}
]
}

service_name

The programmatic name of the service that users must have access to.
role_crns

Section header to indicate a list of access roles.
resources

The resources for a permission.

name

The name of the resource.
description

A description of the resource.

Running secure workloads 133

role_crns

Section header to indicate a list of access roles.

architecture

High-level information about the deployable architecture version that includes a description, features, and a diagram. Multiple diagrams, with
captions, can be provided.
"architecture" {
"descriptions": "",
"features": [
{
"title": "",
"description": ""
}
],
"diagrams": [
{
"diagram" {
"caption": "",
"url": "",
"type": "image/svg+xml"
},
"description": ""
}
]
}

features

Information that highlights the processes, abilities, and results of the version, or if applicable, architecture variation. When onboarding by using
the console, these details are called highlights. These details appear on the variation selection box within your catalog entry. If your product
has multiple architecture variations, users can compare the variation-level features to decide which variation suits their needs.

title

Name of the feature.
description

A description of the feature.

diagrams

Information about the architecture diagram that includes the diagram caption, the URL to embed the SVG of the diagram, the diagram
metadata such as element ID and element description, and the description of the reference architecture.

diagram

Section marker for information about a singular architecture diagram.

url

The URL to the diagram's SVG. You can also embed an SVG.
api_url

The catalog management API URL to the diagram.
url_proxy

Section header for information about a proxied image.
Running secure workloads 134

url

The URL to the proxied image.
sha

The sha identifier of the image.

caption

A short label for the architecture diagram.
type

The type of media.
thumbnail_url

A link to a thumbnail for the diagram.

description

Information about architecture diagram as a whole, including the outline of the system and the relationships, constraints, and boundaries
between components of the deployable architecture.

dependencies

Section header for a list of products that are compatible with the deployable architecture. Dependencies can be required or optional. A dependency
included here can't be added to the swappable_dependencies section as well. Information includes the programmatic name of the product and
product versions. Optionally, you can include the catalog ID and a list of dependent variations.
{
"name": "offering name",
"id": "offering ID",
"kind": "terraform",
"version": "SemVer version e.g. 3.1.2"
"flavors": [
"flavor name"
],
"install_type": "fullstack or extension",
"catalog_id": "catalog ID"
"optional": true,
"input_mapping": [
{
"dependency_output": "kms_instance_crn",
"version_input": "existing_kms_instance_crn"
},
{
"version_input": "region",
"value": "us-south"
},
{
"version_input": "prefix"
"reference_version": true
}
]
}

catalog_id (optional)

ID of the catalog that houses the product. If not specified, the IBM Cloud catalog is the default.

Running secure workloads 135

id (optional)

The product ID. The ID is not required if the name value is set.
name (optional)

Programmatic name of the product.
kind

The format kind of the dependency. Use stack for a deployable architecture made of grouped deployable architectures where a stack config
file is present. Use terraform for deployable architectures made solely of one or more modules.
version

A version or range of versions to include as dependencies in SemVer format.
flavors (optional)

List of variations that the architecture is compatible with.
default_flavor (optional)

Experimental

Specifies a default variation that is selected for your users when multiple variations are compatible with or requird to deploy your architecture.
Your users can select a different variation if it's included in the flavors property. The value is the name of the variation. To use this property,
you must also set dependency_version_2 to true . If not set, then a default variation is not provided for your users.
optional

Experimental

Specifies whether the dependency is required or not required. The default value is

false . To use this property, you must also set

dependency_version_2 to true .
on_by_default

Experimental

Specifies whether an optional dependency is selected for users when they add your deployable architecture to a project from a catalog. Users
can deselect the component if they do not want it. The default value is false . To use this property, you must also set
dependency_version_2 and optional to true .
input_mapping (optional)

Experimental

Section header that specifies the values that are referenced between the compatible architecture and the architecture that you're onboarding.
To use this property, you must also set dependency_version_2 to true .

dependency_output or dependency_input (optional)

Specifies the variable from the dependency that the architecture that you're onboarding references. The value is the name of the variable
from the dependency. Only one of these two properties should be provided. If reference_version is set to true , then this variable
references the version_input variable from the architecture that you’re onboarding.
version_input (optional)

Specifies the name of the input variable in the architecture that you're onboarding that references the

dependency_output or

dependency_input value. If reference_version is set to true , then the dependency_input variable references the
version_input variable from the architecture that you’re onboarding.
value (optional)

Specifies the preset value for an input from the architecture that you’re onboarding ( version_input ) or its dependency
( dependency_input ). The value that is specified here is only used if a version_input or dependency_input is provided, and
dependency_output is not provided. If version_input is provided, then when the architecture and its dependency are added to a

project by a user, the architecture’s version_input is preset to the value specified here. If dependency_input is provided, then when
the architecture and its dependency are added to a project by a user, the dependency’s dependency_input is preset to the value
specified here.
reference_version (optional)

Indicates the flow of references between the architecture that you’re onboarding and its dependency. The default value is

false . The

default behavior is for the architecture input ( version_input ) to reference either an input or output from the dependency
( dependency_input or dependency_output ). When this flag is set to true , the dependency_input references a value from the
version_input .

Running secure workloads 136

ignore_auto_referencing (optional)

Experimental

An array of strings that are the dependency’s inputs. When the architecture that you’re onboarding and the dependency have the same input name
on both of their versions, and no references are set to the dependency_input by using input_mapping , the architecture’s version_input value is
automatically used in the dependency’s dependency_input . You can override this behavior by adding the input’s name to this array. You can also
add “*” and all automatic referencing is ignored.
dependency_version_2 (optional)

Experimental

Specifies that the updated dependency handling is used with this deployable architecture. If you are using the

optional property or the

input_mapping sections within the dependencies section, set this value to true . If not, set it to false . If this property is set to true , all

dependencies that have the optional property set to false are required to deploy the architecture that you're onboarding.
swappable_dependencies (optional)

Experimental

Section header for a list of products that are compatible with the deployable architecture. Unlike the

dependencies array, the products in this

section are swappable. The user can pick which product they want to use to meet the dependency. Swappable dependencies can be required or
optional. A dependency included here can't be added to the dependencies array as well. Information includes the programmatic name of the
product and product versions. Optionally, you can include the catalog ID and a list of dependent variations.
{
"optional": "true or false",
"name": "Name for this group of swappable dependencies",
"default_dependency": "the name of the dependency that is selected by default",
"dependencies": [
{
"name": "offering name"
"id": "offering ID"
"kind": "terraform"
"version": "SemVer version e.g. 3.1.2",
"flavors": [
"flavor name"
],
"install_type": "fullstack or extension",
"catalog_id": "catalog ID",
"input_mapping": [
{
"dependency_output": "kms_instance_crn",
"version_input": "existing_kms_instance_crn"
}
]
},
{
"name": "offering name"
"id": "offering ID"
"kind": "terraform"
"version": "SemVer version e.g. 3.1.2",
"flavors": [
"flavor name"
],
"install_type": "fullstack or extension",
"catalog_id": "catalog ID",
"input_mapping": [
{
"dependency_output": "kms_instance_crn",
"version_input": "existing_kms_instance_crn"
}
]
}
]
}

name (optional)

Used when the architecture is onboarded to a catalog to help you identify the specific group of

swappable_dependencies .

Running secure workloads 137

default_dependency (optional)

The name of one of the dependencies in the group that is selected for users by default.

release_notes_url

URL to the architecture's release notes.
configuration

Section header that specifies the configuration of deployment variables for specific variation. Catalog data types are used to extend native types and
facilitate for a better user experience when you're working in the IBM Cloud console. If you are running your code on a local machine or another
environment, the variables are not used. An example might be a catalog type of password that is used to extend the capabilities of a Terraform
variable defined with a type of string so that it is treated as sensitive in the UI.
{
"key": "The configuration key. This value should match the name of a deployment variable.",
"type": "The data type of the variable. This must be a valid catalog management type.",
"default_value": "The default value set by the person who onboarded the deployable architecture",
"value_constraint": "string",
"description": "The description of the variable that is shown in the catalog to those who use your deployable
architecture.",
"display_name": "The display name for the configuration type.",
"required": boolean,
"options": [
"Selectable option 1",
"Selectable option 2"
],
"hidden": boolean,
"custom_config": {
"type": "The ID of the widget type.",
"grouping": "Where the configuration type is rendered.",
"original_grouping": "The original groupiing type for the configuration.",
"grouping_index": "The order in which the configuration item shows in a particular grouping.",
"config_constraints": "Map of constraint parameters that are passed to the custom widget.",
"associations": "The list of parameters associated with the configuration.",
"options_url": "The URL where the options for your custom type can be pulled by using dynamic data from objects in the
catalog."
},
"configuration_group": "The name of the assocated configuration group."
}

key

The configuration key. The value should match the name of a deployment variable.
type

The type of input that a customer can define or select. The data type must be supported by the Catalog Management service. Native Terraform
types map to some of the supported types. For example, the Terraform type map equates to object . The Terraform type list equates to
array . A Terraform type string with a sensitive attribute equates to password . Customers that consume your deployable architecture

must provide values for the input type that you define in the catalog manifest.
Supported predefined types:
boolean requires a true or false string input from users.
float requires a point decimal from users.
int requires an integer input from users.
number requires a numeric value. The number type can represent both whole numbers and fractional values like 4.56 .
password requires a string input from users. The string is redacted in the console and logs.
string requires a sequence of Unicode characters representing text.
object requires a Terraform object input from users. For more information, see map.

Note: Predefined types require manual input from users.

Running secure workloads 138

Supported custom types:
array requires a list of values separated by a comma.
region requires user to select a region to deploy the deployable architecture from a dropdown list. You can filter the regions that are

available to end users. For example, you might specify country_id:us,ca,jp in the Region filter to limit the available regions to those
countries. For more information, see Filtering syntax.
textarea requires users to input text that can be split into multiple lines. For example, a description.
vpc requires users to select a VPC by name from a dropdown list. The output is the VPC name or ID that your template requires.
vpc ssh key requires users to select a VPC SSH key for authentication to a virtual machine.
cluster requires users to select a Kubernetes Service or Red Hat OpenShift cluster. The output is the cluster ID.
power iaas requires users to select a Power Virtual Server instance.
resource group requires users to select a resource group. The output is the resource ID or name.
multi-line secure value requires users to input text that can be split into multiple lines, which is redacted in the console and logs.

For example, if a long key is required, the value is hidden in workspaces.
schematics workspace requires users to select a specific workspace form a dropdown list. This list is dynamically filtered based on

dependencies defined in the deployable architecture. For example, if your deployable architecture, example-da-1 , depends on another
deployable architecture, example-da-2 , the input dropdown list for example-da-1 shows only workspaces associated with exampleda-2 . Users then select the appropriate instance of example-da-2 's workspace when setting up example-da-1 . For more information,

see dependencies.
json editor gives users a space to specify larger JSON inputs or plain text files.
Platform resource requires users to select an instance resource from a dropdown list for the type of resource that you specify. The

resource type can be VPC Subnet, VPC Image, or VPC Floating IPs. You can specify the ID or name as the values that users can choose
from and allow a single or multiple selections. The output is the name or ID that your template requires.
default_value

The value that is to be set as the default.
description

A description of the variable that you want to display in the UI for users of your deployable architecture.
display_name

The name that is displayed for the configuration type.
required

A boolean that indicates if users are required to specify the parameter during installation.
hidden

A boolean that indicates if the parameter should be hidden from users during installation.
options

An array of options that users can choose from for a parameter.
custom_config

Section header use to indicate that a custom configuration can be used.

type

The ID of the widget type used for configuration
grouping

Where the configuration type should appear in the catalog. Valid values are Target , Resource , and Deployment .
original_grouping

Where the configuration type originally appeared. Valid values are Target , Resource , and Deployment .
grouping_index

The order of this configuration item when there are mulitple.
config_constraints

Map of constraint parameters that are given to the custom widget.

Running secure workloads 139

associations

Section header for parameters that are associated with the configuration.

configuration_group

The name of an associated configuration group.

schematics_env_values

A list of the values and variables that need to be passed to the Schematics service to be used as environment variables during the execution of the
Terraform. This might be a secure value, a setting of the Terraform logging or something else. You can choose to specify a string or create a reference
to Secrets Manager. If both are specified, then the Secrets Manager reference is used.
{
"value": "Environment variables and their values",
"sm_ref": "Specification of an instance of Secrets Manager and a key"
}
minimum_compatible_version (optional)

A semver value that indicates the earliest version that is compatible with the current version. If no earlier versions are compatible with the current
version, specify the current version value in this field. By default, the current version is compatible with all earlier versions.
terraform_version

The Hashicorp Terraform runtime version that is needed to validate and install the version. Setting this value in the manifest overrides what is
specified in the source code.
outputs

Section header for information about Terraform output values.
{
"key": "name of the output value as defined in the Terraform",
"description": "The description of the key"
}

key

Specifies the output value.
description

A short summary of the output value.

install_type

Specifies whether a deployable architecture is fullstack or extension . Architectures listed as extensions require prerequisites. The
dependencies array must also completed if you set this value to extension . This property is ignored if dependency_version_2 is set to true .
scripts

A list of scripts contained within the same repository that can be run by a project during a particular stage of a specified action. Each key in the map
must match the format action and stage in the entry. Stage must be either pre or post . Action must be validate , deploy , or
undeploy .
{
"short_description": "description for the script",
"type": "type of script. i.e. ansible",
"path": "the path to the script in the repo. Must begin with scripts/..."
"stage": "pre or post"
"action": "The action that executes the script. Options include validate, deploy, or undeploy."
}

Running secure workloads 140

Managing compliance information for your deployable architecture
By using the ibm_cloud.json manifest file, you can include claims that your deployable architecture meets specific compliance requirements. After you
onboard and publish your deployable architecture to the catalog, users can view which controls or Security and Compliance Center predefined profiles your
product adheres to. You verify the compliance information before you onboard your deployable architecture.
Here's an example from the VSI on VPC landing zone's catalog page where the Standard variation meets the IBM Cloud Framework for Financial Services
v1.6.0 profile:

Deployable architecture compliance

The process to make a compliance claim for your deployable architecture includes steps that must be completed before and during the onboarding
process to a catalog:
1. Choose a Security and Compliance Center profile and set up an attachment to scan your resources
2. Add compliance information to your ibm_cloud.json manifest file
3. Add your scan results to your deployable architecture when you onboard

Choosing a profile and scanning your resources
Before you onboard your deployable architecture to a catalog, verify compliance with a profile in Security and Compliance Center. To claim compliance, you
scan the resources that the deployable architecture creates.
1. Create all of the resources in your account that your deployable architecture creates.
Tip: Organize the resources in a single resource group to make it easier to run a Security and Compliance Center scan against only those
resources in your account.
2. In the IBM Cloud console, click the Menu icon

> Security and Compliance > Profiles.

3. Select the profile name that represents the controls that are most relevant to your solution. For example, the IBM Cloud Framework for Financial
Services profile is a set of controls that are built specifically for and with the financial services industry. For a list of profiles, see Available predefined
profiles.
4. Select the profile from the list, and copy the profile name that displays at the beginning of the page and the version number. Save this information
locally because you need these values for updating the ibm_cloud.json manifest file.

Running secure workloads 141

Profile name and version

5. Click Attachments > Create .
6. Enter a name for the attachment, and click Next
7. Verify that the profile is the one that you want to use, and click Next.
8. Select the scope. If you organized all resources into a single resource group, set the scope to that resource group.
9. Select Every 30 days as the Schedule frequency, and click Next.
Tip: A scan starts when you finish creating the attachment. To keep you from being charged for scans later, return to this setting and change
it to None after you're finished onboarding your deployable architecture.
10. Review your attachment details, and click Save.
You see a status bar that indicates that a scan is in progress. If you need to start a one-off scan, use the Overflow menu

to select

Start scan.
When the scan is complete, you can use the Overflow menu

to select View scan results to ensure that the scan on your deployable

architecture resources passed the compliance checks as expected. For more information, see Scanning your resources and Viewing results.

Updating the compliance information in the manifest
After you identify the Security and Compliance profile name and version from the previous steps, you must add that information to the

ibm_cloud.json

catalog manifest file in your source repo.
1. If one does not exist, create a catalog manifest file at the root of your repo. For an example catalog manifest file, see the terraform-ibm-landingzone repo.
2. Open the ibm_catalog.json file.
3. Find or add the flavors.compliance field for the variation (flavor) that you want to update.
4. Set authority to scc-v3 .
5. Find or add a profiles[] array:
a. Set profile_name to the profile display name you saved in the previous steps.
b. Set profile_version to the version you noted in the previous steps.
For example:
"authority": "scc-v3",
"profiles": [
{
"profile_name": "IBM Cloud for Financial Services",
"profile_version": "1.3.0"
}
]

Running secure workloads 142

6. Save the file.

Adding a Security and Compliance Center scan during onboarding
When you onboard your deployable architecture in the console , you add your scan results so that users can see the compliance claims when they evaluate
your product in the catalog.
1. On the Manage compliance page, click Add scan.
2. Select the Security and Compliance Center instance that you used to complete your scan in the previous steps.
3. Select the profile.
4. Select your scan.
5. Click Apply scan.
Now that your scan results are added, you can complete onboarding and choose to share the deployable architecture to other accounts or enterprises, or
publish to the IBM Cloud catalog.

Cleaning up your resources
To add compliance claims to your deployable architecture, you had to create the resources in your account and a Security and Compliance Center instance.
To reduce future costs, you can delete all of the resources that you created during this process that you no longer need. You can keep your Security and
Compliance Center instance, but set your attachment scan schedule to None until you're ready to rerun a scan.

Running secure workloads 143

Using private catalogs to share solutions
Creating scripts for deployable architectures
You can have scripts that are run for your deployable architectures before or after validating, deploying, and undeploying. Scripts are configured to a
specific version of your deployable architecture, and must be run and validated through projects. For more information about projects, see Creating a
project.
There are several benefits and use cases for using scripts for your deployable architectures:
Performing custom validation, for example, if you want to ensure that the tag parameter is always a valid cost center ID. The pre-validation script
might call out to a service to check that the cost center ID was valid.
Tracking deployments and adding resources, for example, adding to an inventory system by providing a post-deployment script that can call out to a
service to track which resources were deployed.
Completing data migration. A pre-deployment script can back up data. Then, after the deployable architecture deletes the old data store and creates
the new one, the post-deployement script can restore it to the new data store.
Installing or configuring software
Completing day two maintenance tasks such as manual backup, restore, or key rotations.

Adding pre- and post-scripts
Scripts are optional for an offering, but if they are used they are required to be in the source repository in a directory named

scripts . The script files

themselves must conform to the following naming convention <action>-<stage>-ansible-playbook.yaml . Options for action include deploy ,
validate , and undeploy . Options for stage include pre and post .

Important: Only ansible scripts in the playbook format are currently supported.
You must also reference your scripts in the ibm_catalog.json manifest file in your source repo. Provide the required information for your scripts per
variation of your deployable architecture in the scripts array:
"scripts": [
{
"type": "ansible",
"short_description": "Short description of what your script is intended to do.",
"path": "Path to script location.",
"stage": "The stage. For example, pre.",
"action": "The action. For example, validate."
}
],

Tip: You can add this information to your catalog manifest file in the source repo before you onboard to IBM Cloud, or you can manually add the
scripts during the onboarding workflow in the console. If you manually add the scripts during onboarding, download your manifest file and add it to
your source repo to keep the information in sync for future versions.
All scripts must be able to run more than once without failing. For example, a pre-deployment or post-deployment script must operate correctly, even if it
is run several times. Post-deployment scripts might add resources to a catalog management database and must be sure not to add duplicate resources if
run more than once.

Pre- and post-script examples
The following is an example of a pre-script that is used to display a message after the deployable architecture is validated. Pre-scripts get passed to all of
the inputs from the deployable architecture, including the credentials used to authorize deployment.
- name: Validate pre playbook
hosts: localhost
vars:
ibmcloud_api_key: "{{ lookup(`ansible.builtin.env`, `ibmcloud_api_key`)}}"
cos_instance_name: "{{ lookup(`ansible.builtin.env`, `cos_instance_name`)}}"
workspace_id: "{{ lookup(`ansible.builtin.env`, `workspace_id`)}}"
tasks:
- name: Print message
ansible.builtin.debug:
msg: "The workspace id is {{ workspace_id }}"
Running secure workloads 144

when: workspace_id is defined and workspace_id != ""
- name: Print message
ansible.builtin.debug:
msg: "The cos instance name is {{ cos_instance_name }}"
when: cos_instance_name is defined
- name: Print result
ansible.builtin.debug:
msg: "Received api key"
when: ibmcloud_api_key is defined

The following is an example of a post-script. Post-scripts get passed to the outputs of the deployable architecture.
- name: Deploy post playbook
hosts: localhost
vars:
ibmcloud_api_key: "{{ lookup(`ansible.builtin.env`, `ibmcloud_api_key`)}}"
git_repo_url: "{{ lookup(`ansible.builtin.env`, `git_repo_url`)}}"
tasks:
- name: Print result
ansible.builtin.debug:
msg: "Received api key"
when: ibmcloud_api_key is defined
- name: Print result
ansible.builtin.debug:
msg: "The result is: {{ git_repo_url }}"
when: git_repo_url is defined and git_repo_url != ""

Customizing the IBM Cloud catalog for an enterprise
As the account owner or administrator, you can manage which products in the IBM Cloud® catalog are available for your enterprise. You can choose to
include all products, a set of products, or only certain products. You can also specify what level of the enterprise hierarchy the filters apply to. And, you can
further restrict which products are available for a specific account group or account.

Before you begin
Set up your enterprise .
Make sure that you have the administrator role on the catalog management service .

Managing products at the enterprise level
Centrally manage what's available in the catalog for your entire enterprise hierarchy by setting filters at the enterprise level. The filters automatically apply
to all child account groups and accounts.
Let's say your organization is tasked with implementing a development and deployment model that's focused on improved speed, quality, and control. You
might choose to restrict the catalog to IBM products only that are related to DevOps technologies for all members in your enterprise.
1. Go to Manage > Catalogs > Settings in the IBM Cloud console.
2. Select Exclude all products in the IBM Cloud catalog .
3. Select one or more filters to customize which products are available. In the case of our example, select the following filters:
Category > Developer tools
Provider > IBM
4. Review the Preview table to confirm your selections, and click Update.
5. Verify your updates in the catalog by going to Catalog > Services.
6. Expand the list of accounts in the console menu bar and select a child account to verify that the catalog includes only the products you selected.

Managing products for child account groups and accounts
To build on the example in the previous section, all account groups and accounts in your enterprise have access to Developer tools products provided by
IBM. You can further restrict access to a subset of products for child account groups and accounts. For example, you might want to limit a specific account
group, and its child accounts, to work with only the products that are Financial Services Validated.
1. Go to Manage > Catalogs > Settings in the IBM Cloud console.
Running secure workloads 145

2. Expand the enterprise hierarchy, and select the specific account group.
3. Select Exclude all products in the IBM Cloud catalog .
4. Select Compliance > Financial Services Validated.
5. Review the Preview table to confirm your selections, and click Update.
6. Switch to a child account in the account group by selecting it from the list of accounts in console menu bar.
7. Verify your updates in the catalog by going to Catalog > Services.

Managing products at the enterprise level by using the CLI
This action can be done only in the console or through the API or SDKs. To see the steps, switch to the

UI or API instructions.

Managing products for child account groups and accounts by using the CLI
You can restrict access to a subset of products for child account groups and accounts. For example, within your enterprise you might want to limit a specific
account group, and its child accounts, to work with only the products that are Financial Services Validated.
1. Create a new filter.
ibmcloud catalog filter create [--catalog CATALOG] [--category CATEGORY] [--compliance COMPLIANCE] [--deployment-target
TARGET] [--exclude-list LIST] [--include-all ALL] [--include-list LIST] [--offering-format FORMAT] [--pricing-plan PLAN] [-provider PROVIDER] [--release RELEASE] [--type TYPE]

Note: If you don't specify the --catalog CATALOG command, the filter is created at the account level.
2. Target an account group by specifying the command option --account-group ACCOUNT GROUP .
3. Update the filter to include or exclude a particular product or products. See the

Catalog management CLI guidance for command options or run the

ibmcloud catalog filter options command to retrieve the filter options for each filter category.

Managing products at the enterprise level by using the API
Centrally manage what's available in the catalog for your entire enterprise hierarchy by setting filters at the enterprise level. The filters automatically apply
to all child account groups and accounts.
Java
String id = "{id}";
String revision = "{revision}";
String accountFilters = {accountFilters};
ReplaceCatalogOptions replaceOptions = new
ReplaceEnterpriseOptions.Builder().enterpriseId(id).id(id).rev(revision).accountFilters(accountFilters).build();
Response<Catalog> response = service.replaceEnterprise(replaceOptions).execute();
System.out.println(response.getResult());

Node
id = "{id}";
revision = "{revision}";
accountFilters = {accountFilters};
response = await service.replaceEnterprise({ 'enterpriseId': id, 'id': id, 'rev': revision, 'accountFilters': accountFilters, });
console.log(response);

Python
id = "{id}"
revision = "{revision}"
accountFilters = "{accountFilters}"
response = self.service.replace_enterprise(enterprise_id=id, id=id, rev=revision, account_filters= accountFilters)
print(response)

Go
id := "{id}"
revision := "{revision}"
Running secure workloads 146

accountFilters := {accountFilters}
replaceOptions := {replaceOptions}
replaceOptions := service.NewReplaceEnterpriseOptions(id)
replaceOptions.SetID(id)
replaceOptions.SetRev(revision)
replaceOptions.SetAccountFilters(accountFilters)
response, _ := service.ReplaceEnterprise(replaceOptions)
fmt.Println(response)

Managing products for child account groups and accounts by using the API
You can restrict access to a subset of products for child account groups and accounts. For example, within your enterprise you might want to limit a specific
account group, and its child accounts, to work with only the products that are Financial Services Validated.
The following example request restricts the products for an account group and child accounts. When you call the API, replace the ID variables with the
values that are specific to your target account group or account. The options for {account_filters} are: inculde_all , category_filters , and
id_filters .

Java
String id = "{id}";
Filters accountFilters = {accountFilters};
UpdateCatalogAccountOptions updateOptions = new
UpdateCatalogAccountOptions.Builder().id(id).accountFilters(accountFilters).build();
Response<Void> response = service.updateCatalogAccount(updateOptions).execute();
System.out.println(response.getResult());

Node
id = "{id}";
accountFilters = {accountFilters};
response = await service.updateCatalogAccount({ 'id': id, 'accountFilters': accountFilters });
console.log(response);

Python
id="{id}"
accountFilters={accountFilters}
response = self.service.update_catalog_account(id=id, account_filters=accountFilters)
print(response)

Go
id := "{id}"
accountFilters := {accountFilters}
updateOptions := service.NewUpdateCatalogAccountOptions()
updateOptions.SetID(id)
updateOptions.AccountFilters(accountFilters)
response, _ := service.UpdateCatalogAccount(updateOptions)
fmt.Println(response)

Onboarding a deployable architecture to a private catalog
When you're ready to share your deployable architecture with other members of your organization, you can add it to a private catalog. Additionally, you can
use the onboarding flow to validate your architecture.

Before you begin
Before you can onboard your deployable architecture, be sure that you complete the following prerequisites.
Verify that you're using a Pay-As-You-Go or Subscription account. See Viewing your account type for more details.
Verify that you have the required access to work with private catalogs and deployable architectures.
Manager role on the IBM Cloud Schematics service
Editor role on the Catalog Management service
Viewer role on all resource groups in your account
Running secure workloads 147

SecretsReader role on the Secrets Manager service if you plan to store your secure values in an instance of Secrets Manager
Reader role on the Security and Compliance Center service
Other roles that are required for specific resources in your customized deployable architecture.
Create a private catalog.
Ensure that you have the source code for your deployable architecture stored in a GitHub or GitLab repository. For help with getting your source code
into a repository, see Setting up your source code repository .
Tip: Want to see how it works but don't have a deployable architecture ready to use? Use our sample deployable architecture.

Packaging your source code
To create the .tgz file that you need to onboard your deployable architecture to a private catalog, you must create a release version of your source code.
For help with creating a release, see Managing releases in a repository .
If you're using a private source code repository, be sure that you have a Git personal access token or a secret that is stored in

Secrets Manager.

Adding a deployable architecture to a private catalog
To add your deployable architecture to a private catalog, you can use the following steps.
1. In the IBM Cloud console, go to the Manage > Catalogs > Private catalogs page of the console.
2. Select the private catalog that you want to add a product to. The catalog details page opens.
3. Click Add product. A side panel opens.
4. Select Deployable architecture for Product type.
5. Select Terraform or Stack as your Delivery method.
6. Select the type of repository where your source code is located.
If your source code is located in a private repository, you need to authenticate by using a Git personal access token or a secret from

Secrets Manager.

7. Add a link to your source code in the Source URL field. It should look similar to https://github.com/IBM-Cloud/terraformsample/archive/refs/tags/v1.1.0.tar.gz .

Note: If you are onboarding your deployable architecture for testing purposes, you do not need to have a

.tgz file. You can provide the link

to the root level of your architecture.
8. Select a Variation.
A variation is a type of deployable architecture that applies differing capabilities or complexity to an existing deployable architecture. For example,
there might be a Quick start variation to your deployable architecture that has basic capabilities for simple, low-cost deployment to test internally.
And, you might have a Standard variation that is a bit more complex that is ready for use in production.
9. Enter the software version in the format of major version, minor version, and revision. For example,

1.0.0 . Typically, this version matches the

version number of your release snapshot.
10. Select the Category that you want your deployable architecture to be grouped with in the catalog.
11. Click Add product. The product overview page is displayed.

Editing your catalog entry
After you successfully onboard your deployable architecture to your private catalog, you must specify the information that a user sees when they attempt
to use the architecture. The information includes descriptions of the product, links to documentation, and keywords that ensure that your product is easily
findable.
1. Go to the Manage > Catalogs > Private catalogs page of the console.
2. Select the private catalog that you added your product to. The catalog details page opens.
3. Select the product that you previously onboarded.
4. Edit the way that your entry is shown in the catalog.

Running secure workloads 148

a. In the catalog entry details section, click Edit.
b. Review the information that was imported with your deployable architecture and make edits as needed.
c. Verify that your entry is showing as expected by checking the Catalog entry preview.
d. When you're finished making your selections, click Save.
5. Edit the About page for your product. When a user selects your product from the catalog, an About section is shown that allows them to learn more
about your product and the features that are available.
a. In the Actions drop-down, select Edit product page.
b. Enter a description of your product that explains the product's value and benefits to your users.
c. To add specific feature information, click Features > Add feature.
d. Add product-level features that explain the processes, abilities, and results of the product. Users can see the high-level product features at the
beginning of the product page that apply to the product as a whole, regardless of version or architecture variation differences. For example, if
your product creates Virtual Private Clouds, you can add Creates Virtual Private Clouds as the feature title and Virtual Private
Clouds are created for you with the necessary underlying network components. as the feature description. To add features for

specific variations or versions, you can do so by Adding highlights.
e. Click Update.

Specifying details through the console
Your users see the version-level information that you define as part of the catalog entry for your product. The information provided as part of this flow can
help your users to understand the functionality of the individual components that are associated with it.
Note: To ensure that your selections are carried over into your next release, you can generate a manifest file. The manifest file,
ibm_catalog.json , is the source of truth for your catalog entry. It contains all of the information about your product and the selections that you've

made. After you generate the file, you must add it to the root level of your source code repository. If you prefer to work in the code, the following
sections can be configured directly through the mainfest file. For more information about how to structure the file, see Locally editing your
manifest file.

Getting to the details
After you add your deployable architecture to a private catalog, you're able to use a step-by-step walkthrough in the console to update the general
information about your product. To get to the console page, you can use the following steps.
1. Go to the Manage > Catalogs > Private catalogs page of the console.
2. Select the private catalog where you added your product. The catalog details page opens.
3. Select the product that you previously onboarded.
4. On the Versions tab, select the version of your product that you want to provide information for.
5. Use the following information as a guide to configure your deployable architecture details.

Configuring your version details
On the Configure version tab, you can review and update information about the specific version of your architecture. You configure deployment details,
define the required IAM access, and detail change notices that you want your users to be aware of.
If your deployable architecture requires a specific Terraform runtime version, you can override the default version. If you included

TF_VERSION as an input

variable within your source code repository, it should have automatically been updated when you created your catalog entry.
Input variables are the parameters that users specify when they use your product. You can review and modify the input and output variables that were
imported with your source code, or you can add variables to your deployable architecture as part of this step. When variables are added, you can update
whether they're required, visible, or the format in which they need to be provided.
When you release a new version of your product, there might be changes that you want to notify your users of before they get started with the new version.
You can separate the information into three categories - breaking changes, new features, and general updates.
Breaking changes: Detail any changes to the code of the new version that can cause a disruptive experience to your users who are working with a
previous version.
New features: Highlight any new functionality provided in the new version that a user might want to take advantage of.
Updates: Describe any general updates that were made to the new version. For example, bug fixes or improvements to existing features.

Including pre- and post-scripts
You can have a pre-script or post-script run for your deployable architectures before or after validating, deploying, and undeploying. Scripts are configured
Running secure workloads 149

to a specific version of your deployable architecture as specified in the catalog manifest file, and must be run and validated through projects.
Scripts are optional for an offering but if they are used they are required to be in the repository in a directory named

scripts . The script files themselves

must conform to the following naming convention <action>-<stage>-ansible-playbook.yaml . Options for action include deploy , validate , and
undeploy . Options for stage include pre and post . Only ansible scripts in the playbook format are supported at this time.

All scripts must be able to run more than once without failing. For example, a pre-deployment or post-deployment script must operate correctly, even if it
is run several times. Post-deployment scripts might add resources to a catalog management database and must be sure not to add duplicate resources if
run more than once.
For more information, including examples, see Creating scripts for a deployable architecture .

Adding deployable architecture details
When you make a deployable architecture available to other users in the cloud, you must provide the following information:
An architecture diagram that details how the components in your deployable architecture work together.
Any highlights that can help users to differentiate between which version or variation of your architecture might be best suited to their needs.

Adding license agreements
If users are required to accept any license agreements beyond the IBM Cloud Services Agreement, provide the URL to each agreement.

Editing your readme file
Document the instructions for installing your deployable architecture in the readme file.

Validating the version
Select the target for validation. When a product is validated, the resources are deployed. For a stand-alone deployable architecture, the target can be either
a Schematics workspace in your current account or a specific project. For a deployable architecture stack, you must use a project. Depending on the option
that you select, more configuration information might be required. After your target is configured, you must provide the values for the input and output
variables that are required for your architecture to successfully deploy to the target. After your variables are configured, you can validate the version.
Note: Do not clean up the resources in your account until after you run the compliance evaluation in the managing security and compliance
section.
If the version fails validation because of a CRA scan, an administrator for the account can choose to override the failure and deploy anyway. If the validation
fails for any other reason, it is highly recommended that you fix any issues that are found before publishing your offering.

Reviewing cost
Ensure that you fully understand the costs that are associated with deploying your architecture. The version must be validated before you can generate an
estimated cost.

Managing compliance
When you make a deployable architecture available to others in your organization, you can specify the specific compliance controls that your architecture
meets by using the default installation. Compliance with regulatory controls is evaluated by IBM Cloud Security and Compliance Center. For more
information, see Running an evaluation for IBM Cloud® .
1. Click Add claims.
2. Select a profile. The profile is pulled from the Security and Compliance Center service. You can choose to select a predefined profile or go to Security
and Compliance Center and create one of your own.
3. Specify whether your deployable architecture meets all of the controls in the profile or whether it can satisfy the control requirements for a subset of
the controls.
4. If your architecture can meet only a subset of the controls, then you must select the controls that can be satisfied and add them as claims.
5. Use Security and Compliance Center to confirm the claims that you've identified.
a. In the IBM Cloud console, click the menu icon

> Security and Compliance to access Security and Compliance Center.

b. Create an attachment by using the profile that you selected.
Note: The scope that you define as part of creating an attachment must contain the resources that were deployed when you validated your
Running secure workloads 150

product.
c. Run a scan and wait for the results to be available.
6. In the Manage compliance tab of the catalog UI, click Add scan.
7. Select an Instance, Profile, and the specific scan that you want to add.
8. Click Add

Reviewing requirements
When you've completed the walkthrough, you must review your selections and confirm that you are ready to share your product to your catalog. When
you're ready, click Ready to share.

Downloading the manifest
Whenever changes are made to your product configuration through the console, it is a best practice to generate and download your manifest file to ensure
that your changes are picked up in future releases of your product.
To download a manifest, you can use the following steps.
1. Go to the Manage > Catalogs > Private catalogs page of the console.
2. Select the product that was previously onboarded. A details page opens.
3. On the Versions tab, select the version that you want to generate a manifest for.
4. From the Actions drop-down menu, select Export as code.
5. Add the file into the root folder of your source code repository as

ibm_catalog.json .

Downloading your catalog configuration
If you are working with a deployable architecture stack, there are additional files that are generated in addition to your manifest file. If you have made
updates to your catalog configuration by using the console, it is a best practices to download the files and add them to your source code repository so that
your changes carry over into your next release.
1. Go to the Manage > Catalogs > Private catalogs page of the console.
2. Select the product that was previously onboarded. A details page opens.
3. On the Versions tab, select the version that you want to generate a manifest for.
4. From the Actions drop-down menu, select Export as code.
5. Add the files into the root folder of your source code repository.

Adding a variation
You can add more variations that are a new version of your architecture that is designed to build upon the funtions of the base deployable architecture. If
you created multiple variations in separate working directories in your source repo and specified them in the flavors array in your ibm_catalog.json
manifest file, you must onboard each variation separately.
At this point, you've already onboarded your first variation. Now, you can start back at Adding a deployable architecture to onboard your next variation.
Here are a few tips for onboarding your next variation:
The source URL of the repo release will be the same for all of the variations within that release and they should be imported with the same version
number. The product name and version number are how the variations are linked together and then result as options on the same catalog tile.
On the Add deployable architecture details page, step 3 includes adding highlights. These are known as features in the

ibm_catalog.json manifest

file. You might have already added these in the manifest, so you can review them here. If not, go ahead and add some highlights. These should be
short ability, process, capacity, or other features of this specific architecture. You will use the same highlight "Name" across all variations. The
description is where there should be differences. This enables users to evaluate the differences in the architectures by using the text highlights on
the catalog details page.

Next steps: Sharing and publishing
Now that your deployable architecture is added to a private catalog and the details are set, you're ready to share the product with other members of your
organization. For help with sharing, see Sharing your product.
If you want to publish your deployable architecture to the IBM Cloud catalog, you can use Partner Center to get approval and publish for all users to take
advantage of the solution that you built. For more information, see Publishing your deployable architecture.

Running secure workloads 151

Onboarding modules to a private catalog
A module is a stand-alone unity of automation code that can be reused by developers and shared as part of a larger system. You can choose to create your
own module or select one from the IBM Cloud Terraform module repository. To share a module with others in your organization or to validate the
deployment, you can add the module to a private catalog.

Before you begin
Before you can onboard your module, be sure that you complete the following prerequisites.
Verify that you're using a Pay-As-You-Go or Subscription account. See Viewing your account type for more details.
Verify that you have the required access to work with private catalogs and modules.
Manager role on the IBM Cloud Schematics service
Editor role on the Catalog Management service
Viewer role on all resource groups in your account
SecretsReader role on the Secrets Manager service if you plan to store your secure values in an instance of Secrets Manager
Reader role on the Security and Compliance Center service
Other roles that are required for specific resources in your customized module.
Create a private catalog.
Ensure that you have the source code for your module stored in a GitHub or GitLab repository. For help with getting your source code into a
repository, see Setting up your source code repository .

Packaging your source code
To create the .tgz file that you need to onboard your module to a private catalog, you must create a release version of your source code. For help with
creating a release, see Managing releases in a repository .
If you're using a private source code repository, be sure that you have a Git personal access token or a secret that is stored in Secrets Manager.

Adding a module to your private catalog
1. In the IBM Cloud console, go to the Manage > Catalogs > Private catalogs page of the console.
2. Select the private catalog that you want to add a module to. The catalog details page opens.
3. Click Add product. A side panel opens.
4. Select Module for Product type.
5. Select Terraform as your Delivery method.
6. Select the type of repository where your source code is located.
If your source code is located in a private repository, you need to authenticate by using a Git personal access token or a secret from Secrets
Manager.
7. Add a link to your source code in the Source URL field. It should look similar to https://github.com/terraform-ibm-modules/terraform-ibmcos/archive/refs/tags/v7.0.5.tar.gz .

8. Select the Example that you want to use.
9. Enter the software version in the format of major version, minor version, and revision. For example,

1.0.0 . Typically, this version matches the

version number of your release snapshot.
10. Select the category that you want your module to be grouped with in the catalog.
11. Click Add product. An overview page is displayed.

Adding examples to your module in a private catalog
To add additional examples to your module, you can add a new version.
1. Go to the Manage > Catalogs > Private catalogs page of the console.
2. Select the private catalog that you added your module to. The catalog details page opens.
3. Select the module that you want to provide more details for.

Running secure workloads 152

4. On the Versions tab, click Add version.
5. Follow the process outlined in the previous section - Adding a module to your private catalog .

Editing your catalog entry
After you successfully add your module to a private catalog, you can specify the information that users sees when they attempt to use your module. The
information includes descriptions of the module, links to documentation, and keywords that ensure that your module is easily findable.
1. Go to the Manage > Catalogs > Private catalogs page of the console.
2. Select the private catalog that you added your module to. The catalog details page opens.
3. Select the module that you want to provide more details for.
4. Edit the catalog entry details for your module.
a. In the catalog entry details section, click Edit.
b. Review the information that was imported with your deployable architecture and make edits as needed.
c. Verify that your entry is showing as expected by checking the Catalog entry preview.
d. When you're finished making your selections, click Save.
5. Edit the About page for your module. When users select your module from the catalog, an About section is shown that allows them to learn more
about the features that are available.
a. In the Actions drop-down, select Edit product page.
b. Enter a description of your module that explains the module's value and benefits to your users.
c. To add specific feature information, click Features > Add feature.
d. Add module-level features that explain the processes, abilities, and results of the module.
e. Click Update.

Specifying version details through the console
Your users see the example-level information that you define as part of the catalog entry for your module. The information provided as part of this flow can
help others to understand the functionality of the individual components that are associated with it.
Important: After you specify details through the console, you can generate a manifest file and add it to your source code. By doing so, you can
ensure that your specifications are carried over into future releases and you don't need to reconfigure them with each release.

Getting to the details
After you add your module to a private catalog, you can use a step-by-step walkthrough in the console to update general information about your module.
To get to the console page, you can use the following steps.
1. Go to the Manage > Catalogs > Private catalogs page of the console.
2. Select the private catalog that you added your module to. The catalog details page opens.
3. Select the module that you want to provide more details for.
4. On the Versions tab, select the specific version that you want to provide information for. You can use the console to update any of the sections that
you need to.

Configuring version details
On the Configure version tab, you can review and update information about the specific version of your module. You also configure deployment details,
define the required IAM access, and detail the change notices that you want your users to be aware of.
If your module requires a specific Terraform runtime version, you can override the default version. If you included

TF_VERSION as an input variable within

your source code repository, it was automatically updated when you created your catalog entry.
Input variables are the parameters that users specify when they use your module. You can review and modify the input and output variables that were
imported with your source code, or you can add variables to your module as part of this step. When variables are added, you can update whether they're
required, visible, or the format in which they need to be provided.
When you release a new version of your module, there might be changes that you want to notify your users of before they get started with the new version.
You can separate the information into three categories - breaking changes, new features, and general updates.
Breaking changes: Detail any changes to the code of the new version that can cause a disruptive experience to your users who are working with a
previous version.
New features: Highlight any new functionality provided in the new version that users might want to take advantage of.
Running secure workloads 153

Updates: Describe any general updates that were made to the new version. For example, bug fixes or improvements to existing features.

Adding module details
When you make a module is made available to other users in the cloud, you must provide the following information:
An architecture diagram that details how the components in your module work together.
Each example of a module must have at least one architecture diagram that outlines the relationships, constraints, and boundaries between the
components included in the module example. Architecture diagrams must be provided in .svg format.
Any highlights that can help users to differentiate between which version or example of module might be best suited to their needs. For example, you
might want to list the number of VPCs, network connectivity type, high availability capability, or other important factors that might be used to
differentiate each example.

Adding license agreements
If users are required to accept any license agreements beyond the IBM Cloud Services Agreement, provide the URL to each agreement.

Editing your readme file
Document the instructions for running your module in the readme file.

Validating the version
The validation process tests your Terraform template by running it from the Schematics service that you configure. A successful validation ensures that
users can use your module with your default input variables. You must validate your module before you can share it. To monitor the progress of the
validation process, click View logs from the Actions menu. The Schematics workspace is opened.

Reviewing cost
Ensure that you fully understand the costs that are associated with onboarding your module. The version must be validated before you can generate an
estimated cost.

Managing compliance
When you onboard a module to a private catalog, you can specify compliance controls that your module meets when it is run. Compliance with regulatory
controls is evaluated by IBM Cloud Security and Compliance Center. For more information, see Running an evaluation for IBM Cloud® .
1. Click Add claims.
2. Select a profile. The profile is pulled from the Security and Compliance Center service. You can choose to select a predefined profile or go to Security
and Compliance Center and create one of your own.
3. Specify whether your module meets all of the controls in the profile or whether it can satisfy the control requirements for a subset of the controls.
4. If your module can meet only a subset of the controls, then you must select the controls that can be satisfied and add them as claims.
5. Use Security and Compliance Center to confirm the claims that you've identified.
a. In the IBM Cloud console, click the menu icon

> Security and Compliance to access Security and Compliance Center.

b. Create an attachment between the profile that you selected and a scope that contains the resources that are created during your validation
deployment.
c. Run a scan and wait for the results to be available.
6. In the Manage compliance tab of the catalog UI, click Add scan.
7. Select an Instance, Profile, and the specific scan that you want to add.
8. Click Add

Reviewing requirements
When you've completed the walkthrough, you must review your selections and confirm that you are ready to share your module to your catalog. When
you're ready, click Ready to share.

Downloading the manifest
Whenever changes are made to your module configuration through the console, it is a best practice to generate and download a new manifest file to ensure
Running secure workloads 154

that your changes are picked up in future releases of your modue.
To download a manifest through the UI, you can use the following steps.
1. Go to the Manage > Catalogs > Private catalogs page of the console.
2. Select the module that was previously onboarded. A details page opens.
3. On the Versions tab, select the version that you want to generate a manifest for.
4. From the Actions drop-down menu, select Export as code.
5. Add the file into the root folder of your source code repository as

ibm_catalog.json .

Next steps
Now that your module is added to a private catalog and the details are set, you're ready to share it with other members of your organization. For help with
sharing, see Sharing your product.

Sharing a private catalog
You can share products in your private catalog with users in your account, account groups within your enterprise, the entire enterprise, and even other
enterprises that you have access to. By sharing your product, any user within the account, enterprise, or account groups can create an instance of your
product.

Before you begin
You must be assigned the following access. For more information, see Assigning users access.
Editor role on the Enterprise account management service in the enterprise account.
Administrator role on the Catalog Management account management service in the same account as your product.
Verify that at least one version of your product is in the ready state.

Sharing your product by using the console
When you share a product with enterprises, users in your account, or account groups, they can create instances of any version that is validated and in the
ready state. Versions that are in the draft state are not shared with users. Complete the following steps to share your product:

1. In the IBM Cloud® console, click Manage > Catalogs > Private catalogs.
2. Select the private catalog where your product is located.
3. Select the product that you want to share.
4. Click Actions... > Share.
5. Review the list of affected versions.
Tip: If you don't see the version that you want to share, make sure that the version is in the

ready state.

6. Select one of the following options:
Share to this account
Share to this enterprise or account groups to select the enterprise or specific account groups within the enterprise.
Share with other enterprises to add IDs for enterprises or account groups in other enterprises that you are assigned Editor role or higher on.
This option is used to create an allowlist of other enterprises or account groups to which you want to share your product. You must have the
Editor role on the enterprise or account group that you are trying to add. Select Add accounts, enter the enterprise ID, and click Add > Share.
Note: When you share your product with another enterprise, the enterprise is added to a list of IDs that are granted access to your product.
This list is also known as the allowlist. Any account that is not included in the allowlist can't access your product.
7. Click Share.

Sharing your product by using the CLI
When you share a product with users in your account, enterprise, or account groups, they can create instances of any version that is validated and in the
ready state. Versions that are in the draft state are not shared with users, unless the user has access to the private catalog.

Running secure workloads 155

Run the ibmcloud catalog offering publish enterprise command to share your product to your enterprise:
ibmcloud catalog offering publish enterprise [--catalog CATALOG][--offering OFFERING]

Run the ibmcloud catalog offering publish allowlist command to share your product to an allowlisted set of accounts:
ibmcloud catalog offering publish allowlist [--catalog CATALOG][--offering OFFERING][--account-ids ACCOUNT-IDS]

Note: The ibmcloud catalog offering publish allowlist command shares your product with stand-alone accounts, enterprises, or account
groups based on the IDs listed in the command. You must have Editor role or higher on the other enterprise or enterprise account groups that you
add to the list to successfully share the product. If you add a stand-alone account that is external to your enterprise, the account is added to your
allowlist, but your product isn't shared to that account until you have publishing approval for your product .

Onboarding your deployable architecture by using a Visual Studio Code extension
You can onboard your deployable architecture by using the IBM Cloud Deployable Architecture Builder Visual Studio Code extension. Using the extension
autogenerates materials that are required and it can avoid or minimize issues where a separate configuration is made each time the user runs validation
through the catalog. The extension helps you to easily onboard your deployable architecture to your private catalog and a project.

Before you begin
Before you can onboard your deployable architecture, be sure that you complete the following prerequisites.
Download Visual Studio Code
Verify that you're using a Pay-As-You-Go or Subscription account. See Viewing your account type for more details.
Verify that you have the required access to work with private catalogs and deployable architectures.
Manager role on the IBM Cloud Schematics service
Editor role on the Catalog Management service
Viewer role on all resource groups in your account
SecretsReader role on the Secrets Manager service if you plan to store your secure values in an instance of Secrets Manager
Reader role on the Security and Compliance Center service
Other roles that are required for specific resources in your customized deployable architecture.
Ensure that you have the source code for your deployable architecture stored in a GitHub. For help with getting your source code into a repository,
see Setting up your source code repository .
A Terraform module in a public or private GitHub repository that is cloned to a local folder. For experimentation, you can make a fork of this

sample

Terraform module. If your repository is private, you need a personal access token with repo and read:user permissions.

Getting the VS Code extension
To get the extension, open VS Code, go to Extensions, search for and select IBM Cloud Deployable Architecture Builder to download. After you download,
you can follow the walkthrough to get started or use the following steps. If the walkthrough doesn't automatically open, you can use the command palette.
Go to View > Command Palette. Search for Walkthrough , click Welcome: Open Walkthrough..., then select Get started with IBM Cloud Deployable
Architecture Builder.

Onboarding your deployable architecture
The first time that you validate your deployable architecture, you go through the steps for onboarding it to IBM Cloud. Use the following steps to onboard
your deployable architecture:
1. Log in to your IBM Cloud account.
a. To log in to your account, click View and select Command Palette.
b. In the search field, search for IBM Cloud - Log in .
c. Select IBM Cloud - Log in and log in with an API key, federated ID, or username and password.
d. (Optional) You can change your login environment. Click View, select Command Palette, search for IBM Cloud - Log in , and select IBM
Cloud - Log in > Change login environment. From the menu, select Production or Staging.
2. Make sure that you're logged in to GitHub from VS Code.
a. Select the

> Sign in to Sync Settings .

b. Select your account.

Running secure workloads 156

c. Click Authorize Visual-Studio-Code.
3. Clone your repo and add it to a VS Code workspace.
a. Clone your deployable architectures repo from GitHub.
b. To add it to your workspace within VS Code, click File > Add folder to workspace... , then select the repo from your files.
4. Add the catalog manifest files to the Terraform module.
a. To add the catalog manifest, right-click the module folder in your workspace.
b. Select IBM Cloud > Add deployable architecture manifest files .
5. Onboard and validate your deployable architecture.
a. Right-click the ibm_catalog.json file, and select IBM Cloud > Validate a deployable architecture on IBM Cloud .
b. Select the repo branch. Or you can click + and enter the name of a new one that will be created.
c. Select an existing private catalog. Or you can click + and enter the name of a new one that will be created.
d. Enter the offering version.
e. Select an existing project. Or you can click + and enter the name of a new one that will be created for you.
f. Enter your IBM Cloud API key for the account where resources will be deployed.
g. Enter the relative path for the architectural diagram. If you don't have a diagram, a placeholder is provided.
h. (Optional) If the GitHub repository is private or in GitHub Enterprise, enter your personal access token.
i. The YAML inputs file is opened. Edit the values under the inputs property and save the file.
j. Click Continue
When validation begins, an Output channel is opened that shows the validation logs. If it does not, in the Output view, select the DA Validation channel
from the menu. Validation can take several minutes to complete.

Running secure workloads 157

Deploying architectures and managing resources with projects
Creating a project
In a project, you can add deployable architectures from the catalog and edit their configuration. Deploying a configuration from a project groups resources
based on the configuration that you deployed.

Before you begin
Resources are created in the project account for the user. You must have permission to create a project and permission to create the project tooling
resources within the account. Make sure that you have the following access:
The Editor role on the IBM Cloud Projects service.
The Editor and Manager role on the IBM Cloud® Schematics service
The Viewer role on the resource group for the project
For more information about access and permissions, see Assigning users access to projects .

Adding users to a project
Project access is controlled by IBM Cloud Identity and Access Management (IAM). You add users to a project by granting the Reader role or higher on the
project instance. For more information on assigning access to projects, see Assigning users access to projects .

Creating a project by using the console
You can create a project by going to the Navigation menu icon

and selecting Projects or from a deployable architecture in the

catalog. Projects can also be created by using the Project API.

Adding a deployable architecture to a project by using the console
Deployable architectures that you add to a project are represented as configurations in the project UI. After you add a deployable architecture to a project,
you can edit your configuration before you deploy it. There are a couple of ways to add a deployable architecture to your project.
To add a deployable architecture to your project from the project dashboard, complete the following steps:
1. From the project dashboard, select the Configurations tab.
2. Click Create.
3. Select a deployable architecture from the catalog.
4. Click Add to project.
You can also add a deployable architecture to a project directly from the catalog:
1. Go to the IBM Cloud catalog.
2. Select the deployable architecture.
3. Click Add to project.
4. You can create a new project or add to an existing project.
5. Enter the required details for the deployable architecture.
6. Click Add.
Tip: To back up the project information outside of the IBM Cloud Projects service, you can export the project. For more information, go to

Project

JSON.
Check out the steps on how to configure and deploy a deployable architecture when you're ready to deploy resources from a deployable architecture from
a project.

Creating a project by using the CLI
To create a project by using the CLI, run the following ibmcloud project create command:
ibmcloud project create [--definition DEFINITION | --definition-name DEFINITION-NAME --definition-destroy-on-delete=DEFINITIONDESTROY-ON-DELETE --definition-description DEFINITION-DESCRIPTION --definition-auto-deploy=DEFINITION-AUTO-DEPLOY --definitionmonitoring-enabled=DEFINITION-MONITORING-ENABLED] --location LOCATION --resource-group RESOURCE-GROUP [--configs CONFIGS] [--

Running secure workloads 158

environments ENVIRONMENTS]

See ibmcloud project create for an example command and more information about the command parameters.

Adding deployable architecture to a project by using the CLI
To add a deployable architecture to your project by using the CLI, run the following ibmcloud project config-create command:
ibmcloud project config-create --project-id PROJECT-ID [--definition DEFINITION | --definition-compliance-profile DEFINITIONCOMPLIANCE-PROFILE --definition-locator-id DEFINITION-LOCATOR-ID --definition-description DEFINITION-DESCRIPTION --definitionname DEFINITION-NAME --definition-environment-id DEFINITION-ENVIRONMENT-ID --definition-authorizations DEFINITION-AUTHORIZATIONS
--definition-inputs DEFINITION-INPUTS --definition-settings DEFINITION-SETTINGS --definition-members DEFINITION-MEMBERS -definition-resource-crns DEFINITION-RESOURCE-CRNS] [--schematics SCHEMATICS | --schematics-workspace-crn SCHEMATICS-WORKSPACECRN]

See ibmcloud project config-create for an example command and more information about the command parameters.
Tip: To back up the project information outside of the IBM Cloud Projects service, you can export the project. For more information, go to

Project

JSON.

Creating a project by using the API
You can programmatically create a project by calling the Projects API as shown in the following sample request:
Curl
curl -X POST --location --header "Authorization: Bearer {iam_token}" \
--header "Accept: application/json" \
--header "Content-Type: application/json" \
--data '{ "definition": { "name": "acme-microservice", "description": "A microservice to deploy on top of ACME
infrastructure.", "authorizations": { "method": "trusted_profile", "trusted_profile_id": "Profile-9ac10c5c-195c-41ef-b46568a6b6dg5f12" } }, "configs": [ { "definition": { "name": "account-stage", "description": "The stage account configuration.",
"locator_id": "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global" } }, { "definition": { "name":
"env-stage", "description": "The stage environment configuration that includes services common to all the environment regions.",
"locator_id": "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global", "inputs": { "account_id":
"ref:/configs/account-stage/inputs/account_id", "resource_group": "stage", "access_tags": [ "env:stage" ], "logdna_name": "The
name of the LogDNA stage service instance.", "sysdig_name": "The name of the SysDig stage service instance." } } }, {
"definition": { "name": "region-us-south-stage", "description": "The stage us-south configuration.", "locator_id": "1082e7d25e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global" } }, { "definition": { "name": "region-eu-de-stage",
"description": "The stage eu-de configuration.", "locator_id": "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-978503e8e03bef72-global", "inputs": { "account_id": "ref:/configs/account-stage/inputs/account_id", "resource_group":
"ref:/configs/env-stage/outputs/resource_group_id", "logdna_id": "ref:/configs/env-stage/outputs/logdna_id", "sysdig_id":
"ref:/configs/env-stage/outputs/sysdig_id", "access_tags": [ "region:eu-de" ] } } } ], "location": "us-south", "resource_group":
"Default" }' \
"{base_url}/v1/projects"

Adding a deployable architecture to a project by using the API
You can programmatically add a deployable architecture to an existing project by calling the Projects API and customizing the configuration as shown in
the following sample request:
Curl
curl -X POST --location --header "Authorization: Bearer {iam_token}" \
--header "Accept: application/json" \
--header "Content-Type: application/json" \
--data '{ "definition": { "name": "env-stage", "description": "The stage environment configuration.", "locator_id": "1082e7d25e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global", "inputs": { "account_id": "account_id",
"resource_group": "stage", "access_tags": [ "env:stage" ], "logdna_name": "LogDNA_stage_service", "sysdig_name":
"SysDig_stage_service" } } }' \
"{base_url}/v1/projects/{project_id}/configs"

Tip: To back up the project information outside of the IBM Cloud Projects service, you can export the project. For more information, go to

Project

JSON.

Running secure workloads 159

Creating an environment
Within your project, create an environment to group related configurations together and share values across them for easier deployments. The properties
that you add to an environment are automatically added to configurations that are using that environment. Within the configuration, you can override any
values that are provided by the environment. For more information, see the benefits to using environments .
Tip: When you edit a configuration, you can select an environment for the configuration to use in the Define details section.

Before you begin
You must have the Editor role or greater on the IBM Cloud® Projects service to create and edit environments. For more information about access and
permissions, see Assigning users access to projects .

Creating an environment by using the console
To create an environment from your project, complete the following steps:
1. In the IBM Cloud console, click the Navigation menu icon

> Projects and select a project.

2. From the Manage tab, select Environments.
3. Click Create.
4. Provide a name for your environment, then click Add to add properties.
There are three categories of properties that you can add to an environment: authentication, compliance, and input. You can add these properties
manually, or add multiple properties at once from a configuration in your project.

Adding properties manually
If you add properties manually, consider adding the authentication method first. The authentication method for your target account is required to authorize
a deployment to that target account. The authentication method is also used if you want to pull in a Security and Compliance Center attachment from your
target account. You can add only one authentication property to an environment, and you can only add a compliance property to an environment if you have
a Security and Compliance Center attachment in your target account that you want to use. You can't add a compliance property that uses the default
controls from the deployable architecture, as those default controls vary from architecture to architecture.
Important: You must provide an authentication property in your environment first with valid authentication details if you want to add a compliance
property and specify an attachment from Security and Compliance Center. You can use an API key with Secrets Manager or you can use a trusted
profile to authenticate with the target account that contains your Security and Compliance Center attachment.
Authentication and compliance information is used in all configurations, so if you add an authentication property or a compliance property with a Security
and Compliance Center attachment to your environment, it is automatically added to any configuration that's using the environment.
Input values can also be added as properties to your environment. When you add an input to an environment, the name of your input in the environment
must match the name of the input in the configurations that are using the environment. If the names do not match, the value from the environment is not
used in the configuration. For example, if you add an input to your environment and name it resource_group , but a configuration that is using that
environment has an input that is named resourcegroup the value from the environment is not used in that configuration.
Multiple architectures can use the same environment, but not all architectures have the same input names for similar values. You can add multiple inputs
to your environment with the same value, but different names. For example, you can add two input properties and name one resource_group and the
other resourcegroup . Keep the values the same for both properties. Any configuration that's using the environment and has a

resource_group input

name or a resourcegroup input name will use the same value from the environment.
To add a property manually, complete the following steps:
1. After you create your environment, click the Edit icon

for the environment.

2. Click Add > Add manually...
3. Select which category of property you want to add.
Consider adding an authentication property first with valid authentication details for your target account.
4. Provide the details for the property and click Add.
5. Click Save.

Adding properties from a configuration
Running secure workloads 160

Save time and reduce errors by adding multiple properties to your environment from a configuration. By doing so, you help ensure that the properties are
accurate in your environment, as the input names and values are pulled directly from the configuration that you select. After you add the properties from a
configuration, you can edit them in the environment without affecting your configuration. Future edits to your configuration do not impact the properties in
your environment.
To add multiple properties from a configuration, complete the following steps:
1. After you create your environment, click the Edit icon

for the environment.

2. Click Add > Add from a configuration…
3. Select the configuration that you want to use to add properties to your environment.
4. Select the items from the configuration that you want to add to your environment, and click Add.

Creating an environment by using the CLI
To create an environment by using the CLI, run the following ibmcloud project environment-create command:
ibmcloud project environment-create --project-id PROJECT-ID [--definition DEFINITION]

Within the definition , you can specify the input properties that you want to include in your environment by using the

inputs option. Similarly, you can

specify an authentication property in your environment by using the authorizations option within the definition . And, you can add a compliance
property by including the compliance-profile option within the definition as well.
For example, the following command creates an environment that is named development and has one input property that defines the resource group:
ibmcloud project environment-create \
--project-id exampleString \
--definition '{"name": "development", "inputs": {"resource_group" : "stage"}}'

Similarly, the following command creates an environment that is named development and has one input property that defines the resource group. A
trusted profile is also provided as an authentication property, along with an attachment from Security and Compliance Center for the compliance property
that is located in the us-south region:
ibmcloud project environment-create \
--project-id exampleString \
--definition '{
"name": "development",
"authorizations": {
"method": "trusted_profile",
"trusted_profile_id": "<trusted-profile-id>"
},
"inputs": {
"resource_group": "stage"
},
"compliance_profile": {
"id": "<profile-id>",
"instance_id": "<instance-id>",
"instance_location": "us-south",
"profile_name": "{\"instance_crn\":\"crn:v1:staging:public:compliance:us-south:a/<account>:<instanceid>::\",\"instance_label\":\"compliance\",\"name\":\"Basic Control\",\"version\":\"1.0.0\",\"attachment_label\":\"basic\"}",
"attachment_id": "<attachment-id>"
}
}'

For more information about the command parameters, see ibmcloud project environment-create .

Creating an environment by using the API
You can programmatically create an environment by calling the Projects API as shown in the following sample request. The example creates an
environment that is named development and has two input properties, one to define the resource group and one to define the region:
Curl
curl -X POST --location --header "Authorization: Bearer {iam_token}" \
--header "Accept: application/json" \
--header "Content-Type: application/json" \
--data '{ "definition": { "name": "development", "description": "The environment 'development'", "authorizations": { "method":
Running secure workloads 161

"api_key", "api_key": "TbcdlprpFODhkpns9e0daOWnAwd2tXwSYtPn8rpEd8d9" }, "inputs": { "resource_group": "stage", "region": "ussouth" }, "compliance_profile": { "id": "some-profile-id", "instance_id": "some-instance-id", "instance_location": "us-south",
"profile_name": "some-profile-name", "attachment_id": "some-attachment-id" } } }' \
"{base_url}/v1/projects/{project_id}/environments"

Integrating a project with a Git repository
Connect a project to a Git repository to save configurations there. By doing so, you can use your repository and the CI and CD tools of your choosing to
automate pipelines on configurations in a project.
This is an experimental feature that is available for evaluation and testing purposes and might change without notice.
Pipelines and toolchains are customizable, so you can automate many actions between your Git repository and your project by using projects API methods
or CLI commands. For example, you can create a pipeline to trigger an update in your project when configuration changes are merged to the main branch
in your repository. For more information, see Automating projects actions in your Git repository .
Important: In a project, draft configurations can be saved to any branch in your repository. However, you can validate and deploy draft
configurations only after they are merged to the branch in your repository that manages your CD pipelines. You must also sync the updates from
your repository into your project by updating configurations before you can validate and deploy those configurations. You can automate this update
by using the project.config.update API method or by using the ibmcloud project config-update CLI command.

Before you begin
1. Make sure you have the Editor role on the IBM Cloud Projects service to manage Git repository integrations.
2. Save an access token as a secret to connect to your Git repository. The access token needs write access to the branches that you want to use and to
create commits in your repository. The access token also needs the ability to list branches and read them.
a. Create a Secrets Manager service instance in your IBM Cloud account. To create a secret, you must have the Writer role or higher on the
Secrets Manager service.
b. After you create your secret instance, make sure that you select Other secret type to add an arbitrary secret. For information about creating an
arbitrary secret, see Creating arbitrary secrets in the UI . Your arbitrary secret must contain the access token for your Git repository.

Connecting a project to a Git repository
Connect your Git repository to your project. By doing so, configuration changes are saved to your repository, as opposed to the project JSON file. Because
your project needs to save configurations to your repository, you must provide an access token to authenticate with the repository from your project.
1. In the IBM Cloud console, click the Navigation menu icon

> Projects and select a project.

2. From the Manage tab, select Integrations.
3. In the Git repository integration section, click Connect.
4. From the Repository type menu, select the type of repository that you want to use to manage your configurations. Typically, this repository is the one
you use to manage your pipelines and toolchains. You can select GitHub, GitLab, or GitHub Enterprise.
5. Enter the URL to the repository.
6. Optionally, specify a folder within the repository. Consider specifying a folder if you want to integrate your repository with multiple projects. Each
project can have its own folder.
7. Hover or click the access token field, then click the Secrets icon

to select the secret that contains your access token.

8. If your project already contains configurations, select Copy existing configuration files to this repository to save existing configurations to your
repository.
9. Click Save.

Next steps
Now that your Git repository is connected with your project, you're ready to customize pipelines and toolchains. To learn how to create a pipeline that
automatically updates configurations in your project when changes are merged to your main branch, see Automating projects actions in your Git
repository.

Authorizing deployments
Using an API key with Secrets Manager to authorize a project to deploy an architecture
Running secure workloads 162

When you configure your deployable architecture, you are required to select an authentication method. You can use an API key that is stored as a secret to
authorize a project to deploy in an account.
A secret is a piece of sensitive information, for example an API key, password, or any type of credential that you might use to access a confidential system.
You can use a secret in IBM Cloud® Secrets Manager as a way to manage API keys dynamically and store them securely in your own dedicated instance.
Important: Though it is possible to add your API key directly into your configuration, it is not recommended, as the API key displays in your
project.json file and is visible to anyone who exports it.

Before you begin
1. Make sure that you are assigned the required permissions to create the project tooling resources within the account in addition to permission to
create projects:
The Editor role on the IBM Cloud Projects service.
The Editor and Manager role on the IBM Cloud® Schematics service.
The Viewer role on the resource group for the project.
For more information about access and permissions, see Assigning users access to projects .
2. Each API key that you create has the same access that you are assigned as a user. Before you create an API key, make sure that you have access to
deploy architectures in the account that you want to deploy to, also known as your target account. If you have the following wide-ranging access,
then you can deploy architectures in the account:
The Administrator role for All Identity and Access enabled services.
The Administrator role for All Account Management services.
Alternatively, you can create an API key that is associated with a service ID . Service ID API keys inherit all access that is assigned to the specific
service ID. So, you can scope the access for the service ID to the minimum that is required for the deployable architecture that you're configuring.
This approach is similar to using a trusted profile with specific access based on the deployable architecture. For more information on finding the
required access roles for any given deployable architecture, see granting specific access based on the deployable architecture .
3. Complete the required steps to create a project and add a deployable architecture . You authorize the project to deploy with an API key or existing
secret when you configure your deployable architecture.

Creating an API key
Complete the following steps to create an API key:
1. In the IBM Cloud console, sign in to the account that you want to deploy to.
2. Go to Manage > Access (IAM) > API keys.
3. Click Create an IBM Cloud API key .
4. Enter a name and description for your API key.
5. Click Create.
6. Then, click Show to display the API key. Or, click Copy to copy and save it for later, or click Download.
Tip: For security reasons, the API key is only available to be copied or downloaded at the time of creation. If the API key is lost, you must
create a new API key.

Adding an API key to Secrets Manager
After you create an API key, complete the following steps to add it to Secrets Manager in the account that contains your project:
1. Create a Secrets Manager service instance in your IBM Cloud account. To create a secret, you must have the Writer role or higher on the Secrets
Manager service.
2. After you create your secret instance, make sure that you select Other secret type to add an arbitrary secret. For information about creating an
arbitrary secret, see Creating arbitrary secrets in the UI . Your arbitrary secret must contain the API key. The API key must be created in the target
account that you want to deploy to.

Using a secret reference

Running secure workloads 163

After you create a secret, you can use that secret as a reference to authorize your project to deploy. For more information about references, see
Referencing values. To configure your deployable architecture with a secret reference, complete the following steps:
1. In the IBM Cloud console, sign in to the account that you want to deploy the project to.
2. Go to Menu

> Projects.

3. Select the project that includes the deployable architecture configuration that you want to authorize.
4. From the Configurations tab, select the configuration.
5. Click Edit
6. In the Configure section, hover over the API key field, and select the Key icon.
7. Choose the service instance and select the secret that you want to use and click OK.
Note: You can also use a trusted profile as a reference. In the Configure section, for the method, select Trusted profile and enter your trusted
profile ID. For more information, see Using trusted profiles.

Using trusted profiles to authorize a project to deploy an architecture
Important: Some services cannot fully configure and deploy architectures by using trusted profiles. For more information, see Known issues and
limitations for projects.
When you configure your deployable architecture, you are required to select an authentication method. A project can apply a trusted profile, which grants
the project access to deploy an architecture in the account where the trusted profile exists. This way, you can securely deploy an architecture without the
need for key rotation.
The project uses the trusted profile to create a service ID with the same permissions as the trusted profile and a fresh API key for that service ID to
authorize each deployment. Because the temporary API key exists only for the lifetime of the operation, this improves security because it's harder to
misuse. The trusted profile needs access to create a service ID and create and delete API keys for the service ID, as well as access to deploy the
deployable architecture.

Deploying an architecture in your account or another account
You can deploy an architecture in your own account or in another account, also called a target account, by using trusted profiles.
Depending on your organization, deploying an architecture might require access to another account by using a trusted profile and coordinating with
administrators in multiple accounts. If the IBM Cloud Projects service in another account needs access to your account to deploy an architecture, use
trusted profiles and service IDs to authorize deployments in your account.

Before you begin
Make sure that you create the trusted profile in the account where you want to deploy the architecture. If you have the following access, you can create
trusted profiles:
Account owner
Administrator role on all account management services
Administrator role on the IAM Identity Service. For more information, see IAM Identity service.
All users have access to create a service ID in an account to which they are a member.

Creating the trusted profile
Create a trusted profile that can do the following:
Create a service ID
Create and delete API keys for the service ID
Deploy the deployable architecture
Complete the following steps:
1. Find the project CRN. The CRN is used to authorize deployments to a target acccount.
To find the project CRN while you're editing a project configuration, click the tooltip icon on the trusted_profile_id field and copy the CRN.
Otherwise, go to Menu

> Projects and click the relevant project. Click Manage > Details and copy the CRN.

2. Confirm that you are in the target account to which the project deploys.

Running secure workloads 164

3. In the IBM Cloud® console, click Manage > Access (IAM), and select Trusted profiles.
4. Click Create.
5. Describe your profile by providing a name and a description, then click Continue.
Tip: In the description, provide a list of actions available for this trusted profile.
6. Select IBM Cloud services.
7. Input the CRN from step 1.
8. In the description, enter the project name and any relevant notes.
9. Click Continue.
10. Assign access.
a. Select Access policy.
b. Create a policy that grants the trusted profile access to create service IDs and manage service ID API keys:
a. Select the IAM Identity Service and click Next.
b. Select All resources and click Next.
c. Select the Service ID Creator role and the Administrator role and click Next.
d. Click Add.
This enables the project to generate a unique, temporary API key for each deployment, avoiding the need to manually rotate API keys. For
more information, see Required access for managing service ID API keys
c. Create a policy that grants the trusted profile access to deploy the deployable architecture.
You can choose from a couple of approaches to grant the service ID access to authorize deployments in your account. See

Granting wide-

ranging access or Granting specific access for more information.
d. Click Add.
11. Click Create.

Granting wide-ranging access
Grant the trusted profile Administrator access to everything in the account by assigning two policies. Consider this option if you plan to deploy many
deployable architectures to the same target account. Deployable architectures usually require extensive privileges in the target account since they typically
deploy and configure a wide range of services and IAM policies on those services. You can use the same trusted profile for different deployable
architectures across projects, eliminating the need to continuously update the trusted profile's access policies.
Note: It's secure and convenient to give the trusted profile a wide range of access because the profile contains only a platform service, and not
users. Projects also have many governance checks already in place, including pre-deployment validation and a required approval process. By
granting Administrator access now, you don't need to update the policy for the multiple deployable architectures that you might use that require
different levels of access. This is more secure than directly authorizing a user to have any privileges in the target account.
1. To create the first policy, select All Identity and Access enabled services and click Next.
a. Select All resources and click Next.
b. For the resource group access, select the Administrator role and click Next.
c. Select the Manager service role and the Administrator platform role.
d. Click Add.
2. For the second policy, select All Account Management services and click Next.
a. Select the Administrator role and click Next.
b. Click Add.
3. Click Create.

Granting specific access based on the deployable architecture
Grant the trusted profile the minimum required access role for the configuration that you're deploying. Choose this option if you have one or only a few
deployable architectures with the same access requirements that you plan to deploy to the same target account.
Running secure workloads 165

View the catalog page for specific access roles that are required for a given deployable architecture.
1. In the IBM Cloud console, click Catalog.
2. Search for and select the deployable architecture that you're deploying.
3. Click Deploy with IBM Cloud Schematics to view the required access roles.
Note: You're not deploying yet. This is a quick way to view the required access roles.
4. Continue by assigning the trusted profile the required access roles that you viewed in the previous step.
For more information about assigning access, see Creating the service ID .
5. Click Create.

Granting specific access to existing resources
If you are using a trusted profile to organize existing resources in a project, you can grant the trusted profile access to specific resources, as opposed to all
of them. Choose this option if you want to limit which existing resources a project can manage.
1. To create the first policy, select All Identity and Access enabled services and click Next.
a. Select Specific resources, scope the access to the resources you want, and click Next.
b. For the resource group access, select the Administrator role and click Next.
c. Select the Manager service role and the Administrator platform role.
d. Click Add.
2. For the second policy, select All Account Management services and click Next.
a. Select the Administrator role.
b. Click Add.
3. Click Create.

Creating the service ID
After you create the trusted profile, it auto-generates a service ID. The service ID name begins with

iam-Profile , ends with platform-project-access ,

and includes the ID of the trusted profile in between. If the service ID is ever deleted, it's re-created the next time that the trusted profile is used.

Coordinating with the administrator on the IBM Cloud Projects service
The project user who edits the architecture configuration needs identifying information for the trusted profile that you created to complete the
authorization. Users need the Operator role or higher on the IBM Cloud Projects service to edit a configuration.
To retrieve the trusted profile ID value, complete the following steps.

Finding the trusted profile ID
1. In the IBM Cloud console, click Manage > Access (IAM), and select Trusted profiles.
2. Select the profile that you created for the deployable architecture authorization.
3. Click Details.
4. Copy the Profile ID that begins with Profile .
5. Give this ID to the relevant project user.

Configuring and deploying architectures
Configuring a deployable architecture
After you add a deployable architecture to your project, you can edit the input values to configure the architecture for deployment.
Configurations can be generic, but many projects use a configuration, or a group of configurations, to deploy resources to different environments. For
example, a group of configurations can be used to deploy resources to development, test, and production environments and set up common services
outside of the environments. When you deploy your configuration, IBM Cloud® Schematics uses Terraform to apply the underlying plan.
Note: Before you can deploy your architecture, the inputs, plan, compliance, and estimated cost for the deployable architecture must be validated.
Any changes that are made to the configuration are validated to help ensure that there aren't any issues or failures.

Running secure workloads 166

Setting input values
Input values are used to configure a deployable architecture to match your specific needs. The required inputs vary based on the deployable architecture
that you choose. Depending on how the architecture was designed, some inputs might include a set of options that you can select, or you can enter values
in fields as text strings.

Referencing values
Configurations can be linked together by using the outputs of one configuration as the inputs in another. For example, a configuration for an application
could use an output from an infrastructure configuration, such as a cluster ID, to deploy onto that infrastructure. To achieve this, you can add a reference to
an input or an output from another configuration. You can also reference parameters from an environment. When you add a reference, the value is pulled
from the input, output, or environment and used as the input value in the architecture that you're configuring.
Tip: In the console, you can add a reference in an architecture that you're configuring by hovering over an input and selecting the Reference icon
.
If you are using the API or CLI to configure a deployable architecture, or if you are editing a deployable architecture stack definition and you want to
include a reference, you can write one as a text string. References comply with the URL specification, but use a different ref protocol instead of http .
Just like URLs on websites, you can write a reference that's relative to your current context. For example, if you're adding a reference to an input within the
configuration that you're currently editing, then your current path is /configs/<configname> and you can write a reference relative to that path. For
example, ref:./inputs/region adds a reference to the input that is named region within the same configuration. In this case, the configuration that
you're editing does not need to be deployed to reference another value within it.
Tip: You can find the name of an output to reference by opening a deployed configuration in your project and going to the Outputs tab.

Referencing values from a configuration
The general format to reference a value in a configuration is as follows:
ref:/configs/<config_name>/inputs_or_outputs/<input_or_output_name> .

You can reference an input or an output from a configuration that was deployed from your project. For example, the following reference points to an output
that is named cluster_id within the ProdCluster configuration: ref:/configs/ProdCluster/outputs/cluster_id .
You can add a relative reference to another input within the configuration that you're currently editing. The configuration does not need to be deployed to
do so.

Referencing values in a stack
Experimental

If your configuration is part of a stacked deployable architecture, you can reference outputs from other member configurations in the stack and specify
inputs for the stack itself. The general format to reference a value for a stack is as follows:
ref:/configs/<stack_name>/members/<member_name>/inputs_or_outputs/<input_or_output_name>

If you want to make a relative reference, you can do so. A relative reference between configurations that are members of the same stack would be
formatted as ref:../<member_name>/inputs_or_outputs/<input_or_output_name> . But, if you are referencing a value at the stack level, it would be
formatted as ref:../../inputs/<input_name> within the member configuration. Currently, members can't reference outputs from the stack level.

Referencing inputs from an environment
Since environments are created within a project, and not within a configuration, you don't need to include

/configs/<configname> if you want to

reference a parameter in an environment. But you must include the name of the environment after the environments reference type. Then, specify
inputs and provide the name of the input that you want to reference:

ref:./environments/<environment_name>/inputs/<name> . You can't add a

reference to an authentication parameter or a compliance profile from an environment.
For example, the following reference points to an input parameter that is named cluster_id within the Production environment:
ref:./environments/Production/inputs/cluster_id .

Configuring an architecture by using the console
To create a customized configuration, complete the following steps:
1. From the Security panel, select the authentication method that you want to use to deploy your architecture.
Running secure workloads 167

Note: Add an API key by using IBM Cloud® Secrets Manager. This authorizes the project to deploy to a target account and is required to
deploy your architecture. For more information, see Using an API key with Secrets Manager to authorize a project to deploy an architecture .
2. During validation, a Code Risk Analyzer scan is run on your architecture. Select the controls that you want to use during validation. You can use the
Architecture default controls, or the Select from Security and Compliance Center option if you have an attachment set up in your target account.
If you select Architecture default:
The scan uses the default controls that the owner of the deployable architecture added when they onboarded it.
Controls that the architecture owner added that are also included in the supported set of Security and Compliance Center rules are checked.
Any extra controls that the architecture owner added that are not included in the list of supported rules are not checked when you validate your
configuration.
If the owner of the deployable architecture didn't add compliance controls to their product, the full set of Security and Compliance Center rules
is used.
Tip: To view the list of added controls, go to the IBM Cloud® catalog and select the deployable architecture that you're configuring. The
Security & compliance tab lists all of the controls that were added to the deployable architecture.
If you select Select from Security and Compliance Center , you must have an instance of the service and an attachment through Security and
Compliance Center in the target account that you want to deploy to. For help with creating an attachment, see Evaluating resource configuration
with IBM Cloud Security and Compliance Center.
3. From the Required panel, enter values for the required inputs for the deployable architecture configuration.
4. Optional: You can add values by going to the Optional panel.
5. Click Save.
6. Click Validate. The modal that is displayed provides more details about your in-progress validation.
If the validation fails, you can troubleshoot the failure . Or, an administrator on the IBM Cloud Projects service can review the results through the
Schematics service and override the failure and approve the configuration to deploy anyway. However, ensure that the pipeline failed due to the
Code Risk Analyzer scan and not because of a validation or plan failure. It is not recommended to override a failure that is flagged due to a validation
or plan failure as the configuration might not deploy successfully. For more information about security and compliance in projects, see Achieving
continuous compliance as an enterprise.
Important: If you're configuring deployable architectures that are stacked together, make sure to validate each architecture in order according to
their dependencies. Alternatively, you can edit your project's settings to automatically deploy configuration changes that are validated successfully.
If you do so, each architecture is validated, approved, and deployed automatically according to their dependencies. For more information, go to
Deploying an architecture.

Approving configuration changes by using the console
After you validate your configuration, the changes must be approved by an editor or administrator on the IBM Cloud Projects service. Complete the
following steps to approve changes:
1. From the projects list, select a project.
2. Check that there aren't any outstanding needs attention items on the Overview tab in your project. Needs attention items can block your ability to
deploy.
3. Go to the Configurations tab, and select a deployable architecture configuration.
4. Click Edit.
5. Click View last validation.
6. Add a comment providing more details about the approval, and click Approve.
If your validation failed due to the Code Risk Analyzer scan, an administrator on the IBM Cloud Projects service can

override the failure and approve the

configuration to deploy anyway.

Configuring an architecture by using the CLI
To add a configuration to a project by using the CLI, run the following

ibmcloud project config-create command:

ibmcloud project config-create --project-id PROJECT-ID [--definition DEFINITION] [--schematics SCHEMATICS]

Running secure workloads 168

For more information about the command parameters, see ibmcloud project config-create .

Approving configuration changes by using the CLI
1. Run the following ibmcloud project config-validate command to get a validation check on your configuration:
ibmcloud project config-validate --project-id PROJECT-ID --id ID

For more information about the command parameters, see ibmcloud project config-validate .
2. After validating your configuration, approve your configuration edits and merge them to the main configuration by running the following

ibmcloud

project config-approve command:
ibmcloud project config-approve --project-id PROJECT-ID --id ID [--comment COMMENT]

For more information about the command parameters, see ibmcloud project config-approve .

Configuring an architecture by using the API
You can programmatically add a configuration to a project by calling the Projects API as shown in the following sample request. The example adds a
configuration with the name My new configuration to a project:
Curl
curl -X POST --location --header "Authorization: Bearer {iam_token}" \
--header "Accept: application/json" \
--header "Content-Type: application/json" \
--data '{ "definition": { "name": "env-stage", "description": "Stage environment configuration.", "locator_id": "1082e7d2-5e2f0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global", "inputs": { "account_id": "account_id", "resource_group":
"stage", "access_tags": [ "env:stage" ], "logdna_name": "LogDNA_stage_service", "sysdig_name": "SysDig_stage_service" },
"settings": { "IBMCLOUD_TOOLCHAIN_ENDPOINT": "https://api.us-south.devops.dev.cloud.ibm.com" } } }' \
"{base_url}/v1/projects/{project_id}/configs"

Approving configuration changes by using the API
You can programmatically approve configuration edits and merge them to the main configuration by calling the

Projects API as shown in the following

sample request. The example approves configuration edits and merges them to the configuration:
Curl
curl -X POST --location --header "Authorization: Bearer {iam_token}" \
--header "Accept: application/json" \
--header "Content-Type: application/json" \
--data '{ "comment": "Approving the changes" }' \
"{base_url}/v1/projects/{project_id}/configs/{id}/approve"

Estimating architecture costs in a project
Cost estimation is available for deployable architectures in the IBM Cloud catalog. Depending on the deployable architecture, a starting cost is estimated
based on the available data. This estimate is meant to be a starting point to help you determine how much your account could be charged for deploying an
architecture. This estimated amount is subject to change as the architecture is customized within a project, and it does not include all resources, usage,
licenses, fees, discounts, or taxes.

Viewing the starting cost for your deployable architecture
Depending on the deployable architecture that you select from the catalog, there is an estimated starting cost.
To view the estimated starting cost, complete the following steps:
1. Go to the catalog details page for the deployable architecture.
2. Next, click the Starting at amount for additional details about the cost summary.
After you add the deployable architecture to your project, you can configure the input values. By doing so, you can tailor the architecture to match your
needs. Adjusting the configuration input might adjust the estimated cost.
1. Go to the Projects page, and select a project.
2. Go to Configurations, and select a configuration of the deployable architecture.
Running secure workloads 169

3. Enter the input values to configure the deployable architecture, and click Save. For more information about configuring and deploying, see
Configuring and deploying a deployable architecture .
4. After saving, the validation checks are run and a new cost estimate is computed. This might take a few minutes. After the validation is complete, you
can view the estimated cost for the configured architecture on the validation modal in the Cost estimate successful section.
Important: This estimated amount is subject to change as the architecture is customized and deployed, and it does not include all resources,
usage, licenses, fees, discounts, or taxes.

Approving failed validations
As an administrator on the IBM Cloud® Projects service, if the validation pipeline didn't complete or succeed, you can override the failure and approve it.
Important: Before you override a failed validation, ensure that the pipeline failed due to a Code Risk Analyzer scan and not because of a validation
or plan failure. If you override a failure because of a validation or plan failure, approving isn't recommended because the configuration won't deploy
successfully.

When to approve a failed validation
There might be a couple scenarios where you'd want to override a failed validation. If a major customer-impacting event requires you to make updates
quickly, you might want to deploy your changes even at the risk of introducing compliance errors, which can be fixed later.
Sometimes, compliance errors are introduced that aren't applicable to your configuration or business needs. For example, if your Object Storage bucket
resiliency is not set to cross region, the corresponding compliance goal will fail. However, this compliance issue might not impact your business if you don't
need maximum availability and want to deploy your configuration to only one region.
To approve a failed validation, complete the following steps:
1. From the projects list, select a project.
2. Go to the Configurations tab, select a deployable architecture configuration, and click Edit.
3. Select View details from the menu.
4. Review the issues that caused the validation to fail.
5. If you want to approve the changes, select Override and approve.
6. Add a comment that explains why you're approving the changes.
7. Click Override and approve.

Deploying an architecture
After your deployment updates are validated and approved, you can deploy your architecture to your target account. You can deploy to any account that
has authorized your project for deployments. For more information, see Using an API key with Secrets Manager to authorize a project to deploy an
architecture.
Tip: You can edit your project settings to automatically approve and deploy changes that are successfully validated. To do so, open your project
and go to Manage > Settings and toggle Auto-deploy on. With this setting enabled, if any deployable architectures are stacked together in your
project, after the first architecture is successfully validated, the remaining deployable architectures are validated, approved, and deployed
sequentially according to their dependencies. If no dependencies exist between the architectures, they are deployed in parallel with one another.

Deploying your architecture by using the console
To deploy your architecture, complete the following steps:
1. From the Deployments tab in your project, click the name of your deployable architecture > Edit.
2. Review the input values and make any necessary changes.
3. Click Deploy. This action includes preparing your resources to deploy, which can take a few minutes. You are notified when the deployment is
successful.
4. Review the resources and outputs from the deployable architecture.
If any additional changes are needed, or if a new version of the deployable architecture is available, edit the architecture deployment, validate it, and
deploy it again. Deploy your architecture again if there is any drift detected in your Schematics workspace.

Viewing resources by using the console
Running secure workloads 170

View your resources that are tied to the deployable architecture by completing the following steps:
1. From the projects list, select a project.
2. Go to the Deployments tab, and select a deployable architecture.
3. From the Resources tab, you can view the full list of deployed resources. For additional information, click View in Schematics .

Reviewing output values by using the console
Output values populate after the architecture is deployed, and they provide important information about your created resources. After the deployment is
successful, you can go to the Output tab to view the outputs for your deployment.

Deploying your architecture by using the CLI
1. Run the following ibmcloud project config-validate command to get a validation check on your configured edits:
ibmcloud project config-validate --project-id PROJECT-ID --id ID [--x-auth-refresh-token X-AUTH-REFRESH-TOKEN] [--version
VERSION]

For more information about the command parameters, see ibmcloud project config-validate .
2. Run the following ibmcloud project config-deploy command to deploy your configured edits after they are validated and approved:
ibmcloud project config-deploy --project-id PROJECT-ID --id ID

For more information about the command parameters, see ibmcloud project config-deploy .

Getting the list of resources that are tied to a deployment by using the CLI
To retrieve the resources that are tied to a deployment, run the following ibmcloud project get command:
ibmcloud project get --id ID [--exclude-configs EXCLUDE-CONFIGS] [--complete COMPLETE]

For more information about the command parameters, see ibmcloud project get .
You can also run the following ibmcloud resource search command to retrieve all the resources in an account created by deployments in a project:
ibmcloud resource search "service_tags:\"schematics::project_id:PROJECT_ID\""

Deploying your architecture by using the API
After your edits are approved, you can programmatically deploy your architecture by calling the Projects API as shown in the following sample request.
The example deploys a deployment with the ID 0df9-5602447qf3c7-8cd7-1rge0328-4c88 :
Curl
curl -X POST --location --header "Authorization: Bearer {iam_token}"
--header "Accept: application/json"
"{base_url}/v1/projects/{project_id}/configs/0df9-5602447qf3c7-8cd7-1rge0328-4c88/deploy"

Managing drift
Drift happens when the state of your deployed resources differs from the configurations that you defined in your project. You can set up your project to
automatically detect drift. Then, if drift is detected, you can override the changes by redeploying the configuration. Or you can modify your configuration to
adopt the changes.
This is an experimental feature that is available for evaluation and testing purposes and might change without notice.

Setting up automatic drift detection
You or members of your team can enable automatic drift detection by updating the settings of your project. With drift detection, you can run a daily check
to compare your configurations to your deployed resources to detect any difference.
1. Navigate to the project dashboard, and open the Manage tab.
2. Click Settings.
3. Toggle Detect drift to On.

Running secure workloads 171

Note: If your use case requires it, you can run a drift detection scan manually from the IBM Cloud® Schematics workspace job page. You can trigger
the scan manually without worrying about any impact to the schedule for automatic drift detection. For more information, check out Detecting drift
in workspaces.

Fixing drift
You can review all the historical entries of the daily drift detection scan in the Activity tab of your project. The Needs attention widget also displays the
most current update if drift is detected or the scan fails to run. If no drift is detected, only the Activity log is updated. Complete the following steps to fix
drift.
1. Review the Needs attention widget for a Drift detected entry.
2. Click the drift-related item to view the logs.
3. Review the changes that are identified.
a. To override the changes to your deployed resources, click Redeploy.
b. Update your configuration or the deployable architecture to adopt the changes.

Managing existing resources
Moving resources from a Schematics workspace into a project
You can manage the lifecycle of an enterprise architecture by moving resources from an IBM Cloud® Schematics workspace into an IBM Cloud® project.
While you can use a Schematics workspace for using Terraform and deployable architectures, you can use a project to manage the full lifecycle at scale.
After you complete this task, you have a deployable architecture tile in your private catalog, and you can manage your deployable architecture's lifecycle
from a project.
During this process, you can use the CLI commands ibmcloud catalog utility create-product-from-workspace and ibmcloud project config-create to create
a catalog and a project that are linked together, and then move the Schematics workspace resources into the project.
Watch and learn the process of moving deployed resources to a project.

Watch and learn

View video: Moving a Schematics workspace into a project

Video transcript
I am Gili Mendel, an STSM with the IBM Cloud development team. I am going to show you how to move a Schematics workspace in the IBM Cloud
deployable architecture or a project.
A Schematics workspace is the way that you run a Terraform automation on the IBM Cloud. The workspace holds a link to a Git repository from which it
fetches the Terraform template. It also holds the template variable, and the resources state as it creates it.
It is a great way to run Terraform IaaS automation on the cloud without maintaining a highly available IBM Cloud® Object Storage bucket for the state with
the intimate integrations to cloud resource providers.
However, this approach does not scale if you are driving multiple automations. Managing the resources and rolling up a new version of the template can be
a daunting task.
Although an enterprise leverages Terraform automation, is all about deployable architectures. You publish a reference architecture, with a compliance
footprint designation, cost estimates, and a Terraform template that automates the deployment of the architecture.
The Git repository is used to iterate and build the architecture and its automations. It might or might not be visible to users that deploy the architecture.
The architecture itself has a lifecycle that includes version upgrades.
Step 1: Use the Catalogs management CLI to create a deployable architecture from the existing workspace, and the lifecycle that is needed to publish the
new versions for it.
Step 2: Use the Project CLI to modify the workspace so that it is managed as a deployable architecture by a project. As such, these resources can be

Running secure workloads 172

treated as a single deployable architecture version configuration and can be managed from an admin account across many environments. Version
migration, cost, and the compliance footprint are simpler and is all involving the architecture that is deployed.

Before you begin
Make sure that the IBM Cloud® Schematics workspace is created and the resources are provisioned in your account. The project and the workspace
must be in the same account.
Set a GIT_TOKEN environment variable to authenticate your Git source repository. For example, run export GIT_TOKEN="enter your GIT
TOKEN" .

Set access to your account in either of the following ways:
Set the IC_API_KEY environment variable to access your IBM Cloud account. For example, run IC_API_KEY="Your API key" .
Use your trusted-profile-id details to access your IBM Cloud account. For more information, see Finding the trusted profile ID . For
example, a trusted profile ID might look similar to Profile-1bd5eala-000-4a6666-00000 .
Make sure that the Project and Catalogs management CLI plug-ins are up to date. Run the ibmcloud plugin list command to view the current
version of the CLI plug-ins.
Create a project for production deployment and record the name and ID of the project where you want to move the resources.
Make sure that the Projects service is authorized in your account to communicate with other IBM Cloud services. For more information, see

Granting

access between the Projects service and other IBM Cloud services.

Creating a deployable architecture from a Schematics workspace
Important: Skip this section if you already have a deployable architecture in your Schematics workspace.
If you deployed software by using a Schematics workspace or through a private catalog, you can move the deployed resources to a project by using the
ibmcloud catalog utility create-product-from-workspace command.
The command does the following Git-related tasks:
Clones the deployable architecture repo.
Pushes the ibm_catalog.json manifest file to a new branch.
Creates a placeholder architecture diagram ( architecture-diagram-placeholder.drawio.svg ).
Creates a Git release in the repo.
Provides the release asset URL.
The command also completes the following IBM Cloud-related tasks:
Creates a private catalog in IBM Cloud.
Creates a project where you do development and testing.
Links the project and catalog together by using a trusted profile ID or an API key.
Creates the product tile in the private catalog.
Onboards the product version to the new private catalog.
Marks the version as ready to share.
Completes the onboarding of the workspace and the deployable architecture by moving the workspace to the catalog.
Shows you the project ID, catalog ID, offering ID, and version locator.
Complete the following steps to create a deployable architecture and move all the deployed resources into a project configuration:
1. Run the ibmcloud catalog utility create-product-from-workspace command.
$ ibmcloud catalog utility create-product-from-workspace [--workspace-id ID] [--api-key KEY] [--trusted-profile-id ID] [-catalog-label LABEL] [--offering-label LABEL] [--project-name NAME] [--project-resource-group GROUP] [--target-version
VERSION] [--variation-label LABEL]

Tip: --api-key and --trusted-profile-id are mutually exclusive. You need only one or the other. The --project-name parameter
creates the project where you do development and testing. You might want to name it the same as your workspace ID for simplicity.
See the following example of the utility create-product-from-workspace command options.
$ ibmcloud catalog utility create-product-from-workspace --workspace-id us-south.workspace.move.xxxx --api-key $IC_API_KEY -catalog-label myCatalog --offering-label myOffering --project-name myProject --project-resource-group Default --target-

Running secure workloads 173

version 1.0.0 --variation-label test_standard

When the command is finished running, the command prompt returns

OK .

2. Verify the results in Git by viewing the commit, repo, and the new release. You can see the

.tgz file with the versions.

3. Verify the results in the IBM Cloud console:
a. Go to Manage > Catalogs > Private catalogs.
b. Select the new private catalog.
c. Select the new product in your private catalog, and then select the Versions tab. See that you have version 1.0.0 (or similar) of your
deployable architecture. If you go to your private catalog, you see the same deployable architecture in a tile.
d. Click the Navigation menu icon

> Projects, and look at the new project.

e. Select the Configurations tab to see the deployable architecture. See that it is in draft status.

Creating the project configuration
The ibmcloud project config-create command creates a project configuration that makes the Schematics workspace run under a project where you can
then create another version from the project and modify the deployable architecture as needed.
Before you begin this section, make sure that you have a deployable architecture in a private catalog and a running Schematics workspace and know its
CRN. You can locate the workspace CRN either from the resource list in the IBM Cloud console or by using the CLI.
IBM Cloud console: In the IBM Cloud console, click the Navigation menu icon

> Resource list > Developer tools > find the

workspace, and copy the CRN.
IBM Cloud CLI: Run the ibmcloud schematics workspace get command to fetch the workspace CRN details. For example, run ibmcloud
schematics workspace get --id workspace-id --output destination folder --json output.json to fetch the Schematics workspace CRN

details.
Complete the following steps to add a project configuration and move the Schematics workspace resources to the project:
1. Run the ibmcloud project config-create command.
$ ibmcloud project config-create --project-id PROJECT-ID [--schematics-workspace-crn SCHEMATICS-WORKSPACE-CRN] [-definition-name DEFINITION-NAME] [--definition-locator-id DEFINITION-LOCATOR-ID]

Tip: The value for --project-id is from the project that you created for deployment-production by using the Projects UI earlier. The value
for --definition-locator-id is the same as the version locator from the previous section.
See the following example of project config-create command options.
$ ibmcloud project config-create --project-id myProdProject --schematics-workspace-crn MyWorkspaceCRN --definition-name
production-deployment --definition-locator-id myVersionLocator

When the command is finished running, the command prompt returns the name, state, and type.
2. Verify that your Terraform templates are deployed in your project:
a. In the IBM Cloud console, click the Navigation menu icon

> Projects.

b. Select your project that you first created for deployment production, and go to the Configurations tab.
c. Click the Actions icon

> View last deployment.

d. In the Deployment successful section, click Changes deployed successfully > Logs to view all the deployed resources in the project.
The Schematics workspace deployment is now included in the logs that are inside the new project.
If you want to verify the results by using the CLI, run the ibmcloud project get or ibmcloud project list commands to verify that your workspace was
successfully moved to your project.

Next steps
To complete the remainder of the process for the deployable architecture, complete the following steps:
1. Configure deployment details for the deployable architecture.
2. Define IAM access.
3. Add an architecture diagram, prereqs, and highlights.
Running secure workloads 174

4. Add compliance information (controls).
5. Revalidate to receive a cost estimate.
For more information about how to complete the steps, see Onboarding a customized deployable architecture to your private catalog .
For more information, see Adopting the Enterprise Architecture .

Organizing existing resources by using a project
You can use a project to organize and track resources across accounts, which can help large enterprises separate management accounts from workload
accounts and applications. Separating management accounts from workload accounts reduces the number of users who need access to your workload
accounts, which makes those accounts more secure. For example, you can gather resources that are related to a particular workload across your
development and production accounts into a single project in an administration account. By doing so, your resources remain deployed in their respective
accounts, but you gain an at-a-glance view of those resources in your project.
This is an experimental feature that is available for evaluation and testing purposes and might change without notice.

An administration account that tracks resources from business unit accounts

Within an enterprise account architecture, tracking resources in a project can help a user in a business unit administration account manage separate
workload accounts and applications. The resources exist in different accounts, for example, workload account A, and workload account B. But by adding
resources from workload account A and B to a project in the administration account, the resources are visible from the project in the administration
account as well.
Tip: Within a project, you can further refine groups of resources by adding them to different configurations. Consider grouping the resources based
on their function. For example, within the same project, you can add one configuration that contains the resources for your infrastructure on your
development environment, and another configuration for the resources on your production environment.

Watch and learn
Prefer to see it in action? Check out the following video to learn how to organize existing resources in your project by using the console.

View video: Organizing existing resources in a project

Video transcript
A new feature is available in IBM Cloud that you can use to organize your resources by using a project.
Within your project, you can now add existing resources from other accounts.

Running secure workloads 175

In your project, go to the Resources tab and click Add to select the resources that you want to organize in your project.
First, provide the authentication credentials for the account that contains your resources. Then, click Next to select the resources that you want to organize
in your project. You can search for resources by filtering on the Location, Service, or Tags.
Select each resource that you want to organize in your project and click Add. The resources that you added to your project are now listed on the Resources
tab.
Moving forward, we’re exploring ways to provide meaningful data in your project, such as usage and cost information.

Before you begin
Make sure that you are assigned the following access in the account that contains your project:
The Editor role or greater on the IBM Cloud® Projects service.
The Viewer role on the resource group for the project.
You must also have an authentication method to grant your project access to the account that contains your resources. You can

use an API key or secret or

you can use a trusted profile to grant your project access. Make sure that the API key or trusted profile has the following access:
The Viewer role for All Identity and Access enabled services. You can allow access to all resources, or scope the access to a select few .
The Viewer role for the resource group that contains the existing resources.

Adding existing resources to a project
To add existing resources to a project, complete the following steps:
1. In the IBM Cloud console, click the Navigation menu icon

> Projects and create or select a project.

2. In the project, go to the Resources tab and click Add.
3. In the Authenticate section, select an authentication method that you want to use to authenticate with the target account that contains your
resources.
4. In the Select resources section, select the resources that you want to organize in your project and click Add.
Note: Resources that are in an IBM Cloud® Schematics workspace or were already added to another configuration can’t be added and don't
display in the list of resources. Some resources might not be included in the list if the authentication method was scoped to specific
resources, as opposed to all of them.
The resources that you added to your project are listed on the Resources tab.

Removing IBM Cloud resources from a project
To remove resources from a project, complete the following steps:
1. In the project, go to the Resources tab and find the resource that you want to remove.
2. Click the Actions icon

> Remove.

3. Click Remove to confirm that you want to remove the selected resource from the project.

Undeploying resources
Deploying an architecture creates resources that can incur costs in the target account that you deployed to. Undeploying the resources that were created
destroys the resources and removes them from that target account, and can help reduce costs for your business.
Important: Resources that were deployed by a configuration in your project can be undeployed following the steps here. Resources that were
added to a project for organization and tracking purposes can be removed from the project, but they can't be destroyed in their target accounts by
using a project. For more information, see Organizing existing resources by using a project .

Undeploying resources from a project by using the console
You can undeploy resources without deleting the project or configuration that deployed those resources. Doing so can be useful if you no longer need the
resources in the target account that you deployed to, but want to keep the project or configuration to use again for future deployments. After you undeploy
the resources, the configuration returns to a draft status. Complete the following steps:
1. In the IBM Cloud® console, click the Navigation menu icon

> Projects.

Running secure workloads 176

2. Select the project that contains the configuration that deployed the resources that you want to remove.
3. On the Configurations tab, click the Actions icon

> Undeploy for the configuration.

4. Enter the name of the configuration into the required field.
Important: Make sure that you want to undeploy the resources, as this action can't be undone. While you can re-create the resources based
on the current configuration, any cached data or persisted data is destroyed.
5. Click Undeploy.

Deleting a project and all of its deployed resources by using the console
Important: By default, when you delete a project or a configuration, any resources that were deployed are undeployed automatically. Confirm that
this setting is enabled by opening your project and going to Manage > Settings before you delete your project or configuration. If this setting is
disabled, when you delete your project or configuration, the resources remain deployed, but you lose the ability to manage them easily with your
project. Deployed resources continue accruing costs in your target account.
If you no longer need a project and want to remove any resources that were deployed by configurations in your project, delete the project and undeploy any
Terraform resources that were created. Complete the following steps:
1. In the IBM Cloud® console, click the Navigation menu icon
2. Click the Actions icon

> Projects.

> Delete project for the project that you want to delete.

3. Enter the project name into the required field.
Important: Make sure that you want to delete the project, as this action can't be undone.
4. Click Delete.

Deleting a configuration and all of its deployed resources by using the console
Important: By default, when you delete a project or a configuration, any resources that were deployed are undeployed automatically. Confirm that
this setting is enabled by opening your project and going to Manage > Settings before you delete your project or configuration. If this setting is
disabled, when you delete your project or configuration, the resources remain deployed, but you lose the ability to manage them easily with your
project. Deployed resources continue accruing costs in your target account.
If you no longer need a configuration and want to remove any resources that were deployed by it, delete the configuration and undeploy any resources that
were created. Complete the following steps:
1. In the IBM Cloud® console, click the Navigation menu icon

> Projects.

2. Select the project that contains the configuration that you want to delete.
3. On the Configurations tab, click the Actions icon

> Delete for the configuration that you want to delete.

4. Enter the name of the configuration into the required field.
Important: Make sure that you want to delete the configuration, as this action can't be undone.
5. Click Delete.

Managing your project lifecycle
Viewing needs attention items
Needs attention items are events that specifically impact the project lifecycle. By viewing the needs attention items, you can monitor and address all
project lifecycle events. They are located in the Needs attention widget, a centralized place to view and control these events. Events include changes that
need to be reviewed, validation and deployment failures, configuration and compliance issues, and new available versions of deployable architectures.
Tip: If you want to send and receive notifications about a project by using email, SMS, or other supported delivery channels, you can

enable event

notifications for projects.
Running secure workloads 177

Complete the following steps to view needs attention items:
1. Go to the Projects page, and select a project.
2. On the Overview tab, you can view the needs attention items.
3. Select the item that needs attention to view more information about it.
Tip: You can also check the needs attention column on the Projects page.
The following needs attention items can occur in a project.

Needs attention failures
You can address any failures that occur during your project's lifecycle by using the needs attention widget. For more information on fixing failures that need
your attention, go to How do I fix project failures?

New deployable architecture version available
A new deployable architecture version is available. Edit the configuration to update it to the new version.
Important: If the new version is a major version update, for example, going from version 1.0.0 to 2.0.0 , review the readme file for the
deployable architecture to learn about any special handling that might be required before you deploy the new version.
It's a best practice to deploy new versions in your testing environment first to check for issues. Then, deploy to your production environment. You might
also want to deploy the new version to a single region first to check for issues before you deploy to all regions.
To update your configuration, complete the following steps:
1. From the projects list, select a project.
2. Go to the Configurations tab, and select a deployable architecture configuration.
3. Click Edit.
4. In the Select inputs section, use the Version menu to select the new version of the deployable architecture.
5. Click Save.
6. Validate and approve your changes before you deploy.

Changes not deployed
After your save and validate your changes, you are notified that the changes are not deployed. Your changes must be approved before you deploy your
configuration. You can also go to the Activity tab for more details on this update.

Validation successful
The validation of your changes is complete. Issues didn't occur during the validation process, and you can deploy your changes.

Deleting a project
When you delete a project, destroy any resources that were deployed by configurations within the project to avoid additional costs.
Important: By default, when you delete a project, any resources that were deployed are destroyed automatically. Confirm that this setting is
enabled by opening your project and going to Manage > Settings. If this setting is disabled and you delete your project, the resources remain
deployed, but you lose the ability to manage them easily with your project. Deployed resources continue accruing costs in your target account.
Make sure that you want to delete a project because this action can't be undone. To delete a project, complete the following steps:
1. In the IBM Cloud® console, click the Navigation menu icon
2. Click the Actions icon

> Projects.

> Delete project for the project that you want to delete.

3. Enter the project name into the required field.
4. Click Delete.

Tracking usage and spend for projects
As a billing or FinOps manager, you need to track spending for teams in your organization and bill them back for the resources that they deploy.

Projects

Running secure workloads 178

help with accounting by ensuring that all resources that are associated with a project can be tracked back to the project with tagging and resource usage
reports.
Resources in a project are automatically given service tags with the ID for the project and configuration that they're associated with. These tags are visible
in usage reports or by using the command-line interface (CLI) or API. You can use these tags to filter your usage report and get a clear view of spending for
projects. This way, it's easier to bill usage back to the teams that are deploying projects.
Note: The services themselves exclusively manage service tags. Users can't add or remove service tags. For more information, see

Tag types.

If you're just getting started, you might want to estimate architecture costs in a project .

Mapping resources on a usage report to a project
1. Find the ID for a project.
a. In the IBM Cloud console, go to the account that contains a project that you're managing billing for.
b. Click the Navigation menu icon

> Projects and select a project.

c. In the project, go to the Manage tab.
d. Copy the ID and save it to reference later.
Note: You can also use the following IBM Cloud CLI command to list all projects and their IDs:

ibmcloud project list --all-pages . For

more information, see the Project CLI reference.
2. Get your usage report.
a. In the IBM Cloud console, go to the enterprise account.
b. Go to Manage > Billing and usage .
c. Click View usage > Export CSV .
3. Open the usage report.
4. Go to the column service_tag::project::project_id .
5. Sort the column to organize resources by project ID.
Add up the usage cost for each resource associated with a project ID to get the total spend for a project over a billing period.
Tip: You can use the ibmcloud resource search command to retrieve the resources in a project based on the project ID service tag.

Running secure workloads 179

Ensuring continuous compliance
Evaluating resource configuration with IBM Cloud® Security and Compliance Center
For highly regulated industries, such as financial services, achieving continuous compliance within a cloud environment is an important first step toward
protecting customer and application data. Historically, that process was difficult and manual, which placed your organization at risk. But, with IBM Cloud®
Security and Compliance Center, you can integrate daily, automatic compliance checks into your development lifecycle to help minimize that risk.
Tip: A new and improved experience of Security and Compliance Center is here! Be sure that you're working with the latest architecture to avoid
migration issues later. To learn more, see How it works .

Before you begin
Before you get started, be sure that you have the following prerequistes:
Resources in your account to evaluate.
An IBM Cloud Object Storage bucket for results storage.
The proper access to perform scans.
Important: Scanning your resources does not ensure regulatory compliance. An evaluation provides a point in time statement of your current
posture for a specific resource. It is your responsibility to review and interpret the results to ensure that your organization is adhering to the
controls that are required for your industry.

Configuring results storage
Before you can start evaluating your resources for compliance, you must configure an Object Storage bucket where Security and Compliance Center can
forward your results data for long-term storage. For more information about bucket requirements, see Storing and processing data in Security and
Compliance Center.
To connect your Object Storage bucket, you can use the Security and Compliance Center UI.
1. Go to the Security and Compliance Center by clicking the Menu icon in the IBM Cloud console and selecting Security and Compliance.
2. In the navigation, click Settings.
3. On the Storage tile, click Connect.
4. Ensure that the service-to-service policy between Object Storage and Security and Compliance Center is configured. If a policy is already in place,
this screen is not shown and you can skip to the next step.
5. Select an instance of Object Storage.
6. From the table, select the bucket that you want to use.
7. Click Connect.

Creating an attachment
An attachment is how you target a specific grouping of your resources to evaluate against a specific profile.
1. In the Security and Compliance Center navigation, click Dashboard Then, click Get started.
2. Select the Profile that you want to use to evaluate compliance.
If you don't see a profile that meets your specific needs, you can always create a custom profile.
3. Target your attachment by selecting a Scope and identifying any resources that you want to Exclude. Then, click Next.
4. Optional: Customize the evaluations in your scan by editing the default parameters to match your specific use case.
5. Click Next.
6. Select the frequency at which you want to evaluate your attachment.
7. Optional: Configure notifications.
a. If you want to receive notifications, toggle Notify me to On.
b. By default, when notifications are enabled, you are alerted when 15% or more of your controls fail in a single scan. You can change this by
adjusting the Threshold percentage.
Running secure workloads 180

For example, if you have a profile with 100 controls and you want to be notified if 5 of them fail, you would select 5% as your threshold.
c. Optional: Select specific controls that you want to be notified about. If there are high priority controls that pertain specifically to your job role,
you might want to be notified every time that they fail. You can identify up to 15 controls per scan that you can receive individual notifications
for. These notifications are sent regardless of whether the threshold identified in the previous step has been met.
a. Click Select control.
b. Select the controls that you want to be notified about by checking the box next to the control.
c. Click Ok.
8. Review your choices and click Create.
When you create your attachment, a scan is scheduled and results are available within 24 hours. When the scan completes your results are available on the
Dashboard in the Security and Compliance Center UI.

Interpreting results
When your scan completes, the results are available on the Dashboard tab in the Security and Compliance Center UI. The results are provided in both a
graphical and detailed format.
When you visit the dashboard, you can see three graphical representations of data that has been aggregated from your scans.

Example dashboard

The three graphs that you can see are:

Success rate
The rate at which your configurations pass the evaluation that is conducted. Note: The number of evaluations conducted does not always match the
number of billable evaluations, as there is no charge for assessments evaluated as unable to perform. Be sure to look for the billable evaluations in
each scan result if you need to estimate your cost.
Total controls
The total number of controls that have been evaluated in the past 30 days.

Running secure workloads 181

Total evaluations
The total number of evaluations that have been run in the past 30 days. An evaluation is the check of one resource against one assessment.

From the dashboard, you can drill into your results to see more detailed information about each evaluation that was conducted.

Next steps
While you wait for your scan to complete, learn more about adding Security and Compliance Center into your pipelines through DevSecOps.

Enabling continuous compliance in your application software development cycle
Taking advantage of DevSecOps to automate the integration of security at every phase of your enterprise application development lifecycle addresses
security issues as they emerge, making them easier, faster, and less expensive to fix. By using the DevSecOps Application Lifecycle Management
deployable architecture, you can take advantage of the two main benefits of using DevSecOps, which are speed and security.
Throughout the development cycle, the code is reviewed, scanned, and tested for security issues. This integrated security allows your team to catch issues
early, and reduces duplicative reviews and unnecessary rebuilds, resulting in more secure code that is delivered faster. As DevSecOps integrates
vulnerability scanning and patching into the development and release cycle, the ability to identify and patch common vulnerabilities and exposures (CVE) is
increased. This limits the window a threat actor has to take advantage of vulnerabilities in public-facing production systems. Additionally, continuous
compliance with periodic scanning of applications in production is included.
Implementing automated scanning and testing can ensure that incorporated software dependencies are at appropriate patch levels, and confirm that
software passes security unit testing. Plus, it can test and validate code for security with static and dynamic analysis. Evidence of scan results is securely
stored, collected, and summarized as part of an automated change management process that gates deployments, before changes are promoted to
production.
Review the following sections to get an overview of the essential steps for ensuring that your application development lifecycle is secure by using the IBM
Cloud DevSecOps tools.

Setting up your secure software development architecture
The DevSecOps Application Lifecycle Management deployable architecture streamlines the process to set up your secure software supply chain by using a
set of continuous integration (CI), continuous deployment (CD), and continuous compliance (CC) toolchain templates. These templates use a collection of
tool integrations and customizable reference Tekton pipelines for build, scan, test, change management, and deploy applications.
The Tekton pipelines provide a framework of custom scripts that you can use to ensure the compliant and automated orchestration of code and
configuration changes. The pipelines maintain a GitOps release inventory, while they collect and store evidence that can be used to generate auditable
change requests. Additionally, the continuous compliance pipeline periodically scans the deployed artifacts and associated source code repositories for
vulnerabilities.
For more information about configuring the deployable architecture to fit your needs, see the DevSecOps deployment guide. You can use a project to
deploy this architecture in all of your application development environments, so that your development team can take a shift-left approach by identifying
security risks and exposures early, so that they are addressed before code ever reaches production.

Ensuring continuous compliance with the CC pipeline
The CI/ CD pipelines ensure that the application code that your team develops is secure and free of vulnerabilities before code is pushed to production.
Once your code reaches production, you can use the CC pipeline to continuously scan your production code for new vulnerabilities. The CC pipeline can be
triggered manually or periodically by using triggers.
The CC pipeline scans existing deployed artifacts and their source repositories independent of your deployment schedule. It runs the static scans and
dynamic scans on the Application Source Code, detect secrets in Git repos, Bill Of Materials (BOM) check, CIS check, and Vulnerability Advisor scan.

Managing issues and collecting evidence to be audit-ready
After scanning and running checks on artifacts and source repositories, the pipeline creates a new incident issue or updates the existing incident issues in
the incident repository. Finally, using these issues and the results, the pipeline collects evidence and summarizes the evidence. The evidence is reported to
the IBM Cloud Security and Compliance Center, and included in an automated change rquest document.
Two types of issues are reported from your CI and CC pipelines: incident issues and nonincident issues. Incident issues can arise due to vulnerabilities or
CVEs found inside the code or the deployed artifacts, and nonincident issues do not arise from vulnerabilities, but rather represent a deviation from the
compliance posture, for example, unit test failures and branch protection check failures. For more information about managing issues, see Processing
incident and nonincident issues and Managing incident issues

Running secure workloads 182

Compliance evidence creates the trail that auditors look for during a compliance audit. One of the goals of DevSecOps is automated evidence generation
and storage in auditable change requests and durable evidence lockers. For more information, see Evidence.

Running secure workloads 183

Observability
Activity tracking events for a project
As a security officer, auditor, or manager, you can use the IBM Cloud® Activity Tracker Event Routing service to track how users and applications interact
with the IBM Cloud Projects service.
Activity tracking events report on activities that change the state of a service in IBM Cloud. You can use the events to investigate abnormal activity and
critical actions and to comply with regulatory audit requirements.
You can use IBM Cloud Activity Tracker Event Routing, a platform service, to route auditing events in your account to destinations of your choice by
configuring targets and routes that define where activity tracking events are sent. For more information, see About IBM Cloud Activity Tracker Event
Routing.
You can use IBM Cloud Logs to visualize and alert on events that are generated in your account and routed by IBM Cloud Activity Tracker Event Routing to
an IBM Cloud Logs instance.
Important: As of 28 March 2024, the IBM Cloud Activity Tracker service is deprecated and will no longer be supported as of 30 March 2025.
Customers will need to migrate to IBM Cloud Logs before 30 March 2025. During the migration period, customers can use IBM Cloud Activity
Tracker along with IBM Cloud Logs. Activity tracking events are the same for both services. For information about migrating from IBM Cloud Activity
Tracker to IBM Cloud Logs and running the services in parallel, see migration planning.

Locations where activity tracking events are generated
IBM Cloud Projects sends IBM Cloud Activity Tracker Event Routing events in the following regions: Sydney, Frankfurt, and Washington.

Locations where activity tracking events are sent to IBM Cloud Activity Tracker Event Routing hosted event
search
IBM Cloud Projects sends activity tracking events to IBM Cloud Activity Tracker Event Routing hosted event search in the followng regions: Sydney,
Frankfurt, and Washington.

Viewing activity tracking events for IBM Cloud Projects
You can use IBM Cloud Logs to visualize and alert on events that are generated in your account and routed by IBM Cloud Activity Tracker Event Routing to
an IBM Cloud Logs instance.

Launching IBM Cloud Logs from the Observability page
For information on launching the IBM Cloud Logs UI, see Launching the UI in the IBM Cloud Logs documentation.

List of management events
IBM Cloud Projects supports the management events that are indicated in the following table.
Action

Description

project.project.create

Create a project.

project.project.read

Read a project.

project.project.list

List all projects under the account.

project.project.update

Update a project.

project.project.delete

Delete a project.

project.config.create

Create a project config.

project.config.read

Read a project config.

Running secure workloads 184

project.config.update

Update a project config.

project.config.validate

Validate a project config.

project.config.list

List all project configs under the account.

project.config.update

Update a project config.

project.config.approve

Approve a project config draft.

project.config.force-approve

Force approve a project config draft.

project.config.delete

Delete a project config.

project.config.deploy

Deploy a project config.

project.config.undeploy

Undeploy (destroy) a project config.

project.config.manual-tag

Add a tag to a config.

project.config.export-stack-definition

Experimental

Add a deployable architecture stack to a private catalog.

project.environment.create

Create a project environment.

project.environment.read

Read a project environment.

project.environment.list

List all project environments under the account.

project.environment.update

Update a project environment.

project.environment.delete

Delete a project environment.
Actions that generate management events

Note: For a complete list of custom request and response parameters for each event, see the Project API. The update actions don't provide
information about the delta, only the new value is provided.

Enabling event notifications for projects
As an administrator of projects, you might want to send notifications of events in projects to other users, or human destinations, by using email, SMS, or
other supported delivery channels. You might want to send these notifications of events to other applications to build logic by using event-driven
programming by using webhooks, for example. This is made possible by the integration between projects and IBM Cloud® Event Notifications.
To send information to Event Notifications, you must connect your projects instance to Event Notifications. For more information about working with Event
Notifications, see Getting started with Event Notifications.

How events are collected and sent by projects
When an event of interest takes place in your project instance, projects communicate with a connected Event Notifications instance to forward a
notification to a supported destination. Events are generated based on actions that users take within the project. For example, if the validation of a
configuration is successful, an event is generated to notify users of this action.

Events for projects
The following table lists the projects events.
Event type

Description

Running secure workloads 185

check.pipeline.failed

Changes failed validation. An event is generated when a validation fails.

config.install-job.failed

Changes failed to deploy. An event is generated when an architecture deployment fails.

config.uninstall-job.failed

Destroy resources failed. An event is generated when the action to destroy configuration resources fails.

check.pipeline.ready

Changes require approval. An event is generated when the latest changes require approval.

config.version.available

A version update is available. An event is generated when a new version of a deployable architecture is
available.

config.defn.updated

Changes are ready to deploy. An event is generated when a configuration is updated in the project.

config.install-job.succeeded

Deployment complete. An event is generated when a configuration is successfully deployed.

config.uninstall-

Destroy resources complete. An event is generated when deployed resources are successfully destroyed.

job.succeeded

Actions that generate event notifications in projects

Enabling notifications
Events that are generated by an instance of the IBM Cloud Projects service can be forwarded to an Event Notifications service instance that is available in
the same account.

Connecting to Event Notifications in the console
Before you can enable notifications for projects, be sure that you have an Event Notifications service instance that is in the same account as your projects
instance. Then, you can connect to the Event Notifications service from Manage > Integrations in your project.
1. In the console, click the Navigation Menu icon

> Projects.

2. Select the project that you'd like to connect to Event Notifications.
3. Click Manage > Integrations .
4. In the Connected instance section, click Connect.
5. Add a name to the connection and optionally provide a description.
6. Select the resource group and Event Notifications service instance that you want to connect.
If an IAM authorization between projects and Event Notifications doesn't exist in your account, a dialog is displayed. Follow the prompts to grant
access between the services.
a. To grant access between projects and Event Notifications, click Authorize.
b. Select Event Notifications as the target service.
c. From the list of instances, select the Event Notifications service instance that you want to authorize.
d. Select the Event Source Manager role.
e. Click Review.
f. Click Assign.
7. Click Save.

Connecting to Event Notifications with the API
Before you can enable notifications for projects, be sure that you have an Event Notifications service instance that is in the same account as your projects
instance. Then, you can connect to Event Notifications programmatically by calling the projects API.
The following example shows a query that you can use to register your projects source details with Event Notifications. When you call the API, replace the
ID variables and IAM token with the values that are specific to your projects instance.
Tip: You can find the event_notifications_instance_crn value in the console by going to the Resource list page and clicking the Event
Notifications instance row.
Running secure workloads 186

[enter API example here]
A successful response returns the CRN value of your connected Event Notifications service instance. For more information about the required and optional
request parameters, see the API docs.

Delivering notifications to select destinations
After you enable notifications for projects, create topics and subscriptions in Event Notifications so that alerts can be forwarded and delivered to your
selected destinations.
Tip: For a complete list of supported destinations, see the Event Notifications documentation.

Email notifications
You can use the IBM Cloud email service as a delivery channel for projects event notifications. Create an Event Notifications subscription between an
existing topic and the IBM Cloud email service to forward your alerts to various recipients by email.
An email from IBM Cloud that contains information about a projects event resembles the following example:
Subject: Validation successful for terrafrom-1234567890-a12a triggered by IBMid-12345ABCD1
Body: Validation is complete. Review and approve the validation results to deploy the changes.
Project Service event details:
Type: check.pipeline.succeeded
Target: Config terrafrom-1234567890-a12a for Project example-email-notification-project
Source: pipelinerun-123ab1ab-1a1a-1a11-1a12-ac1a1a12a12a
Triggered by: IBMid-12345ABCD1
Action URL: https://cloud.ibm.com/devops/pipelines/example
Date: Fri April 10 2023 09:15:08 GMT-0500 (Eastern Standard Time)

Tip: To receive detailed information about an event notification in your email, select the Add notification payload option when you create an
Event Notifications subscription. Your email displays the notification payload details that are associated with the event.

Webhooks
You can configure a webhook destination so that an incoming notification can be consumed programmatically by an app or service. For more information
about setting up webhooks, check out the Event Notifications documentation.

Notification payload details
Successful events that are generated by projects contain various fields that help you to identify the source and details of an event.
Note: Event notifications from projects contain only metadata properties, such as names or identifiers of resources. Sensitive data, for example
API keys or passwords, are not included in generated events.
The properties that are sent to Event Notifications vary depending on the event type. For example, if an

check.pipeline.succeeded event takes place,

projects sends a notification payload to Event Notifications that is similar to the following example.
{
"_id": "a7110265-88e5-4fda-8686-ae4d5bb3f86a",
"event": "check.pipeline.succeeded",
"target": "639d4201-8cf9-4e29-b076-5129b6a3f839:1:true",
"source": "d1542c4b-533c-4276-9272-00ce5134a7a3",
"triggered_by": "IBMid-test-notification",
"action_url": "https://cloud.ibm.com/schematics/workspaces/us-south.workspace.projects-service.e7de98e8/jobs?region=us",
"severity": "INFO",
"timestamp": "2023-04-10T16:00:43.195Z"
}

Review following table for more information about event notification properties.
Property

Description

Running secure workloads 187

event_sub_type

The subtype that corresponds with the type of event that triggered a notification.

event_type

The type of event that triggered a notification.

source_instance_api_url

The dedicated endpoint URL that is assigned to your IBM Cloud Projects service instance.

source_instance_crn

The Cloud Resource Name (CRN) that uniquely identifies your IBM Cloud Projects service instance.

source_instance_dashboard_url

The URL to your IBM Cloud Projects service dashboard in the console.

source_service

The display name of the service that sent the event notification.
Properties in an event notification payload

Auditing events for account, IAM, catalog management
As a security officer, auditor, or manager, you can use the IBM Cloud® Activity Tracker Event Routing service to track how users and applications interact
with an IBM Cloud® account, the IBM Cloud catalog, private catalogs, and with IBM Cloud Identity and Access Management (IAM).
To get started with monitoring your user's actions, see Activity Tracker.

Account management events
You can track the following events:
Managing an account by creating an account, updating information, activating an account, or creating a Subscription account
Adding or removing users
Creating organizations

IAM events
You must create an instance of the Activity Tracker service in the Frankfurt (eu-de) region to start tracking IAM events. When you create the instance,
you can track the following events:
Managing access groups by creating and deleting groups or adding and removing users
Creating, updating, or deleting service IDs
Creating, updating, or deleting API keys
Creating, updating, or deleting access policies
Creating, updating, or deleting trusted profiles
Logging in to IBM Cloud by using an API key, authorization code, passcode, password, or an API key associated with a service ID
Logging in to IBM Cloud by using a trusted profile. For more information, see Monitoring login sessions for trusted profiles .
For more information, see IAM events.

Enterprise IAM events
In addition, you can track the following events in an enterprise account:
Creating, updating, or deleting enterprise-managed IAM templates
Assigning enterprise-managed IAM templates to child accounts
You can track the following enterprise events in an child account:
Enterprise-managed IAM templates assigned to your account
For more information, see IAM events.

Catalog management events
You can track the following events:
Viewing or updating account settings
Viewing or updating a catalog
Running secure workloads 188

Listing all products in a catalog
Listing all products in an account
Creating, updating, viewing, or deleting a product
Important: unavailable indicates when an update is made, but specific details about the update aren't included.
For more information, see Account management events.

Context-based restrictions events
You can track the following events:
Creating, updating, or deleting rules
Creating, updating, or deleting network zones
For more information, see Context-based restrictions events.

Monitoring enterprise IAM templates
Enterprise IAM templates are used to centrally administer IAM access and account settings throughout an enterprise. You can use IBM Cloud® Activity
Tracker to monitor IAM template assignments to child accounts, versioning, and changes that child account administrators make to enterprise-managed
IAM resources in their account.

Before you begin
You must create an instance of the Activity Tracker service in the Frankfurt (eu-de) region to monitor events for enterprise IAM templates. For more
information, see Provisioning an instance.

Reviewing IAM template events by using Activity Tracker
When you assign an enterprise-managed IAM template to target child accounts, multiple events generate. The enterprise account and each target child
account have their own corresponding events.

Analyzing template create events in the enterprise account
Complete the following steps to review the creation of IAM templates in an enterprise account:
1. In the IBM Cloud console, go to the Navigation Menu icon

> Observability > Activity Tracker.

2. Click Open dashboard on the dashboard that you use to monitor enterprise IAM templates.
3. Click Sources and select the IAM service name to filter the results and view only events for the type of template that you're looking for.
Access group templates: iam-groups
Trusted profile templates: iam-identity
Settings templates: iam-identity
Policy templates: iam-access-management
4. Search for the template.create action.
a. For access group templates, search for action:iam-groups.group-template.create
b. For trusted profile templates, search for action:iam-identity.profile-template.create
c. For settingstemplates, search for action:iam-identity.account-settings-template.create
d. For access group templates, search for action:iam-access-management.policy-template.create
Tip: Use the search field to view new version events by adding responseData.version=={{version number}} to your search. For example,
action:iam-identity.profile-template.create responseData.version=={{version number}} .

Analyzing assignment events in the enterprise account
Complete the following steps to review IAM template assignments from the enterprise account to child accounts:
1. In the IBM Cloud console, go to the Navigation Menu icon

> Observability > Activity Tracker.

2. Click Open dashboard on the dashboard that you use to monitor enterprise IAM templates.
3. Click Sources and select the IAM service name to filter the results and view only events for the type of template that you're looking for.
Running secure workloads 189

Access group templates: iam-groups
Trusted profile templates: iam-identity
Settings templates: iam-identity
Policy templates: iam-access-management
4. Use the search field to view IAM templates events.
a. For access group templates, search for action:iam-groups.groups-assignment.create
b. For trusted profile templates, search for action:iam-identity.profile-assignment.create
c. For settings templates, search for action:iam-identity.account-settings-assignment.create
d. For access policy templates, search for action:iam-access-management.policy-assignment.create
5. Select an event to view the fields that have identifying information.
Tip: To search for failed assignments, add outcome==failure to your search. For example, action:iam-groups.groups-assignment.create
outcome==failure .

Analyzing changes to enterprise-managed IAM resources in child accounts
You can set action controls in access group template to enable administrators in chid accounts to change certain attributes of an enterprise-managed
group in their account. For example, you can set the action control for adding policies to true. This allows access group administrators in child accounts to
add policies the group assigned to their account.
You can stream child account events to the Activity Tracker instance in your enterprise account to monitor how child account administrators modify the
enterprise-managed IAM resources in their account. For more information, see Configuring streaming to an Activity Tracker instance through the UI .
Complete the following steps to review how child account administrators are modifying the enterprise-managed IAM resources in their account:
1. In the IBM Cloud console, go to the Navigation Menu icon

> Observability > Activity Tracker.

2. Click Open dashboard on the dashboard that you use to monitor enterprise IAM templates.
3. Click Sources and select the IAM service name to filter the results and view only events for the type of template that you're looking for.
Access group templates: iam-groups
Trusted profile templates: iam-identity
Settings templates: iam-identity
Policy templates: iam-access-management
4. Use the search field to view IAM templates events by searching for the action and template_id . For example, action:iam-groups.update
template_id=={template_id} .

Analyzing events in child accounts
All enterprise-managed IAM resources that are created in child accounts from an enterprise assignment contain request data that maps the resource to an
enterprise IAM template.
The request data includes the following attributes and example values:
"template_version": "1",
"template_id": "706f6c69637954656d706c6174652" ,
"assignment_id": "76450570-1ef3-41d2-ab24-935966032f93"

Complete the following steps to review IAM template assignments in your child account:
1. In the IBM Cloud console, go to the Navigation Menu icon

> Observability > Activity Tracker.

2. Click Open dashboard on the dashboard that you use to monitor IAM events.
3. Click Sources and select the IAM service name to filter the results and view only events for the type of template that you're looking for.
Access group templates: iam-groups
Trusted profile templates: iam-identity
Settings templates: iam-identity
Policy templates: iam-access-management
4. Use the search field to view enterprise-managed IAM events by searching for template .

Examples
Running secure workloads 190

Policy template creation
An access policy template that is named SecretsEditor is created and has the following identifying attributes:
Attribute

Value

Description

outcome

success

The outcome of the request.

action

iam-access-management.policy-template.create

The action that triggers the event.

initiator ID

IBMid-779000XKG2

The unique ID of the requester.

initiator name

user@example.com

The email of the requester.

tempalate_id

policyTemplate-b4fcbb84-9761-4b21-8aea-f78692c34641

The policy template ID.

name

SecretsEditor

The name of the policy.

account_id

b04d9d6240ac4071nnf9152bf46bd94e

The enterprise account ID.

policy

See Example policy

The structure of the policy. The type access gratns access
to users, and authorization grants access between
services.

version

1

The version of the policy template.

description

Grant Editor Role on Secrets Manager service.

The description of the policy.

transaction_id

99450571-2df3-51c2-tn24-565813689t91

Used for debug interactions and tracing the request with
support.

errors

{ "code": "insufficent_permissions", "message": "You

If the outcome is failure, an error message is shown.

are not allowed to create the requested policy
template."}

Sample policy template attributes and values in Activity Tracker

Example policy
$ "policy": "{

\"type\": \"access\",

\"control\": {

\"crn:v1:bluemix:public:iam::::role:Editor\"
\"value\": \"hyperp-dbaas-mongodb\",

}

\"grant\": {
]

}

},

\"roles\": [
\"resource\": {

\"operator\": \"stringEquals\",

{

\"role_id\":

\"attributes\": [

{

\"key\": \"serviceName\"

}

]

}}"

Access group template creation
An access group template that is named dev-group-1 hasn't been committed yet:
Attribute

Value

Description

action

iam-groups.group-template.create

The action that triggers the event.

outcome

success

The outcome of the request.

correlationId

76450570-1ef3-41d2-ab24-

Used for debug interactions and tracing the request with support.

935966032f9

initiator ID

IBMid-779000XKG2

The unique ID of the requester.

initiator name

user@example.com

The email of the requester.

Running secure workloads 191

account_id

b04d9d6240ac4071nnf9152bf46bd94e

The enterprise account ID.

committed

false

Committed flag determines if the template is ready for assignment.

description

Dev group description

The description of the policy.

id

AccessGroupTemplateId-2324f8a0-

The access group template ID.

3f87-42c2-a678-6595b0a59b55

name

dev-group-1

The name of the access group template shown in the enterprise
account.

version

1

The version of the policy template.

group

action_controls, assertions,

The structure of the access group.

description, members, name

action_controls

See Example group

Determines whether access group administrators in child accounts
can add policies to the enterprise-managed group in their account.

assertions

See Example group

Includes dynamic rules and the action controls that determines
whether access group administrators in child accounts can add,
remove, and update dynamic rules to the enterprise-managed group
in their account.

description

Access group description

The access group description that is shown in child accounts.

members

See Example group

The enterprise members and service IDs to add to the access groups
in child accounts. This also includes the action controls that determine
whether access group administrators in child accounts can add and
remove members in the enterprise-managed group in their account.

name

groupName 1690274020835 - VPC-

The acces group name shown in child accounts.

Staging

policy_template_references

errors

See Example
policy_template_references

Existing policy templates that you can reference to assign access in
the trusted profile template.

"code": "template_conflict_error",

If the outcome is failure, an error message is shown.

"message": "An access group
template with the name
"AccessGroup" already exists.
Enter a different name."

Sample access group template creattion attributes and values in Activity Tracker

Example group
"group": {
"action_controls": "{
"assertions": "{
"action_controls": {
"blueGroup",
12,

"access": {

"add": true

"action_controls": {

"add": true,

"remove": false,

"remove": false,

"update": false

"operator": "CONTAINS",

"name": "Manager group rule",

}}",
},

"update": false

},

"conditions": [

"value": "\\"test-bluegroup-saml\\""

"realm_name": "https://idp.example.org/SAML2"

{
}

}

"rules": [

{
"claim":

],

"expiration":

]}",

"description": "Access group description",
"members": "{

"action_controls": {

4145-aa55-ffb87aa81715",
665000T8WY"

"add": true,

"remove": false

},

"services": [

"ServiceId-d9ddc9ca-9c4c-4405-839f-43a25fdefd0e"

],

"users": [

"ServiceId-ad7d5c39-da76"IBMid-50PJGPKYJJ",

"IBMid-

]}",

"name": "groupName 1690274020835 - VPC-Staging"
}

Example policy_template_references
Running secure workloads 192

"policy_template_references": [
{
"id": "policyTemplate-2c8998aa-a706-4e07-bc35-6f23c9753c51",
"version": "1"
},
{
"id": "policyTemplate-998f1122-aca4-4094-a6dd-b14010d487bf",
"version": "1"
}
]

Access group template assignment
An access group template named dev-group-1 that's assigned to child accouts has the following identifying attributes:
Attribute

Value

Description

action

iam-groups.group-assignment.create

The action that triggers the event.

outcome

success

The outcome of the request.

correlationId

6dd6adda-42c2-45ce-9718-373b5cdf1923

Used for debug interactions and tracing the request with
support. The assignment event in child accounts have the
same assignmentId.

initiator ID

IBMid-999200LPO7

The unique ID of the requester.

initiator name

user@example.com

The email of the requester.

AssignmentId

AccessGroupAssignmentId-AccessGroupTemplateId-

The assignment ID. Once groups are created in the target
accounts, individual events in each account referencing the
assignment are created.

274f883e-fe00-4445-8e75-1698a7c76918-Targeta5d1c4130c62404dbc857a37237c49bf

TemplateName

dev-group-1

TemplateVersion

2

Version number of the template assigned.

account_id

8f27b893b8ce49e19e748bf654ab999e

Enterprise account ID.

operation

assign

The operation that maps to the action.

status

succeeded

Status of the assignment.

target

a5d1c4130c62404dbc857a37237c49bf

The ID of the target account or account group.

target_type

AccountGroup

The target can be either an Account or an AccountGroup.

template_id

AccessGroupTemplateId-274f883e-fe00-4445-8e75-

ID of the access group template assigned.

1698a7c76918

Sample access group template assignment attributes and values in Activity Tracker

Trusted profile template creation
Attribute

Value

Description

action

iam-identity.profile-template.create

The action that triggers the event.

outcome

failure

The outcome of the request.

correlationId

bGxxcmw-06b47d9c53564bb1984dded8b3fdb455

Used for debug interactions and tracing the request with support.

Running secure workloads 193

initiator ID

IBMid-999200LPO7

The unique ID of the requester.

initiator name

user@example.com

The email of the requester.

realm_id

IBMid

The identity provider.

template_committed

false

Committed flag determines if the template is ready for assignment.
Sample trusted profile template attributes and values in Activity Tracker

Trusted profile template assignment
Attribute

Value

Description

action

iam-identity.profile-assignment.create

The action that triggers the event.

outcome

success

The outcome of the request.

correlationId

dHptOTc-574744cfcb474f67b9299082fcd2b1ff

Used for debug interactions and tracing
the request with support. The assignment
event in child accounts have the same
assignmentId.

initiator ID

IBMid-999200LPO7

The unique ID of the requester.

initiator name

user@example.com

The email of the requester.

realm_id

IBMid

The identity provider.

bss_account

86a1004d3f1848a291de32874cb48120

The enterprise account ID.

url

https://iam.cloud.ibm.com/v1/profile_assignments/TemplateAssignment-

URL to look up the assigned child
accounts. See Example url curl request

691487d2-a249-4475-b976-a7bf655ef3be

template_id

ProfileTemplate-73e6bad8-0815-44f7-b086-0cac24b0d3a7

ID of the trusted profile template
assigned.

template_type

profile

The type of IAM template.

template_version

1

The version number of the trusted profile
template.

instance_id

TemplateAssignment-691487d2-a249-4475-b976-a7bf655ef3be

The assignment ID. Once profiles are
created in the target accounts, individual
events in each account referencing the
assignment are created.

Sample trusted profile assignment attributes and values in Activity Tracker

Example url curl request
The following example request uses the URL to get the assigned child accounts.
curl -H "Authorization: Bearer $TOKEN" "https://iam.test.cloud.ibm.com/v1/profile_assignments/TemplateAssignment-691487d2-a2494475-b976-a7bf655ef3be"

State of an assignment
Attribute

Description

accepted

The assignment record is accepted and the assignment will be processed.

Running secure workloads 194

in

The assignment records were successfully created and the assignment process is in progress.

progress

success

The assignment process has completed and the template has been assigned to all target accounts and account groups successfully.

fail

The assignment process is complete but there is one or more target accounts where the template failed to be assigned.

superseded

The assignment has been superseded by another assignment record with the same template at a target account group higher in the
enterprise accounts hierarchy. For more information, see Superseeding a version.
The possible states for an IAM template assignment in Activity Tracker

Running secure workloads 195

Project JSON
Each configuration in a project is stored as JSON in a file called project.json . Projects require governance over configuration changes that are stored in
project.json , for example, requiring approvals and ensuring that automated checks pass before changes are saved.

What's in my Project.json file?
The project.json file has several parts:
The project ID and description, which are user-defined values.
The project metadata, which includes project CRN, location, resource group, and state.
An array of configuratons that contains a reference to the deployable architecture and all of the input values.
It's recommended to create your initial project.json from the Projects page in the console. This provides an initial project.json file that can be
edited. When you create a project in the console, the project.json is automatically created for you.

Project metadata
Project metadata might contain cumulative_needs_attention_view , if there are events that have happened related to the project that the user must
now take action on. event_notifications_crn is also an optional value, if the project is configured as a source for Event Notifications. For more
information, see Enabling event notifications for projects .
$

...
"id": "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"name": "CRA Test",
"description": "",
"metadata": {
"crn": "crn:v1:staging:public:project:us-south:a/<account_id>:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"location": "us-south",
"resource_group": "Default",
"state": "READY",
"cumulative_needs_attention_view": [
{
"event": "config.defn.update"
},
{
"event_id": "489f0090-6d7c-4af5-8f20-9106543e4974"
},
{
"config_id": "069ab83e-5016-4bf2-bd50-cc95cf678293"
},
{
"config_version": 1
}
],
"event_notifications_crn": "crn:v1:staging:public:event-notifications:us-south:a/<account_id>:instance-id::"
}
...

A project's ID and CRN can't be editied and are stored by IBM Cloud. Also, tags on the project instance itself are stored in global search and tagging.

Configurations
Each validated and approved configuration in a project has an object in the configs array. Each configuration object has a name, an array of inputs, and a
type. If the type is an IaC template, then a catalog locator_id is included.
$ ...
"configs": [
{
"id": "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"name": "my-deployment",
"description": "A microservice to deploy on top of ACME infrastructure.",
"locator_id": "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global",
"type": "terraform_template",
"input": [
{
"name": "cos_bucket_name",
Running secure workloads 196

"type": "string",
"required": true,
"default": "sample-cos-bucket",
"value": ""
},
{
"name": "ibmcloud_api_key",
"type": "password",
"required": true,
"default": "__NOT_SET__",
"value": ""
},
],
"output": [
{
"name": "resource_group_id"
},
{
"name": "logdna_id"
}
]
]
...

Exporting the project JSON by using the console
As a user that's working with projects, you can export the project JSON to back up the project information outside of the IBM Cloud Projects service.
Tip: Interested in managing your project in your own Git repository? While you can export the project JSON to manually manage your project, you
can also integrate your project with a Git repository directly. For more information, go to Integrating a project with a Git repository .
To export the project JSON, complete the following steps:
1. In the IBM Cloud console, click the Navigation menu icon
2. From the project dashboard, click the Actions icon

> Projects.
> Export JSON

3. From the modal, click Export.

Setting the JSON output format by using the CLI
By using the following --output json option on the command line, you can set the output of a command to JSON:
--output json

Exporting the project JSON by using the CLI
As a user that's working with projects, you can export the project JSON to back up the project information outside of the IBM Cloud Projects service.
Tip: Interested in managing your project in your own Git repository? While you can export the project JSON to manually manage your project, you
can also integrate your project with a Git repository directly. For more information, go to Integrating a project with a Git repository .
To export the project JSON by using the CLI, run the following

ibmcloud project get command:

ibmcloud project get --id ID

See ibmcloud project get for an example command and more information about the command parameters.

Exporting the project JSON by using the API
As a user that's working with projects, you can export the project JSON to back up the project information outside of the IBM Cloud Projects service.
Tip: Interested in managing your project in your own Git repository? While you can export the project JSON to manually manage your project, you
can also integrate your project with a Git repository directly. For more information, go to Integrating a project with a Git repository .

Running secure workloads 197

You can programmatically export the project JSON by calling the Projects API as shown in the following sample request:
Curl
curl -X GET --location --header "Authorization: Bearer {iam_token}" \
--header "Accept: application/json" \
"{base_url}/v1/projects/{id}"

Running secure workloads 198

Understanding your responsibilities when using projects
Learn about the management responsibilities and terms and conditions that you have when you use projects. For a high-level view of the service types in
IBM Cloud® and the breakdown of responsibilities between the customer and IBM for each type, see Shared responsibilities for IBM Cloud offerings .
Review the following sections for the specific responsibilities for you and for IBM when you use projects. For the overall terms of use, see

IBM Cloud®

Terms and Notices.

Incident and operations management
Incident and operations management includes tasks such as monitoring, event management, high availability, problem determination, recovery, and full
state backup and recovery.
Task

IBM Responsibilities

Your Responsibilities

Monitor the
status of a
project

IBM provides the ability for
customers to monitor their
project's lifecycle.

Use the needs attention widget to monitor events that specifically impact the lifecycle of your
project. You can also use the IBM Cloud Activity Tracker service to audit events for a project .

Responsibilites for incident and operations

Change management
Change management includes tasks such as deployment, configuration, upgrades, patching, configuration changes, and deletion.
Task

IBM Responsibilities

Your Responsibilities

Updates, fixes,
and new features

IBM provides regular updates and bug fixes, as well as
new features following a continuous delivery model in
a manner transparent to the customer.

N/A

Creating and
deploying
configurations

IBM provides the ability for customers to create and
deploy configurations by using projects.

Use projects to configure and deploy a deployable architecture .

Deleting a project

IBM provides the ability for customers to delete a
project.

Customers can delete a project whenever they need to.

Pulling
deployable
architecture
changes into a
project

IBM provides the ability for customers to update the
version of a deployable architecture in a project,
should a new version become available.

Customers are notified when a new deployable architecture version
is available so they can update their project accordingly.
Customers can save their existing project data with API, CLI, or by
exporting the project.json from the UI, which can be used as backup
or as rollover plan if there is an issue.
Customers can then test the deployable architecture changes by
deploying in a development or test environment before going to
production. This can all be done within the same project.

Responsibilites for change management

Identity and access management
Identity and access management includes tasks such as authentication, authorization, access control policies, and approving, granting, and revoking
access.
Task

IBM Responsibilities

Your Responsibilities

Accessing projects

IBM provides the ability to control
user access to projects.

Use Identity and Access Management (IAM) to assign users access to projects .

Running secure workloads 199

Authorize a project
to deploy a
configuration

IBM provides the ability to
authorize a project to deploy a
configuration.

Choose an authentication method to authorize a project to deploy in an account. Use an
API key or an existing secret to authorize a project to deploy an architecture in an
account.

Responsibilites for identity and access management

Security and regulation compliance
Security and regulation compliance includes tasks such as security controls implementation and compliance certification.
Task

IBM Responsibilities

Your Responsibilities

Meet
security
and
compliance
objectives

Provide a secure IBM Cloud
Projects service that complies
with key standards. For more
information about data
security, see How do I know
that my data is safe?.

Secure your workloads and data. Integrate tools into your toolchains that satisfy your security and
compliance requirements. To learn more about securing your cloud apps, see Security to
safeguard and monitor your cloud apps. To learn more about securing your data while you are using
the IBM Cloud Projects service, see Securing your data. To learn more about regulatory
compliance with the IBM Cloud Projects service, see Understanding tool integrations with IBM for
Financial Services.
Responsibilites for security and regulation compliance

Disaster recovery
Disaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and
configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.
Task

IBM Responsibilities

Your Responsibilities

Meet
disaster
recovery
objectives

IBM follows best practices for disaster recovery. All IBM applications
automatically recover and restart after any disaster event. For more
information about disaster recovery see the IBM Disaster Recovery Plan.

Customer can help meet DR objectives by deploying
their project in a development or test environment
before deploying to production.
There are no other actions the customer needs to
take to prepare for an event of a catastrophic failure
in a region.

Meet high
availability
objectives

IBM is available globally and load balanced from a single URL. It is highly
available and continues to run even if your resources are unavailable. For
more information about high availability, please see the IBM service level
objectives and the sample application architecture.

N/A

Back up
project
data

IBM performs regular electronic backups of project data with Recovery Time
Objective (RTO) and Recovery Point Objective (RPO) of hours as documented
in the IBM Disaster Recovery Plan.

Customers are not responsible for backups for data
stored by projects. However, customers can use
project data via API, CLI, or by downloading the
project.json from the UI and as a backup.

Restore
project
data

IBM automatically restores project data from backups in case of a data loss
event.

Customers can retrieve project data via API, CLI, or
by downloading the project.json from the UI

Responsibilites for disaster recovery

Running secure workloads 200

Understanding your responsibilities when you use IBM deployable architectures
Learn about the management responsibilities and terms and conditions that you have when you use IBM® deployable architectures. For a high-level view of
the service types in IBM Cloud® and the breakdown of responsibilities between the customer and IBM for each type, see Shared responsibilities for using
IBM Cloud products.
Review the following sections for the specific responsibilities for you and for IBM when you use an IBM deployable architecture. For the overall terms of
use, see IBM Cloud Terms and Notices .

Incident and operations management
Incident and operations management includes tasks such as monitoring, event management, high availability, problem determination, recovery, and full
state backup and recovery.
Task

IBM Responsibilities

Your Responsibilities

Monitor the status of a
deployable architecture

IBM provides the ability for customers to
monitor the lifecycle of the deployable
architecture.

Use the needs attention widget or enable Event Notifications to
monitor events that specifically impact the lifecycle of your
deployable architecture.

Monitor the status of a product
spun up by your deployable
architecture

IBM provides the ability for customers to
monitor the lifecycle of the instances.

Use the resource list, service instance pages, or the Status page to
monitor events that specifically impact your service instance.

Responsibilities for incident and operations

Change management
Change management includes tasks such as deployment, configuration, upgrades, patching, configuration changes, and deletion.
Task

IBM Responsibilities

Your Responsibilities

Creation of the IBM Cloud
deployable architectures

IBM provides the base pattern as a deployable
architecture for instantiation through Terraform.

N/A

Must use supported version of
IBM Cloud Terraform Provider.

IBM publishes Terraform provider of all
Terraform enabled services on IBM Cloud.

Customers should use the latest major version. Terraform
Providers version requirements are documented within
the version.tf file for each deployable architecture.

Third-party Terraform Providers
used within templates

N/A

Customer is responsible for any use of third-party
Terraform code that is used with the deployable
architecture.

Running default configuration
(out of the box)

IBM provides the ability for customers to create
and deploy configurations of deployable
architectures by using projects, Terraform-as-aservice, or the projects CLI.

Use projects to configure and deploy a deployable
architecture.

Running templates locally by
using Terraform directly

N/A

Customer can run the deployable architecture on their
local system.

Customize modules or
deployable architectures with
pre-supported modules

IBM provides and supports base Terraform
modules for services on IBM Cloud, and provides
preset JSON configuration overrides for
templates.

Customer can use these base Terraform modules to
extend their base deployable architecture pattern.

Workload Management
(Application Migration and
Backup/Restore)

N/A

Customer responsibility to manage and migrate
application workloads.

Running secure workloads 201

Fixes, new features, and updates
to the next major deployable
architecture release

IBM provides regular updates, bug fixes, and new
features in a continuous delivery model that is
apparent to the customer. IBM provides a
migration path when possible.

N/A

Keep deployed services and
resources up to date

N/A

Apply fixes and updates to the compute resources that are
created from the deployable architecture. These
resources are not updated through the deployable
architecture unless otherwise indicated.

Issues found in IBM-provided
versions of Terraform modules

IBM provides a way for customers to open
issues. If the issue is with a deployable
architecture, open a case. If the issue is with a
module, open an issue in the module GitHub
repo.

Customer provides information to reproduce any problem.

Issues with IBM container
images

IBM provides a way for customers to open
issues.

Customer provides information to reproduce any problem.

Issues with third party and open
source container images

N/A

Customer resolves with third-party vendor or open source
community.

Issues with IBM Cloud-provided
stock operating system images

N/A

Customer must get a compatible stock image from the
vendor.

Issues with the services that the
Terraform creates from a
deployable architecture

IBM Cloud resolves issues with the services.

N/A

IBM Cloud resource outages or
issues that occur during
automated template execution by
using IBM Cloud Terraform
Provider

IBM reports outages for any cloud resources on
the Status page.

Customers can redeploy after the issue is resolved.

IBM Cloud catalog and private
catalog support

IBM provides a way for you to discover available
deployable architectures in our public catalog
and save your versions to a private catalog.

N/A

Provide ability for drift detection

IBM notifies you if your instantiated resources
differ from the base pattern.

Customer decides when to remediate any configurations
detected in drift detection.

Pulling deployable architecture
changes into a project

IBM provides the ability for customers to update
the version of a deployable architecture in a
project if a new version becomes available.

Customers are notified when a new deployable
architecture version is available so they can update their
project.
\n Customers can save their existing project data through
an API, CLI, or by exporting the project.json from the UI.
The saved information can be used as a backup or as a
rollover plan if an issue exists.
\n Customers can then test the deployable architecture
changes by deploying in a development or test
environment before they deploy to production. These
actions can all be completed within the same project.

Provide notice of end of support

IBM provides notice through regular channels.

N/A

Responsibilities for change management

Identity and access management
Identity and access management includes tasks such as authentication, authorization, access control policies, and approving, granting, and revoking
access.

Running secure workloads 202

Task

IBM Responsibilities

Your Responsibilities

Accessing deployed
deployable
architectures

IBM provides the ability to control
user access to resources
provisioned through projects.

Use Identity and Access Management (IAM) to assign users access to projects .

Authorize a project to
deploy a deployable
architecture
configuration

IBM provides the ability to
authorize a project to deploy a
deployable architecture
configuration.

Choose an authentication method to authorize a project to deploy in an account.
It’s recommended to use a trusted profile, but you can use an API key or an
existing secret to authorize a project to deploy in an account.

Responsibilities for identity and access management

Security and regulation compliance
Security and regulation compliance includes tasks such as security controls implementation and compliance certification.
Task

IBM Responsibilities

Your Responsibilities

Apply patches and
security updates to
operating system in
customer instances

IBM notifies you of updates.

Customer must apply all updates.

Install software and
OS patches into
customer-managed
virtual machines

N/A

Customer must apply all patches.

Meet security and
compliance
objectives

Provide a secure deployable architecture that
complies with declared standards. For more
information about data security, see How do I
know that my data is safe?.

Secure your workloads and data. Integrate tools into your toolchains
that satisfy your security and compliance requirements. To learn more
about securing your cloud apps, see Security to safeguard and
monitor your cloud apps.

Responsibilities for security and regulation compliance

Disaster recovery
Disaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and
configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.
Task

IBM Responsibilities

Your Responsibilities

Meet
disaster
recovery
objectives

IBM follows best practices for disaster recovery for the IBM
Cloud platform and services. For more information about
disaster recovery, see the IBM Disaster Recovery Plan.

Customers can help meet disaster recovery objectives when using
deployable architectures by understanding their responsibilities and
maintaining a disaster recovery plan for services and software that are
deployed by using deployable architectures and customer-owned
data stored within those services or software.

Meet high
availability
objectives

IBM Cloud is available globally and load balanced from a
single URL. It is highly available and continues to be available
even if your resources are unavailable. For more information
about high availability, see the IBM service level objectives
and the sample application architecture.

IBM deployable architectures represent best practice deployment
patterns. It is the customer's responsibility to understand high
availability considerations when selecting and configuring deployable
architectures.

Responsibilities for disaster recovery

Running secure workloads 203

Learning about project architecture and workload isolation
Review the following sample architecture for projects and learn more about different isolation levels so you can choose the solution that best meets the
requirements of the workloads that you want to run in the cloud.

Project architecture
Projects are an IBM Cloud® platform feature that's supported by a highly available multi-region infrastructure. The project UI and API services are
managed microservices, which are deployed to a minimum of three multi-zone regions around the world. A single zone failure results in service instances
in other zones that are in the same region taking over. A regional failure results in another region taking over. Project microservices use IBM managed
instances of Continuous Delivery Toolchains in at least three regions to run multi-step validation, deployments, and destroy resource jobs.
Projects create instances of IBM Cloud Schematics workspaces in your account and uses them to perform plan, deploy, and destory resource jobs. This
ensures that Terraform state storage and any access to private resources is completely under customer control. The Schematics workspace UI, API, and
CLI can be used, if needed, to provide additional control and visibility over how Infrastructure as Code (IaC) is managed by projects.
Note: Deleting a Schematics workspace that's used by a project can cause the loss of the Terraform state for that configuration, which can lead to
unexpected behavior for project users, for example, causing the project to create duplicate resources on the next deployment. Project-created
Schematics workspaces are tagged with the related projects and configurations.

Project data storage
Projects are a multi-tenant service that uses a regional data storage model where the data is stored in the region that is selected for the project.
Specifically, project configuration data (the deployable architecture reference and selected inputs) is stored in a multi-tenant IBM managed IBM Cloudant
database in the project region. The Schematics instances that are created in the customer account for a project are also located in the project region. This
ensures that all configuration data is stored in the customer selected region. However, basic project metadata, like the name, description, and state is
replicated globally to enable global search and the ability to list all projects across regions.

Project data protection
Project's are a multi-tenant platform service where all project data is encrypted at rest and in flight. Project primary storage uses separate documents for
each project in IBM® Cloudant® for IBM Cloud®. IBM Cloudant provides robust data protection and security. For example, IBM Cloudant encrypts all data at
rest and automatically stores three copies of every document to different nodes in a cluster. In addition, project data is periodically backed up to IBM
Cloud® Object Storage, which is also encrypted. Access to project data is protected by IAM authentication and authorization policies that ensure client
isolation. All project data is encrypted in flight by using HTTPS with TLS1.2+.
For more information on IBM Cloudant data protection, see Securing your data in IBM Cloudant . For more information on Object Storage data protection,
see Data security.

Running secure workloads 204

Service dependency map for IBM Cloud Projects
If a service depends on other IBM Cloud services, there can be impacts if any of the dependent services are having issues. The dependency severity
indicates the impact to the service when the dependency is down.

Critical
When the the dependency is down, the service is down.
Significant
When the dependency is down, the service features are impacted.
Medium
When the dependency is down, the service might be impacted and a workaround is possible.
Minimal
When the dependency is down, the main service features are not impacted.

The following table provides the dependency listing of this service following a standard deployment.
Dependencies

Dependency impacts

Customer

Control or data

Location of

provided

plane

dependency

IBM Cloud Classic DNS Servers

Availability, Change
management

No

Both

Same data center

IBM Cloud Classic Infrastructure Resource
Management

Availability, Change
management

No

Both

Global

IBM Cloud Public IP Address Management

Availability, Change
management

No

Both

Global

IBM Cloud Projects service dependency information - Critical dependencies

Dependencies

Dependency impacts

Customer

Control or

Location of

provided

data plane

dependency

IBM Cloudant for IBM Cloud

Availability, Change management, Disaster
recovery, Security compliance

No

Both

Same region

IBM Cloud Object Storage

Availability, Change management, Disaster
recovery

No

Both

Same region

IBM Cloud Continuous Delivery

Availability, Change management, Disaster
recovery

No

Both

Same region

IBM Cloud Global Resource Catalog

Availability, Change management

No

Both

Same region

IBM Cloud Business Support Services

Availability

No

Both

Same region

IBM Log Analysis and IBM Cloud Activity
Tracker

Access management, Availability, Operations,
Security compliance

No

Both

Same region

IBM Cloud Classic NTP Servers

Availability, Change management

No

Both

Same data
center

IBM Cloud Kubernetes Service and Red Hat
OpenShift on IBM Cloud

Availability, Change management, Disaster
recovery

No

Both

Same region

Running secure workloads 205

IBM Cloud Secrets Manager

Availability, Change management, Disaster
recovery, Security compliance

Yes

Both

Same region

IBM Cloud Monitoring

Availability, Operations

No

Both

Same region

Akamai

Availability, Change management, Disaster
recovery

No

Both

Same region

IBM Cloud Internet Services

Availability, Change management, Disaster
recovery

No

Both

Same region

IBM Cloud Identity and Access
Management

Availability, Change management, Security
compliance

No

Both

Same region

IBM Cloud Schematics

Availability, Change management, Disaster
recovery

No

Both

Same region

IBM Cloud Event Notifications

Availability

No

Both

Same region

IBM Cloud Projects service dependency information - Significant dependencies

This table can be used to answer the following questions:
What is the expected impact to the functions described? Each severity tab in the table indicates the impact that your provisioned service might
encounter if the dependency were to go offline. This means that the dependency high availability and disaster recovery influences the severity of the
impact and therefore is used for general guidance to help you understand potential issues that might arise if the dependency was impacted by an
incident.
Note: Services that are regional are not impacted by a severe outage of a single availability zone because of the failover that is built in to
default to another zone. For these occurrences, there might be a slight performance impact, if any, while the system fails over to the other
location. This also applies to global services where the impact is lowered even more as it can fail over to other regions if necessary. This
reduces the frequency at which these items might have the impact that is shown.
What services does my service depend on? The Dependencies column lists the services. These are the major service to service dependencies
including major internal dependencies that might not be visible externally.
What function does the dependency impact? Functions include access management, availability, change management, configuration management,
customer responsibility, disaster recovery, instance control, none, operations or security compliance. If the dependency goes offline, these functions
might be impacted. Definitions for each available values are as follows:

access management
Authentication, authorization and governance of the customer users access to the service and service instances.
availability
Availability of the service and service instances.
change management
Deployment, upgrade, patch, and so on of the service and service instances.
configuration management
Deployment, upgrade, patch, and so on of the service and service instances.
customer responsibility
Functions provides by customers to support specific service and service instances function. For example: IBM Key Protect for IBM Cloud
instances provided by customer to support service BYOK encryption.
disaster recovery
Backup, recovery, restart of the service and service instances in case of disruption.
instance control
Creation, deletion, start, stop actions on lifecycle of the service instances.

Running secure workloads 206

none
No function impacted.
operations
Monitoring, troubleshooting, etc of the service and service instances.
security compliance
Vulnerability management and other security and compliance management of the service and service instances.

The Customer provided column will show if there is any dependency that has been provided by the customer to enable specific functionality. (for
example: To properly configure and set up using BYOK into a service, the customer would provision a service like IBM Key Protect for IBM Cloud. But
there may be other examples like this.) For details on how to enable the features and which services you need to provision, please see the
documentation on the service.
Where do dependency services need to be deployed regarding my service? In the Location of dependency column you can view if the dependency
is located in the same region or deployed to a specific data center. You can use this data with the data in the Control or data plane column for a quick
reference to identify if your data leaves the region or not in a standard setup.
To find where your service can be deployed, see Service and infrastructure availability by location .
Note: The table shows a standard cloud deployment. If a special deployment is used like Fedramp or other region-bound deployment
models, the data might differ from the details available in the table. Refer to the specific deployment that you are using for that information.
Where are the separate control plane and data plane located, if applicable? Sometimes, the dependency might have a separate control plane and
data plane. In these cases, there are separate lines that show the location in relation to the deployed customer instance of the service where these
will be provisioned. The lines might have different impacts and different functions. See the Control or data plane column to understand what possible
impact this type of outage might have.
Same region means that the dependent services are in the same region as the provisioned instance. Other values might show data center or region
names if the service must be used from a specific region, a specific availability zone, or set of availability zones. If a service is tied to a specific region
or site, and the region goes offline, the service might go offline as well. It is recommended that you go through the high availability and disaster
recovery documentation of the dependency to determine if there are any steps that you should take to mitigate these types of risks.
For more information about the policies that are related to the services, you can refer to the following resources:
Service Level Agreement
Shared responsibilities for using IBM Cloud products
Service and infrastructure availability by location

Running secure workloads 207

High availability and disaster recovery
Understanding business continuity and disaster recovery for projects
Disaster recovery involves a set of policies, tools, and procedures for returning a system, an application, or an entire data center to full operation after a
catastrophic interruption. It includes procedures for copying and storing an installed system's essential data in a secure location, and for recovering that
data to restore normalcy of operation.

Responsibilities
For more information about your responsibilities when using projects, see Shared responsibilities for projects.

Disaster recovery strategy
IBM Cloud has business continuity plans in place to provide for the recovery of services within hours if a disaster occurs. You are responsible for your data
backup and associated recovery of your content.
IBM Cloud performs regular electronic backups of project data with Recovery Time Objective (RTO) and Recovery Point Objective (RPO) of hours as
documented in the IBM Cloud Disaster Recovery Plan. Projects don't replicate data outside of a region, except for backup data. When possible, backup
data is kept within the data centers of a country but data is always kept within a geography. European data does not leave the EU.
Disaster recovery objective

Target Value

RPO

1 hour

RTO

4 hours
RPO and RTO for projects

Locations
For more information about service availability within regions and data centers, see Service and infrastructure availability by location .

Understanding high availability for projects
IBM Cloud® projects is a general availability (GA) service that is offered in multiple regions: Dallas, Washington, Frankfurt, and London. Each location has
three different data centers for redundancy. The data for each location is kept in the three data centers near that location. If all of the data centers in a
location fail, the IBM Cloud Projects service for that location becomes unavailable.
See ensure zero downtime to learn more about the disaster recovery standards. You can also find information about IBM Cloud Service Level Objectives.

Responsibilities
For more information about high availability and disaster recovery and your responsibilities when you use projects, see Understanding your responsibilities
when using projects.

What level of availability do I need?
You can achieve high availability on different levels in your IT infrastructure and within different components of your cluster. The level of availability that is
correct for you depends on several factors, such as your business requirements, the service level agreements (SLAs) that you have with your customers,
and the resources that you want to expend.

What level of availability does IBM Cloud offer?
The level of availability that you set up for your cluster impacts your coverage under the IBM Cloud high availability service level agreement terms.
Service level objectives (SLOs) describe the design points that the IBM Cloud services are engineered to meet. Projects are designed to achieve the
following availability target.
Availability target

Target Value

Availability %

99.999%
SLO for projects
Running secure workloads 208

The SLO is not a warranty and IBM will not issue credits for failure to meet an objective. Refer to the SLAs for commitments and credits that are issued for
failure to meet any committed SLAs. For a summary of all SLOs, see IBM Cloud service level objectives .

Locations
For more information about service availability within regions and data centers, see Service and infrastructure availability by location .

Running secure workloads 209

Understanding data portability for projects
Data portability involves a set of tools and procedures that enable you to export the digital artifacts that are needed to implement similar workload and
data processing on different service providers or on-premises software. It includes procedures for copying and storing the service customer content,
including the related configuration that is used by the service to store and process the data, in your location.

Responsibilities
IBM Cloud services provide interfaces and instructions to guide you through the process of copying and storing service customer content, including the
related configuration, in your selected location.
You're responsible for the use of the exported data and configuration for data portability to other infrastructures, which includes:
The planning and execution for setting up alternative infrastructure on different cloud providers or on-premises software that provide similar
capabilities to the IBM services.
The planning and execution for the porting of the required application code on the alternative infrastructure, including the adaptation of your
application code, deployment automation, and so on.
The conversion of the exported data and configuration to the format that's required by the alternative infrastructure and adapted applications.
For more information about your responsibilities for projects, see Understanding your responsibilities when using projects .

Data export procedures
The IBM Cloud Projects service provides the mechanisms to export your content that's uploaded, stored, and processed when you use the service. In
addition, the IBM Cloud Projects service provides mechanisms to export settings and configurations that are used to process your content. You can do so
by exporting the project JSON .

Exported data formats
The exported data for a project is stored as a JSON file called project.json . For more information about this file and its contents, go to Project JSON.

Data ownership
All exported data is classified as customer content. Apply the full customer ownership and licensing rights, as stated in the

IBM Cloud Service Agreement .

Running secure workloads 210

API reference
IAM Policy Management API change log
In this change log you can learn about the latest changes, improvements, and updates to the IAM Policy Management API. The change log lists changes
that have been made, ordered by the date they were released. Changes to existing API versions are designed to be compatible with existing client
applications.
For information about the latest changes to the IAM Policy Management SDKs and CLI, see the change logs in the SDK repositories:
Java SDK change log
Node SDK change log
Python SDK change log
Go SDK change log
Cloud CLI change log

API versioning
The IAM Policy Management API uses URI path versioning. Incompatible changes are versioned as major changes by incrementing the URI path number
( ../v1/policies ). All other changes to the api are expected to be compatible with existing usage.

Active version
The following table shows the behavior changes for each version.
Version

Summary of changes

v2

New schema to support conditions and advanced operators dealing with date and time

v1

Initial version of IAM Policy Management API
IAM Policy Management API versions

Important: The v1 API is not forwards compatible with the v2 API. You can't add conditions to a policy that is created with the v1 API. To add
conditions, you must delete the v1 policy and replace it with a new access policy that includes conditions.

31 August 2023
This change log introduces new capabilities for the v2 IAM Policy Management API that aren't compatible with v1 . This new release adds the ability to
create IAM policy templates in enterprise accounts, which you can reference to assign access in access group templates and trusted profile templates. For
more information, see Creating enterprise-managed policy templates and How enterprise-managed IAM works .

24 January 2023
This change log introduces a new version ( v1 -> v2 ) of the IAM Policy Management API. This version adds a new JSON schema to support a conditional
policy construct and several time-based comparison operators. These operators provide the capability to restrict access based on time and date. With
time-based access control, customers can establish granular policy enforcement based on a specified time period.
To get started, see Limiting access with time-based conditions.
For detailed operator descriptions and examples, see: Conditions in v2 access policies
The new v2/polices schema provides backwards functional compatibility and allows for more complex comparisons and operators. The

v1/polices

schema remains supported and available. For more information, see Comparing /v1/policies and /v2/policies syntax.

Projects API change log
In this change log, you can learn about the latest changes, improvements, and updates for the Projects API. The change log lists changes that have been
made, ordered by the date they were released. Changes to existing API versions are designed to be compatible with existing client applications.

03 April 2024
Projects API v1.0.0 is now available. Make sure you update your version from beta.
Running secure workloads 211

The following changes impact the pagination of list operations. For more information, see the pagination section of the Projects API docs.

list-projects
GET /v1/projects

The page token query parameter was renamed from start to token .
For example, calling the list-projects operation changed from GET /v1/projects?limit=5&start={page_token} to GET /v1/projects?
limit=5&token={page_token} .

The first page is returned without the token query parameter in the request URL. For example,

GET /v1/projects?limit=5 OR GET

/v1/projects .

The first page is also returned when the specified page token is invalid.
The last and previous fields are no longer supported, nor included in the response payload.

list-configs
GET /v1/projects/{project_id}/configs

This operation is now paginated.
A default of 10 records is returned if the page size is not specified in the

limit query parameter.

The maximum page size is of 100 records.
The first page is returned without the token query parameter in the request URL. For example,

GET /v1/projects/{project_id}/configs/?

limit=5 OR GET /v1/projects/{project_id}/configs .

The first page is also returned when the specified page token is invalid.

list-environments
GET /v1/projects/{project_id}/environments

This operation is now paginated.
A default of 10 records are returned if the page size is not specified in the

limit query parameter.

The maximum page size is of 100 records.
The first page is returned without the token query parameter in the request URL. For example, GET /v1/projects/{project_id}/environments/?
limit=5 OR GET /v1/projects/{project_id}/environments .

The first page is also returned when the specified page token is invalid.

Methods to support stacking deployable architectures
Experimental

Added experimental methods to support stacking deployable architectures.

06 November 2023
The latest update includes the following breaking change:
The configurations response models for all methods no longer use a pipeline_state . All status information of a configuration is available
in the augmented state property in the canonical schema of a configuration .

Projects and configurations changes
create-project: POST /v1/projects

The resource_group and location are now to be embedded in the request payload. They are no longer supported as query parameters.
delete-config: PATCH /v1/projects/{project_id}/configs/{id}

The draft_only query parameter is deprecated.
The API now supports delete of configuration of a specified project ID and version . See projects#delete-config-version.

Renamed configuration endpoints
The following configuration endpoints are renamed as follows:
POST /v1/projects/{project_id}/configs/{id}/check is changed to POST /v1/projects/{project_id}/configs/{id}/validate .

Running secure workloads 212

POST /v1/projects/{project_id}/configs/{id}/install is changed to POST /v1/projects/{project_id}/configs/{id}/deploy .
POST /v1/projects/{project_id}/configs/{id}/uninstall is changed to POST /v1/projects/{project_id}/configs/{id}/undeploy .

Replaced configuration endpoints
The drafts methods were replaced by the versions operations as follows:
GET /v1/projects/{project_id}/configs/{config_id}/drafts is changed to GET /v1/projects/{project_id}/configs/{id}/versions .
GET /v1/projects/{project_id}/configs/{config_id}/drafts/{version} is changed to GET
/v1/projects/{project_id}/configs/{id}/versions/{version}

Configuration states
The state model for configurations is flattened. The pipeline_state is no longer available, and the one state property is now augmented to capture
all possible statuses of a configuration .
The following are the new state values:
approved
deleted
deleting
deleting_failed
discarded
deployed
deploying_failed
deploying
superceded
undeploying
undeploying_failed
validated
validating
validating_failed

All configuration endpoints include this state property in the response model. For an example, see projects#get-config-version-response.

Configuration new metadata
The response model of configurations operations now defines new metadata in the root. If an approve job was run on a configuration , an
approved_version property is included in the response payload. Similarly, if a deploy job was run on a configuration , then deployed_version

and last_deployed metadata are available in the response body. Running a validation job yields the metadata last_validated , while running an
undeploy job yields the metadata last_undeployed in the response .

25 October 2023
In projects and configurations operations, such as create and update , definition properties such as name and description must now be
provided in a definition wrapper. Similarly, these properties are now only available inside a definition block in the response payload of create ,
update , get , and list operations. This is a breaking change that was originally released on 06 July 2023. The following sections provide more

information about the methods that are affected by this update.

Projects
create-project: POST /v1/projects

For both the request & response , the name , description , and destroy_on_delete are now wrapped inside a definition object.
Callers of this endpoint are now expected to supply the definition properties inside this wrapper, for example:
definition: {“name”: “test”, “description”: “This is a test project”, “destroy_on_delete”: false} .

If destroy_on_delete is not provided, a default value of true is assigned on a project create operation.
See projects#create-project-request.
Similarly, in the response body, the previously mentioned properties are now available in a definition block.
See projects#create-project-response.
update-project: PATCH /v1/projects/{id}
Running secure workloads 213

For both the request & response , the name , description , and destroy_on_delete are now wrapped inside a definition object.
Callers of this endpoint are now expected to supply the definition properties inside this wrapper, for example:
definition: {“name”: “test_update”, “description”: “This is an updated test project“} .

See projects#update-project-request.
Similarly, in the response body, the previously mentioned properties are now available in a definition block.
See projects#update-project-response.
get-projects: GET /v1/projects/{id}

In the response of this operation, the name , description , and destroy_on_delete are now wrapped inside a definition block.
See projects#get-project-response.
list-project: GET /v1/projects

Each project that is returned in the response array wraps the name , description , and destroy_on_delete properties in a definition block.
See projects#list-projects-response.

Configurations
create-config: POST /v1/projects/{project_id}/configs

For both request & response , the locator_id , name , labels , authorizations , compliance_profile , input , setting , description
are now wrapped inside a definition object.
Callers of this endpoint are now expected to supply the definition properties inside this wrapper, for example:
definition: {“name”: “test”, “description”: “This is a test config”, “locator_id”: “1082e7d2-5e2f-0a11-a3bcf88a8e1931fc.cd596f95-95a2-4f21-9b84-477f21fd1e95-global”} .

See projects#create-config-request.
Similarly, in the response body, the previously mentioned properties are now available in a definition block.
A setting property is also included in the definition block.
See projects#create-config-response.
update-config: PATCH /v1/projects/{project_id}/configs/{id}

For both request & response , the locator_id , name , labels , authorizations , compliance_profile , input , setting , description
are now wrapped inside a definition object.
Callers of this endpoint are now expected to supply the definition properties inside this wrapper, for example:
definition: {“name”: “test”, “description”: “This is a test config”, “locator_id”: “1082e7d2-5e2f-0a11-a3bcf88a8e1931fc.cd596f95-95a2-4f21-9b84-477f21fd1e95-global”} .

See projects#update-config-request.
Similarly, in the response body the previously mentioned properties are moved into a definition block.
See projects#update-config-response.
get-config: GET /v1/projects/{id}

In the response of this operation, the locator_id , name , labels , authorizations , compliance_profile , input , setting ,
description , and setting are now wrapped inside a definition object.

See projects#get-config-response.
list-configs: GET /v1/projects/{project_id}/configs

In the response of this operation, the name and description are now wrapped inside a definition object.
See projects#list-configs-response.

06 July 2023
Important: The response models for all methods now enforce a lower snake case format in state values. This format is to be expected in the
response when you are calling the project and configuration endpoints. This update is a breaking change.
Project state values can now be ready , deleting , and deleting_failed . For an example, see the response schema for the update-project
method.
Configuration state values can now be deleted , deleting , deleting_failed , installed , installed_failed , installing , not_installed ,
uninstalling , uninstalling_failed , and active . For an example, see the response schema for the get-config method.
Running secure workloads 214

Command reference
Catalogs management CLI plug-in
The IBM Cloud® catalogs management command-line interface (CLI) provides additional capabilities for working with products in the IBM Cloud catalog
and the private catalogs in your account. You can use this CLI plug-in to manage your private catalogs, onboard private software products, and manage
catalog visibility between the public catalog and your private catalogs.

Before you begin
Install the IBM Cloud CLI. For more information, see Getting started with the IBM Cloud CLI . The prefix for running commands by using the IBM
Cloud CLI is ibmcloud .
Before you run the registry commands, log in to IBM Cloud with the ibmcloud login command to generate an access token and authenticate your
session.

Installing the catalogs management plug-in
To install the catalogs management plug-in, run the following command:
ibmcloud plugin install catalogs-management

In the command line, you are notified when updates to the ibmcloud CLI and catalogs-management CLI plug-in are available. Ensure that you keep your
CLI up to date so that you can use all the available commands and flags.
If you want to view the current version of your catalogs-management CLI plug-in, run ibmcloud plugin list .
Important: To maintain privacy and security, don't put personal information in your catalog names or catalog descriptions.

ibmcloud catalog account add-approval-access
Run the following command to add approval access to your catalog account.
ibmcloud catalog account add-approval-access [--account-ids IDS] [--object-kind KIND]

Command options
--object-kind VALUE
Provide the object kind. Options are offering , vpe , proxy_source , or preset_configuration .
--account-ids VALUE
Provide a comma-separated list of account IDs prefixed with one of the following.

-acct- for regular accounts, -ent- for enterprise accounts, and

-entgrp- for enterprise account groups.

ibmcloud catalog account delete-approval-access
Run the following command to delete approval access to your catalog account.
ibmcloud catalog account delete-approval-access [--account-ids IDS] [--object-kind KIND]

Command options
--object-kind VALUE
Provide the object kind. Options are offering , vpe , proxy_source , or preset_configuration .
--account-ids VALUE
Provide a comma-separated list of account IDs prefixed with one of the following.

-acct- for regular accounts, -ent- for enterprise accounts, and

-entgrp- for enterprise account groups.

Running secure workloads 215

ibmcloud catalog account get-approval-list
Run the following command to get an approval list for your catalog account.
ibmcloud catalog account get-approval-list [--object-kind KIND]

Command options
--object-kind VALUE
Provide the object kind. Options are offering , vpe , proxy_source , or preset_configuration .

ibmcloud catalog account get-approval-list-source
Run the following command to get all target accounts pointing to a source.
ibmcloud catalog account get-approval-list-source [--approval-state STATE] [--enterprise-id ID] [--object-kind KIND]

Command options
--object-kind VALUE
Provide the object kind. Options are offering , vpe , proxy_source , or preset_configuration .
--approval-state VALUE
Provide the approval state. Options are approved , pending , or rejected .
--enterprise-id VALUE (optional)
Provide an enterprise or enterprise account group ID to view or manage requests for the enterprise. Prefix the ID with

-ent- for an enterprise and -

entgrp for an account group.

ibmcloud catalog account set-approval-state-source
Run the following command to set the approval state for target accounts that point to a source.
ibmcloud catalog account set-approval-state-source [--account-ids IDS] [--approval-state STATE] [--enterprise-id ID] [--objectkind KIND]

Command options
--object-kind VALUE
Provide the object kind. Options are offering , vpe , proxy_source , or preset_configuration .
--approval-state VALUE
Provide the approval state. Options are approved , pending , or rejected .
--account-ids VALUE
Provide a comma-separated list of account IDs prefixed with one of the following.

-acct- for regular accounts, -ent- for enterprise accounts, and

-entgrp- for enterprise account groups.

--enterprise-id VALUE (optional)
Provide an enterprise or enterprise account group ID to view or manage requests for the enterprise. Prefix the ID with

-ent- for an enterprise and -

entgrp for an account group.

Running secure workloads 216

ibmcloud catalog create
Use this command to create a new private catalog in your account. A private catalog is used to organize a set of products, private ones you add, or
references to products in the IBM Cloud catalog. A user must have access to your private catalog through an IAM access policy and the resource group that
contains your private catalog to view and work with the products.
Important: Target a resource group to create a catalog because the catalog exists in the context of a particular resource group. To get the list of
resource groups, you can run the ibmcloud resource groups command, and then the ibmcloud target -g "resource group" command.

ibmcloud catalog create --name CATALOG [--catalog-description "DESCRIPTION"]

Command options
--name CATALOG
The catalog name.
--catalog-description DESCRIPTION (optional)
Short description for the new catalog.

Example
Create a catalog called dev-catalog with the description a catalog for development and testing purpsoses .
ibmcloud catalog create --name dev-catalog --catalog-description "a catalog for development and testing purposes"

ibmcloud catalog list
Run the following command to retrieve the list of catalogs in this particular account.
ibmcloud catalog list [--output FORMAT]

Command options
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json .

Output
The command returns the following output:
Name

ID

Description

Last

93f592fb-e09b-4a53-bbd9-92f6ab9e253b

short-description

2019-11-21

7a246530-e191-45e2-87cc-07c8c7033d2b

short-description

2019-08-19

Updated
dev-catalog
21:28:28.347 +0000 UTC
ABDemoTestCatalog
17:43:48.59 +0000 UTC

ibmcloud catalog get
Run the following command to retrieve information for a particular catalog in the account.
ibmcloud catalog get --catalog CATALOG [--output FORMAT]

Command options
--catalog CATALOG
Running secure workloads 217

The catalog name or ID.
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json .

Output
The command returns the following output:
Name

Current State

Version Locator

Draft

480fb4e3-d7ba-4e9b-9d4c-42f0ab811040.fd8f91a3-8027-4919-ad6d-

dev-catalog
|__dev-offering
|

|__Openshift

|

|__1.0.0

c5189a4a8ee

ibmcloud catalog delete
Run the following command to delete a particular catalog in the account.
ibmcloud catalog delete --catalog CATALOG

Command options
--catalog CATALOG
The catalog name or ID.

ibmcloud catalog search
Run the following command to search the public catalog for published products, including services and software.
ibmcloud catalog search <QUERY> [--catalog CATALOG] [--type TYPE] [-r, --region REGION] [-k, --kind KIND] [--fields FIELDS] [-p,
--price PRICE] [-t, --tag TAG] [--sort-by PROPERTY] [--col COLUMNS] [--reverse] [--output TYPE] [--global]

Command options
--type TYPE (optional)
Optional. Default is services . Valid options are services and software .
--catalog CATALOG (optional)
Search for the software published by your account. Specify the catalog name or ID to search by.
--output FORMAT (optional)
Specifies output format. Default is terminal compatible and the only alternative options are

json and csv .

--kind KIND (optional)
The flag is only valid for searching services. Provide a comma-separated list of types of products.
--region REGION (optional)
The flag is only valid for searching services. Provide a comma-separated list of regions. Run

ibmcloud cs regions to return a valid list.

--price PRICE (optional)
The flag is only valid for searching services. Provide a comma-separated list of pricing types.
--tag TAG (optional)
The flag is only valid for searching services. Provide a comma-separated list of tags.
--global (optional)

Running secure workloads 218

The flag is only valid for searching services. Use it to operate in a global scope.
--sort-by TYPE (optional)
The flag is only valid for searching services and used to order the search result. Available options are

name , displayname , kind , provider ,

created , and updated .

--reverse (optional)
The flag is only valid for searching services. Use it to reverse the sorting order.
--fields FIELDS (optional)
The flag is only valid for searching services. Customize the table, for example, --fields name,kind,metadata.service.iam_compatible .

Output
The command returns the following output:
Name

ID

Category

2 Zone VPC

f10d9ae9-ac94-4718-b24a-3994241ae2a4-global

Networking

Apache

Qml0bmFtaS1hcGFjaGU=-global

Developer Tools

Apache Airflow

Qml0bmFtaS1haXJmbG93-global

Databases

Apache Airflow

Qml0bmFtaS1haXJmbG93-global

Developer Tools

ibmcloud catalog filter get
Run the following command to retrieve filter details for either the account or a particular catalog.
ibmcloud catalog filter get --catalog CATALOG [--output FORMAT]

Command options
--catalog CATALOG
The catalog name or ID.
--account-group ACCOUNT GROUP
The account group name or ID. This field applies only to enterprise accounts.
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json .

Output
The command returns the following output:
Account: The IBM Cloud catalog is visible to all users in this account.
Filter:
Including IBM Cloud catalog
Type

Include

Tags

Pricing plan

false

Free

Provider

false

Third Party

ibmcloud catalog filter create
Run the following command to create a new filter. If a filter exists, this command overrides the current filter.
ibmcloud catalog filter create [--catalog CATALOG] [--category CATEGORY] [--compliance COMPLIANCE] [--deployment-target TARGET]
[--exclude-list LIST] [--include-all ALL] [--include-list LIST] [--offering-format FORMAT] [--pricing-plan PLAN] [--provider
PROVIDER] [--release RELEASE] [--type TYPE]

Running secure workloads 219

Command options
--catalog CATALOG (optional)
Specify the catalog name or ID. If not specified, the filter is created at the account level.
--account-group ACCOUNT GROUP
The account group name or ID. This option applies only to enterprise accounts.
--hide-ibm-catalog (optional)
By default, the catalog is visible to all users in this account. By providing this flag, you can make products available only to the users you choose by
turning off visibility to the IBM Cloud catalog and adding the products to your private catalogs.
--include-all BOOLEAN (optional)
Default is true if flag is not provided. Valid values are true and false . If set to true, the filter defaults to include the entire public catalog, and
subsequent filters are excluded. If set to false, the filter excludes the entire public catalog, and subsequent flags are included. For more information,
see Managing catalog settings.

--offering-format FORMAT (optional)

--category CATEGORY (optional)
Provide the category that best fits how users might use your product. Categories are used to organize products in the catalog based on common
solutions, function, or use. You can select only one category. Run the ibmcloud catalog offering category-options command to view all
options. Default is Developer tools .
--compliance TYPE (optional)
Provide a comma-separated list of compliance categories that you want to include or exclude. Run the

ibmcloud catalog filter options

command to view all options.
--deployment-target TARGET (optional)
Provide a comma-separated list of deployment targets that you want to include or exclude. Run the

ibmcloud catalog filter options command

to view all options.
--exclude-list LIST (optional)
Provide a comma-separated list of product IDs or names that must be excluded in the filtered public catalog.
--include-list LIST (optional)
Provide a comma-separated list of product IDs or names that must be included in the filtered public catalog.
Provide a comma-separated list of product formats that you want to include or exclude. Run the

ibmcloud catalog filter options command to

view all options.
--pricing-plan PLAN (options)
Provide a comma-separated list of pricing plans that you want to include or exclude. Run the

ibmcloud catalog filter options command to

view all options.
--provider PROVIDER (optional)
Provide a comma-separated list of providers that you want to include or exclude. Run the

ibmcloud catalog filter options command to view all

options.
--release RELEASE (optional)
Provide a comma-separated list of categories that you want to include or exclude. Run the

ibmcloud catalog filter options command to view

all options.
--type TYPE (optional)
Provide a comma-separated list of software types that you want to include or exclude. Run the

ibmcloud catalog filter options command to

view all options.

ibmcloud catalog filter delete
Running secure workloads 220

Run the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to
include all products in the public catalog.
ibmcloud catalog filter delete --catalog CATALOG

Command options
--catalog CATALOG
The catalog name or ID.
--account-group ACCOUNT GROUP
The account group name or ID. This option applies only to enterprise accounts.

ibmcloud catalog filter offering
Update the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or
account group is specified.
ibmcloud catalog filter offering --offering PRODUCT-NAME

Command options
--catalog CATALOG
The catalog name or ID.
--account-group ACCOUNT GROUP
The account group name or ID. This option applies only to enterprise accounts.
--plans-list PLANS LIST
A comma-separated list of plan IDs or names to include or exclude.
--offering OFFERING
The product name or ID.
--include
The default value is true if a flag is not provided. Valid values are

true and false . If set to true, the product and plans provided are visible to users

in the account. If set to false, the product and plans aren't visible to users in the account.

ibmcloud catalog filter hide-ibm-public-catalog
By default, the IBM Cloud catalog is visible to all users in the account. You can make products available only to the users you choose by turning off visibility
to the IBM Cloud catalog and adding the products to your private catalogs.
ibmcloud catalog filter hide-ibm-public-catalog

ibmcloud catalog filter show-ibm-public-catalog
By default, the IBM Cloud catalog is visible to all users in the account. You can make products available only to the users you choose by turning off visibility
to the IBM Cloud catalog and adding the products to your private catalogs.
ibmcloud catalog filter show-ibm-public-catalog

ibmcloud catalog filter options
Run the following command to retrieve the filter options for each filter category.
ibmcloud catalog filter options
Running secure workloads 221

Command options
--all
Includes industry, solution type, and pricing plan in the list of filters.
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json .

Output
The command returns the following output:
Deployment target

ID

IBM Cloud Kubernetes Service

target_iks

IBM Cloud Schematics

target_terraform

Red Hat OpenShift

target_roks

VMware vCenter Server

target_vcenter

Virtual private cloud

target_vpc-x86

Power Systems Virtual Server

target_power-iaas

Provider

ID

Third party

ibm_third_party

Community

ibm_community

IBM

ibm_created

Release

ID

Beta

ibm_beta

Deprecated

ibm_deprecated

Works with

ID

SAP Certified

sap_certified

Quantum Technologies

quantum_tech

Satellite Enabled

satellite_enabled

HPC

hpc

Support

ID

Third party supported

support_third_party

Community supported

support_community

IBM supported

support_ibm

Delivery method

ID

Cloud Paks

cloud_pak

Helm charts

helm

Operators

operator

OVA Images

ova

Starter kits

template

Terraform

terraform

Server Images

vsi_image

Blueprint

blueprint

Toolchains

toolchain

Compliance

ID

EU Supported

eu_access

Financial Services Validated

fs_ready

HIPAA Enabled

hipaa

IAM-enabled

rc_compatible

Service Endpoint Supported

service_endpoint_supported

Category

ID

Compute

compute

Tags

compute,compute_classic,content,openwhisk,runtime,virtualservers,compute_baremetal
Containers

containers

containers,clusters,registry

Networking

network

network,network_vpc,network_classic,network_edge,network_interconnectivity

Storage

storage

storage,storage_vpc,storage_classic,storage_datamovement

Converged infrastructure

converged_infra

converged_infra

Running secure workloads 222

Enterprise applications

enterprise_app

enterprise_app

AI / Machine Learning

ai

watson,ai

Analytics

analytics

data_analytics,business_analytics,analytics

Blockchain

blockchain

blockchain

Databases

databases

data_management,database

Developer tools

devops

dev_ops

Logging and monitoring

logging_monitoring

logging_monitoring

Migration

migration_tools

migration_tools

Integration

integration

integration,api

Internet of Things

iot

internet_of_things

Security

security

security

Mobile

mobile

mobile,web_and_app

ibmcloud catalog offering create
Run the following command to add a product to a private catalog in the account.
ibmcloud catalog offering create [--catalog CATALOG_NAME] [--zipurl URL] [--include-config] [--target-version VERSION] [--token
TOKEN] [--vpc-body BODY]

Command options
--catalog CATALOG_NAME
The catalog name or ID.
--zipurl URL (optional)
URL pointing to the .zip file of the product.
--target-version VERSION
Specify the version of the product.
--include-config (optional)
If provided, all configuration values are included and available when you add the product.
--token TOKEN (optional)
Specify the personal access token for a private repository.
--vpc-body BODY (optional)
Provide the information to import a virtual server image for VPC, including a name, label, install kind, target kind, version, sha, tags, and metadata.

Virtual server image for VPC Example #1
Import a virtual server image for VPC as an offering to a catalog with ID 51c9e0db-2911-45a6-adb0-ac5332d27cf2 .
ibmcloud catalog offering create --catalog 51c9e0db-2911-45a6-adb0-ac5332d27cf2 --vpc-body '{
"name": "virtual-server-image",
"label": "virtual server image",
"install_kind": "instance",
"target_kinds": ["vpc-x86"],
"version": "0.0.10",
"sha": "64245e5f3f1e9c4048b18db3abd1450d4b6f9e263ac1b33df6fc1ae96fcbdebb",
"tags": ["virtualservers"],
"metadata": {
"operating_system": {
"dedicated_host_only": false,
"vendor": "CentOS",
"name": "centos-7-amd64",
"href": "https://us-south-stage01.iaasdev.cloud.ibm.com/v1/operating_systems/centos-7-amd64",
"display_name": "CentOS 7.x - Minimal Install (amd64)",
"family": "CentOS",
"version": "7.x - Minimal Install",
"architecture": "amd64"
},
"minimum_provisioned_size": 100,

Running secure workloads 223

"file": {
"size": 1
},
"images": [{"id": "r134-14903434-faf0-4a66-b861-7b35198de393", "name": "virtual-server-image", "region": "us-south"}]
}
}'

Virtual server image for VPC Example #2
Import a virtual server image for VPC as an offering to a catalog with ID 2bdc3974-dfcf-4711-b298-cd238f7d3734 .
$ ibmcloud catalog offering create --catalog 2bdc3974-dfcf-4711-b298-cd238f7d3734 --vpc-body '{
"name": "virtual-server-image-s390x",
"label": "virtual-server-image-s390x",
"install_kind": "instance",
"target_kinds": ["vpc-z"],
"version": "0.0.10",
"sha": "4739f1eaeeebc69ad5d48f9191fcc0d23960cb720bb16c67e915e5556c1da9b2",
"tags": ["virtualservers"],
"metadata": {
"operating_system": {
"dedicated_host_only": false,
"vendor": "SUSE Linux Enterprise Server",
"name": "sles-15-sp2-s390x-byol",
"href": "https://us-south-stage01.iaasdev.cloud.ibm.com/v1/operating_systems/sles-15-s390x",
"display_name": "Suse enterprise server(s390x)",
"family": "SUSE",
"version": "15-sp2",
"architecture": "s390x"
},
"minimum_provisioned_size": 100,
"file": {
"size": 1
},
"images": [{"id": "r134-f20e2e4e-3133-423c-afa2-365afa14c4dc", "name": "virtual-server-image-s390x", "region": "us-south"}]
}

ibmcloud catalog offering list
Run the following command to get details about the products in your private catalogs. This command provides a filter by private catalog, product, and
version.
ibmcloud catalog offering list [--catalog CATALOG] [--offering OFFERING_NAME] [--version VERSION] [--output FORMAT]

Command options
--catalog CATALOG
The catalog name or ID.
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example,

--output json .

Example
List all of the products that are in the dev-catalog catalog.
ibmcloud catalog offering list --catalog dev-catalog

Output
The command returns the following output:
Name

ID

Cloud Pak for Automation

cb90274e-398b-4373-9b28-d6428d3302df

Current State

Version Locator

Running secure workloads 224

|__OpenShift
|__19.0.2

New

7b7e590f-259b-437b-b1f4-

New

7b7e590f-259b-437b-b1f4-

New

7b7e590f-259b-437b-b1f4-

New

7b7e590f-259b-437b-b1f4-

New

7b7e590f-259b-437b-b1f4-

New

7b7e590f-259b-437b-b1f4-

39e8615ed837.21d1d712-80ab-4318-9d05-73c6caaaee23
Cloud Pak for Data

8993c7b1-1794-4447-9275-db83faa08ee4

|__OpenShift
|__2.1.0.2
39e8615ed837.ab6ba56f-788d-4d6b-b880-a1001fca8451
harbor

927adb44-6784-4bec-a771-f639900f07f1

|__Kubernetes
|__1.9.1
39e8615ed837.e437b06c-273f-49de-8c44-f55e408abf78
IBM Starter Collection for Openshift

fd1857f4-cf17-4e97-9443-b615bc71f6a0

|__OpenShift
|__0.0.1
39e8615ed837.72e0f636-9dc4-49ae-b3c2-7a5de90487b9
tf_cloudless_sleepy-2.0

c260a67a-1b25-49fc-9896-46e7e6212990

|__
|__1.0.0
39e8615ed837.965df91d-5760-4872-adf6-4019796c06b0
|__1.0.1
39e8615ed837.aff4cecb-4c9b-41ba-ae3d-71f4217dc0bc

ibmcloud catalog offering search
Run the following command to get details about the products in your private catalogs. This command provides a filter by private catalog, product, and
version.
ibmcloud catalog offering search [--catalog CATALOG] [--offering OFFERING_NAME] [--version VERSION] [--output FORMAT]

Command options
--catalog CATALOG (optional)
The catalog name or ID.
--offering OFFERING (optional)
The product name or ID.
--version VERSION (optional)
The version name or ID.
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example,

--output json .

Example
List all of the products that are in the dev-catalog catalog.
ibmcloud catalog offering list --catalog dev-catalog

Output
The command returns the following output:
Name

Current State

Version Locator

Validated

b636d651-8489-4425-bd6a-f30af1603577.17ac792e-a603-4f1a-a1b6-

Published to account

b636d651-8489-4425-bd6a-f30af1603577.decdb0e1-46d2-401a-b482-

dev-catalog
|__dev-offering
|

|__Kubernetes

|

|__1.0.0

48e90a46940c
|__dev-offering-2.0
|

|__Kubernetes

|

|__1.0.0

80f9d6855f98

Running secure workloads 225

ibmcloud catalog offering get
Run the following command to get details about a specific product in the catalog.
ibmcloud catalog offering get --catalog CATALOG --offering OFFERING_NAME [--output FORMAT]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING_NAME
The product name or ID.
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example,

--output json .

Output
The command returns the following output:
Name

Current State

Version Locator

Draft

480fb4e3-d7ba-4e9b-9d4c-42f0ab811040.a92f5409-ebd9-413c-88ae-7ed311c1b793

dev-offering
|__
|__1.0.0

ibmcloud catalog offering import-version
Run the following command to import a new version of a product in your private catalog.
ibmcloud catalog offering import-version --catalog CATALOG --offering OFFERING_NAME [--zipurl URL] [--target-version APP_VERSION]
[--include-config] [--vpc-body BODY]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING_NAME
: The product name or ID.
--zipurl URL (optional)
The URL pointing to the .zip file of the product.
--target-version APP_VERSION (optional)
The application version of the "tgz" being imported.
--include-config (optional)
If provided, all configurations values are included and available when you import the new version.
--vpc-body BODY (optional)
Provide the information to import a virtual server image for VPC, including a name, label, install kind, target kind, version, sha, tags, and metadata.

Virtual server image for VPC Example
Import a virtual server image for VPC to an existing offering with to a catalog with ID 51c9e0db-2911-45a6-adb0-ac5332d27cf2 and offering ID
97cdaf1b-62b2-48e2-8589-10b31023866d .

Running secure workloads 226

ibmcloud catalog offering import-version --catalog 51c9e0db-2911-45a6-adb0-ac5332d27cf2 --offering 97cdaf1b-62b2-48e2-858910b31023866d --vpc-body '{
"name": "virtual-server-image",
"label": "virtual server image",
"install_kind": "instance",
"target_kinds": ["vpc-x86"],
"version": "0.0.10",
"sha": "64245e5f3f1e9c4048b18db3abd1450d4b6f9e263ac1b33df6fc1ae96fcbdebb",
"tags": ["virtualservers"],
"metadata": {
"operating_system": {
"dedicated_host_only": false,
"vendor": "CentOS",
"name": "centos-7-amd64",
"href": "https://us-south-stage01.iaasdev.cloud.ibm.com/v1/operating_systems/centos-7-amd64",
"display_name": "CentOS 7.x - Minimal Install (amd64)",
"family": "CentOS",
"version": "7.x - Minimal Install",
"architecture": "amd64"
},
"minimum_provisioned_size": 100,
"file": {
"size": 1
},
"images": [{"id": "r134-14903434-faf0-4a66-b861-7b35198de393", "name": "virtual-server-image", "region": "us-south"}]
}
}''

ibmcloud catalog offering update
To update a product in your private catalog, you first need to get the product and then you can update.
Run the offering get command. For more information, see the ibmcloud catalog offering get.
ibmcloud catalog offering get -c <CATALOGID> -o <OFFERINGID> --output json

Run the offering update command.
ibmcloud catalog offering update -c <CATALOGID> -o <OFFERINGID> --updated-offering <UPDATED_OFFERING.json>

ibmcloud catalog offering version preinstall
Run the following command to run the preinstallation script for a particular product.
ibmcloud catalog offering version preinstall --version-locator VERSION_NUMBER --cluster CLUSTER_ID --namespace NAME

Command options
--version-locator VERSION_NUMBER
To get the version locator for this product, run the ibmcloud catalog offering list command and locate the specified product and version that
you'd like to use.
--cluster CLUSTER_ID
Provide the cluster ID of the cluster where you want to install the product.
--namespace NAME
Provide the namespace that you'd like to use. You can specify a new one and it is automatically created as part of the preinstallation.

Example
Run the preinstallation script for a product with a version locator number of b636d651-8489-4425-bd6a-f30af1603577.18aad484-c78b-4269-808b52027621abd4 in cluster with ID bn5ebho206o7fg45f2e0 in the namespace called test-namespace .

Running secure workloads 227

ibmcloud catalog offering version preinstall --version-locator b636d651-8489-4425-bd6a-f30af1603577.18aad484-c78b-4269-808b52027621abd4 --cluster bn5ebho206o7fg45f2e0 --namespace test-namespace

ibmcloud catalog offering version preinstall-status
Run the following command to get the status of an ongoing preinstallation.
ibmcloud catalog offering version preinstall-status --version-locator VERSION_NUMBER --cluster CLUSTER_ID --namespace NAME [-output FORMAT]

Command options
--version-locator VERSION_NUMBER
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product and version that
you'd like to use.
--cluster CLUSTER_ID
Provide the cluster ID of the cluster where the preinstallation was run.
--namespace NAME
Provide the namespace used for the preinstallation.
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example,

--output json .

ibmcloud catalog offering version validate
Run the following command to validate a new version of a product in your private catalog. Products must be validated to ensure that they work as expected
before they can be published to the account for other users to create an instance from the private catalog.
ibmcloud catalog offering version validate --version-locator VERSION_NUMBER --cluster CLUSTER_ID --namespace NAME [--timeout
TIMEOUT] [--wait WAIT] [--override-values VALUES|FILENAME] [--workspace-tf-version VERSION] [--workspace-region REGION] [-workspace-rg-id ID][--schematics-destroy][--schematics-delete]

Command options
--version-locator VERSION_NUMBER
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product and version you'd
like to use.
--cluster CLUSTER_ID
Provide the cluster ID of the cluster where you want to install the product.
--namespace NAME
Provide the namespace that you'd like to use. You can specify a new one and it is automatically created as part of the preinstallation.
--timeout TIMEOUT
Specify in seconds how long the Schematics workspace waits it installs. Default is

180 .

--wait WAIT
Wait and track the progress of the Schematics workspace job. If true , installation waits. If false , the software installs immediately. Default is
true .

--override-values VALUES|FILENAME (optional)
Provide any custom configurations for the installation. You can provide this value either inline or by using a JSON or TXT file. For example,

override-

values values.json . When validating a virtual server image for VPC, the following fields must be provided: vsi_instance_name, vsi_id, vpc_profile,

subnet_id, vpc_id, subnet_zone, ssh_key_id, vpc_region
--workspace-tf-version VERSION (optional)

Running secure workloads 228

Provide a workspace terraform version.
--workspace-region REGION (optional)
Provide a workspace region.
--workspace-rg-id ID (optional)
Provide a workspace resource group ID.
--schematics-destroy (optional)
Provide this flag to delete the workspace resources after validation and installation.
--schematics-delete VALUE (optional)
Provide this flag to delete the Schematics workspace after validation and installation.

Example validating a product that uses a cluster
Validate a product with the version locator b636d651-8489-4425-bd6a-f30af1603577.18aad484-c78b-4269-808b-52027621abd4 in a cluster with the ID
bn5ebho206o7fg45f2e0 within a namespace called test-namespace . This installation has custom configurations, so the values are provided by using a
values.json file.
ibmcloud catalog offering version validate --version-locator b636d651-8489-4425-bd6a-f30af1603577.18aad484-c78b-4269-808b52027621abd4 --cluster bn5ebho206o7fg45f2e0 --namespace test-namespace --override-values values.json

Override values example format from the values.json file:
{
"username": "provision-test-1",
"password": "passw0rd"
}

Virtual server image for VPC Example
Validate a product with the version locator 51c9e0db-2911-45a6-adb0-ac5332d27cf2.ecebffdc-f1f8-4a85-965f-9cbe31920542 in a VPC with the ID
r134-476cbb67-a6c2-4957-9806-3fcbac3498be .
ibmcloud catalog offering version validate --version-locator 51c9e0db-2911-45a6-adb0-ac5332d27cf2.ecebffdc-f1f8-4a85-965f9cbe31920542 --workspace-region=us-south --workspace-rg-id Default --override-values '{
"vsi_instance_name": "instance-name-1",
"vsi_id": "r134-14903434-faf0-4a66-b861-7b35198de393",
"vpc_profile": "bx2-2x8",
"subnet_id": "0716-d799c449-466c-4844-902c-a5d3f8948d7d",
"vpc_id": "r134-476cbb67-a6c2-4957-9806-3fcbac3498be",
"subnet_zone": "us-south-1",
"ssh_key_id": "r134-0c53e7f2-771f-4d0e-a19e-39f2e6e6949c",
"vpc_region": "us-south"
}

ibmcloud catalog offering version validate-status
Run the following command to get the status of an ongoing validation.
ibmcloud catalog offering version validate-status --version-locator VERSION_NUMBER [--output FORMAT]

Command options
--version-locator VERSION_NUMBER
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you
want to use.
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example,

--output json .

Running secure workloads 229

ibmcloud catalog offering category-options
Run the following command to retrieve the list of category choices.
ibmcloud catalog offering category-options [--output FORMAT]

Command options
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example,

--output json .

Example
ibmcloud catalog offering category-options

Output
The command returns the following output:
Name

Tags

Description

VPC Infrastructure

vpc

Fully customizable, software-defined virtual

network with superior isolation.
Compute

compute,content,containers,openwhisk,vmware,runtime

Build your virtual environments

Containers

containers,clusters,registry

Get started by creating a Kubernetes cluster, or

manage your Docker images in the registry.
Networking

network

Order network.

Storage

storage

Order storage.

ibmcloud catalog offering add-category
Run the following command to add a category tag to a product. You can provide the category name, which you can find by running the

ibmcloud catalog

offering category-options command. The products must be placed in a category to be visible in the catalog. Default is Developer tools .
ibmcloud catalog offering category-options [--output FORMAT]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.
--category CATEGORY
Provide the category that best fits how users might use your product. Categories are used to organize products in the catalog based on common
solutions, function, or use. You can select only one category. Run the ibmcloud catalog offering category-options command to view all
options. Default is Developer tools .

Example
ibmcloud catalog offering add-category --catalog dev-catalog --offering dev-offering --category dev_ops

ibmcloud catalog offering categories
Run the following command to retrieve the category of a product version.

Running secure workloads 230

ibmcloud catalog offering version categories [--catalog CATALOG] [--offering OFFERING] [--output OUTPUT]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json .

Example
Retrieve the category of a product that is called dev-offering and located in the dev-catalog .
ibmcloud catalog offering version categories --catalog dev-catalog --offering dev-offering

ibmcloud catalog offering version get-claims
Run the following command to retrieve the security and compliance information that a version claimed.
ibmcloud catalog offering version get-claims [--output OUTPUT] [--version-locator LOCATOR]

Command options
--version-locator LOCATOR
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you
want to use.
--output value (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example,

--output json .

ibmcloud catalog offering version update-claims
Run the following command to update the security and compliance claims of a version.
ibmcloud catalog offering version update-claims [--claims CLAIMS] [--version-locator LOCATOR]

Command options
--claims CLAIMS
Specify the claims data for a version as a JSON object or file.
--version-locator LOCATOR
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you
want to use.

ibmcloud catalog offering version scc-apply
Run the following command to add a Security and Compliance Center scan to your version. Add security and compliance information to your version and
validate your version before you can add a scan.

Running secure workloads 231

ibmcloud catalog offering version scc-apply [--instance-region REGION] [--scan SCAN] [--service-instance INSTANCE] [--targetaccount-name NAME] [--target-api-key KEY] [--timeout TIMEOUT] [--version-locator LOCATOR] [--wait WAIT]

Command options
--instance-region REGION
The region of the instance.
--scan SCAN
The ID of a Security and Compliance Center scan.
--service-instance INSTANCE
Provide the Security and Compliance Center instance ID.
--target-account-name NAME (optional)
Provide the name of the target account.
--target-api-key KEY (optional)
Provide an API key if you want to use an alternative account (target account) to apply a scan to your source account. For more information, see
Setting up a target account .
--timeout TIMEOUT
Specify in seconds how long you want to wait for the scan to be applied to the version before the command returns. The default value is 600 (10
minutes).
--version-locator LOCATOR
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you
want to use.
--wait WAIT
Wait and track the progress of a scan application. Default is true if flag is not provided. If

true , the command tracks the progress of the scan

application. If false , the command returns immediately.

ibmcloud catalog offering version scc-apply-status
Run the following command to see the status of a Security and Compliance Center scan application to your version.
ibmcloud catalog offering version scc-apply-status [--scan SCAN] [--version-locator LOCATOR]

Command options
--scan SCAN
The ID of a Security and Compliance Center scan.
--version-locator LOCATOR
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you
want to use.

ibmcloud catalog offering version get-scans
Run the following command to retrieve the Security and Compliance Center scans that are added to your version.
ibmcloud catalog offering version get-scans [--instance-region REGION] [--output OUTPUT] [--profiles PROFILES] [--serviceinstance INSTANCE] [--target-account-name NAME] [--target-api-key KEY]

Command options

Running secure workloads 232

--instance-region REGION
Provide the region of the instance.
--output OUTPUT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json .

--profiles PROFILES
Provide a comma-separated list of profile names with versions, for example, "IBM Cloud for Financial Services::1.2.0" .
--service-instance INSTANCE
Provide the Security and Compliance Center instance ID.
--target-account-name NAME (optional)
Provide the name of the target account.
--target-api-key KEY (optional)
Provide an API key if you want to use an alternative account (target account) to apply a scan to your source account. For more information, see
Setting up a target account .

ibmcloud catalog offering get-scan-results
Run the following command to generate a report of your version's Code Risk Analyzer and Security and Compliance Center scan results. To generate a full
report, you must run the Code Risk Analyzer and Security and Compliance Center scans.
ibmcloud catalog offering get-scan-results [--version-locator LOCATOR]

Command options
--version-locator LOCATOR
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you
want to use.

ibmcloud catalog offering version create-draft
Run the following command to create a draft of an existing version. This command is useful for changing an existing version that you want to publish
without introducing a new version. Some changes, like changing the source file, require you to revalidate the product.
ibmcloud catalog offering version create-draft --version-locator VERSION_NUMBER [--output FORMAT]

Command options
--version-locator VERSION_NUMBER
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you
want to use.
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json .

ibmcloud catalog offering version delete-version
Run the following command to delete a version of a product.
ibmcloud catalog offering version delete-version --version-locator VERSION_NUMBER [--output FORMAT]

Running secure workloads 233

Command options
--version-locator VERSION_NUMBER
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you
want to use.
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json .

ibmcloud catalog offering version deprecate-version
Run the following command to deprecate a previously published product version from the IBM Cloud catalog.
ibmcloud catalog offering version deprecate-version --version-locator VERSION_NUMBER

Command options
--version-locator VERSION_NUMBER
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you
want to use.

ibmcloud catalog offering version refresh-version
Run the following command to create a change in the source file of a draft version. This command is useful for updating an existing version.
ibmcloud catalog offering version refresh-version --version-locator VERSION_NUMBER --zipurl URL [--include-config]

Command options
--version-locator VERSION_NUMBER
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you
want to use.
--zipurl URL
The URL pointing to the compressed file of the product.
--include-config (optional)
If provided, all configuration values are included and available when you add the product.

ibmcloud catalog offering version merge-draft
Run the following command to merge a draft version of a product.
ibmcloud catalog offering version merge-draft --version-locator VERSION_NUMBER

Command options
--version-locator VERSION_NUMBER
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you
want to use.

Running secure workloads 234

ibmcloud catalog offering enable-sharing
Run the following command to enable your product to be shared.
ibmcloud catalog offering enable-sharing --catalog CATALOG --offering OFFERING

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.

ibmcloud catalog offering ready
Run the following command to mark your product as ready to share or publish.
ibmcloud catalog offering ready --version-locator VERSION_NUMBER

Command options
--version-locator VERSION_NUMBER
To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you
want to use.

ibmcloud catalog offering delete
Run the following command to delete a product from your private catalog. You cannot delete a product that is published in the IBM Cloud catalog. To
deprecate a published product from the IBM Cloud catalog, see ibmcloud catalog offering deprecate-offering .
ibmcloud catalog offering delete --catalog CATALOG --offering OFFERING

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.

ibmcloud catalog offering publish account
Run the following command to publish a product from your private catalog to an account. After the product is published, users in the account that have
access to the private catalog. Its containing resource group can create an instance and start to use it.
ibmcloud catalog offering publish account [--catalog CATALOG][--offering OFFERING]

Command options
--catalog CATALOG
The catalog name or ID.

Running secure workloads 235

--offering OFFERING
The product name or ID.

ibmcloud catalog offering publish allowlist
Run the following command to publish a product from your private catalog to a set of allowlisted accounts. After the product is published, users in the
allowlisted accounts can create an instance and start to use it.
ibmcloud catalog offering publish allowlist [--catalog CATALOG][--offering OFFERING][--account-ids ACCOUNT-IDS]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.
--account-ids ACCOUNT-IDS
The account IDs.

ibmcloud catalog offering publish enterprise
Run the following command to publish a product to an enterprise. After the product is published, users within the enterprise can create an instance of the
product.
ibmcloud catalog offering publish enterprise [--catalog CATALOG][--offering OFFERING]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.

ibmcloud catalog offering suspend-offering
Run the following command to suspend a product from the catalog. You can suspend it for a short time without permanently deleting or deprecating it.
Suspending a product can be useful if, for example, you discover a bug or a vulnerability in your product that must be investigated before more customers
install it.
ibmcloud catalog offering suspend-offering [--catalog CATALOG][--offering OFFERING]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.

Running secure workloads 236

ibmcloud catalog offering version suspend-version
Run the following command to suspend a version of a product from the catalog. You can suspend the version for a short time without permanently deleting
or deprecating it.
ibmcloud catalog offering version suspend-version [--version-locator VERSION_NUMBER]

Command options
--version-locator VERSION_NUMBER
To get the version locator for this offering, run ibmcloud catalog offering list and locate the version that you want to use.

ibmcloud catalog offering workspaces
Run the following command to get the Schematics workspaces for a product version.
ibmcloud catalog offering workspaces [--version-locator VERSION_NUMBER] [output FORMAT]

Command options
--version-locator VERSION_NUMBER
To get the version locator for this offering, run ibmcloud catalog offering list and locate the specified version that you want to use.
--output FORMAT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json .

ibmcloud catalog install
Run the following command to install a software version from the IBM Cloud catalog.
ibmcloud catalog install [--version-locator VERSION_NUMBER] [--cluster CLUSTER_ID] [--namespace NAME] [--override-values VALUES]
[--timeout TIMEOUT] [--wait WAIT] [--workspace-name NAME] [--workspace-tags TAGS] [--workspace-tf-version VERSION] [--workspaceregion REGION] [--workspace-rg-id ID] [schematics-delete VALUE]

Command options
--version-locator VERSION_NUMBER
To get the version locator for this offering, run ibmcloud catalog offering list and locate the version that you want to use.
--cluster CLUSTER_ID
Specify the cluster name or ID.
--namespace NAME
Specify the namespace that you'd like to use.
--override-values VALUES
Provide any custom configurations for the installation. You can provide this value either inline or by using a JSON or TXT file. For example,

override-

values values.json .

--timeout TIMEOUT
Specify in seconds how long the Schematics workspace waits before it installs. Default is

180 .

--wait WAIT
Wait and track the progress of the Schematics workspace job. If true , installation waits. If false , the software installs immediately. Default is
true .

--workspace-name NAME (optional)
Running secure workloads 237

Provide a workspace name. Default is OfferingName-Date .
--workspace-tags TAGS (optional)
Provide a comma-separated list of tags.
--workspace-tf-version VERSION (optional)
Provide a workspace terraform version.
--workspace-region REGION (optional)
Provide a workspace region.
--workspace-rg-id ID (optional)
Provide a workspace resource group ID.
--schematics-delete VALUE (optional)
Provide this flag to delete the Schematics workspace after validation and installation.

Example
Install the software version 1 by using cluster A , namespace install , and the override values JSON values.json .
ibmcloud catalog install [--version-locator 1] [--cluster A] [--namespace install] [--override-values values.json]

Override values example format from the values.json file:
{
"username": "install-test-1",
"password": "passw0rd"
}

ibmcloud catalog pricing
Run the following command to get pricing information for catalog offerings.
$ ibmcloud catalog pricing [-r, --region REGION] [-k, --kind KIND] [-p, --price PRICE] [--tag TAG] [--country COUNTRY] [--global]
[--iam] [--json] [--csv] [-f, --file FILENAME]

Command options
-r, --region (optional)
Filter by geo.
-k, --kind (optional)
Filter by the kind of resources. Currently service (default), iaas , runtime , template , and geography are supported
-p, --price (optional)
Filter by price. Currently free , paygo , and subscription are supported
-t, --tag (optional)
Filter by tag. This flag is repeatable and results in a logical OR of all the tags specified.
--co, --country (optional)
Filter by a country. Output to CSV or JSON may use the value

ALL to get values for all countries.

--json (optional)
Output a JSON response.
--csv (optional)
Output a CSV file.
-f, --file (optional)
Specify a file name for the csv output.
Running secure workloads 238

--global (optional)
Operate in global scope.
--iam (optional)
Filter by IAM compatible offerings.

Example
Get pricing information for Virtual Server for VPC for a Pay-As-You-Go account.
ibmcloud catalog pricing is.instance [--price paygo]

ibmcloud catalog utility create-product-from-workspace
Run the following command to create a deployable architecture tile from a Schematics workspace that was created directly from the Git repository. The
deployable architecture creates a project so that you can continue to develop and maintain the deployable architecture with the future version.
The command requires a GIT_TOKEN environment variable to authenticate with your source repository so a catalog manifest can be added. The command
pushes to a new branch in the Git repository that is found in the Schematics workspace and creates a release that is used for onboarding.
ibmcloud catalog utility create-product-from-workspace [--workspace-id ID] [--api-key KEY] [--trusted-profile-id ID] [--cataloglabel LABEL] [--offering-label LABEL] [--project-name NAME] [--project-resource-group GROUP] [--target-version VERSION] [-variation-label LABEL]

Command options
--api-key or --ak API KEY
Provide an API key that is used to link the catalog and project. Mutually exclusive with '--trusted-profile-id'.
--catalog-label CATALOG LABEL (optional)
Provide the label of an existing catalog to import into or the name of a new catalog to create. The default is 'Migrated DAs'.
--offering-label OFFERING LABEL (optional)
Provide the label of an existing offering to import into or the name of a new offering to create. The default is 'Migrated <workspace_name>'. The label
overwrites the existing offering label if the workspace is created from a catalog offering.
--project-name NAME (optional)
Provide a project name that is linked to the onboarded catalog. If the project does not exist, it is created. The default name is 'Dev Migration Project'.
--project-resource-group (optional)
Provide a resource group for the project that is created. The default resource group is 'Default'.
--target-version VERSION (optional)
Provide the target version for the migrated offering. The default is '1.0.0'.
--trusted-profile-id or --tpi TRUSTED PROFILE ID
Provide a trusted profile ID that is used to link the catalog and project. Mutually exclusive with '--api-key'.
--variation-label VARIATION LABEL (optional)
Provide a variation label for the version to be onboarded. The default is 'Standard'. The label overwrites the existing version label if the workspace is
created from a catalog offering.
--workspace-id WORKSPACE ID
Provide a Schematics workspace ID. To get the workspace ID, you must create the Schematics workspace. For more information, see

ibmcloud

schematics workspace new .

ibmcloud catalog utility netrc
Run the following command to create a .netrc file, generate the machine name in your .netrc file, or update the credential in your .netrc file. A

Running secure workloads 239

.netrc file stores the required login information that is needed to use Terraform modules from the IBM Cloud catalog.

By running this command, you configure a .netrc file for the machine name cm.globalcatalog.cloud.ibm.com with iamtoken as the username and
your IAM token as the password.
Note: You need version 1.2.7 or higher of the catalogs management CLI plug-in to run the

.netrc command.

ibmcloud catalog utility netrc

ibmcloud catalog utility update-module-references
Run the following command to check your working directory's Terraform modules for updates from the catalog and update the source attribute to the latest
version. The README.md is also updated.
ibmcloud catalog utility update-module-references

ibmcloud catalog offering unpublish account
Run the following command to unpublish a product from your account. After the product is unpublished, users in your account cannot create an instance of
the product.
ibmcloud catalog offering unpublish account [--catalog CATALOG][--offering OFFERING]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.

ibmcloud catalog offering unpublish allowlist
Run the following command to remove account IDs from the product's allowlist. Accounts that are removed from the allowlist cannot create an instance of
the product.
ibmcloud catalog offering unpublish allowlist [--catalog CATALOG][--offering OFFERING][--account-ids ACCOUNT-IDS]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.
--account-ids ACCOUNT-IDS
The account IDs.

ibmcloud catalog offering unpublish enterprise
Run the following command to unpublish a product from an enterprise. After the product is unpublished, the enterprise cannot create an instance of the
product.
ibmcloud catalog offering unpublish enterprise [--catalog CATALOG][--offering OFFERING]

Running secure workloads 240

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.

ibmcloud catalog offering unpublish ibm
Run the following command to unpublish a product from IBM. After the product is unpublished, IBM employees cannot create an instance of the product.
ibmcloud catalog offering unpublish ibm [--catalog CATALOG][--offering OFFERING]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.

ibmcloud catalog offering publish ibm
Run the following command to publish an offering that is already available in your account to all IBMers. This part of the publication process creates a tile
in the staging and production catalogs that is visible only to IBMers. By publishing an offering to IBMers, you can test the offering in production before you
make it available to all users in the IBM Cloud catalog.
ibmcloud catalog offering publish ibm [--catalog CATALOG][--offering OFFERING]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.

ibmcloud catalog offering publish public
Run the following command to publish your private offering to the IBM Cloud catalog for all users to see and use. To get to this step in the publication
process, you must first publish the offering to your account and to all IBMers to complete the testing process. After your testing is complete, you can run
this command.
Important: This option requires approval. When your approval is complete, your tile is available for all IBM Cloud customers.

ibmcloud catalog offering publish public [--catalog CATALOG][--offering OFFERING]

Command options
--catalog CATALOG

Running secure workloads 241

The catalog name or ID.
--offering OFFERING
The product name or ID.

ibmcloud catalog offering deprecate-offering
Run the following command to deprecate a previously published offering version in the IBM Cloud catalog.
ibmcloud catalog offering deprecate-offering [--catalog CATALOG][--offering OFFERING]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.

ibmcloud catalog offering restore-offering
Run the following command to restore a previously deprecated product in the IBM Cloud catalog. After you validate a version of your product, you can
restore it to the published state that it was in before it was deprecated.
ibmcloud catalog offering restore-offering [--catalog CATALOG][--offering OFFERING]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.

ibmcloud catalog offering version restore-version
Run the following command to restore a previously deprecated version of a product in the IBM Cloud catalog. Restoring it places the version in a draft state.
After you validate it, you can restore the original version to the published state that it was in before it was deprecated.
ibmcloud catalog offering version restore-version [--catalog CATALOG][--offering OFFERING] [--include-config]

Command options
--catalog CATALOG
The catalog name or ID.
--offering OFFERING
The product name or ID.
--include-config (optional)
If provided, all configuration values are included and available when you add the product.

Running secure workloads 242

ibmcloud catalog object create vpe
Run the following command to add an object to a private catalog in the account.
ibmcloud catalog object create vpe [--catalog CATALOG] [--crn CRN] [endpoint-type TYPE] [--fqdn FQDN] [--name NAME] [--region
REGION]

Command options
--catalog CATALOG
Specify the catalog name or ID.
--crn CRN
Provide the Cloud Resource Name (CRN).
--endpoint-type TYPE
Specify the VPE endpoint type.
--fqdn FQDN
Provide a comma-separated list of fully qualified domain names.
--name NAME
Specify the name of the object.
--region REGION
Specify the region for the VPE endpoint.

ibmcloud catalog object delete
Run the following command to delete the object.
ibmcloud catalog object delete [--catalog CATALOG] [--name NAME]

Command options
--catalog CATALOG
Specify the catalog name or ID.
--name NAME
Provide the name of the object.

ibmcloud catalog object update vpe
Run the following command to update the object.
ibmcloud catalog object update vpe [--catalog CATALOG] [--name NAME] [--crn CRN] [--endpoint-type TYPE] [--fqdn FQDN] [--region
REGION]

Command options
--catalog CATALOG
Specify the catalog name or ID.
--name NAME
Specify the name of the object.
--crn CRN (optional)
Running secure workloads 243

Provide the Cloud Resource Name (CRN).
--endpoint-type TYPE (optional)
Specify the VPE endpoint type.
--fqdn FQDN (optional)
Provide a comma-separated list of fully qualified domain names.
--region REGION (optional)
Specify the region for the VPE endpoint.

ibmcloud catalog object get
Run the following command to retrieve information for a particular object.
ibmcloud catalog object get [--catalog CATALOG] [--name NAME] [--output OUTPUT]

Command options
--catalog CATALOG
Specify the catalog name or ID.
--name NAME
Provide the name of the object.
--output OUTPUT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json

ibmcloud catalog object list
Run the following command to retrieve a list of objects in a catalog.
ibmcloud catalog object list [--catalog CATALOG] [--output OUTPUT]

Command options
--catalog CATALOG
Specify the catalog name or ID.
--output OUTPUT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json

ibmcloud catalog object search
Run the following command to search objects by using Lucene query syntax.
ibmcloud catalog object search [--query QUERY] [--output OUTPUT]

Command options
--query QUERY
Provide the Lucene query string.
--output OUTPUT (optional)

Running secure workloads 244

Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json

ibmcloud catalog object ready
Run the following command to mark your object as ready to share or publish.
ibmcloud catalog object ready [--catalog CATALOG] [--name NAME]

Command options
--catalog CATALOG
Specify the catalog name or ID.
--name NAME
Specify the name of the object.

ibmcloud catalog object enable-sharing
Run the following command to enable sharing of a Partner Center managed object. Enable sharing before you can share an object to an account or access
list.
ibmcloud catalog object enable-sharing [--catalog CATALOG] [--name NAME]

Command options
--catalog CATALOG
Specify the catalog name or ID.
--name NAME
Specify the name of the object.

ibmcloud catalog object publish
Run the following command to publish the object to an access list, your account, IBM employees, or IBM Cloud catalog for all users to see and use.
ibmcloud catalog object publish COMMAND [--catalog CATALOG] [--name NAME]

Command options
Command
Specify where you want to publish the object. Valid values are accesslist , account , ibm , or public .
--catalog CATALOG
Specify the catalog name or ID.
--name NAME
Provide the name of the object.

Example
Publish an object called dev-object that's in the catalog dev-catalog to IBM employees.
ibmcloud catalog object publish ibm --catalog dev-catalog --name dev-object
Running secure workloads 245

ibmcloud catalog object access-list add
Run the following command to add account IDs to an object's access list.
ibmcloud catalog object access-list add [--account-id ID] [--catalog CATALOG] [--name NAME]

Command options
--account-id ID
Provide a comma-separated list of account IDs.
--catalog CATALOG
Specify the catalog name or ID.
--name NAME
Specify the name of the object.

ibmcloud catalog object access-list get
Run the following command to retrieve information for a particular access list for an object.
ibmcloud catalog object access-list get [--catalog CATALOG] [--name NAME] [--output OUTPUT]

Command options
--catalog CATALOG
Specify the catalog name or ID.
--name NAME
Specify the name of the object.
--output OUTPUT (optional)
Specifies output format. The default is terminal compatible and the only supported alternative is JSON. For example,

--output json

ibmcloud catalog object access-list rm
Run the following command to remove account IDs from the object's access list.
ibmcloud catalog object access-list rm [--account-id ID] [--catalog CATALOG] [--name NAME]

Command options
--account-id ID
Provide a comma-separated list of account IDs.
--catalog CATALOG
Specify the catalog name or ID.
--name NAME
Specify the name of the object.

Managing IAM access, API keys, trusted profiles, service IDs, and access groups
Running secure workloads 246

(ibmcloud iam)
Use the following commands from the IBM Cloud® Command Line Interface to manage API keys, service IDs, access groups, and authorization policies for
users, services, trusted profiles, and access groups.

ibmcloud iam service-ids
List all service IDs:
ibmcloud iam service-ids [--uuid] [-n, --name STRING] [-d, --description STRING]

Command options
--uuid
Show UUID of service IDs only.
-d, --description STRING
Filter results to list the service IDs with descriptions that include the supplied string.
-n, --name STRING
Filter results to list the service IDs with names that include the supplied string.

Examples
List UUID of all service IDs under current account:
ibmcloud iam service-ids --uuid

ibmcloud iam service-id
Display details of a service ID:
$ ibmcloud iam service-id (NAME|UUID) [--uuid]

Command options
NAME (required)
Name of the service, exclusive with UUID.
UUID (required)
UUID of the service, exclusive with NAME.
--uuid
Display the UUID of the service ID.

Examples
Show details of service ID sample-test :
ibmcloud iam service-id sample-test

Show details of service ID ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 :
ibmcloud iam service-id ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976

ibmcloud iam service-id-create
Running secure workloads 247

Create a service ID:
ibmcloud iam service-id-create NAME [-d, --description DESCRIPTION] [--lock]

Command options
NAME (required)
Name of the service.
-d, --description
Description of the service ID.
--lock
Lock the service ID during creation.

Examples
Create a service ID with service name sample-test and description hello, world! :
ibmcloud iam service-id-create sample-test -d 'hello, world!'

Create a locked service ID with service name sample-test and description hello, world! :
ibmcloud iam service-id-create sample-test -d 'hello, world!' --lock

ibmcloud iam service-id-update
Update a service ID:
ibmcloud iam service-id-update (NAME|UUID) [-n, --name NEW_NAME] [-d, --description DESCRIPTION] [-f, --force]

Command options
NAME (required)
Name of the service, exclusive with UUID.
UUID (required)
UUID of the service, exclusive with NAME.
-n, --name
New name of the service.
-d, --description
New description of the service.
-f, --force
Update without confirmation.

Examples
Rename service ID sample-test to sample-test-2 without confirmation:
ibmcloud iam service-id-update sample-test -n sample-test-2 -f

Update description of the service sample-test :
ibmcloud iam service-id-update sample-test -d 'hello, friend!'

Running secure workloads 248

Rename service ID ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 to sample-test-3 with new description:
ibmcloud iam service-id-update ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 -n sample-test-3 -d 'hello, my friends!'

ibmcloud iam service-id-delete
Delete a service ID:
ibmcloud iam service-id-delete (NAME|UUID) [-f, --force]

Command options
NAME (required)
Name of the service, exclusive with UUID.
UUID (required)
UUID of the service, exclusive with NAME.
-f, --force
Delete without confirmation.

Examples
Delete service ID sample-teset without confirmation:
ibmcloud iam service-id-delete sample-teset -f

Delete service ID ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 :
ibmcloud iam service-id-delete ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976

ibmcloud iam service-id-lock
Lock a service ID:
ibmcloud iam service-id-lock (NAME|UUID) [-f, --force]

Command options
NAME (required)
Name of the service, exclusive with UUID.
UUID (required)
UUID of the service, exclusive with NAME.
-f, --force
Lock without confirmation.

Examples
Lock service ID sample-teset without confirmation:
ibmcloud iam service-id-lock sample-teset -f

Lock service ID ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 :
ibmcloud iam service-id-lock ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976

Running secure workloads 249

ibmcloud iam service-id-unlock
Unlock a service ID:
ibmcloud iam service-id-unlock (NAME|UUID) [-f, --force]

Command options
NAME (required)
Name of the service, exclusive with UUID.
UUID (required)
UUID of the service, exclusive with NAME.
-f, --force
Unlock without confirmation.

Examples
Unlock service ID sample-teset without confirmation:
ibmcloud iam service-id-unlock sample-teset -f

Unlock service ID ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 :
ibmcloud iam service-id-unlock ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976

ibmcloud iam api-keys
List all IBM Cloud platform API keys:
ibmcloud iam api-keys [--uuid] [-n, --name STRING] [-d, --description STRING]

Command options
--uuid
Show the UUID of the API key.
-d, --description STRING
Filter results to list the API keys with descriptions that include the supplied string.
-n, --name STRING
Filter results to list the API keys with names that include the supplied string.

ibmcloud iam api-key-create
Create an IBM Cloud platform API key:
ibmcloud iam api-key-create NAME [-d DESCRIPTION] [--file FILE] [--lock]

Note: Using the IBM Cloud CLI login with an API Key does not work with the legacy SL API Key that is found on

control.softlayer.com option.

An upgraded IBM Cloud Account where Infrastructure is managed through cloud.ibm.com is required for the IBM Cloud CLI login with an API Key.

Command options

Running secure workloads 250

NAME (required)
Name of the API key to be created.
-d DESCRIPTION (optional)
Description of the API key.
--file FILE
Save API key information to the specified file.
--action-if-leaked value
The action to take if the key is leaked, can be "NONE", "DISABLE", or "DELETE". The default is "Disable".
--lock
Lock the API key when it is created.

Examples
Create an API key and save it to a file:
ibmcloud iam api-key-create MyKey -d "this is my API key" --file key_file

Create a locked API key with name "test-key":
ibmcloud iam api-key-create test-key --lock

ibmcloud iam api-key-update
Update a IBM Cloud platform API key:
ibmcloud iam api-key-update (NAME|UUID) [-n name] [-d description]

Command options
NAME (required)
The old name of the API key is to be updated, exclusively with UUID.
UUID (required)
The UUID of the API key is to be updated, exclusively with NAME.
-n NAME (optional)
The new name of the API key.
-d DESCRIPTION (optional)
The new description of the API key.
--action-if-leaked value
The action to take if the key is leaked, can be "NONE", "DISABLE", or "DELETE". The default is "Disable"

Examples
Update the description of an API key:
ibmcloud iam api-key-update MyKey -d "the new description of my key"

Note: The iam-identity.apikey.manage privilege is required for the account when the NAME and UUID command options are used. For more
information, see Managing user API keys and IAM Identity Service.

Running secure workloads 251

ibmcloud iam api-key-delete
Delete a IBM Cloud platform API key:
ibmcloud iam api-key-delete (NAME|UUID) [-f, --force]

Command options
NAME (required)
Name of the API key to be deleted, exclusively with UUID.
UUID (required)
UUID of the API key to be deleted, exclusively with NAME.
-f, --force
Force deletion without confirmation.

ibmcloud iam api-key-lock
Lock a platform API key:
ibmcloud iam api-key-lock (NAME|UUID) [-f, --force]

Command options
NAME (required)
The name of the API key to be locked, exclusively with UUID.
UUID (required)
UUID of the API key to be locked, exclusively with NAME.
-f, --force
Force lock without confirmation.

Examples
Lock API key test-api-key:
ibmcloud iam api-key-lock test-api-key

Lock API key with given UUID without confirmation:
ibmcloud iam api-key-lock ApiKey-18f773b0-db53-43f1-ad68-92c667c218fe --force

ibmcloud iam api-key-unlock
Unlock a platform API key:
ibmcloud iam api-key-unlock (NAME|UUID) [-f, --force]

Command options
NAME (required)
The name of the API key to be unlocked, exclusively with UUID.
UUID (required)

Running secure workloads 252

The UUID of the API key to be unlocked, exclusively with NAME.
-f, --force
Unlock an API key without confirmation.

Examples
Unlock API key test-api-key:
ibmcloud iam api-key-unlock test-api-key

Unlock API key with given UUID without confirmation:
ibmcloud iam api-key-unlock ApiKey-18f773b0-db53-43f1-ad68-92c667c218fe --force

ibmcloud iam api-key-disable
Disable a platform API key:
ibmcloud iam api-key-disable (NAME|UUID) [-f, --force]

Command options
NAME (required)
The name of the API key to be disabled, exclusively with UUID.
UUID (required)
The UUID of the API key to be disabled, exclusively with NAME.
-f, --force
Force disable without confirmation.

Examples
Disable an API key test-api-key:
ibmcloud iam api-key-disable test-api-key

Disable an API key with given UUID without confirmation:
ibmcloud iam api-key-disable ApiKey-18f773b0-db53-43f1-ad68-92c667c218fe --force

ibmcloud iam api-key-enable
Enable a platform API key:
ibmcloud iam api-key-enable (NAME|UUID) [-f, --force]

Command options
NAME (required)
The name of the API key to be enabled, exclusively with UUID.
UUID (required)
The UUID of the API key to be enabled, exclusively with NAME.
-f, --force

Running secure workloads 253

Force enable without confirmation.

Examples
Enable API key test-api-key:
ibmcloud iam api-key-enable test-api-key

Enable API key with given UUID without confirmation:
ibmcloud iam api-key-enable ApiKey-18f773b0-db53-43f1-ad68-92c667c218fe --force

ibmcloud iam service-api-keys
List all API keys of a service:
ibmcloud iam service-api-keys ([-a, --all], SERVICE_ID_NAME|SERVICE_ID_UUID) [-n, --name STRING] [-d, --description STRING] [-f,
--force]

Command options
-a, --all
Display all API keys that are associated with all services.
SERVICE_ID_NAME (required)
The name of the service ID, exclusive with SERVICE_ID_UUID.
SERVICE_ID_UUID (required)
The UUID of the service ID, exclusive with SERVICE_ID_NAME.
-d, --description STRING
Filter results to list the service API keys with descriptions that include the supplied string.
-n, --name STRING
Filter results to list the service API keys with names that include the supplied string.
-f, --force
Display service API keys without confirmation.

Examples
List all API keys of the service sample-service :
ibmcloud iam service-api-keys sample-service

ibmcloud iam service-api-key
List details of a service API key:
ibmcloud iam service-api-key (APIKEY_NAME|APIKEY_UUID) (SERVICE_ID_NAME|SERVICE_ID_UUID) [--uuid] [-f, --force]

Command options
APIKEY_NAME (required)
Name of the API key, exclusive with APIKEY_UUID.
APIKEY_UUID (required)
UUID of the API key, exclusive with APIKEY_NAME.
Running secure workloads 254

SERVICE_ID_NAME (required)
Name of the service ID, exclusive with SERVICE_ID_UUID.
SERVICE_ID_UUID (required)
UUID of the service ID, exclusive with SERVICE_ID_NAME.
--uuid
Display the UUID of the service API key.
-f, --force
Display service API key without confirmation.

Examples
Show details of service API key sample-key of service sample-service :
ibmcloud iam service-api-key sample-key sample-service

ibmcloud iam service-api-key-create
Create a service API key:
ibmcloud iam service-api-key-create NAME (SERVICE_ID_NAME|SERVICE_ID_UUID) [-d, --description DESCRIPTION] [--file FILE] [-f, -force] [--lock]

Command options
NAME (required)
Name of the service ID or newly created service API key.
SERVICE_ID_NAME (required)
Name of the service ID, exclusive with SERVICE_ID_UUID.
SERVICE_ID_UUID (required)
UUID of the service ID, exclusive with SERVICE_ID_NAME.
-d, --description
Description of the API key.
--file FILE
Save API key information to the specified file.
--action-if-leaked value
The action to take if the key is leaked. The options are "NONE", "DISABLE", or "DELETE". The default option is "Disable".
-f, --force
Force creation without confirmation.

Examples
Create a service API key sample-key for service sample-service without confirmation:
ibmcloud iam service-api-key-create sample-key sample-service -f

ibmcloud iam service-api-key-update
Update a service API key:
ibmcloud iam service-api-key-update (APIKEY_NAME|APIKEY_UUID) (SERVICE_ID_NAME|SERVICE_ID_UUID)

[-n, --name NEW_NAME] [-d, -Running secure workloads 255

description DESCRIPTION] [-f, --force]

Command options
APIKEY_NAME (required)
Name of the API key, exclusive with APIKEY_UUID.
APIKEY_UUID (required)
UUID of the API key, exclusive with APIKEY_NAME.
SERVICE_ID_NAME (required)
Name of the service ID, exclusive with SERVICE_ID_UUID.
SERVICE_ID_UUID (required)
UUID of the service ID, exclusive with SERVICE_ID_NAME.
-n, --name
The new name of the service API key.
-d, --description
The new description of the service API key.
--action-if-leaked value
The action to take if the key is leaked, can be "NONE", "DISABLE", or "DELETE". The default is "Disable".
-f, --force
Update without confirmation.

Examples
Rename the service API key sample-key to new-sample-key :
ibmcloud iam service-api-key-update sample-key sample-service -n new-sample-key

ibmcloud iam service-api-key-delete
Delete a service API key:
ibmcloud iam service-api-key-delete (APIKEY_NAME|APIKEY_UUID) (SERVICE_ID_NAME|SERVICE_ID_UUID) [-f, --force]

Command options
APIKEY_NAME (required)
Name of the API key, exclusive with APIKEY_UUID.
APIKEY_UUID (required)
UUID of the API key, exclusive with APIKEY_NAME.
SERVICE_ID_NAME (required)
Name of the service ID, exclusive with SERVICE_ID_UUID.
SERVICE_ID_UUID (required)
UUID of the service ID, exclusive with SERVICE_ID_NAME.
-f, --force
Delete without confirmation.

Examples
Running secure workloads 256

Delete service API key sample-key of service ID sample-service :
ibmcloud iam service-api-key-delete sample-key sample-service

ibmcloud iam service-api-key-lock
Lock a service API key:
ibmcloud iam service-api-key-lock (APIKEY_NAME|APIKEY_UUID) (SERVICE_ID_NAME|SERVICE_ID_UUID) [-f, --force]

Command options
APIKEY_NAME (required)
Name of the API key, exclusive with APIKEY_UUID.
APIKEY_UUID (required)
UUID of the API key, exclusive with APIKEY_NAME.
SERVICE_ID_NAME (required)
Name of the service ID, exclusive with SERVICE_ID_UUID.
SERVICE_ID_UUID (required)
UUID of the service ID, exclusive with SERVICE_ID_NAME.
-f, --force
Lock without confirmation.

Examples
Lock service API key sample-key of service ID sample-service :
ibmcloud iam service-api-key-lock sample-key sample-service

ibmcloud iam service-api-key-unlock
Unlock a service API key:
ibmcloud iam service-api-key-unlock (APIKEY_NAME|APIKEY_UUID) (SERVICE_ID_NAME|SERVICE_ID_UUID) [-f, --force]

Command options
APIKEY_NAME (required)
Name of the API key, exclusive with APIKEY_UUID.
APIKEY_UUID (required)
UUID of the API key, exclusive with APIKEY_NAME.
SERVICE_ID_NAME (required)
Name of the service ID, exclusive with SERVICE_ID_UUID.
SERVICE_ID_UUID (required)
UUID of the service ID, exclusive with SERVICE_ID_NAME.
-f, --force
Unlock without confirmation.

Examples
Running secure workloads 257

Unlock service API key sample-key of service ID sample-service :
ibmcloud iam service-api-key-unlock sample-key sample-service

ibmcloud iam service-api-key-disable
Disable a service API key:
ibmcloud iam service-api-key-disable (APIKEY_NAME|APIKEY_UUID) (SERVICE_ID_NAME|SERVICE_ID_UUID) [-f, --force]

Command options
APIKEY_NAME (required)
The name of the API key, exclusive with APIKEY_UUID.
APIKEY_UUID (required)
The UUID of the API key, exclusive with APIKEY_NAME.
SERVICE_ID_NAME (required)
The name of the service ID, exclusive with SERVICE_ID_UUID.
SERVICE_ID_UUID (required)
The UUID of the service ID, exclusive with SERVICE_ID_NAME.
-f, --force
Disable without confirmation.

Examples
Disable service API key sample-key of service ID sample-service :
ibmcloud iam service-api-key-disable sample-key sample-service

ibmcloud iam service-api-key-enable
Enable a service API key:
ibmcloud iam service-api-key-enable (APIKEY_NAME|APIKEY_UUID) (SERVICE_ID_NAME|SERVICE_ID_UUID) [-f, --force]

Command options
APIKEY_NAME (required)
The name of the API key, exclusive with APIKEY_UUID.
APIKEY_UUID (required)
The UUID of the API key, exclusive with APIKEY_NAME.
SERVICE_ID_NAME (required)
The name of the service ID, exclusive with SERVICE_ID_UUID.
SERVICE_ID_UUID (required)
The UUID of the service ID, exclusive with SERVICE_ID_NAME.
-f, --force
Enable without confirmation.

Examples
Running secure workloads 258

Enable service API key sample-key of service ID sample-service :
ibmcloud iam service-api-key-enable sample-key sample-service

ibmcloud iam user-policies
List all access policies for a specified user:
ibmcloud iam user-policies USER_NAME

Command options
USER_NAME (required)
User name to whom the policies belong.

Examples
List policies of user name@example.com :
ibmcloud iam user-policies name@example.com

ibmcloud iam user-policy
Display details of an access policy for a user:
ibmcloud iam user-policy USER_NAME POLICY_ID [--output FORMAT] [-q, --quiet] [--api-version v1 | v2]

Command options
USER_NAME (required)
User name to whom the policy belongs.
POLICY_ID (required)
ID of the policy.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
List policy 0bb730daa of user name@example.com :
ibmcloud iam user-policy name@example.com 0bb730daa

ibmcloud iam user-policy-create
Create an access policy for the specified user in the current account:
ibmcloud iam user-policy-create USER_NAME {--file JSON_FILE | --roles ROLE_NAME1,ROLE_NAME2... [--service-name SERVICE_NAME] [-service-instance SERVICE_INSTANCE_GUID] [--region REGION] [--resource-type RESOURCE_TYPE] [--resource RESOURCE] [--resourcegroup-name RESOURCE_GROUP_NAME] [--resource-group-id RESOURCE_GROUP_ID] [--account-management] [--attributes

Running secure workloads 259

name=value,name=value...]} [--output FORMAT] [-q, --quiet] [--api-version v1 | v2]

Command options
USER_NAME (required)
Username to whom the policy belongs.
--file FILE (optional)
JSON file of policy definition. You can use advanced operators in a JSON policy document to grant access to resources that satisfy specific naming
conventions. For more information about using advanced operators to create wildcard policies, see Assigning access by using wildcard policies .
--roles ROLE_NAME1,ROLE_NAME2... (optional)
Role names of the policy definition. For supported roles of a specific service, run

ibmcloud iam roles --service SERVICE_NAME . This option is

exclusive with the --file option.
--service-name SERVICE_NAME (optional)
Service name of the policy definition. This option is exclusive with the --file option.
--service-instance SERVICE_INSTANCE_GUID (optional)
GUID of service instance of the policy definition. This option is exclusive with the

--file option.

--region REGION (optional)
Region of the policy definition. This option is exclusive with the --file option.
--resource-type RESOURCE_TYPE (optional)
Resource type of the policy definition. This option is exclusive with the --file option.
--resource RESOURCE (optional)
Resource of the policy definition. This option is exclusive with the --file option.
--resource-group-name RESOURCE_GROUP_NAME (optional)
Name of the resource group. * means all resource groups. This option is exclusive with the --file , --resource and --resource-group-id
options.
--resource-group-id RESOURCE_GROUP_ID (optional)
ID of the resource group. * means all resource groups. This option is exclusive with the --file , --resource and --resource-group-name
options.
--account-management (optional)
Give access to all account management services.
--attributes name=value,name=value...
Set resource attributes in the form of name=value,name=value....
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
Create user policy for user name@example.com from policy JSON file policy.json :
ibmcloud iam user-policy-create name@example.com --file @policy.json

Give name@example.com Administrator role for all instances of sample-service service:
ibmcloud iam user-policy-create name@example.com --roles Administrator --service-name sample-service
Running secure workloads 260

Give name@example.com Editor role and a custom role Responder for all instances of sample-service service:
ibmcloud iam user-policy-create name@example.com --roles Editor,Responder --service-name sample-service

Give name@example.com Editor role for resource key123 of sample service instance with GUID d161aeea-fd02-40f8-a487-df1998bd69a9 in ussouth region:
ibmcloud iam user-policy-create name@example.com --roles Editor --service-name sample-service --service-instance d161aeea-fd0240f8-a487-df1998bd69a9 --region us-south --resource-type key --resource key123

Give name@example.com Operator role for resource group with ID dda27e49d2a1efca58083a01dfde18f6 :
ibmcloud iam user-policy-create name@example.com --roles Operator --resource-type resource-group --resource
dda27e49d2a1efca58083a01dfde18f6

Give name@example.com Viewer role for the members of the resource group sample-resource-group :
ibmcloud iam user-policy-create name@example.com --roles Viewer --resource-group-name sample-resource-group

Give name@example.com Viewer role for the members of the resource group with ID

dda27e49d2a1efca58083a01dfde18f6 :

ibmcloud iam user-policy-create name@example.com --roles Viewer --resource-group-id dda27e49d2a1efca58083a01dfde18f6

Give name@example.com Viewer role for service is resources with attribute instanceId equal to * :
ibmcloud iam user-policy-create name@example.com --roles Viewer --service-name is --attributes "instanceId=*"

ibmcloud iam user-policy-update
Update an access policy for the specified user in the current account:
ibmcloud iam user-policy-update USER_NAME POLICY_ID {--file JSON_FILE | [--roles ROLE_NAME1,ROLE_NAME2...] [--service-name
SERVICE_NAME] [--service-instance SERVICE_INSTANCE_GUID] [--region REGION] [--resource-type RESOURCE_TYPE] [--resource RESOURCE]
[--resource-group-name RESOURCE_GROUP_NAME] [--resource-group-id RESOURCE_GROUP_ID] [--account-management] [--attributes
name=value,name=value...]} [--output FORMAT] [-q, --quiet] [--api-version v1 | v2]

Command options
USER_NAME (required)
Username to whom the policy belongs.
POLICY_ID (required)
ID of the policy to update. --file FILE (optional)
JSON file of policy definition.
--roles ROLE_NAME1,ROLE_NAME2... (Optional)
Role names of the policy definition. For supported roles of a specific service, run

ibmcloud iam roles --service SERVICE_NAME option. This

option is exclusive with the --file option.
--service-name SERVICE_NAME (optional)
Service name of the policy definition. This option is exclusive with the --file option.
--service-instance SERVICE_INSTANCE_GUID (optional)
GUID of service instance of the policy definition. This option is exclusive with the

--file option.

--region REGION (optional)
Region of the policy definition. This option is exclusive with the --file option.
--resource-type RESOURCE_TYPE (optional)
Resource type of the policy definition. This option is exclusive with the --file option.

Running secure workloads 261

--resource RESOURCE (optional)
Resource of the policy definition. This option is exclusive with the --file option.
--resource-group-name RESOURCE_GROUP_NAME (optional)
Name of the resource group. * means all resource groups. This option is exclusive with the --file , --resource and --resource-group-id
options.
--resource-group-id RESOURCE_GROUP_ID (optional)
ID of the resource group. * means all resource groups. This option is exclusive with the --file , --resource and --resource-group-name
options.
--account-management (optional)
Give access to all account management services.
--attributes name=value,name=value...
Set resource attributes in the form of 'name=value,name=value....'
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
Update user policy with the one in JSON file：
ibmcloud iam user-policy-update name@example.com 0bb730daa --file @policy.json

Update user policy to give name@example.com Administrator role for all instances of sample-service service：
ibmcloud iam user-policy-update name@example.com user-policy-id --roles Administrator --service-name sample-service

Update user policy to give name@example.com Editor role and a custom role Responder for all instances of sample-service service：
ibmcloud iam user-policy-update name@example.com user-policy-id --roles Editor,Responder --service-name sample-service

Update user policy to give name@example.com Editor role for resource key123 of sample service instance with GUID d161aeea-fd02-40f8-a487df1998bd69a9 in us-south region:
ibmcloud iam user-policy-update name@example.com --roles Editor --service-name sample-service --service-instance d161aeea-fd0240f8-a487-df1998bd69a9 --region us-south --resource-type key --resource key123

Update user policy to give name@example.com Operator role for resource group with ID dda27e49d2a1efca58083a01dfde18f6 :
ibmcloud iam user-policy-update name@example.com user-policy-id --roles Operator --resource-type resource-group --resource
dda27e49d2a1efca58083a01dfde18f6

Update user policy to give name@example.com Viewer role for members of the resource group sample-resource-group :
ibmcloud iam user-policy-update name@example.com user-policy-id --roles Viewer --resource-group-name sample-resource-group

Update user policy to give name@example.com Viewer role for members of a resource group with ID dda27e49d2a1efca58083a01dfde18f6 :
ibmcloud iam user-policy-update name@example.com user-policy-id --roles Viewer --resource-group-id
dda27e49d2a1efca58083a01dfde18f6

Update user policy to give name@example.com Viewer role for service is resources with attribute instance equal to * :

Running secure workloads 262

ibmcloud iam user-policy-update name@example.com user-policy-id --roles Viewer --service-name is --attributes "instanceId=*"

ibmcloud iam user-policy-delete
Delete an access policy for the specified user:
ibmcloud iam user-policy-delete USER_ID POLICY_ID [-f, --force] [-q, --quiet] [--api-version v1 | v2]

Command options
-f, --force
Delete user policy without confirmation.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
Delete policies user-policy-id of user name@example.com :
ibmcloud iam user-policy-delete name@example.com user-policy-id

Delete policies user-policy-id of user name@example.com without confirmation:
ibmcloud iam user-policy-delete name@example.com user-policy-id -f

ibmcloud iam service-policies
List all access policies for a specified service ID:
$ ibmcloud iam service-policies SERVICE_ID [-f, --force] [-q, --quiet] [--api-version v1 | v2]

Command options
SERVICE_ID (required)
Name or UUID of service ID.
-f, --force (optional)
Display service policies without confirmation.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
List policies of service test :
ibmcloud iam service-policies test

Running secure workloads 263

List policies of service ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 :
ibmcloud iam service-policies ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976

ibmcloud iam service-policy
Display details of an access policy for a specified service ID:
ibmcloud iam service-policy SERVICE_ID POLICY_ID [--output FORMAT] [-f, --force] [-q, --quiet] [--api-version v1 | v2]

Command options
SERVICE_ID (required)
Name or UUID of service ID.
POLICY_ID (required)
ID of the service policy.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-f, --force (optional)
Display service policy without confirmation.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
Show policy 140798e2-8ea7db3 of service test :
ibmcloud iam service-policies test 140798e2-8ea7db3

Show policy 140798e2-8ea7db3 of service ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 :
ibmcloud iam service-policies ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 140798e2-8ea7db3

ibmcloud iam service-policy-create
Create an access policy and assign it to a service ID:
ibmcloud iam service-policy-create SERVICE_ID {--file JSON_FILE | -r, --roles ROLE_NAME1,ROLE_NAME2... [--service-name
SERVICE_NAME] [--service-instance SERVICE_INSTANCE_GUID] [--region REGION] [--resource-type RESOURCE_TYPE] [--resource RESOURCE]
[--resource-group-name RESOURCE_GROUP_NAME] [--resource-group-id RESOURCE_GROUP_ID] [--account-management] [--attributes
name=value,name=value...]} [--output FORMAT] [-q, --quiet] [-f, --force] [--api-version v1 | v2]

Command options
SERVICE_ID (required)
Name or UUID of service ID.
--file
JSON file of policy definition. This option is exclusive with the -r, --roles , --service-name , --service-instance , --region , --resourcetype , --resource , --resource-group-name and --resource-group-id options. You can use advanced operators in a JSON policy document to

grant access to resources that satisfy specific naming conventions. For more information about using advanced operators to create wildcard policies,
see Assigning access by using wildcard policies .
Running secure workloads 264

-r, --roles
Role names of the policy definition. For supported roles of a specific service, run

ibmcloud iam roles --service SERVICE_NAME option. This

option is exclusive with the --file option.
--service-name
Service name of the policy definition. This option is exclusive with the --file option.
--service-instance SERVICE_INSTANCE_GUID
GUID of service instance of the policy definition. This option is exclusive with the

--file option.

-region
Region of the policy definition. This option is exclusive with the --file option.
--resource-type
Resource type of the policy definition. This option is exclusive with the --file option.
--resource
Resource of the policy definition. This option is exclusive with the --file option.
--resource-group-name
Name of the resource group. * means all resource groups. This option is exclusive with the --file and --resource-group-id options.
--resource-group-id
ID of the resource group. * means all resource groups. This option is exclusive with the --file and --resource-group-name options.
--account-management (optional)
Give access to all account management services.
--account-management (optional)
Give access to all account management services.
--attributes name=value,name=value...
Set resource attributes in the form of 'name=value,name=value....'
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
-f, --force
Create a service policy without confirmation.
--api-version
Version of the access policy API.

Examples
Create service policy from JSON file for service test :
ibmcloud iam service-policy-create test --file @policy.json

Create service policy from JSON file for service ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 :
ibmcloud iam service-policy-create ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 --file @policy.json

Grant service test the Administrator role for all account management services:
ibmcloud iam service-policy-create test --roles Administrator --account-management

Grant service test the Viewer role for all resources in account:
ibmcloud iam service-policy-create test --roles Viewer
Running secure workloads 265

Grant service test the Viewer role and a custom role Responder for all sample service instances in the account:
ibmcloud iam service-policy-create test --roles Viewer,Responder --service-name sample

Give service test the Viewer role for service is resources with attribute instanceId equal to * :
ibmcloud iam service-policy-create sample-service --roles Viewer --service-name is --attributes "instanceId=*"

ibmcloud iam service-policy-update
Update an access policy for a service ID:
ibmcloud iam service-policy-update SERVICE_ID POLICY_ID {--file JSON_FILE | [-r, --roles ROLE_NAME1,ROLE_NAME2...] [--servicename SERVICE_NAME] [--service-instance SERVICE_INSTANCE_GUID] [--region REGION] [--resource-type RESOURCE_TYPE] [--resource
RESOURCE] [--resource-group-name RESOURCE_GROUP_NAME] [--resource-group-id RESOURCE_GROUP_ID] [--account-management] [-attributes name=value,name=value...]} [--output FORMAT] [-q, --quiet] [-f, --force] [--api-version v1 | v2]

Command options
SERVICE_ID (required)
Name or UUID of service ID.
POLICY_ID (required)
ID of the service policy.
--file
JSON file of policy definition. This option is exclusive with the -r, --roles , --service-name , --service-instance , --region , --resourcetype , --resource , resource-group-name , and resource-group-id options.

-r, --roles
Role names of the policy definition. For supported roles of a specific service, run

ibmcloud iam roles --service SERVICE_NAME . This option is

exclusive with the --file .
-service-name
Service name of the policy definition. This option is exclusive with the --file option.
-service-instance SERVICE_INSTANCE_GUID
GUID of service instance of the policy definition. This option is exclusive with the

--file option.

-region
Region of the policy definition. This option is exclusive with the --file option.
-resource-type
Resource type of the policy definition. This option is exclusive with the --file option.
-resource
Resource of the policy definition. This option is exclusive with the --file option.
--resource-group-name
Name of the resource group. * means all resource groups. This option is exclusive with the --file and --resource-group-id options.
--resource-group-id
ID of the resource group. * means all resource groups. This option is exclusive with the --file and --resource-group-name options.
--account-management (optional)
Give access to all account management services.
--attributes name=value,name=value...
Set resource attributes in the form of 'name=value,name=value....'
--output FORMAT
Specify the output format. Only 'JSON' is supported.
Running secure workloads 266

-q, --quiet
Suppress verbose output.
-f, --force
Update service policy without confirmation.
--api-version
Version of the access policy API.

Examples
Update service policy 140798e2-8ea7db3 from JSON file for service test :
ibmcloud iam service-policy-update test 140798e2-8ea7db3 --file @policy.json

Update service policy 140798e2-8ea7db3 from JSON file for service test :
ibmcloud iam service-policy-update test 140798e2-8ea7db3 --file @policy.json

Update service policy 140798e2-8ea7db3 to grant service test the Administrator role for all account management services:
ibmcloud iam service-policy-update test 140798e2-8ea7db3 --roles Administrator --account-management

Update service policy 140798e2-8ea7db3 to grant service test the Viewer role for all resources in account:
ibmcloud iam service-policy-update test 140798e2-8ea7db3 --roles Viewer

Update the service policy 140798e2-8ea7db3 to grant service test the Viewer role and a custom role Responder for all sample service instances in
the account:
ibmcloud iam service-policy-update test 140798e2-8ea7db3 --roles Viewer,Responder --service-name sample

Update service policy 140798e2-8ea7db3 to grant service test the Viewer role for service is resources with attribute instanceId equal to * :
ibmcloud iam service-policy-update test 140798e2-8ea7db3 --roles Viewer --service-name is --attributes "instanceId=*"

ibmcloud iam service-policy-delete
Delete an access policy for a service ID:
ibmcloud iam service-policy-delete SERVICE_ID POLICY_ID [-f, --force] [-q, --quiet] [--api-version v1 | v2]

Command options
SERVICE_ID (required)
Name or UUID of service ID.
POLICY_ID (required)
ID of the service policy.
-f, --force
Delete without confirmation.
-q, --quiet
Suppress verbose output.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
--api-version

Running secure workloads 267

Version of the access policy API.

Examples
Delete policy 140798e2-8ea7db3 of service test :
ibmcloud iam service-policy-delete test 140798e2-8ea7db3

Delete policy 140798e2-8ea7db3 of service ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 :
ibmcloud iam service-policy-delete ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 140798e2-8ea7db3

ibmcloud iam logins
Retrieve and display recent login history:
ibmcloud iam logins

ibmcloud iam oauth-tokens
Retrieve and display the OAuth tokens for the current session:
ibmcloud iam oauth-tokens

ibmcloud iam roles
List platform, service-defined, and custom roles:
ibmcloud iam roles [--service SERVICE_NAME [--resource-type RESOURCE_TYPE] [--source-service SOURCE_SERVICE_NAME]] [--roles
ROLE_NAME]

Command options
--resource-type
Resource type of the service. '--service' must be set along with this option.
--roles ROLE_NAME1,ROLE_NAME2...
Show details of specific roles
--service SERVICE_NAME
Name of the service. Only list platform-defined roles if not specified.
--source-service
Name of the service. Only list platform-defined roles if not specified. This option does not support private endpoints.

Examples
List platform default access roles and custom roles:
ibmcloud iam roles

List details of platform default access policy roles Administrator , Operator :
ibmcloud iam roles --roles Administrator,Operator

List details of access policy role Writer of cloud-object-storage service in JSON format:
ibmcloud iam roles --service cloud-object-storage --roles Writer --output JSON

Running secure workloads 268

List access policy roles for all account management service in JSON:
ibmcloud iam roles --service allacctmgmtroles --output JSON

List details of resource group access policy role Administrator :
ibmcloud iam roles --service resource-controller --roles Administrator

List details of access policy roles of resource type image of service is :
ibmcloud iam roles --service is --resource-type image

List authorization roles for source service cloud-object-storage and target service kms :
ibmcloud iam roles --source-service cloud-object-storage --service kms

ibmcloud iam role-create
Create a role:
ibmcloud iam role-create ROLE_NAME --display-name DISPLAY_NAME --service-name SERVICE_NAME [-a, --actions ROLE_ACTION1
[ROLE_ACTION2...]] [-d, --description DESCRIPTION] [--output FORMAT] [-q --quiet]

Command options
--display-name DISPLAY_NAME
The display name of the role that is shown in the console.
--service-name SERVICE_NAME
The name of the service.
-a, --actions ROLE_ACTION1,ROLE_ACTION2...
The actions of the role. For more information, see IAM roles and actions .
-d, --description DESCRIPTION
The description of the role.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
Create a role to perform any Cloudant database action:
ibmcloud iam role-create CloudDBAdmin --display-name "Cloudant DB Administrator" --service-name cloudantnosqldb --actions
cloudantnosqldb.db.any

Create a role for read-only access to Certificate Manager by using multiple role actions:
ibmcloud iam role-create ReadonlyCertManager --display-name "Readonly Certificate Manager" --service-name cloudcerts --actions
cloudcerts.certificate-metadata.read,cloudcerts.notifications-channel.list

Create a role to view toolchain dashboards and return the role in JSON format:
ibmcloud iam role-create PreviewCDCI --display-name "Preview Toolchains" --service-name toolchain --actions
toolchain.dashboard.view --output JSON

Running secure workloads 269

Create a role that has a description:
ibmcloud iam role-create ServiceIDCreator --display-name "Service ID Creator" --service-name iam-identity --actions iamidentity.serviceid.create --description "Can only create service keys"

ibmcloud iam access-policies
List all access policies under the current account:
ibmcloud iam access-policies [-t, --type user | service_id | access_group | trusted_profile] [--sort-by id | type | href |
created_at | created_by_id | last_modified_at | last_modified_by_id | state ] [--output FORMAT] [-q, --quiet ] [--api-version v1
| v2]

Command options
-t, --type ACCESS_POLICY_TYPE
List all access policies under the current account filtered by policy type. Valid options are:

user | service_id | access_group |

trusted_profile

--sort-by ATTRIBUTE
Sort the policies based on attributes. Valid options are: id | type | href | created_at | created_by_id | last_modified_at | last_modified_by_id | state.
Prepend a minus (for example, -id , -type ) for reverse sorting.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
List all access policies under the current account:
ibmcloud iam access-policies

List all user access policies under the current account:
ibmcloud iam access-policies --type user

List all service ID access policies under the current account:
ibmcloud iam access-policies --type service_id

List all access group access policies under the current account:
ibmcloud iam access-policies --type access_group

List all trusted profile access policies under the current account:
ibmcloud iam access-policies --type trusted_profile

List all trusted profile access policies that are sorted by created_at in ascending order under the current account:
ibmcloud iam access-policies --type trusted_profile --sort-by created_at

List all trusted user policies that are sorted by last_modified_at in descending order under the current account:

Running secure workloads 270

ibmcloud iam access-policies --type user --sort-by -last_modified_at

ibmcloud iam access-policy-template
Show details of an access policy template under the current account:
ibmcloud iam access-policy-template (TEMPLATE_ID | TEMPLATE_NAME) [--output FORMAT] [-q, --quiet]

Command options
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
Show access policy template AccessPolicyUserTemplate
ibmcloud iam access-policy-template AccessPolicyUserTemplate

ibmcloud iam access-policy-templates
List all access policy templates under current account:
ibmcloud iam access-policy-templates [--output FORMAT] [-q, quiet]

Command options
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
List all access policy template under current account
ibmcloud iam access-policy-templates

ibmcloud iam access-policy-template-create
Create an access policy template:
ibmcloud iam access-policy-template-create --file JSON_FILE

Command options
--file JSON_FILE
JSON file of access policy template definition
-q, --quiet
Suppress verbose output.

Running secure workloads 271

Examples
Create an access policy template
imcloud iam access-policy-template-create --file /path/to/access_policy_template.json

ibmcloud iam access-policy-template-version
Get a version of an access policy template:
ibmcloud iam access-policy-template-version (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION [-q, --quiet] [--output JSON]

Command options
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
Show version 1 of access policy template AccessPolicyUserTemplate
ibmcloud iam access-policy-template-version AccessPolicyUserTemplate 1

ibmcloud iam access-policy-template-version-create
Create a new version of an access policy template:
ibmcloud iam access-policy-template-version-create (TEMPLATE_ID | TEMPLATE_NAME) [--file JSON_FILE] [-q, --quiet]

Command options
--file JSON_FILE
JSON file of access policy template definition
-q, --quiet
Suppress verbose output.

Examples
Create a new version for access policy template AccessPolicyUserTemplate
$ ibmcloud iam access-policy-template-version-create AccessPolicyUserTemplate --file /path/to/access_policy_template.json

ibmcloud iam access-policy-template-version-update
Update an existing version of an access policy template:
ibmcloud iam access-policy-template-update (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION --file JSON_FILE [-q, --quiet] [-output FORMAT]

Command options

Running secure workloads 272

--file JSON_FILE
JSON file of access policy template definition
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
Update version 1 of access policy template AccessPolicyUserTemplate
ibmcloud iam access-policy-template-version-create AccessPolicyUserTemplate 1 --file /path/to/access_policy_template.json

ibmcloud iam access-policy-template-version-delete
Delete a version of an access policy template:
ibmcloud iam access-policy-template-version-delete (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION [-q, --quiet] [-f, --force]

Command options
-f, --force
Force deletion without confirmation.
-q, --quiet
Suppress verbose output.

Examples
Delete version 2 of access policy template AccessPolicyUserTemplate
ibmcloud iam access-policy-template-version-delete AccessPolicyUserTemplate 2

ibmcloud iam access-policy-template-version-commit
Commit a version of an access policy template:
ibmcloud iam access-policy-template-version-commit (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION [-q, --quiet]

Command options
-q, --quiet
Suppress verbose output.

Examples
Commit version 1 of access policy template AccessPolicyUserTemplate
$ ibmcloud iam access-policy-template-version-commit AccessPolicyUserTemplate 1

ibmcloud iam access-policy-assignment
Show details of an access policy assignment:
Running secure workloads 273

ibmcloud iam access-policy-assignment ASSIGNMENT_ID [-q, --quiet] [--output FORMAT]

Command options
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
Show access policy assignment AccessPolicyAssignment-adee40a7f8324d6fbcd4c4a67b326eb5
ibmcloud iam access-policy-assignment AccessPolicyAssignment-adee40a7f8324d6fbcd4c4a67b326eb5

ibmcloud iam access-policy-assignments
List all access policy assignments on the current account:
ibmcloud iam access-policy-templates [--output FORMAT] [-q, --quiet]

Command options
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
List all access policy template assignments under current account
ibmcloud iam access-policy-assignments

ibmcloud iam account-policies
List all account policies under current account:
ibmcloud iam account-policies [-t, --type access | auth] [--output FORMAT] [-q, --quiet] [--api-version v1 | v2]

Command options
-t, --type access | auth
List all policies under current account filtered by policy type. Valid options are: access | auth
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Running secure workloads 274

Examples
List all account policies under current account:
ibmcloud iam account-policies

List all authorization policies under current account. Provides the same list as ibmcloud iam authorization-policies :
ibmcloud iam account-policies -t auth

List all access policies under current account. Provides the same list as ibmcloud iam access-policies :
ibmcloud iam account-policies -t access

ibmcloud iam authorization-policy-create
Create an authorization policy to allow a service instance access to another service instance:
ibmcloud iam authorization-policy-create { SOURCE_SERVICE_NAME TARGET_SERVICE_NAME ROLE_NAME1,ROLE_NAME2... [--source-serviceinstance-name SOURCE_SERVICE_INSTANCE_NAME | --source-service-instance-id SOURCE_SERVICE_INSTANCE_ID] [--source-service-account
ACCOUNT_GUID] [--source-resource-group-id RESOURCE_GROUP_ID] [--source-resource-type RESOURCE_TYPE] [--source-resource RESOURCE]
[--target-service-instance-name TARGET_SERVICE_INSTANCE_NAME | --target-service-instance-id TARGET_SERVICE_INSTANCE_ID] [-target-resource-group-id RESOURCE_GROUP_ID] [--target-resource-type RESOURCE_TYPE] [--target-resource RESOURCE] | --file
JSON_FILE } [--output FORMAT] [-q, --quiet]

Command options
SOURCE_SERVICE_NAME
The source service that can be authorized to access. To find the service's name, run the

ibmcloud catalog service-marketplace command.

TARGET_SERVICE_NAME
The target service that the source service can be authorized to access. To find the service's name, run the

ibmcloud catalog service-

marketplace command.

ROLE_NAME1,ROLE_NAME2...
The roles that provide access for the source service.
--source-service-instance-name SOURCE_SERVICE_INSTANCE_NAME
Source service instance name, mutually exclusive with --source-service-instance-id and --source-service-account . If source service
instance is not specified, all instances of the source service are authorized to access.
--source-service-instance-id SOURCE_SERVICE_INSTANCE_ID
Source service instance ID, mutually exclusive with --source-service-instance-name . If not specified, all instances of the source service are
authorized to access.
--source-service-account ACCOUNT_GUID
Account GUID of source service, mutually exclusive with --source-service-instance-name . Use this option if source service is from another
account.
--source-resource-group-id RESOURCE_GROUP_ID
Source resource group ID, mutually exclusive with '--source-service-instance-id'.
--source-resource-type
Resource type of source service.
--source-resource
Resource of source service. --target-service-instance-name TARGET_SERVICE_INSTANCE_NAME
Target service instance name, mutually exclusive with --target-service-instance-id . If not specified, all instances of the target service are
authorized to access.
--target-service-instance-id TARGET_SERVICE_INSTANCE_ID

Running secure workloads 275

Target service instance ID, mutually exclusive with --target-service-instance-name . If not specified, all instances of the target service are
authorized to access.
--target-resource-group-id RESOURCE_GROUP_ID
Target resource group ID, mutually exclusive with '--target-service-instance-id'.
--target-resource-type
Resource type of target service.
--target-resource
Resource of target service.
--file FILE
JSON file of policy definition.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Note: Currently, some combination of --source-service and --service might fail under private endpoints. Use --file as a workaround, or
you can create the policy from public endpoints or the UI console.

ibmcloud iam authorization-policy-delete
Delete an authorization policy:
ibmcloud iam authorization-policy-delete AUTHORIZATION_POLICY_ID [-f, --force]

Command options
AUTHORIZATION_POLICY_ID
ID of authorization policy to be deleted.
-f, --force
Delete without confirmation.

ibmcloud iam authorization-policy
Show details of an authorization policy:
ibmcloud iam authorization-policy AUTHORIZATION_POLICY_ID [--output FORMAT] [-q, --quiet] [--api-version v1 | v2]

Command options
AUTHORIZATION_POLICY_ID
ID of authorization policy to show.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.
Running secure workloads 276

ibmcloud iam authorization-policies
List authorization policies under the current account:
ibmcloud iam authorization-policies

ibmcloud iam access-groups
List access groups under current account:
ibmcloud iam access-groups [-u USER_NAME | -s SERVICE_ID_NAME | -p (PROFILE_NAME | PROFILE_ID)] [--output FORMAT] [-q, --quiet]

Command options
-u
List access groups the user belongs to. This option is exclusive to '-s' and '-p'.
-s
List access groups the service ID belongs to. This option is exclusive to '-u' and '-p'.
-p
List access groups the trusted profile belongs to. This option is exclusive to '-s' and '-u'.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
List all access groups:
ibmcloud iam access-groups

List all access groups the trusted profile test_profile belongs to:
ibmcloud iam access-groups -p test_profile

ibmcloud iam access-group
Show details of an access group:
ibmcloud iam access-group GROUP_NAME [--id]

Command options
-id
Show the ID only.

Examples
Show details of access group example_group :
ibmcloud iam access-group example_group
Running secure workloads 277

ibmcloud iam access-group-create
Create an access group:
ibmcloud iam access-group-create GROUP_NAME [-d, --description DESCRIPTION]

Command options
-d, --description
Description of access group.

Examples
Create an access group example_group :
ibmcloud iam access-group-create example_group -d "example access group"

ibmcloud iam access-group-update
Update an access group:
ibmcloud iam access-group-update GROUP_NAME [-n, --name NEW_NAME] [-d, --description NEW_DESCRIPTION] [-f, --force]

Command options
-n, --name
New access group name.
-d, --description
New description.
-f, --force
Force update without confirmation.

Examples
Rename access group example_group to hello_world_group :
ibmcloud iam access-group-update example_group --name "hello_world_group"

ibmcloud iam access-group-delete
Delete an access group:
ibmcloud iam access-group-delete GROUP_NAME [-f, --force] [-r, --recursive] [-a, --all]

Command options
-f, --force
Force deletion without confirmation.
-r, --recursive
Delete an access group and its members.
-a, --all
Force to delete access groups with the same name.
Running secure workloads 278

Examples
Delete access group example_group :
ibmcloud iam access-group-delete example_group --force

ibmcloud iam access-group-users
List users in an access group:
ibmcloud iam access-group-users GROUP_NAME

Examples
List all users in access group example_group :
ibmcloud iam access-group-users example_group

ibmcloud iam access-group-user-add
Add users to an access group:
ibmcloud iam access-group-user-add GROUP_NAME (USER_NAME [USER_NAME2...] | [--iam-ids IAM_ID1,IAM_ID2,...])

Examples
Add user name@example.com to access group example_group :
$ ibmcloud iam access-group-user-add example_group name@example.com

Add user by IAM ID IAM000000 to access group example_group :
$ ibmcloud iam access-group-user-add example_group --iam-ids IAM000000

ibmcloud iam access-group-user-remove
Remove a user from an access group:
ibmcloud iam access-group-user-remove GROUP_NAME USER_NAME

Examples
Remove user name@example.com from access group example_group :
ibmcloud iam access-group-user-remove example_group name@example.com

ibmcloud iam access-group-user-purge
Remove user from all access groups:
ibmcloud iam access-group-user-purge USER_NAME [-f, --force]

Command options
-f, --force
Delete without confirmation.

Running secure workloads 279

Examples
Remove user name@example.com from all access groups:
ibmcloud iam access-group-user-purge name@example.com -f

ibmcloud iam access-group-service-ids
List service IDs in an access group:
ibmcloud iam access-group-service-ids GROUP_NAME

Examples
List all service IDs in access group example_group :
ibmcloud iam access-group-service-ids example_group

ibmcloud iam access-group-service-id-add
Add a service ID to an access group:
ibmcloud iam access-group-service-id-add GROUP_NAME SERVICE_ID_NAME [SERVICE_ID_NAME2...]

Examples
Add service ID example-service to access group example_group :
ibmcloud iam access-group-service-id-add example_group example-service

ibmcloud iam access-group-service-id-remove
Remove a service ID from an access group:
ibmcloud iam access-group-service-id-remove GROUP_NAME SERVICE_ID_NAME

Examples
Remove service ID example-service from access group example_group :
ibmcloud iam access-group-service-id-remove example_group example-service

ibmcloud iam access-group-service-id-purge
Remove service ID from all access groups:
ibmcloud iam access-group-service-id-purge SERVICE_ID_NAME [-f, --force]

Command options
-f, --force
Delete without confirmation.

Examples
Remove service ID example-service from all access groups:
ibmcloud iam access-group-service-id-purge example --force

Running secure workloads 280

ibmcloud iam access-group-trusted-profiles
List trusted profiles of an access group:
ibmcloud iam access-group-trusted-profiles GROUP_NAME [--output FORMAT] [-q, --quiet]

Command options
GROUP_NAME (required)
Name of the access group.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
List all trusted profiles in access group example_group :
ibmcloud iam access-group-trusted-profiles example_group

ibmcloud iam access-group-trusted-profile-add
Add trusted profiles to an access group:
ibmcloud iam access-group-trusted-profile-add GROUP_NAME (PROFILE_NAME | PROFILE_ID) [PROFILE_NAME2 | PROFILE_ID2...] [--output
FORMAT] [-q, --quiet]

Command options
GROUP_NAME (required)
The name of the access group.
PROFILE_NAME | PROFILE_ID (required)
The names or IDs of the trusted profiles to add to the access group.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
Add a trusted profile my-profile to access group example_group :
ibmcloud iam access-group-trusted-profile-add example_group my-profile

ibmcloud iam access-group-trusted-profile-remove
Remove a trusted profile from an access group:
ibmcloud iam access-group-trusted-profile-remove GROUP_NAME (PROFILE_NAME | PROFILE_ID) [-f, --force] [-q, --quiet]

Command options
Running secure workloads 281

GROUP_NAME (required)
Name of the access group.
PROFILE_NAME | PROFILE_ID (required)
Name or ID of the trusted profile to remove from the access group.
-f, --force
Remove without confirmation.
-q, --quiet
Suppress verbose output.

Examples
Remove trusted profile my-profile from access group example_group :
ibmcloud iam access-group-trusted-profile-remove example_group my-profile

ibmcloud iam access-group-trusted-profile-purge
Remove a trusted profile from all access groups:
ibmcloud iam access-group-trusted-profile-purge (PROFILE_NAME | PROFILE_ID) [-f, --force] [-q, --quiet]

Command options
PROFILE_NAME | PROFILE_ID (required)
Name or ID of the trusted profile to remove from all access groups.
-f, --force
Purge without confirmation.
-q, --quiet
Suppress verbose output.

Examples
Remove trusted profile my-profile from all access groups:
ibmcloud iam access-group-trusted-profile-purge my-profile

ibmcloud iam access-group-policies
List policies of an access group:
ibmcloud iam access-group-policies GROUP_NAME [--output FORMAT] [-q, --quiet] [--api-version v1 |v2]

Command options
GROUP_NAME
Name of the access group.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet

Running secure workloads 282

Suppress verbose output.
--api-version
Version of the access policy API.

Examples
List all policies of access group example_group :
ibmcloud iam access-group-policies example_group

ibmcloud iam access-group-policy
Show details of an access group policy:
ibmcloud iam access-group-policy GROUP_NAME POLICY_ID [--output FORMAT] [-q, --quiet] [--api-version v1 | v2]

Command options
GROUP_NAME
Name of the access group.
POLICY_ID
The ID of the policy to retrieve.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
Show details of the policy 51b9717e-76b0-4f6a-bda7-b8132431f926 of access group example_group :
ibmcloud iam access-group-policy example_group 51b9717e-76b0-4f6a-bda7-b8132431f926

ibmcloud iam access-group-policy-create
Create an access group policy:
ibmcloud iam access-group-policy-create GROUP_NAME {--file @JSON_FILE | --roles ROLE_NAME1,ROLE_NAME2... [--service-name
SERVICE_NAME] [--service-instance SERVICE_INSTANCE_GUID] [--region REGION] [--resource-type RESOURCE_TYPE] [--resource RESOURCE]
[--resource-group-name RESOURCE_GROUP_NAME] [--resource-group-id RESOURCE_GROUP_ID] [--tags name1:value1,name2:value2...] [-account-management] [--attributes name=value,name=value...]}} [--output FORMAT] [-q, --quiet] [--api-version v1 | v2]

Command options
--file
JSON file of policy definition. You can use advanced operators in a JSON policy document to grant access to resources that satisfy specific naming
conventions. For more information about using advanced operators to create wildcard policies, see Assigning access by using wildcard policies .
-roles
Role names of the policy definition. For supported roles of a specific service, run

ibmcloud iam roles --service SERVICE_NAME . This option is

exclusive with the --file option.
Running secure workloads 283

-service-name
Service name of the policy definition. This option is exclusive with the --file option.
-service-instance SERVICE_INSTANCE_GUID
GUID of service instance of the policy definition. This option is exclusive with the

--file option.

-region
Region of the policy definition. This option is exclusive with the --file option.
-resource-type
Resource type of the policy definition. This option is exclusive with the --file option.
-resource
Resource of the policy definition. This option is exclusive with the --file option.
-resource-group-name
Name of the resource group. * means all resource groups. This option is exclusive with the --file and --resource-group-id option.
-resource-group-id
ID of the resource group. * means all resource groups. This option is exclusive with the --file and --resource-group-name option.
-tags
Access tags of the resource. Use tags to organize, track usage costs, or manage access to your resources. For more information on tags, see

Working

with tags.
--account-management
Give access to all account management services.
--attributes name=value,name=value...
Set resource attributes in the form of 'name=value,name=value....'
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
Create an access group policy from a JSON file:
ibmcloud iam access-group-policy-create example_group -f @policy.json

Give example_group Administrator role for all sample-service resources:
ibmcloud iam access-group-policy-create example_group --roles Administrator --service-name sample-service

Give example_group Editor role and a custom role Responder for all instances of sample-service in us-south region:
ibmcloud iam access-group-policy-create example_group --roles Editor,Responder --service-name sample-service --region us-south

Give example_group Editor role for resource key123 of sample-service instance with GUID d161aeea-fd02-40f8-a487-df1998bd69a9 in ussouth region:
ibmcloud iam access-group-policy-create example_group --roles Editor --service-name sample-service --service-instance d161aeeafd02-40f8-a487-df1998bd69a9 --region us-south --resource-type key --resource key123

Give example_group Operator role for resource group with ID dda27e49d2a1efca58083a01dfde18f6 :

Running secure workloads 284

ibmcloud iam access-group-policy-create example_group --roles Operator --resource-type resource-group --resource
dda27e49d2a1efca58083a01dfde18f6

Give example_group Viewer role for the members of the resource group sample-resource-group :
ibmcloud iam access-group-policy-create example_group --roles Viewer --resource-group-name sample-resource-group

Give example_group Viewer role for the members of the resource group with ID

dda27e49d2a1efca58083a01dfde18f6 :

ibmcloud iam access-group-policy-create example_group --roles Viewer --resource-group-id dda27e49d2a1efca58083a01dfde18f6

Give example_group Administrator role for all account management services:
ibmcloud iam access-group-policy-create example_group --roles Administrator --account-management

Give example_group Viewer role for all resources in account:
ibmcloud iam access-group-policy-create example_group --roles Viewer

Give example_group Viewer role for service is resources with attribute instanceId equal to * :
ibmcloud iam access-group-policy-create example_group --roles Viewer --service-name is --attributes "instanceId=*"

Create access tags for the resource:
ibmcloud iam access-group-policy-create --tags env:dev,env:test

ibmcloud iam access-group-policy-update
Update an access group policy:
ibmcloud iam access-group-policy-update GROUP_NAME POLICY_ID {--file JSON_FILE | [--roles ROLE_NAME1,ROLE_NAME2...] [--servicename SERVICE_NAME] [--service-instance SERVICE_INSTANCE_GUID] [--region REGION] [--resource-type RESOURCE_TYPE] [--resource
RESOURCE] [--resource-group-name RESOURCE_GROUP_NAME] [--resource-group-id RESOURCE_GROUP_ID] [--account-management] [-attributes name=value,name=value...]} [--output FORMAT] [-q, --quiet] [--api-version v1| v2]

Command options
--file
JSON file of policy definitions.
--roles
Role names of the policy definition. For supported roles of a specific service, run

ibmcloud iam roles --service SERVICE_NAME . This option is

exclusive with the --file option.
-service-name
Service name of the policy definition. This option is exclusive with the --file option.
-service-instance SERVICE_INSTANCE_GUID
GUID of service instance of the policy definition. This option is exclusive with the

--file option.

-region
Region of the policy definition. This option is exclusive with the --file option.
-resource-type
Resource type of the policy definition. This option is exclusive with the --file option.
-resource
Resource of the policy definition. This option is exclusive with the --file option.
-resource-group-name
Name of the resource group. * means all resource groups. This option is exclusive with the --file and --resource-group-id option.
Running secure workloads 285

-resource-group-id
ID of the resource group. * means all resource groups. This option is exclusive with the --file and --resource-group-name option.
--account-management (optional)
Give access to all account management services.
--attributes name=value,name=value...
Set resource attributes in the form of 'name=value,name=value....'
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
Update the access group policy b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 with the one in policy JSON file:
ibmcloud iam access-group-policy-update example_group b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 -f @policy.json

Update access group policy b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 to give example_group Administrator role for all sample-service resources:
ibmcloud iam access-group-policy-update example_group b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 --roles Administrator --service-name
sample-service

Update access group policy b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 to give example_group Editor role and a custom role Responder for all
instances of sample-service in us-south region:
ibmcloud iam access-group-policy-update example_group --roles Editor,Responder --service-name sample-service --region us-south

Update access group policy b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 to give example_group Editor role for resource key123 of sample-service
instance with GUID d161aeea-fd02-40f8-a487-df1998bd69a9 in us-south region:
ibmcloud iam access-group-policy-update example_group --roles Editor --service-name sample-service --service-instance d161aeeafd02-40f8-a487-df1998bd69a9 --region us-south

Update access group policy b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 to give example_group Operator role for resource group with ID
dda27e49d2a1efca58083a01dfde18f6 :
ibmcloud iam access-group-policy-update example_group b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 --roles Operator --resource-type
resource-group --resource dda27e49d2a1efca58083a01dfde18f6

Update access group policy b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 to give example_group Viewer role for members of the resource group
sample-resource-group :
$ ibmcloud iam access-group-policy-update example_group b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 --roles Viewer --resource-group-name
sample-resource-group
```bash
{: codeblock}
Update access group policy `b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4` to give `example_group` `Viewer` role for members of resource
group with ID `dda27e49d2a1efca58083a01dfde18f6`:
```bash {: codeblock}
ibmcloud iam access-group-policy-update example_group b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 --roles Viewer --resource-group-id
dda27e49d2a1efca58083a01dfde18f6

Update access group policy b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 to give example_group Administrator role for all account management
services:

Running secure workloads 286

ibmcloud iam access-group-policy-update example_group b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 --roles Administrator --accountmanagement

Update access group policy b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 to give example_group Viewer role for all resources in the account:
ibmcloud iam access-group-policy-update example_group b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 --roles Viewer

Update access group policy b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 to give example_group Viewer role for service is resources with attribute
instanceId equal to * :
ibmcloud iam access-group-policy-update example_group b8638ceb-5c4d-4d58-ae06-7ad95a10c4d4 --roles Viewer --service-name is -attributes "instanceId=*"

ibmcloud iam access-group-policy-delete
Delete an access group policy:
ibmcloud iam access-group-policy-delete GROUP_NAME POLICY_ID [-f, --force] [-q, --quiet] [--api-version v1 |v2]

Command options
--api-version
Version of the access policy API.
-f, --force
Force deletion without confirmation.
-q, --quiet
Suppress verbose output.

Examples
Delete policy 51b9717e-76b0-4f6a-bda7-b8132431f926 of access group example_group :
ibmcloud iam access-group-policy-delete example_group 51b9717e-76b0-4f6a-bda7-b8132431f926 -f

ibmcloud iam access-group-template-create
Create an access group template
ibmcloud iam access-group-template-create (TEMPLATE_NAME --access-group-name ACCESS_GROUP_NAME [-d, --description DESCRIPTION] |
--file JSON_FILE) [--output FORMAT]

Command options
--access-group-name NAME
Access group name to create for the template
-d, --description DESCRIPTION
Description of the template
--file FILE
Description of the template
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
Running secure workloads 287

Examples
Create an access group template with specified name and access group name
$ ibmcloud iam access-group-template-create example-template-name --access-group-name example-access-group -d example-description

Create an access group template by using a JSON file
ibmcloud iam access-group-template-create --file JSON_FILE

ibmcloud iam access-group-template
Show details of an access group template
ibmcloud iam access-group-template (TEMPLATE_ID | TEMPLATE_NAME) [--output FORMAT] [-q, --quiet]

Command options
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
Show details of an access group template in JSON format
ibmcloud iam access-group-template --output JSON

ibmcloud iam access-group-template-version
Show details of a specified version of an access group template
ibmcloud iam access-group-template-version (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION [-q, --quiet] [--output FORMAT]

Command options
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
Show details of a specified version of an access group template in JSON format
ibmcloud iam access-group-template-version example-template-name 1 --output JSON

ibmcloud iam access-group-template-version-commit
Commit an access group template version
ibmcloud iam access-group-template-version-commit TEMPLATE_ID TEMPLATE_VERSION
Running secure workloads 288

Command options
-q, --quiet
Suppress verbose output.

Examples
Commit a specified version of an access group template
ibmcloud iam access-group-template-version-commit example-template-id 1

ibmcloud iam access-group-template-version-create
Create an access group template version
ibmcloud iam access-group-template-version-create TEMPLATE_ID --file JSON_FILE

Command options
--file FILE
Description of the template
-q, --quiet
Suppress verbose output.

Examples
Create a new version of an access group template
ibmcloud iam access-group-template-version-create example-template-id --file JSON_FILE

ibmcloud iam access-group-template-version-delete
Delete an access group template version
ibmcloud iam access-group-template-version-delete TEMPLATE_ID TEMPLATE_VERSION

Command options
-q, --quiet
Suppress verbose output.

Examples
Delete a specified version of an access group template
ibmcloud iam access-group-template-version-delete example-template-id 1

ibmcloud iam access-group-template-version-update
Update an existing version of access group template version
ibmcloud iam access-group-template-version-update (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION --file JSON_FILE [-q, --quiet]

Running secure workloads 289

Command options
--file FILE
Description of the template
-q, --quiet
Suppress verbose output.

Examples
Update a specified version of an access group template with a JSON file
ibmcloud iam access-group-template-version-update example-template-name 1 --file JSON_FILE

ibmcloud iam access-group-template-versions
List the versions of an access group template
ibmcloud iam access-group-template-versions (TEMPLATE_ID | TEMPLATE_NAME) [-q, --quiet] [--output FORMAT]

Command options
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
List all versions of an access group template
ibmcloud iam access-group-template-versions example-template-name

ibmcloud iam access-group-templates
List all access group templates under current account
ibmcloud iam access-group-templates [-q, --quiet] [--output FORMAT]

Command options
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
List all access group templates under current account in JSON format
ibmcloud iam access-group-template-versions example-template-name --output JSON

Running secure workloads 290

ibmcloud iam access-group-assignment
Show details of an access group assignment
ibmcloud iam access-group-assignment [--output FORMAT]

Command options
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
Show details of an access group assignment in JSON format
ibmcloud iam access-group-assignments --output JSON

ibmcloud iam access-group-assignment-create
Create an access group assignment
ibmcloud iam access-group-assignment-create TEMPLATE_ID TEMPLATE_VERSION --target-type TYPE --target TARGET

Command options
--target value
ID of the entity targeted --target-type value
Type of entity targeted -q, --quiet
Suppress verbose output

Examples
Show details of an access group assignment in JSON format
ibmcloud iam access-group-assignment-create example-template-id 1 --target-type Account --target example-account-id

ibmcloud iam access-group-assignment-delete
Delete an access group assignment
ibmcloud iam access-group-assignment-delete ASSIGNMENT_ID

Command options
-q, --quiet
Suppress verbose output

Examples
Delete a specified access group assignment

Running secure workloads 291

ibmcloud iam access-group-assignment-delete example-assignment-id

ibmcloud iam access-group-assignment-update
Update an access group assignment
ibmcloud iam access-group-assignment-update ASSIGNMENT_ID

Command options
-q, --quiet
Suppress verbose output

Examples
Update a specified access group assignment
ibmcloud iam access-group-assignment-update example-assignment-id

ibmcloud iam access-group-assignments
Get all access group assignments in your current account
ibmcloud iam access-group-assignments [-q, --quiet] [--output FORMAT]

Command options
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
List all access group assignments under current account in JSON format
ibmcloud iam access-group-assignments --output JSON

ibmcloud iam trusted-profile-create
Create a trusted profile:
ibmcloud iam trusted-profile-create NAME [-d, --description DESCRIPTION] [--output FORMAT] [-q, --quiet]

Command options
NAME (required)
Name of the new profile.
-d, --description DESCRIPTION
Description of the profile.
--output FORMAT
Specify the output format. Only 'JSON' is supported.

Running secure workloads 292

-q, --quiet
Suppress verbose output.

Examples
Create a trusted profile with name sample-test and description "sample trusted profile":
ibmcloud iam trusted-profile-create sample-test -d "sample trusted profile"

ibmcloud iam trusted-profile
Get a trusted profile by name or ID:
ibmcloud iam trusted-profile NAME|ID [--id | --output FORMAT] [-q, --quiet]

Command options
NAME|ID (required)
Name or ID of the profile.
--id
Show the ID of the profile only.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
Retrieve trusted profile with name sample-test :
ibmcloud iam trusted-profile sample-test

Retrieve trusted profile with profile ID Profile-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 :
ibmcloud iam trusted-profile Profile-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976

ibmcloud iam trusted-profiles
List trusted profiles under current account
ibmcloud iam trusted-profiles [--can-assume] [--id | --output FORMAT] [-n, --name STRING] [-d, --description STRING] [-q, -quiet]

Command options
--can-assume
Show profiles that can be assumed with the current account only.
--id
Show ID of profiles only.
-d, --description STRING
Filter results to list the trusted proifles with descriptions that include the supplied string.
-n, --name STRING
Running secure workloads 293

Filter results to list the trusted profiles with names that include the supplied string.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
List ID of all trusted profiles under current account:
ibmcloud iam trusted-profiles --id

List trusted profiles that can be assumed with the current account:
ibmcloud iam trusted-profiles --can-assume

ibmcloud iam trusted-profile-assume
Assume a trusted profile:
ibmcloud iam trusted-profile-assume [NAME|ID] [--output FORMAT] [-q, --quiet]

Command options
NAME|ID
The name or ID of the profile to assume. --output FORMAT
The specified output format. Only 'JSON' is supported. -q, --quiet
Suppress verbose output.

Examples
Assume a trusted profile with name sample-test :
$ ibmcloud iam trusted-profile-assume sample-test

View the currently assumed trusted profile:
ibmcloud iam trusted-profile-assume

ibmcloud iam trusted-profile-leave
Leave a trusted profile:
ibmcloud iam trusted-profile-leave [-q, --quiet]

Command options
-q, --quiet
Suppress verbose output.

Examples
Running secure workloads 294

Leave a trusted profile previously assumed:
ibmcloud iam trusted-profile-leave

ibmcloud iam trusted-profile-update
Update a trusted profile
ibmcloud iam trusted-profile-update NAME|ID [-n, --name NEW_NAME] [-d, --description NEW_DESCRIPTION] [--output FORMAT] [-f, -force] [-q, --quiet]

Command options
NAME|ID (required)
Name or ID of the profile to update.
-n, --name NEW_NAME
New name of the trusted profile.
-d, --description NEW_DESCRIPTION
New description of the profile. Providing an empty description clears the description of the profile.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-f, --force
Force failure if multiple profiles are found.
-q, --quiet
Suppress verbose output.

Examples
Update trusted profile with name sample-test to new name of test :
ibmcloud iam trusted-profile-update sample-test -n test

Update trusted profile sample-test with new description of testing trusted profile update :
ibmcloud iam trusted-profile-update sample-test -d "testing trusted profile update"

ibmcloud iam trusted-profile-delete
Delete a trusted profile
ibmcloud iam trusted-profile-delete NAME|ID [-f, --force] [-q, --quiet]

Command options
NAME|ID (required)
Name or ID of the profile to delete.
-f, --force
Delete a trusted profile without confirmation.
-q, --quiet
Suppress verbose output.

Running secure workloads 295

Examples
Delete trusted profile with name sample-test :
ibmcloud iam trusted-profile-delete sample-test

ibmcloud iam trusted-profile-policy-create
Create an access policy and assign it to a trusted profile
ibmcloud iam trusted-profile-policy-create (NAME|ID) {--file JSON_FILE | -r, --roles ROLE_NAME1,ROLE_NAME2... [--service-name
SERVICE_NAME] [--service-instance SERVICE_INSTANCE_GUID] [--region REGION] [--resource-type RESOURCE_TYPE] [--resource RESOURCE]
[--resource-group-name RESOURCE_GROUP_NAME] [--resource-group-id RESOURCE_GROUP_ID] [--tags name1:value1,name2:value2...] [-account-management] [--attributes name=value,name=value...]} [--output FORMAT] [-q, --quiet] [-f, --force] [--api-version v1 |
v2]

Command options
NAME|ID (required)
The name or ID of the profile to assign the new policy to
--account-management
Give access to all account management services.
--api-version
Version of the access policy API.
--attributes name=value,name-value...
Set resource attributes in the form of 'name=value,name=value....'
--file JSON_FILE
JSON file of policy definition.
-f, --force
Force failure if multiple profiles are found.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
--region REGION
Region of the policy definition. This option is exclusive with '--file'. For supported regions, run 'ibmcloud regions'.
--resource RESOURCE
Resource of the policy definition. This option is exclusive with '--file'.
--resource-group-id RESOURCE_GROUP_ID
ID of the resource group. '*' means all resource groups. This option is exclusive with '--file' and '--resource-group-name'.
--resource-group-name RESOURCE_GROUP_NAME
Name of the resource group. '*' means all resource groups. This option is exclusive with '--file' and '--resource-group-id'.
--resource-type RESOURCE_TYPE
Resource type of the policy definition. This option is exclusive with '--file'.
--roles ROLE_NAME1,ROLE_NAME2...
Role names of the policy definition. For supported roles of a specific service, run 'ibmcloud iam roles --service SERVICE_NAME'. This option is
exclusive with '--file'.
-q, --quiet
Suppress verbose output.
--service-instance SERVICE_INSTANCE_GUID
GUID of service instance of the policy definition. This option is exclusive with '--file'.

Running secure workloads 296

--service-name SERVICE_NAME
Service name of the policy definition. This option is exclusive with '--file'.
--tags name1:value1,name2:value2...
Access tags of the resource.

Examples
Create a trusted profile policy for my-profile from a JSON file:
iam trusted-profile-policy-create my-profile --file policy.json

Give my-profile Viewer role for the members of resource group sample-resource-group :
iam trusted-profile-policy-create my-profile --roles Viewer --resource-group-id sample-resource-group

Give my-profile Viewer role for all resources in account:
iam trusted-profile-policy-create my-profile --roles Viewer

ibmcloud iam trusted-profile-policy
Display details of an access policy for a specified trusted profile
ibmcloud iam trusted-profile-policy (NAME|ID) POLICY_ID [--output FORMAT] [-f, --force] [-q, --quiet] [--api-version v1 | v2]

Command options
NAME|ID (required)
Name or ID of the profile.
POLICY_ID (required)
The ID of the policy to retrieve.
-f, --force
Force failure if multiple profiles are found.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
Get policy bdf62c30-35dd-4852-bcb8-2f0dd3929701 of trusted profile my-profile :
ibmcloud iam trusted-profile-policy my-profile bdf62c30-35dd-4852-bcb8-2f0dd3929701

ibmcloud iam trusted-profile-policies
List all access policies for a specified trusted profile
ibmcloud iam trusted-profile-policies (NAME|ID) [--output FORMAT] [-f, --force] [-q, --quiet] [--api-version v1 | v2]

Running secure workloads 297

Command options
NAME|ID (required)
Name or ID of the profile.
-f, --force
Force failure if multiple profiles are found.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
List all policies of trusted profile ID Profile-bdf62c30-35dd-4852-bcb8-2f0dd3929701 :
ibmcloud iam trusted-profile-policies Profile-bdf62c30-35dd-4852-bcb8-2f0dd3929701

ibmcloud iam trusted-profile-policy-update
Update an access policy for a trusted profile
ibmcloud iam trusted-profile-policy-update (NAME|ID) POLICY_ID {--file JSON_FILE | -r, --roles ROLE_NAME1,ROLE_NAME2... [-service-name SERVICE_NAME] [--service-instance SERVICE_INSTANCE_GUID] [--region REGION] [--resource-type RESOURCE_TYPE] [-resource RESOURCE] [--resource-group-name RESOURCE_GROUP_NAME] [--resource-group-id RESOURCE_GROUP_ID] [--tags
name1:value1,name2:value2...] [--account-management] [--attributes name=value,name=value...]} [--output FORMAT] [-q, --quiet] [f, --force] [--api-version v1 | v2]

Command options
NAME|ID (required)
The name or ID of the profile to assign the new policy to update.
POLICY_ID (required)
The ID of the policy to update.
--account-management
Give access to all account management services.
--attributes name=value,name-value...
Set resource attributes in the form of 'name=value,name=value....'
--file JSON_FILE
JSON file of policy definition.
-f, --force
Force failure if multiple profiles are found.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
--region REGION
Region of the policy definition. This option is exclusive with '--file'. For supported regions, run 'ibmcloud regions'.
--resource RESOURCE

Running secure workloads 298

Resource of the policy definition. This option is exclusive with '--file'.
--resource-group-id RESOURCE_GROUP_ID
ID of the resource group. '*' means all resource groups. This option is exclusive with '--file' and '--resource-group-name'.
--resource-group-name RESOURCE_GROUP_NAME
Name of the resource group. '*' means all resource groups. This option is exclusive with '--file' and '--resource-group-id'.
--resource-type RESOURCE_TYPE
Resource type of the policy definition. This option is exclusive with '--file'.
--roles ROLE_NAME1,ROLE_NAME2...
Role names of the policy definition. For supported roles of a specific service, run 'ibmcloud iam roles --service SERVICE_NAME'. This option is
exclusive with '--file'.
--service-instance SERVICE_INSTANCE_GUID
GUID of service instance of the policy definition. This option is exclusive with '--file'.
--service-name SERVICE_NAME
Service name of the policy definition. This option is exclusive with '--file'.
--tags name1:value1,name2:value2...
Access tags of the resource.
-q, --quiet
Suppress verbose output.
--api-version
Version of the access policy API.

Examples
Update policy 85f3a4d6-c2e1-417e-b2d5-7199d610c160 to give trusted profile my-profile Administrator role for all account management services:
ibmcloud iam trusted-profile-policy-update my-profile 85f3a4d6-c2e1-417e-b2d5-7199d610c160 --roles Administrator --accountmanagement

Update policy bdf62c30-35dd-4852-bcb8-2f0dd3929701 from my-profile with contents in JSON file:
ibmcloud iam trusted-profile-policy-update my-profile bdf62c30-35dd-4852-bcb8-2f0dd3929701 --file @policy.json

ibmcloud iam trusted-profile-policy-delete
Delete an access policy for a trusted profile
ibmcloud iam trusted-profile-policy-delete (NAME|ID) POLICY_ID [-f, --force] [-q, --quiet] [--api-version v1 | v2]

Command options
NAME|ID (required)
The name or ID of the profile that contains the policy to delete.
POLICY_ID (required)
The ID of the policy to delete.
-f, --force
Delete access policy without confirmation.
-q, --quiet
Suppress verbose output.
--api-version
Running secure workloads 299

Version of the access policy API.

Examples
Delete policy ID bdf62c30-35dd-4852-bcb8-2f0dd3929701 from my-profile without confirmation:
ibmcloud iam trusted-profile-policy-delete my-profile bdf62c30-35dd-4852-bcb8-2f0dd3929701 -f

ibmcloud iam trusted-profile-link-create
Create a link to a compute resource for a trusted profile
ibmcloud iam trusted-profile-link-create (NAME|ID) --name LINK_NAME --cr-type CR_TYPE --link-crn CRN [--link-namespace NAMESPACE
--link-name NAME] [--output FORMAT] [-q, --quiet] [-f, --force]

Command options
NAME|ID (required)
The name or ID of the profile to link the compute resource to.
--name
The name for the link.
--cr-type (required)
The compute resource type. VSI for Virtual Service Instance on VPC, IKS_SA for Service Accounts on Kubernetes clusters, or ROKS_SA for managed
Red Hat OpenShift.
--link-crn (required)
CRN of the VSI instance / cluster instance.
--link-namespace
Namespace of the service account for IKS_SA or ROKS_SA, required if IKS_SA or ROKS_SA.
--link-name
Name of the service account for IKS_SA or ROKS_SA, required if IKS_SA or ROKS_SA.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-f, --force
Force failure if multiple profiles are found.
-q, --quiet
Suppress verbose output.

Examples
Create a link named my_link for trusted profile my-profile for an IKS_SA compute resource with service account name default , default
namespace, and my_compute_resource_crn CRN:
ibmcloud iam trusted-profile-link-create my_profile --name my_link --cr-type IKS_SA --link-name default

--link-namespace default

--link-crn my_compute_resource_crn

Create a link that is named my_link for trusted profile ID Profile-bdf62c30-35dd-4852-bcb8-2f0dd3929701 for an IKS_SA compute resource with
service account name default in the namespace my_namespace and with a CRN of my_resource_crn :
ibmcloud iam trusted-profile-link-create Profile-bdf62c30-35dd-4852-bcb8-2f0dd3929701 --name my_link --cr-type IKS_SA --link-name
default --link-namespace my_namespace --link-crn my_resource_crn

Running secure workloads 300

Create a link named my_link for trusted profile ID Profile-bdf62c30-35dd-4852-bcb8-2f0dd3929701 for a VSI compute resource with a CRN of
my_resource_crn :
ibmcloud iam trusted-profile-link-create Profile-bdf62c30-35dd-4852-bcb8-2f0dd3929701 --name my_link --cr-type VSI --link-crn
my_resource_crn

ibmcloud iam trusted-profile-links
List all links to compute resources for a specified trusted profile
ibmcloud iam trusted-profile-links (NAME|ID) [--id | --output FORMAT] [-f, --force] [-q, --quiet]

Command options
NAME|ID (required)
The name or ID of the trusted profile to retrieve links.
--id
Show ID of links only.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-f, --force
Force failure if multiple profiles are found.
-q, --quiet
Suppress verbose output.

Examples
Display the ID of all links in the trusted profile my-profile :
ibmcloud iam trusted-profile-links my-profile --id

Display all of the links in the trusted profile my-profile in JSON format:
ibmcloud iam trusted-profile-links my-profile --output JSON

ibmcloud iam trusted-profile-link-delete
Delete a link to a compute resource for a trusted profile:
ibmcloud iam trusted-profile-link-delete (NAME|ID) (LINK_NAME|LINK_ID) [-f, --force] [-q, --quiet]

Command options
NAME|ID (required)
The name or ID of the profile that contains the link to delete.
LINK_NAME|LINK_ID (required)
Name or ID of the link to delete.
-f, --force
Force deletion without confirmation.
-q, --quiet
Suppress verbose output.

Running secure workloads 301

Examples
Delete the link my_link from trusted profile my-profile without confirmation:
ibmcloud iam trusted-profile-link-delete my-profile my_link -f

ibmcloud iam trusted-profile-identity
Retrieve and display a trusted profile identity
ibmcloud iam trusted-profile-identity (NAME|ID) (IDENTITY_IDENTIFIER|IDENTITY_ID) --id-type IDENTIFIER_TYPE [--id | --output
FORMAT] [-q, --quiet]

Command options
NAME|ID (required)
Name or ID of the trusted profile.
IDENTITY_IDENTIFIER|IDENTITY_ID (required)
Identifier or ID of the Identity to retrieve.
--id-type (required)
The type of identifier to retrieve for the trusted profile. USER for a user IAM ID, SERVICEID for a service ID, or CRN for a service CRN
--id
Show ID of the identity only.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

ibmcloud iam trusted-profile-identities
Retrieve and display trusted profile identities
ibmcloud iam trusted-profile-identities (NAME|ID) [--id-type IDENTIFIER_TYPE] [--id | --output FORMAT] [-f, --force] [-q, -quiet]

Command options
NAME|ID (required)
Name or ID of the trusted profile.
--id-type
The type of identifiers to retrieve for the trusted profile. USER for a user IAM ID, SERVICEID for a service ID, or CRN for a service CRN
--id
Show the ID of the identities only.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-f, --force
Force a failure if multiple profiles are found.
-q, --quiet

Running secure workloads 302

Suppress verbose output.

ibmcloud iam trusted-profile-identity-create
Connect a trusted profile to an identity
ibmcloud iam trusted-profile-identity-create (NAME|ID) --id IDENTIFIER_TO_CONNECT --id-type IDENTIFIER_TYPE [--description
DESCRIPTION] [--output FORMAT] [-q, --quiet]

Command options
NAME|ID (required)
The name or ID of the profile to connect the identity to.
--id (required)
ID for the identity.
--id-type (required)
The type of identifier to connect to the trusted profile. USER for a user IAM ID, SERVICEID for a service ID, or CRN for a service CRN
--description DESCRIPTION
Optional description for the connection to the trusted profile
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

ibmcloud iam trusted-profile-identity-delete
Disconnect a trusted profile from an identity
ibmcloud iam trusted-profile-identity-delete (NAME|ID) (IDENTITY_IDENTIFIER|IDENTITY_ID) --id-type IDENTIFIER_TYPE [--force] [-q,
--quiet]

Command options
NAME|ID (required)
The name or ID of the profile to disconnect the identity from.
IDENTITY_IDENTIFIER|IDENTITY_ID (required)
Identifier or ID of the Identity to disconnect.
--id-type (required)
The type of identifier to disconnect from the trusted profile. USER for a user IAM ID, SERVICEID for a service ID, or CRN for a service CRN
-f, --force
Force deletion without confirmation.
-q, --quiet
Suppress verbose output.

ibmcloud iam trusted-profile-rule-create
Create a rule for a trusted profile:

Running secure workloads 303

ibmcloud iam trusted-profile-rule-create (NAME|UUID) --name RULE_NAME --type RULE_TYPE

[--realm-name REALM_NAME] --conditions

<LIST_OF_CONDITIONS> [--expiration EXPIRATION_SEC] [--cr-type CR_TYPE] [--output FORMAT] [-q, --quiet] [-f, --force]

Note: To view a full list of valid operators and claim attribute options for --conditions , see IAM condition properties.

Command options
NAME|ID (required)
Name or ID of the profile to create a rule for.
--type (required)
'Profile-SAML' for a SAML rule or 'Profile-CR' for a compute resource rule
--conditions (required)
List of conditions, provided as a comma-separated list of triple values "claim:CLAIM,operator:OPERATOR,value:VALUE". To specify multiple
conditions, specify the flag multiple times --conditions "claim:CLAIM1,operator:OPERATOR1,value:VALUE1" --conditions
"claim:CLAIM2,operator:OPERATOR2,value:VALUE2".
--expiration
Specify an expiration in seconds for SAML rules. Must not be provided for trusts that are established to Compute Resources (type = Profile-CR).
--name
Name for the rule.
--cr-type
The compute resource type that the rule applies to is required only if type is specified as 'Profile-CR'. Values are VSI for Virtual Service Instance on
VPC, IKS_SA for Service Accounts on Kubernetes clusters, or ROKS_SA for managed Red Hat OpenShift.
--realm-name
The issuer ID for trusts established via IBMid with federation, or appid:// for trusts established by using App ID federation. Must not be provided
for trusts that are established to Compute Resources (type = Profile-CR).
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-f, --force
Force failure if multiple profiles are found.
-q, --quiet
Suppress verbose output.

Examples
Create a Profile-SAML rule with rule name my-rule , realm name set to https://w3id.sso.ibm.com/auth/sps/samlidp2/saml20 , expiration set to
1200 seconds for trusted profile my-profile with the rule conditions: cn EQUALS my_user
ibmcloud iam trusted-profile-rule-create my-profile --name my-rule --type Profile-SAML --conditions
claim:cn,operator:EQUALS,value:my_user --realm-name https://w3id.sso.ibm.com/auth/sps/samlidp2/saml20 --expiration 1200

Create a Profile-SAML rule with realm name set to https://w3id.sso.ibm.com/auth/sps/samlidp2/saml20 and expiration set to 1200 seconds for
trusted profile my-profile with the rule conditions: cn EQUALS my_user and blueGroups NOT_EQUALS jaas_master
ibmcloud iam trusted-profile-rule-create my-profile --type Profile-SAML --conditions claim:cn,operator:EQUALS,value:my_user -conditions claim:blueGroups,operator:NOT_EQUALS,value:jaas_master --realm-name https://w3id.sso.ibm.com/auth/sps/samlidp2/saml20
--expiration 1200

Create a Profile-CR rule with rule name my-rule , compute resource type IKS_SA , and with the rule conditions: namespace EQUALS default and
crn EQUALS crn:test:bluemix:public:containers-kubernetes:us-south:a/test::
ibmcloud iam trusted-profile-rule-create my-profile --name my-rule --type Profile-CR --conditions

Running secure workloads 304

claim:namespace,operator:EQUALS,value:default --conditions claim:crn,operator:EQUALS,value:crn:test:bluemix:public:containerskubernetes:us-south:a/test:: --cr-type IKS_SA

ibmcloud iam trusted-profile-rules
List all rules for a specified trusted profile:
ibmcloud iam trusted-profile-rules (NAME|ID) [--output FORMAT] [-f, --force] [-q, --quiet]

Command options
NAME|ID (required)
Name or ID of the trusted profile to retrieve rules for.
--output FORMAT.
Specify the output format. Only 'JSON' is supported.
-f, --force
Force failure if multiple profiles are found.
-q, --quiet
Suppress verbose output.

Examples
Display all rules in the trusted profile my-profile :
ibmcloud iam trusted-profile-rules my-profile

ibmcloud iam trusted-profile-rule-update
Update a rule for a trusted profile:
ibmcloud iam trusted-profile-rule-update (NAME|ID) (RULE_NAME|RULE_ID) --name RULE_NAME --type RULE_TYPE

[--realm-name

REALM_NAME] --conditions <LIST_OF_CONDITIONS> [--cr-type CR_TYPE] [--expiration EXPIRATION_SEC] [--output FORMAT] [-q, --quiet]
[-f, --force]

Note: To view a full list of valid operators and claim attribute options for --conditions , see IAM condition properties.

Command options
NAME|ID (required)
The name or ID of the trusted profile to update a rule for.
RULE_NAME|RULE_ID (required)
The name or ID of the rule to update.
--type
'Profile-SAML' for a SAML rule or 'Profile-CR' for a compute resource rule.
--conditions
List of conditions, provided as a comma-separated list of triple values "claim:CLAIM,operator:OPERATOR,value:VALUE". To specify multiple
conditions, specify the flag multiple times --conditions "claim:CLAIM1,operator:OPERATOR1,value:VALUE1" --conditions
"claim:CLAIM2,operator:OPERATOR2,value:VALUE2".
--cr-type
The compute resource type that the rule applies to is required only if type is specified as 'Profile-CR'. Values are VSI for Virtual Service Instance on
VPC, IKS_SA for Service Accounts on Kubernetes clusters, or ROKS_SA for managed Red Hat OpenShift.

Running secure workloads 305

--expiration
Specify an expiration in seconds for SAML rules. Must not be provided for trusts that are established to Compute Resources (type = Profile-CR).
--name
New name for the rule.
--realm-name
Issuer Id for trusts established via IBMid with federation, or appid:// for trusts established via App ID federation. Must not be provided for trusts
that are established to Compute Resources (type = Profile-CR).
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-f, --force
Force failure if multiple rules are found.
-q, --quiet
Suppress verbose output.

Examples
Update rule ClaimRule-test-id in profile my-profile with new name test-rule :
ibmcloud iam trusted-profile-rule-update my-profile ClaimRule-test-id --name test-rule

Update Profile-SAML rule my-rule in profile my-profile with new realm name https://www.example.org/my-nice-idp :
ibmcloud iam trusted-profile-rule-update my-profile my-rule --realm-name https://www.example.org/my-nice-idp

Update rule conditions and expiration time for Profile-SAML rule ClaimRule-a448e998-311f-4e23-8af8-66b855c5da11 in profile my-profile :
ibmcloud iam trusted-profile-rule-update my-profile ClaimRule-a448e998-311f-4e23-8af8-66b855c5da11 --conditions
claim:cn,operator:EQUALS,value:my_user --expiration 1200

Update rule conditions and compute resource type for Profile-CR rule ClaimRule-cb8e3a2c-2d16-422b-b691-8791355b53bc in profile my-profile :
ibmcloud iam trusted-profile-rule-update my-profile ClaimRule-cb8e3a2c-2d16-422b-b691-8791355b53bc --conditions
claim:crn,operator:EQUALS,value:crn:v1:bluemix:public:containers-redhat:us-south:a/test:: --cr-type ROKS_SA

ibmcloud iam trusted-profile-rule-delete
Delete a rule for a trusted profile:
ibmcloud iam trusted-profile-rule-delete (NAME|ID) (RULE_NAME|RULE_ID) [-f, --force] [-q, --quiet]

Command options
NAME|ID (required)
The name or ID of the profile that contains the rule to delete.
RULE_NAME|RULE_ID (required)
The name or ID of the rule to delete.
-f, --force
Force deletion without confirmation.
-q, --quiet
Suppress verbose output.

Running secure workloads 306

Examples
Delete rule my-rule from trusted profile my-profile without confirmation:
ibmcloud iam trusted-profile-rule-delete my-profile my-rule -f

ibmcloud iam trusted-profile-templates
List all profile templates in your current account
ibmcloud iam trusted-profile-templates [--output FORMAT] [-q, --quiet]

Command options
-q, --quiet
Suppress verbose output.
--output FORMAT
Specify the output format. Only 'JSON' is supported.

Examples
List trusted profile templates in table format
ibmcloud iam trusted-profile-templates

ibmcloud iam trusted-profile-template-create
Create a trusted profile template
ibmcloud iam trusted-profile-template-create --file JSON_FILE

Command options
--file JSON_FILE
JSON file of the template definition

ibmcloud iam trusted-profile-template-version
Get a specified version of a trusted profile template
ibmcloud iam trusted-profile-template-version (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION

Examples
List details of a specified version of a trusted profile template
ibmcloud iam trusted-profile-template-version example-template-name 1

Command options
-q, --quiet
Suppress verbose output.
--output FORMAT
Specify the output format. Only 'JSON' is supported.
Running secure workloads 307

ibmcloud iam trusted-profile-template-version-commit
Commit a specified version of a trusted profile template
ibmcloud iam trusted-profile-template-version-commit (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION

Command options
Examples
Commit a specified version of a trusted profile template
ibmcloud iam trusted-profile-template-version-commit example-template-name 1

-q, --quiet
Suppress verbose output.

ibmcloud iam trusted-profile-template-version-create
Create a new version of a trusted profile template
ibmcloud iam trusted-profile-template-version-create (TEMPLATE_ID | TEMPLATE_NAME) --file JSON_FILE

Command options
-q, --quiet
Suppress verbose output.
--file JSON_FILE
JSON file of the template definition.

Examples
Create a new version of a specified template from a JSON file
$ ibmcloud iam trusted-profile-template-version-create example-template-name --file JSON_FILE

ibmcloud iam trusted-profile-template-version-delete
Delete a specified version of a trusted profile template
ibmcloud iam trusted-profile-template-version-delete TEMPLATE_ID TEMPLATE_VERSION

Command options
-q, --quiet
Suppress verbose output.

Examples
Delete a specified version of a trusted profile template
Running secure workloads 308

ibmcloud iam trusted-profile-template-version-delete example-template-name 1

ibmcloud iam trusted-profile-template-version-update
Update a specified version of a trusted profile template
ibmcloud iam trusted-profile-template-version-update (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION --file JSON_FILE

Command options
-q, --quiet
Suppress verbose output.
--file JSON_FILE
JSON file of the template definition.

Examples
Update a specified version of a trusted profile template with a JSON file
ibmcloud iam trusted-profile-template-version-update example-template-name 1 --file JSON_FILE

ibmcloud iam trusted-profile-template-versions
List all versions of a trusted profile template
ibmcloud iam trusted-profile-template-versions TEMPLATE_ID | TEMPLATE_NAME

Command options
-q, --quiet
Suppress verbose output.
--output FORMAT
Specify the output format. Only 'JSON' is supported.

Examples
List all versions of a trusted profile template in JSON format
ibmcloud iam trusted-profile-template-versions --output JSON

ibmcloud iam trusted-profile-assignment
Show details of a trusted profile assignment
ibmcloud iam trusted-profile-assignment ASSIGNMENT_ID

Command options
-q, --quiet
Suppress verbose output.
--output FORMAT
Specify the output format. Only 'JSON' is supported.

Running secure workloads 309

Examples
Show details of a trusted profile assignment in JSON format
ibmcloud iam trusted-profile-assignment example-assignment-id --output JSON

ibmcloud iam trusted-profile-assignment-create
Create a trusted profile assignment
ibmcloud iam trusted-profile-assignment-create TEMPLATE_ID TEMPLATE_VERSION --target-type TYPE --target TARGET

Command options
-q, --quiet
Suppress verbose output.
--target TARGET
ID of the entity targeted
--target-type TYPE
Type of entity targeted

Examples
Create a trusted profile assignment in a specified target account
ibmcloud iam trusted-profile-assignment-create example-template-id 1 --target-type Account --target example-account-id

ibmcloud iam trusted-profile-assignment-delete
Delete a trusted profile assignment
ibmcloud iam trusted-profile-assignment-delete ASSIGNMENT_ID

Command options
-q, --quiet
Suppress verbose output.

Examples
Create a trusted profile assignment in a specified target account
ibmcloud iam trusted-profile-assignment-create example-template-id 1 --target-type Account --target example-account-id

ibmcloud iam trusted-profile-assignment-update
Update a trusted profile assignment
ibmcloud iam trusted-profile-assignment-update ASSIGNMENT_ID TEMPLATE_VERSION

Command options

Running secure workloads 310

-q, --quiet
Suppress verbose output.

Examples
Update a trusted profile assignment
ibmcloud iam trusted-profile-assignment-update example-template-id 1

ibmcloud iam trusted-profile-assignments
Get all trusted profile assignments in your current account
ibmcloud iam trusted-profile-assignments

Command options
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
List all trusted profile assignments in current account in JSON format
ibmcloud iam trusted-profile-assignments --output JSON

ibmcloud iam account-settings
List account setting values:
ibmcloud iam account-settings [--show-external-identity] [--output FORMAT] [-q, --quiet]

Command options
--show-external-identity
Show settings for external identities
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

ibmcloud iam account-settings-update
Update settings under current account:
ibmcloud iam account-settings-update [--restrict-create-service-id RESTRICTION_SETTING] [--restrict-create-platform-apikey
RESTRICTION_SETTING] [--allowed-ip-addresses ADDRESS_LIST] [--unset-allowed-ip-addresses] [--mfa MFA] [--session-expiration-inseconds SECONDS_EXP] [--session-invalidation-in-seconds SECONDS_INV] [--max-sessions-per-identity SESSIONS_MAX] [--output FORMAT]
[-q, --quiet]

Running secure workloads 311

Command options
--restrict-create-service-id RESTRICTION_SETTING
The restriction level on Service ID creation (one of RESTRICTED , NOT_RESTRICTED , or NOT_SET ).
--restrict-create-platform-apikey RESTRICTION_SETTING
The restriction level on API Key creation (one of RESTRICTED , NOT_RESTRICTED , or NOT_SET ).
--allowed-ip-addresses ADDRESS_LIST
The IP addresses and subnets from which IAM tokens can be created (the default is "").
--unset-allowed-ip-addresses
Clear all IP address restrictions
--session-expiration-in-seconds SECONDS_EXP
The number of seconds after which the session expires (can also be NOT_SET , which resets the value to default).
--session-invalidation-in-seconds SECONDS_INV
The number of seconds of inactivity after which a session is invalidated (can also be "NOT_SET", which resets the value to default).
--max-sessions-per-identity SESSIONS_MAX
The maximum number of sessions per identity on the account (can also be

NOT_SET , which resets the value to default).

--mfa MFA
The type of MFA on the account (one of NONE , TOTP , TOTP4ALL , LEVEL1 , LEVEL2 , or LEVEL3 ).
--output FORMAT
Specify the output format. Only 'JSON' is supported.
-q, --quiet
Suppress verbose output.

Examples
Update the multi-factor authentication setting of an account to LEVEL3 :
ibmcloud iam account-settings-update --mfa LEVEL3

Update the number of seconds after which a session expires to default (with NOT_SET ):
ibmcloud iam account-settings-update --session-expiration-in-seconds NOT_SET

ibmcloud iam account-settings-external-interaction-update
Update external interaction account settings under current account:
ibmcloud iam account-settings-external-interaction-update (service | service_id | user) [--state STATE] [--allowed-accounts
ACCOUNT_1, ACCOUNT_2, ...] [--output FORMAT] [-q, --quiet]

Command options
--state STATE
The state of the setting. The options include: limited , enabled , or monitor .
--allowed-accounts ACCOUNT_1, ACCOUNT_2, ...
Comma separated list of account IDs allowed access under the identity type.
--output FORMAT
Specify the output format. Only 'JSON' is supported.

Running secure workloads 312

-q, --quiet
Suppress verbose output.

Examples
Update the user external interaction setting of an account to monitor :
ibmcloud iam account-settings-external-interaction-update user --state monitor

Update the service external interaction setting of an account with an allowed account The-Account-ID :
ibmcloud iam account-settings-external-interaction-update service --allowed-accounts The-Account-ID

ibmcloud iam account-settings-template
Show details of an account settings template:
ibmcloud iam account-settings-template (TEMPLATE_ID | TEMPLATE_NAME) [-q,--quiet] [--output JSON]

Command options
-q, --quiet
Suppress verbose output.
--output FORMAT
Specify the output format. Only 'JSON' is supported.

Examples
Show details for account settings template AccountSettingsEditorTemplate
ibmcloud iam account-settings-template AccountSettingsEditorTemplate

ibmcloud iam account-settings-templates
List account settings templates for an enterprise account:
ibmcloud iam account-settings-templates [-q,--quiet] [--output JSON]

Command options
-q, --quiet
Suppress verbose output.
--output FORMAT
Specify the output format. Only 'JSON' is supported.

Examples
List account settings templates on your current account
ibmcloud iam account-settings-templates

ibmcloud iam account-settings-template-create
Running secure workloads 313

Create a new account settings template for an enterprise account:
ibmcloud iam account-settings-template-create TEMPLATE_NAME [-d, --description DESCRIPTION] [--file JSON_FILE] [-q,--quiet]

Command options
-d , --description DESCRIPTION
Description of the template
--file JSON_FILE
JSON file of the template definition
-q, --quiet
Suppress verbose output.
--output FORMAT
Specify the output format. Only 'JSON' is supported.

Examples
Create an account settings template on your current account
ibmcloud iam account-settings-template-create AccountSettingsEditorTemplate --fie /path/to/account_settings_template.json

ibmcloud iam account-settings-template-version
Get a specific version of an account settings template in an enterprise account:
ibmcloud iam account-settings-template-version (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION [-q,--quiet] [--output JSON]

Command options
-q, --quiet
Suppress verbose output.
--output FORMAT
Specify the output format. Only 'JSON' is supported.

Examples
Show version 1 of account settings template AccountSettingsEditorTemplate
ibmcloud iam account-settings-template-create AccountSettingsEditorTemplate 1

ibmcloud iam account-settings-template-versions
List versions of an account settings template in an enterprise account:
ibmcloud iam account-settings-template-versions (TEMPLATE_ID | TEMPLATE_NAME) [-q,--quiet] [--output JSON]

Command options
-q, --quiet
Suppress verbose output.
--output FORMAT

Running secure workloads 314

Specify the output format. Only 'JSON' is supported.

Examples
List versions of account settings template AccountSettingsEditorTemplate
ibmcloud iam account-settings-template-versions AccountSettingsEditorTemplate

ibmcloud iam account-settings-template-version-create
Create a new version of an account settings template in an enterprise account:
ibmcloud iam account-settings-template-version-create {(TEMPLATE_ID |TEMPLATE_NAME) (--file JSON_FILE)} [-q,--quiet] [--output
FORMAT]

Command options
--file JSON_FILE
JSON file of account settings template definition
-q, --quiet
Suppress verbose output.
--output FORMAT
Specify the output format. Only 'JSON' is supported.

Examples
Create a new version of the account settings template AccountSettingsEditorTemplate
ibmcloud iam account-settings-template-version-create AccountSettingsEditorTemplate --file
/path/to/account_settings_template.json

ibmcloud iam account-settings-template-version-update
Update a specific version of an account settings template in an enterprise account:
ibmcloud iam account-settings-template-version-update (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION --file JSON_FILE [-d, -description DESCRIPTION] [-q,--quiet]

Command options
-d value, --description DESCRIPTION
Description of the template
--file JSON_FILE
JSON file of template definition
-q, --quiet
Suppress verbose output.

Examples
Update version 1 of account settings template AccountSettingsEditorTemplate
ibmcloud iam account-settings-template-version-update AccountSettingsEditorTemplate 1 --file

Running secure workloads 315

/path/to/account_settings_template.json

ibmcloud iam account-settings-template-version-delete
Delete a version of an account settings template for an enterprise account:
ibmcloud iam account-settings-template-version-delete (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION [-q,--quiet]

Command options
-q, --quiet
Suppress verbose output.

Examples
Delete version 2 of account settings template AccountSettingsEditorTemplate
$ ibmcloud iam account-settings-template-delete AccountSettingsEditorTemplate 2

ibmcloud iam account-settings-template-version-commit
Commit a specific version of an account settings template in an enterprise account:
ibmcloud iam account-settings-template-commit (TEMPLATE_ID | TEMPLATE_NAME) TEMPLATE_VERSION [-q,--quiet]

Command options
-q, --quiet
Suppress verbose output.

Examples
Commit version 1 of account settings template AccountSettingsEditorTemplate
ibmcloud iam account-settings-template-version-commit AccountSettingsEditorTemplate 1

ibmcloud iam account-settings-assignments
List assignments for account settings on an enterprise account:
ibmcloud iam account-settings-assignments [--output FORMAT] [-q, --quiet]

Command options
-q, --quiet
Suppress verbose output.
--output FORMAT
Specify the output format. Only 'JSON' is supported.

Examples
List assignments in current account

Running secure workloads 316

ibmcloud iam account-settings-assignments

ibmcloud iam account-settings-assignment
Get an assignment for an account settings template:
ibmcloud iam account-settings-assignment ASSIGNMENT_ID [-q,--quiet] [--output FORMAT]

Command options
-q, --quiet
Suppress verbose output.
--output FORMAT
Specify the output format. Only 'JSON' is supported.

Examples
Get account settings assignment AccountSettingsAssignment-7c4345c7f2cb4c75a9f29b68fc1e1e88
ibmcloud iam account-settings-assignment AccountSettingsAssignment-7c4345c7f2cb4c75a9f29b68fc1e1e88

ibmcloud iam account-settings-assignment-create
Create an assignment for an account settings template:
ibmcloud iam account-settings-assignment-create TEMPLATE_NAME TEMPLATE_VERSION TARGET_TYPE TARGET [-q, --quiet]

Command options
-q, --quiet
Suppress verbose output.

Examples
Assign account settings template to account
ibmcloud iam account-settings-assignment-create TemplateTest 1 Account f7fc6938256e46e1a25ee09e14ca9c20

Assign account settings template to account group
ibmcloud iam account-settings-assignment-create TemplateTest 1 AccountGroup 955fc2274567474f8da802d5c376504b

ibmcloud iam account-settings-assignment-update
Update an assignment to retry failed assignments or migrate resources to a new version:
ibmcloud iam account-settings-assigment-update ASSIGNMENT_ID TEMPLATE_VERSION [-q,--quiet]

Command options
-q, --quiet
Suppress verbose output.

Running secure workloads 317

Examples
Update account settings assignment AccountSettingsAssignment-63d65ed159ff463b8ec09ea77d22a05b to a template version 2
ibmcloud iam account-settings-assignment-update AccountSettingsAssignment-63d65ed159ff463b8ec09ea77d22a05b 2

ibmcloud iam account-settings-assignment-delete
Delete an account settings assignment. This action removes any resources that this assignment creates:
ibmcloud iam account-settings-assigment-delete ASSIGNMENT_ID [-q, --quiet]

Command options
-q, --quiet
Suppress verbose output.

Examples
Delete account settings assignment AccountSettingsAssignment-63d65ed159ff463b8ec09ea77d22a05b
ibmcloud iam account-settings-assignment-delete AccountSettingsAssignment-63d65ed159ff463b8ec09ea77d22a05b

Project CLI reference
The IBM Cloud® command-line interface (IBM Cloud CLI) provides additional capabilities for service offerings. You can use the IBM Cloud CLI to manage
projects you have access to.

Before you begin
Install the IBM Cloud CLI.
Install the Project CLI by running the following command:
$ ibmcloud plugin install project

Tip: You're notified on the command line when updates to the IBM Cloud CLI and plug-ins are available. Be sure to keep your CLI up to date so
that you can use the latest commands. You can view the current version of all installed plug-ins by running ibmcloud plugin list .

Note: IBM Cloud CLI requires Java™ 1.8.0.

Projects
Commands for Projects resource.

ibmcloud project create
Create a project and asynchronously setup the tools to manage it. Add a deployable architecture by customizing the configuration. After the changes are
validated and approved, deploy the resources that the project configures. For more information, see Creating a project.
$ ibmcloud project create [--definition DEFINITION | --definition-name DEFINITION-NAME --definition-destroy-on-delete=DEFINITIONDESTROY-ON-DELETE --definition-description DEFINITION-DESCRIPTION --definition-auto-deploy=DEFINITION-AUTO-DEPLOY --definitionmonitoring-enabled=DEFINITION-MONITORING-ENABLED] --location LOCATION --resource-group RESOURCE-GROUP [--configs CONFIGS] [-environments ENVIRONMENTS]

Command options
--definition ( ProjectPrototypeDefinition)

Running secure workloads 318

The definition of the project. This JSON option can instead be provided by setting individual fields with other options. It is mutually exclusive with
those options.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --

definition=@path/to/file.json .
--location (string)

The IBM Cloud location where a resource is deployed. Required.
Allowable values are: us-south , us-east , eu-gb , eu-de , ca-tor .
--resource-group (string)

The resource group name where the project's data and tools are created. Required.
The maximum length is 64 characters. The minimum length is 0 characters. The value must match the regular expression /^(?!\\s)(?!.*\\s$)
[^'" <>{}\x00-\x1F]*$/`.
--configs ( ProjectConfigPrototype[] )

The project configurations. These configurations are included in the response of creating a project only if a configuration array is specified in the
request payload.
The default value is [] . The maximum length is 100 items. The minimum length is 0 items.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --

configs=@path/to/file.json .
--environments ( EnvironmentPrototype[])

The project environment. These environments are included in the response of creating a project only if an environment array is specified in the
request payload.
The default value is [] . The maximum length is 20 items. The minimum length is 0 items.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --

environments=@path/to/file.json .
--definition-name (string)

The name of the project. It's unique within the account across regions. This option provides a value for a sub-field of the JSON option 'definition'. It is
mutually exclusive with that option.
The maximum length is 128 characters. The minimum length is 1 character. The value must match the regular expression /^(?!\\s)(?!.*\\s$)
[^'" <>{}\x00-\x1F]+$/`.
--definition-destroy-on-delete (bool)

The policy that indicates whether the resources are undeployed or not when a project is deleted. This option provides a value for a sub-field of the
JSON option 'definition'. It is mutually exclusive with that option.
The default value is true .
--definition-description (string)

A brief explanation of the project's use in the configuration of a deployable architecture. You can create a project without providing a description. This
option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that option.
The default value is ``. The maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression
/^$|^(?!\\s)(?!.*\\s$)[^\\x00-\\x1F]*$/ .
--definition-auto-deploy (bool)

A boolean flag to enable auto deploys. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that
option.
The default value is false .
--definition-monitoring-enabled (bool)

A boolean flag to enable automatic drift detection. Use this field to run a daily check to compare your configurations to your deployed resources to
detect any difference. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that option.
Running secure workloads 319

The default value is false .

Examples
$ ibmcloud project create \
--definition '{"name": "acme-microservice", "destroy_on_delete": true, "description": "A microservice to deploy on top of
ACME infrastructure.", "auto_deploy": false, "monitoring_enabled": false}' \
--location us-south \
--resource-group Default \
--configs '[{"definition": {"compliance_profile": {"id": "exampleString", "instance_id": "exampleString",
"instance_location": "us-south", "attachment_id": "exampleString", "profile_name": "exampleString"}, "locator_id": "1082e7d25e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global", "description": "The stage account configuration.",
"name": "account-stage", "environment_id": "exampleString", "authorizations": {"trusted_profile_id": "exampleString", "method":
"api_key", "api_key": "exampleString"}, "inputs": {"anyKey": "anyValue"}, "settings": {"anyKey": "anyValue"}}, "schematics":
{"workspace_crn": "crn:v1:staging:public:project:us-south:a/4e1c48fcf8ac33c0a2441e4139f189ae:bf40ad13-b107-446a-8286c6d576183bb1::"}}]' \
--environments '[{"definition": {"description": "exampleString", "name": "exampleString", "authorizations":
{"trusted_profile_id": "exampleString", "method": "api_key", "api_key": "exampleString"}, "inputs": {"anyKey": "anyValue"},
"compliance_profile": {"id": "exampleString", "instance_id": "exampleString", "instance_location": "us-south", "attachment_id":
"exampleString", "profile_name": "exampleString"}}}]'

Alternatively, granular options are available for the sub-fields of JSON string options:
$ ibmcloud project create \
--location us-south \
--resource-group Default \
--configs '[projectConfigPrototype]' \
--environments '[environmentPrototype]' \
--definition-name exampleString \
--definition-destroy-on-delete=true \
--definition-description exampleString \
--definition-auto-deploy=false \
--definition-monitoring-enabled=false

ibmcloud project list
List existing projects. Projects are sorted by ID. Note: If the --all-pages option is not set, the command retrieves only a single page of the collection.
$ ibmcloud project list [--token TOKEN] [--limit LIMIT]

Command options
--token (string)

The server uses this parameter to determine the first entry that is returned on the next page. If this parameter is not specified, the logical first page is
returned.
The default value is ``. The maximum length is 1536 characters. The minimum length is 0 characters. The value must match regular expression
/^$|^(?!\\s)(?!.*\\s$)[^\\x00-\\x1F]*$/ .
--limit (int64)

The maximum number of resources to return. The number of resources that are returned is the same, except for the last page.
The default value is 10 . The maximum value is 100 . The minimum value is 1 .
--all-pages (bool)

Start multiple requests to display all pages of the collection for list.

Example
$ ibmcloud project list \

Running secure workloads 320

--token exampleString \
--limit 10

Example output
An example request to list projects.
{
"limit" : 10,
"first" : {
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"next" : {
"href" : "https://projects.api.cloud.ibm.com/v1/projects/12349050-1234-ac97-0000-ba5a12fe9087"
},
"projects" : [ {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"href" : "https://projects.service.url/v1/projects/cfbf901-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"description" : "A project example.",
"name" : "iaas-infra-prestage-env",
"auto_deploy" : false,
"destroy_on_delete" : false,
"monitoring_enabled" : false
},
"location" : "us-south",
"state" : "ready",
"resource_group" : "Default",
"resource_group_id" : "f37d2637ea814cfd9a1742683a713d24",
"cumulative_needs_attention_view" : [ {
"event" : "project.instance.update"
}, {
"event_id" : "489f0090-6d7c-4af5-8f20-9106543e4974"
}, {
"config_id" : "069ab83e-5016-4bf2-bd50-cc95cf678293"
}, {
"config_version" : 1
} ]
}, {
"id" : "1123ed42-4356-efa1-1101-235900fe9087",
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"href" : "https://projects.service.url/v1/projects/cfbf901-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"description" : "A project example.",
"name" : "iaas-infra-stage-env",
"auto_deploy" : false,
"destroy_on_delete" : false,
"monitoring_enabled" : false
},
"crn" : "crn:v1:staging:public:project:eu-de:a/06580d923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"location" : "eu-gb",
"state" : "ready",
"resource_group" : "Default",
"resource_group_id" : "f37d2637ea814cfd9a1742683a713d24",
"cumulative_needs_attention_view" : [ ]
} ]
}

ibmcloud project get
Get information about a project.
$ ibmcloud project get --id ID

Command options
Running secure workloads 321

--id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .

Example
$ ibmcloud project get \
--id exampleString

Example output
A sample response for retrieving a project with configurations.
{
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"href" : "https://projects.service.url/v1/projects/cfbf901-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "acme-microservice",
"description" : "A microservice to deploy on top of ACME infrastructure.",
"auto_deploy" : false,
"destroy_on_delete" : true,
"monitoring_enabled" : false
},
"configs" : [ {
"id" : "673d79e4-52bf-4184-b8e9-d3ca3c110f96",
"created_at" : "2023-02-22T19:51:23.253Z",
"definition" : {
"name" : "common-variables",
"description" : "The common-variables configuration."
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/673d79e4-52bf-4184b8e9-d3ca3c110f96",
"is_draft" : true,
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"state" : "draft",
"modified_at" : "2023-02-22T19:51:23.253Z",
"update_available" : false,
"version" : 1
}, {
"id" : "4a1d4ba2-54ba-43a7-975a-d82b5a7612d1",
"created_at" : "2023-02-22T19:51:23.253Z",
"definition" : {
"name" : "account-stage",
"description" : "The stage account configuration. The stage account hosts test environments prestage, performance, stage.
This configuration configures services that are common to all these environments and regions. It's a `terraform_template` type of
configuration that points to a GitHub repository that hosts the terraform modules that a Schematics workspace can deploy."
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/4a1d4ba2-54ba-43a7975a-d82b5a7612d1",
"is_draft" : true,
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
Running secure workloads 322

"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"state" : "draft",
"update_available" : false,
"modified_at" : "2023-02-22T19:51:23.253Z",
"version" : 1
}, {
"id" : "293c3c36-a094-4115-a12b-de0a9ca39be5",
"created_at" : "2023-02-22T19:51:23.253Z",
"definition" : {
"name" : "env-stage",
"description" : "The stage environment configuration. It includes services that are common to all the environment regions.
You must have a blueprint that configures all the services that are common to the stage regions. It's a `terraform_template` type
of configuration that points to a GitHub repository that hosts the Terraform modules that a Schematics workspace can deploy."
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/293c3c36-a094-4115a12b-de0a9ca39be5",
"is_draft" : true,
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"state" : "draft",
"update_available" : false,
"modified_at" : "2023-02-22T19:51:23.253Z",
"version" : 1
}, {
"id" : "596e8656-9d4b-41a5-8340-b0cbe8bd374a",
"created_at" : "2023-02-22T19:51:23.253Z",
"definition" : {
"name" : "region-us-south-stage",
"description" : "The stage `us-south` configuration. You must have a blueprint that configures the Virtual Private Cloud
and Red Hat OpenShift stage `us-south`."
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/596e8656-9d4b-41a58340-b0cbe8bd374a",
"is_draft" : true,
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"state" : "draft",
"update_available" : false,
"modified_at" : "2023-02-22T19:51:23.253Z",
"version" : 1
}, {
"id" : "9c7afed6-17fb-4c56-a13d-440a78f936bd",
"created_at" : "2023-02-22T19:51:23.253Z",
"definition" : {
"name" : "region-eu-de-stage",
"description" : "The stage `eu-de` configuration. You must have a blueprint that configures the Virtual Private Cloud and
Red Hat OpenShift stage `eu-de`."
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/9c7afed6-17fb-4c56a13d-440a78f936bd",
"is_draft" : true,
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
Running secure workloads 323

},
"state" : "draft",
"update_available" : false,
"modified_at" : "2023-02-22T19:51:23.253Z",
"version" : 1
} ],
"environments" : [ {
"id" : "b0c44146-1ef6-40c2-82ba-74d51149770a",
"definition" : {
"name" : "dev-environment",
"description" : "The development environment."
},
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"created_at" : "2023-02-10T10:05:35.787Z",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/environments/b0c44146-1ef640c2-82ba-74d51149770a"
} ],
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"cumulative_needs_attention_view" : [ {
"event" : "project.instance.update"
}, {
"event_id" : "489f0090-6d7c-4af5-8f20-9106543e4974"
}, {
"config_id" : "069ab83e-5016-4bf2-bd50-cc95cf678293"
}, {
"config_version" : 1
} ],
"event_notifications_crn" : "crn:v1:staging:public:event-notifications:us-south:a/06580c923e40314421d3b6cb40c01c68:instanceid::",
"location" : "us-south",
"resource_group" : "Default",
"resource_group_id" : "f37d2637ea814cfd9a1742683a713d24",
"state" : "ready"
}

ibmcloud project update
Update a project by specifying its ID.
$ ibmcloud project update --id ID [--definition DEFINITION | --definition-name DEFINITION-NAME --definition-destroy-ondelete=DEFINITION-DESTROY-ON-DELETE --definition-auto-deploy=DEFINITION-AUTO-DEPLOY --definition-description DEFINITIONDESCRIPTION --definition-monitoring-enabled=DEFINITION-MONITORING-ENABLED]

Command options
--id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--definition ( ProjectPatchDefinitionBlock)

The definition of the project. This JSON option can instead be provided by setting individual fields with other options. It is mutually exclusive with
those options.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --

definition=@path/to/file.json .
--definition-name (string)

The name of the project. It's unique within the account across regions. This option provides a value for a sub-field of the JSON option 'definition'. It is

Running secure workloads 324

mutually exclusive with that option.
The maximum length is 128 characters. The minimum length is 1 character. The value must match the regular expression /^(?!\\s)(?!.*\\s$)
[^'" <>{}\x00-\x1F]+$/`.
--definition-destroy-on-delete (bool)

The policy that indicates whether the resources are destroyed or not when a project is deleted. This option provides a value for a sub-field of the
JSON option 'definition'. It is mutually exclusive with that option.
--definition-auto-deploy (bool)

A Boolean flag to enable auto deploys. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that
option.
--definition-description (string)

A brief explanation of the project's use in the configuration of a deployable architecture. You can create a project without providing a description. This
option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that option.
The maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression /^$|^(?!\\s)
(?!.*\\s$)[^\\x00-\\x1F]*$/ .
--definition-monitoring-enabled (bool)

A Boolean flag to enable automatic drift detection. Use this field to run a daily check to compare your configurations to your deployed resources to
detect any difference. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that option.

Examples
$ ibmcloud project update \
--id exampleString \
--definition '{"name": "acme-microservice", "destroy_on_delete": true, "auto_deploy": true, "description": "A microservice to
deploy on top of ACME infrastructure.", "monitoring_enabled": true}'

Alternatively, granular options are available for the sub-fields of JSON string options:
$ ibmcloud project update \
--id exampleString \
--definition-name exampleString \
--definition-destroy-on-delete=true \
--definition-auto-deploy=true \
--definition-description exampleString \
--definition-monitoring-enabled=true

Example output
A sample response for retrieving a project with configurations.
{
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"href" : "https://projects.service.url/v1/projects/cfbf901-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "acme-microservice",
"description" : "A microservice to deploy on top of ACME infrastructure.",
"auto_deploy" : false,
"destroy_on_delete" : true,
"monitoring_enabled" : false
},
"configs" : [ {
"id" : "673d79e4-52bf-4184-b8e9-d3ca3c110f96",
"created_at" : "2023-02-22T19:51:23.253Z",
"definition" : {
"name" : "common-variables",
"description" : "The common-variables configuration."
},
Running secure workloads 325

"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/673d79e4-52bf-4184b8e9-d3ca3c110f96",
"is_draft" : true,
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"state" : "draft",
"modified_at" : "2023-02-22T19:51:23.253Z",
"update_available" : false,
"version" : 1
}, {
"id" : "4a1d4ba2-54ba-43a7-975a-d82b5a7612d1",
"created_at" : "2023-02-22T19:51:23.253Z",
"definition" : {
"name" : "account-stage",
"description" : "The stage account configuration. The stage account hosts test environments prestage, performance, stage.
This configuration configures services that are common to all these environments and regions. It's a `terraform_template` type of
configuration that points to a GitHub repository that hosts the terraform modules that a Schematics workspace can deploy."
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/4a1d4ba2-54ba-43a7975a-d82b5a7612d1",
"is_draft" : true,
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"state" : "draft",
"update_available" : false,
"modified_at" : "2023-02-22T19:51:23.253Z",
"version" : 1
}, {
"id" : "293c3c36-a094-4115-a12b-de0a9ca39be5",
"created_at" : "2023-02-22T19:51:23.253Z",
"definition" : {
"name" : "env-stage",
"description" : "The stage environment configuration. It includes services that are common to all the environment regions.
You must have a blueprint that configures all the services that are common to the stage regions. It's a `terraform_template` type
of configuration that points to a GitHub repository that hosts the Terraform modules that a Schematics workspace can deploy."
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/293c3c36-a094-4115a12b-de0a9ca39be5",
"is_draft" : true,
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"state" : "draft",
"update_available" : false,
"modified_at" : "2023-02-22T19:51:23.253Z",
"version" : 1
}, {
"id" : "596e8656-9d4b-41a5-8340-b0cbe8bd374a",
"created_at" : "2023-02-22T19:51:23.253Z",
"definition" : {
"name" : "region-us-south-stage",
"description" : "The stage `us-south` configuration. You must have a blueprint that configures the Virtual Private Cloud
and Red Hat OpenShift stage `us-south`."
},
Running secure workloads 326

"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/596e8656-9d4b-41a58340-b0cbe8bd374a",
"is_draft" : true,
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"state" : "draft",
"update_available" : false,
"modified_at" : "2023-02-22T19:51:23.253Z",
"version" : 1
}, {
"id" : "9c7afed6-17fb-4c56-a13d-440a78f936bd",
"created_at" : "2023-02-22T19:51:23.253Z",
"definition" : {
"name" : "region-eu-de-stage",
"description" : "The stage `eu-de` configuration. You must have a blueprint that configures the Virtual Private Cloud and
Red Hat OpenShift stage `eu-de`."
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/9c7afed6-17fb-4c56a13d-440a78f936bd",
"is_draft" : true,
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"state" : "draft",
"update_available" : false,
"modified_at" : "2023-02-22T19:51:23.253Z",
"version" : 1
} ],
"environments" : [ {
"id" : "b0c44146-1ef6-40c2-82ba-74d51149770a",
"definition" : {
"name" : "dev-environment",
"description" : "The development environment."
},
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"created_at" : "2023-02-10T10:05:35.787Z",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/environments/b0c44146-1ef640c2-82ba-74d51149770a"
} ],
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"cumulative_needs_attention_view" : [ {
"event" : "project.instance.update"
}, {
"event_id" : "489f0090-6d7c-4af5-8f20-9106543e4974"
}, {
"config_id" : "069ab83e-5016-4bf2-bd50-cc95cf678293"
}, {
"config_version" : 1
} ],
"event_notifications_crn" : "crn:v1:staging:public:event-notifications:us-south:a/06580c923e40314421d3b6cb40c01c68:instanceid::",
"location" : "us-south",
"resource_group" : "Default",
Running secure workloads 327

"resource_group_id" : "f37d2637ea814cfd9a1742683a713d24",
"state" : "ready"
}

ibmcloud project delete
Delete a project document by specifying the ID. A project can be deleted only after you delete all of its resources.
$ ibmcloud project delete --id ID

Command options
--id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .

Example
$ ibmcloud project delete \
--id exampleString

Example output
The example response to a request to delete a project.
{
"id" : "4059955c-ccb3-4fd3-aa48-34e3b8334f80"
}

Environments
Commands for Environments resource.

ibmcloud project environment-create
Create an environment to group related configurations together and share values across them for easier deployment. For more information, see

Creating

an environment.
$ ibmcloud project environment-create --project-id PROJECT-ID [--definition DEFINITION | --definition-description DEFINITIONDESCRIPTION --definition-name DEFINITION-NAME --definition-authorizations DEFINITION-AUTHORIZATIONS --definition-inputs
DEFINITION-INPUTS --definition-compliance-profile DEFINITION-COMPLIANCE-PROFILE]

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--definition ( EnvironmentDefinitionRequiredProperties)

The environment definition. This JSON option can instead be provided by setting individual fields with other options. It is mutually exclusive with
those options.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --

definition=@path/to/file.json .
--definition-description (string)

The description of the environment. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that
option.
Running secure workloads 328

The default value is ``. The maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression
/^$|^(?!\\s)(?!.*\\s$)[^\\x00-\\x1F]*$/ .
--definition-name (string)

The name of the environment. It's unique within the account across projects and regions. This option provides a value for a sub-field of the JSON
option 'definition'. It is mutually exclusive with that option.
The maximum length is 128 characters. The minimum length is 1 character. The value must match the regular expression /^(?!\\s)(?!.*\\s$)
[^'" <>{}\x00-\x1F]+$/`.
--definition-authorizations ( ProjectConfigAuth)

The authorization details. You can authorize by using a trusted profile or an API key in Secrets Manager. This option provides a value for a sub-field of
the JSON option 'definition'. It is mutually exclusive with that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

authorizations=@path/to/file.json .
--definition-inputs (generic map)

The input variables that are used for configuration definition and environment. This option provides a value for a sub-field of the JSON option
'definition'. It is mutually exclusive with that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

inputs=@path/to/file.json .
--definition-compliance-profile ( ProjectComplianceProfile )

The profile that is required for compliance. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with
that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

compliance-profile=@path/to/file.json .

Examples
$ ibmcloud project environment-create \
--project-id exampleString \
--definition '{"description": "The environment development.", "name": "development", "authorizations": {"trusted_profile_id":
"Profile-9ac10c5c-195c-41ef-b465-68a6b6dg5f12", "method": "trusted_profile", "api_key": "exampleString"}, "inputs": {"anyKey":
"anyValue"}, "compliance_profile": {"id": "some-profile-id", "instance_id": "some-instance-id", "instance_location": "us-south",
"attachment_id": "some-attachment-id", "profile_name": "some-profile-name"}}'

Alternatively, granular options are available for the sub-fields of JSON string options:
$ ibmcloud project environment-create \
--project-id exampleString \
--definition-description exampleString \
--definition-name exampleString \
--definition-authorizations projectConfigAuth \
--definition-inputs '{"anyKey": "anyValue"}' \
--definition-compliance-profile projectComplianceProfile

Example output
The sample environment response.
{
"id" : "env123",
"definition" : {
"name" : "development",
"description" : "The environment development.",
"authorizations" : {
"method" : "trusted_profile",
"trusted_profile_id" : "Profile-9ac10c5c-195c-41ef-b465-68a6b6dg5f12"
},

Running secure workloads 329

"inputs" : {
"resource_group" : "stage",
"region" : "us-south"
},
"compliance_profile" : {
"id" : "some-profile-id",
"instance_id" : "some-instance-id",
"instance_location" : "us-south",
"profile_name" : "some-profile-name",
"attachment_id" : "some-attachment-id"
}
},
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"created_at" : "2023-06-29T03:28:14.709Z",
"modified_at" : "2023-06-29T03:28:14.709Z",
"href" : "https://projects.api.test.cloud.ibm.com/v1/projects/6fd53106-7ce6-429e-8c57-f22e832d0c4b/environments/2102afed-94c746fe-90f2-7fff290637b4"
}

ibmcloud project environments
List all available environments. For more information, see Creating an environment. Note: If the --all-pages option is not set, the command retrieves
only a single page of the collection.
$ ibmcloud project environments --project-id PROJECT-ID [--token TOKEN] [--limit LIMIT]

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--token (string)

The server uses this parameter to determine the first entry that is returned on the next page. If this parameter is not specified, the logical first page is
returned.
The default value is ``. The maximum length is 1536 characters. The minimum length is 0 characters. The value must match regular expression
/^$|^(?!\\s)(?!.*\\s$)[^\\x00-\\x1F]*$/ .
--limit (int64)

The maximum number of resources to return. The number of resources that are returned is the same, except for the last page.
The default value is 10 . The maximum value is 100 . The minimum value is 1 .
--all-pages (bool)

Start multiple requests to display all pages of the collection for environments.

Example
$ ibmcloud project environments \
--project-id exampleString \
--token exampleString \
--limit 10

Running secure workloads 330

Example output
The sample environment response for a list.
{
"limit" : 1,
"first" : {
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/environments?limit=1"
},
"next" : {
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/environments?
limit=1&token=da969bff-vf9q-3t1t-b677-d6rt5c0de54e"
},
"environments" : [ {
"id" : "env123",
"definition" : {
"name" : "development",
"description" : "The environment development.",
"authorizations" : {
"method" : "trusted_profile",
"trusted_profile_id" : "Profile-9ac10c5c-195c-41ef-b465-68a6b6dg5f12"
},
"inputs" : {
"resource_group" : "stage",
"region" : "us-south"
},
"compliance_profile" : {
"id" : "some-profile-id",
"instance_id" : "some-instance-id",
"instance_location" : "us-south",
"profile_name" : "some-profile-name",
"attachment_id" : "some-attachment-id"
}
},
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"created_at" : "2023-06-29T03:28:14.709Z",
"modified_at" : "2023-06-29T03:28:14.709Z",
"href" : "https://projects.api.test.cloud.ibm.com/v1/projects/6fd53106-7ce6-429e-8c57-f22e832d0c4b/environments/2102afed94c7-46fe-90f2-7fff290637b4"
} ]
}

ibmcloud project environment
Get an environment. Learn more.
$ ibmcloud project environment --project-id PROJECT-ID --id ID

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The environment ID. Required.
The maximum length is 256 characters. The minimum length is 1 character. The value must match regular expression /^(?!\\s)
(?!.*\\s$).+$/ .

Running secure workloads 331

Example
$ ibmcloud project environment \
--project-id exampleString \
--id exampleString

Example output
The sample environment response.
{
"id" : "env123",
"definition" : {
"name" : "development",
"description" : "The environment development.",
"authorizations" : {
"method" : "trusted_profile",
"trusted_profile_id" : "Profile-9ac10c5c-195c-41ef-b465-68a6b6dg5f12"
},
"inputs" : {
"resource_group" : "stage",
"region" : "us-south"
},
"compliance_profile" : {
"id" : "some-profile-id",
"instance_id" : "some-instance-id",
"instance_location" : "us-south",
"profile_name" : "some-profile-name",
"attachment_id" : "some-attachment-id"
}
},
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"created_at" : "2023-06-29T03:28:14.709Z",
"modified_at" : "2023-06-29T03:28:14.709Z",
"href" : "https://projects.api.test.cloud.ibm.com/v1/projects/6fd53106-7ce6-429e-8c57-f22e832d0c4b/environments/2102afed-94c746fe-90f2-7fff290637b4"
}

ibmcloud project environment-update
Update an environment by specifying its ID. Learn more.
$ ibmcloud project environment-update --project-id PROJECT-ID --id ID [--definition DEFINITION | --definition-description
DEFINITION-DESCRIPTION --definition-name DEFINITION-NAME --definition-authorizations DEFINITION-AUTHORIZATIONS --definitioninputs DEFINITION-INPUTS --definition-compliance-profile DEFINITION-COMPLIANCE-PROFILE]

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The environment ID. Required.
The maximum length is 256 characters. The minimum length is 1 character. The value must match regular expression /^(?!\\s)
Running secure workloads 332

(?!.*\\s$).+$/ .
--definition ( EnvironmentDefinitionPropertiesPatch)

The environment definition that is used for updates. This JSON option can instead be provided by setting individual fields with other options. It is
mutually exclusive with those options.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --

definition=@path/to/file.json .
--definition-description (string)

The description of the environment. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that
option.
The maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression /^$|^(?!\\s)
(?!.*\\s$)[^\\x00-\\x1F]*$/ .
--definition-name (string)

The name of the environment. It's unique within the account across projects and regions. This option provides a value for a sub-field of the JSON
option 'definition'. It is mutually exclusive with that option.
The maximum length is 128 characters. The minimum length is 1 character. The value must match the regular expression /^(?!\\s)(?!.*\\s$)
[^'" <>{}\x00-\x1F]+$/`.
--definition-authorizations ( ProjectConfigAuth)

The authorization details. You can authorize by using a trusted profile or an API key in Secrets Manager. This option provides a value for a sub-field of
the JSON option 'definition'. It is mutually exclusive with that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

authorizations=@path/to/file.json .
--definition-inputs (generic map)

The input variables that are used for configuration definition and environment. This option provides a value for a sub-field of the JSON option
'definition'. It is mutually exclusive with that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

inputs=@path/to/file.json .
--definition-compliance-profile ( ProjectComplianceProfile )

The profile that is required for compliance. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with
that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

compliance-profile=@path/to/file.json .

Examples
$ ibmcloud project environment-update \
--project-id exampleString \
--id exampleString \
--definition '{"description": "The environment development.", "name": "development", "authorizations": {"trusted_profile_id":
"Profile-9ac10c5c-195c-41ef-b465-68a6b6dg5f12", "method": "trusted_profile", "api_key": "exampleString"}, "inputs": {"anyKey":
"anyValue"}, "compliance_profile": {"id": "some-profile-id", "instance_id": "some-instance-id", "instance_location": "us-south",
"attachment_id": "some-attachment-id", "profile_name": "some-profile-name"}}'

Alternatively, granular options are available for the sub-fields of JSON string options:
$ ibmcloud project environment-update \
--project-id exampleString \
--id exampleString \
--definition-description exampleString \
--definition-name exampleString \
--definition-authorizations projectConfigAuth \

Running secure workloads 333

--definition-inputs '{"anyKey": "anyValue"}' \
--definition-compliance-profile projectComplianceProfile

Example output
The sample environment response.
{
"id" : "env123",
"definition" : {
"name" : "development",
"description" : "The environment development.",
"authorizations" : {
"method" : "trusted_profile",
"trusted_profile_id" : "Profile-9ac10c5c-195c-41ef-b465-68a6b6dg5f12"
},
"inputs" : {
"resource_group" : "stage",
"region" : "us-south"
},
"compliance_profile" : {
"id" : "some-profile-id",
"instance_id" : "some-instance-id",
"instance_location" : "us-south",
"profile_name" : "some-profile-name",
"attachment_id" : "some-attachment-id"
}
},
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"created_at" : "2023-06-29T03:28:14.709Z",
"modified_at" : "2023-06-29T03:28:14.709Z",
"href" : "https://projects.api.test.cloud.ibm.com/v1/projects/6fd53106-7ce6-429e-8c57-f22e832d0c4b/environments/2102afed-94c746fe-90f2-7fff290637b4"
}

ibmcloud project environment-delete
Delete an environment in a project by specifying its ID.
$ ibmcloud project environment-delete --project-id PROJECT-ID --id ID

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The environment ID. Required.
The maximum length is 256 characters. The minimum length is 1 character. The value must match regular expression /^(?!\\s)
(?!.*\\s$).+$/ .

Example
$ ibmcloud project environment-delete \

Running secure workloads 334

--project-id exampleString \
--id exampleString

Example output
The sample environment delete response.
{
"id" : "env123"
}

Configurations
Commands for Configurations resource.

ibmcloud project config-create
Add a configuration to a project.
$ ibmcloud project config-create --project-id PROJECT-ID [--definition DEFINITION | --definition-compliance-profile DEFINITIONCOMPLIANCE-PROFILE --definition-locator-id DEFINITION-LOCATOR-ID --definition-description DEFINITION-DESCRIPTION --definitionname DEFINITION-NAME --definition-environment-id DEFINITION-ENVIRONMENT-ID --definition-authorizations DEFINITION-AUTHORIZATIONS
--definition-inputs DEFINITION-INPUTS --definition-settings DEFINITION-SETTINGS --definition-members DEFINITION-MEMBERS -definition-resource-crns DEFINITION-RESOURCE-CRNS] [--schematics SCHEMATICS | --schematics-workspace-crn SCHEMATICS-WORKSPACECRN]

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--definition ( ProjectConfigDefinitionPrototype)

This JSON option can instead be provided by setting individual fields with other options. It is mutually exclusive with those options.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --

definition=@path/to/file.json .
--schematics ( SchematicsWorkspace)

A Schematics workspace to use for deploying this deployable architecture.

If you are importing data from an existing Schematics workspace that is not backed by cart, then you must provide a

locator_id . If you are

using a Schematics workspace that is backed by cart, a locator_id is not required because the Schematics workspace has one.
3 scenarios exist:
1. If only a locator_id is specified, a new Schematics workspace is instantiated with that locator_id .
2. If only a schematics workspace_crn is specified, a 400 is returned if a locator_id is not found in the existing schematics workspace.
3. If both a Schematics workspace_crn and a locator_id are specified, a 400 code is returned if the specified locator_id does not
agree with the locator_id in the existing Schematics workspace.
For more information, see Creating workspaces and importing your Terraform template . This JSON option can instead be provided by setting individual
fields with other options. It is mutually exclusive with those options.
$ Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a `@`, for
example `--schematics=@path/to/file.json`.

--definition-compliance-profile ( ProjectComplianceProfile )

The profile that is required for compliance. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with
Running secure workloads 335

that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

compliance-profile=@path/to/file.json .
--definition-locator-id (string)

A unique concatenation of the catalog ID and the version ID that identify the deployable architecture in the catalog. If you're importing from an
existing Schematics workspace that is not backed by cart, a locator_id is required. If you're using a Schematics workspace that is backed by cart, a
locator_id is not necessary because the Schematics workspace has one.

3 scenarios exist:
1. If only a locator_id is specified, a new Schematics workspace is instantiated with that locator_id .
2. If only a schematics workspace_crn is specified, a 400 is returned if a locator_id is not found in the existing schematics workspace.
3. If both a Schematics workspace_crn and a locator_id are specified, a 400 message is returned if the specified locator_id does
not agree with the locator_id in the existing Schematics workspace. For more information about creating a Schematics workspace,
see Creating workspaces and importing your Terraform template . This option provides a value for a sub-field of the JSON option
'definition'. It is mutually exclusive with that option.
$ The maximum length is `512` characters. The minimum length is `1` character. The value must match regular expression `/^(?!\\s)
(?!.*\\s$)[\\.0-9a-z-A-Z_-]+$/`.

--definition-description (string)

A project configuration description. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that
option.
The default value is ``. The maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression
/^$|^(?!\\s)(?!.*\\s$)[^\\x00-\\x1F]*$/ .
--definition-name (string)

The configuration name. It's unique within the account across projects and regions. This option provides a value for a sub-field of the JSON option
'definition'. It is mutually exclusive with that option.
The maximum length is 128 characters. The minimum length is 1 character. The value must match regular expression /^[a-zA-Z0-9][a-zA-Z09-_ ]*$/ .
--definition-environment-id (string)

The ID of the project environment. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that option.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--definition-authorizations ( ProjectConfigAuth)

The authorization details. You can authorize by using a trusted profile or an API key in Secrets Manager. This option provides a value for a sub-field of
the JSON option 'definition'. It is mutually exclusive with that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

authorizations=@path/to/file.json .
--definition-inputs (generic map)

The input variables that are used for configuration definition and environment. This option provides a value for a sub-field of the JSON option
'definition'. It is mutually exclusive with that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

inputs=@path/to/file.json .
--definition-settings (generic map)

The Schematics environment variables to use to deploy the configuration. Settings are only available if they are specified when the configuration is
initially created. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definitionRunning secure workloads 336

settings=@path/to/file.json .
Experimental

--definition-members ( StackConfigMember[])

The member deployable architectures that are included in your stack. This option provides a value for a sub-field of the JSON option 'definition'. It is
mutually exclusive with that option.
The maximum length is 100 items. The minimum length is 0 items.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

members=@path/to/file.json .
--definition-resource-crns ([]string)

The CRNs of the resources that are associated with this configuration. This option provides a value for a sub-field of the JSON option 'definition'. It is
mutually exclusive with that option.
The list items must match the regular expression /(?!\\s)(?!.*\\s$)^(crn)[^'" <>{}\s\x00-\x1F]*/ . The maximum length is 110 items.
The minimum length is 0` items.
--schematics-workspace-crn (string)

An IBM Cloud resource name that uniquely identifies a resource. This option provides a value for a sub-field of the JSON option 'schematics'. It is
mutually exclusive with that option.
The maximum length is 512 characters. The minimum length is 4 characters. The value must match the regular expression /(?!\\s)
(?!.*\\s$)^(crn)[^'" <>{}\s\x00-\x1F]*/`.

Examples
$ ibmcloud project config-create \
--project-id exampleString \
--definition '{"compliance_profile": {"id": "exampleString", "instance_id": "exampleString", "instance_location": "us-south",
"attachment_id": "exampleString", "profile_name": "exampleString"}, "locator_id": "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04e772-4ca2-9785-03e8e03bef72-global", "description": "The stage environment configuration.", "name": "env-stage",
"environment_id": "exampleString", "authorizations": {"trusted_profile_id": "exampleString", "method": "api_key", "api_key":
"exampleString"}, "inputs": {"anyKey": "anyValue"}, "settings": {"anyKey": "anyValue"}}' \
--schematics '{"workspace_crn": "crn:v1:staging:public:project:us-south:a/4e1c48fcf8ac33c0a2441e4139f189ae:bf40ad13-b107446a-8286-c6d576183bb1::"}'

Alternatively, granular options are available for the sub-fields of JSON string options:
$ ibmcloud project config-create \
--project-id exampleString \
--definition-compliance-profile projectComplianceProfile \
--definition-locator-id exampleString \
--definition-description exampleString \
--definition-name exampleString \
--definition-environment-id exampleString \
--definition-authorizations projectConfigAuth \
--definition-inputs '{"anyKey": "anyValue"}' \
--definition-settings '{"anyKey": "anyValue"}' \
--schematics-workspace-crn crn:v1:staging:public:project:us-south:a/4e1c48fcf8ac33c0a2441e4139f189ae:bf40ad13-b107-446a-8286c6d576183bb1::

ibmcloud project configs
Retrieve the collection of configurations. Note: If the --all-pages option is not set, the command retrieves only a single page of the collection.
$ ibmcloud project configs --project-id PROJECT-ID [--token TOKEN] [--limit LIMIT]

Command options
--project-id (string)

The unique project ID. Required.
Running secure workloads 337

The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--token (string)

The server uses this parameter to determine the first entry that is returned on the next page. If this parameter is not specified, the logical first page is
returned.
The default value is ``. The maximum length is 1536 characters. The minimum length is 0 characters. The value must match regular expression
/^$|^(?!\\s)(?!.*\\s$)[^\\x00-\\x1F]*$/ .
--limit (int64)

The maximum number of resources to return. The number of resources that are returned is the same, except for the last page.
The default value is 10 . The maximum value is 100 . The minimum value is 1 .
--all-pages (bool)

Start multiple requests to display all pages of the collection for configs.

Example
$ ibmcloud project configs \
--project-id exampleString \
--token exampleString \
--limit 10

Example output
The example response for a request to get project configurations.
{
"limit" : 2,
"first" : {
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs?limit=2"
},
"next" : {
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs?limit=2&token=da969bffvf9q-3t1t-b677-d6rt5c0de54e"
},
"configs" : [ {
"id" : "293c3c36-a094-4115-a12b-de0a9ca39be5",
"definition" : {
"name" : "env-stage",
"description" : "The stage environment configuration."
},
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"version" : 1,
"state" : "validated",
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/db268db0-160b-4911-8f93-89659000a927/configs/293c3c36-a094-4115a12b-de0a9ca39be5"
}, {
"id" : "9c7afed6-17fb-4c56-a13d-440a78f936bd",
"definition" : {
"name" : "region-eu-de-stage",
"description" : "The stage `eu-de` configuration."
},
"approved_version" : {
"definition" : {

Running secure workloads 338

"locator_id" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global"
},
"version" : 1,
"state" : "approved",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/db268db0-160b-4911-8f93-89659000a927/configs/9c7afed6-17fb-4c56a13d-440a78f936bd/versions/1"
},
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"version" : 2,
"state" : "draft",
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/db268db0-160b-4911-8f93-89659000a927/configs/9c7afed6-17fb-4c56a13d-440a78f936bd"
} ]
}

ibmcloud project config
Retrieve the specified project configuration in a specific project. For more information about project configurations, see Monitoring the status of a
configuration and its resources.
$ ibmcloud project config --project-id PROJECT-ID --id ID

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .

Example
$ ibmcloud project config \
--project-id exampleString \
--id exampleString

ibmcloud project config-update
Update a configuration in a project by specifying the ID. Learn more.
$ ibmcloud project config-update --project-id PROJECT-ID --id ID [--definition DEFINITION | --definition-compliance-profile
DEFINITION-COMPLIANCE-PROFILE --definition-locator-id DEFINITION-LOCATOR-ID --definition-description DEFINITION-DESCRIPTION -definition-name DEFINITION-NAME --definition-environment-id DEFINITION-ENVIRONMENT-ID --definition-authorizations DEFINITIONAUTHORIZATIONS --definition-inputs DEFINITION-INPUTS --definition-settings DEFINITION-SETTINGS --definition-resource-crns
DEFINITION-RESOURCE-CRNS --definition-members DEFINITION-MEMBERS]

Command options
--project-id (string)

Running secure workloads 339

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--definition ( ProjectConfigDefinitionPatch)

This JSON option can instead be provided by setting individual fields with other options. It is mutually exclusive with those options.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --

definition=@path/to/file.json .
--definition-compliance-profile ( ProjectComplianceProfile )

The profile that is required for compliance. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with
that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

compliance-profile=@path/to/file.json .
--definition-locator-id (string)

A unique concatenation of the catalog ID and the version ID that identify the deployable architecture in the catalog. If you're importing from an
existing Schematics workspace that is not backed by cart, a locator_id is required. If you're using a Schematics workspace that is backed by cart, a
locator_id is not necessary because the Schematics workspace has one.

There are 3 scenarios:
1. If only a locator_id is specified, a new Schematics workspace is instantiated with that locator_id .
2. If only a schematics workspace_crn is specified, a 400 is returned if a locator_id is not found in the existing schematics workspace.
3. If both a Schematics workspace_crn and a locator_id are specified, a 400 message is returned if the specified locator_id does
not agree with the locator_id in the existing Schematics workspace. For more information about creating a Schematics workspace,
see Creating workspaces and importing your Terraform template . This option provides a value for a sub-field of the JSON option
'definition'. It is mutually exclusive with that option.
$ The maximum length is `512` characters. The minimum length is `1` character. The value must match regular expression `/^(?!\\s)
(?!.*\\s$)[\\.0-9a-z-A-Z_-]+$/`.

--definition-description (string)

A project configuration description. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that
option.
The maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression /^$|^(?!\\s)
(?!.*\\s$)[^\\x00-\\x1F]*$/ .
--definition-name (string)

The configuration name. It's unique within the account across projects and regions. This option provides a value for a sub-field of the JSON option
'definition'. It is mutually exclusive with that option.
The maximum length is 128 characters. The minimum length is 1 character. The value must match regular expression /^[a-zA-Z0-9][a-zA-Z09-_ ]*$/ .
--definition-environment-id (string)

The ID of the project environment. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that option.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--definition-authorizations ( ProjectConfigAuth)

Running secure workloads 340

The authorization details. You can authorize by using a trusted profile or an API key in Secrets Manager. This option provides a value for a sub-field of
the JSON option 'definition'. It is mutually exclusive with that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

authorizations=@path/to/file.json .
--definition-inputs (generic map)

The input variables that are used for configuration definition and environment. This option provides a value for a sub-field of the JSON option
'definition'. It is mutually exclusive with that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

inputs=@path/to/file.json .
--definition-settings (generic map)

The Schematics environment variables to use to deploy the configuration. Settings are only available if they are specified when the configuration is
initially created. This option provides a value for a sub-field of the JSON option 'definition'. It is mutually exclusive with that option.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

settings=@path/to/file.json .
--definition-resource-crns ([]string)

The CRNs of the resources that are associated with this configuration. This option provides a value for a sub-field of the JSON option 'definition'. It is
mutually exclusive with that option.
The list items must match the regular expression /(?!\\s)(?!.*\\s$)^(crn)[^'" <>{}\s\x00-\x1F]*/ . The maximum length is 110 items.
The minimum length is 0` items.
Experimental

--definition-members ( StackConfigMember[])

The member deployable architectures that are included in your stack. This option provides a value for a sub-field of the JSON option 'definition'. It is
mutually exclusive with that option.
The maximum length is 100 items. The minimum length is 0 items.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --definition-

members=@path/to/file.json .

Examples
$ ibmcloud project config-update \
--project-id exampleString \
--id exampleString \
--definition '{"compliance_profile": {"id": "exampleString", "instance_id": "exampleString", "instance_location": "us-south",
"attachment_id": "exampleString", "profile_name": "exampleString"}, "locator_id": "exampleString", "description":
"exampleString", "name": "env-stage", "environment_id": "exampleString", "authorizations": {"trusted_profile_id":
"exampleString", "method": "api_key", "api_key": "exampleString"}, "inputs": {"anyKey": "anyValue"}, "settings": {"anyKey":
"anyValue"}}'

Alternatively, granular options are available for the sub-fields of JSON string options:
$ ibmcloud project config-update \
--project-id exampleString \
--id exampleString \
--definition-compliance-profile projectComplianceProfile \
--definition-locator-id exampleString \
--definition-description exampleString \
--definition-name exampleString \
--definition-environment-id exampleString \
--definition-authorizations projectConfigAuth \
--definition-inputs '{"anyKey": "anyValue"}' \
--definition-settings '{"anyKey": "anyValue"}'

ibmcloud project config-delete

Running secure workloads 341

Delete a configuration in a project by specifying its ID.
$ ibmcloud project config-delete --project-id PROJECT-ID --id ID

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .

Example
$ ibmcloud project config-delete \
--project-id exampleString \
--id exampleString

Example output
The example response to a request to delete a configuration.
{
"id" : "293c3c36-a094-4115-a12b-de0a9ca39be5"
}

ibmcloud project config-force-approve
Force approve configuration edits to the main configuration with an approving comment.
$ ibmcloud project config-force-approve --project-id PROJECT-ID --id ID --comment COMMENT

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--comment (string)

Notes on the project draft action. If this action is a force approve on the draft configuration, you must include a nonempty comment. Required.
The maximum length is 1024 characters. The minimum length is 1 character. The value must match regular expression /^(?!\\s)(?!.*\\s$)
[^\\x00-\\x1F]+$/ .

Example
$ ibmcloud project config-force-approve \
--project-id exampleString \
Running secure workloads 342

--id exampleString \
--comment 'Approving the changes'

Example output
The example response to a request for a deployable architecture configuration draft.
{
"id" : "293c3c36-a094-4115-a12b-de0a9ca39be5",
"definition" : {
"name" : "env-stage",
"description" : "The stage environment configuration.",
"locator_id" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global",
"inputs" : {
"account_id" : "ref:/configs/account-stage/inputs/account_id",
"resource_group" : "stage",
"access_tags" : [ "env:stage" ],
"logdna_name" : "The name of the LogDNA stage service instance.",
"sysdig_name" : "The name of the SysDig stage service instance."
}
},
"is_draft" : true,
"version" : 2,
"outputs" : [ {
"name" : "resource_group_id"
}, {
"name" : "logdna_id"
}, {
"name" : "sysdig_id"
} ],
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"schematics" : {
"workspace_crn" : "crn:v1:staging:public:schematics:us-south:a/38acaf4469814090a4e675dc0c317a0d:95ad49de-ab96-4e7d-a08c45c38aa448e6:workspace:us-south.workspace.service.e0106139"
},
"state" : "validated",
"update_available" : true,
"needs_attention_state" : [ ],
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/b0c44146-1ef6-40c2-82ba74d51149770a",
"deployment_mode" : "project_deployed"
}

ibmcloud project config-approve
Approve and merge configuration edits to the main configuration.
$ ibmcloud project config-approve --project-id PROJECT-ID --id ID [--comment COMMENT]

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
Running secure workloads 343

The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--comment (string)

Notes on the project draft action. If this action is a force approve on the draft configuration, you must include a nonempty comment.
The maximum length is 1024 characters. The minimum length is 1 character. The value must match regular expression /^(?!\\s)(?!.*\\s$)
[^\\x00-\\x1F]+$/ .

Example
$ ibmcloud project config-approve \
--project-id exampleString \
--id exampleString \
--comment 'Approving the changes'

Example output
The example response to a request for a deployable architecture configuration draft.
{
"id" : "293c3c36-a094-4115-a12b-de0a9ca39be5",
"definition" : {
"name" : "env-stage",
"description" : "The stage environment configuration.",
"locator_id" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global",
"inputs" : {
"account_id" : "ref:/configs/account-stage/inputs/account_id",
"resource_group" : "stage",
"access_tags" : [ "env:stage" ],
"logdna_name" : "The name of the LogDNA stage service instance.",
"sysdig_name" : "The name of the SysDig stage service instance."
}
},
"is_draft" : true,
"version" : 2,
"outputs" : [ {
"name" : "resource_group_id"
}, {
"name" : "logdna_id"
}, {
"name" : "sysdig_id"
} ],
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"schematics" : {
"workspace_crn" : "crn:v1:staging:public:schematics:us-south:a/38acaf4469814090a4e675dc0c317a0d:95ad49de-ab96-4e7d-a08c45c38aa448e6:workspace:us-south.workspace.service.e0106139"
},
"state" : "validated",
"update_available" : true,
"needs_attention_state" : [ ],
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/b0c44146-1ef6-40c2-82ba74d51149770a",
"deployment_mode" : "project_deployed"
}

ibmcloud project config-validate

Running secure workloads 344

Run a validation check on a specific configuration in the project. The check includes creating or updating the associated Schematics workspace with a plan
job, running the CRA scans, and cost estimation.
$ ibmcloud project config-validate --project-id PROJECT-ID --id ID

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .

Example
$ ibmcloud project config-validate \
--project-id exampleString \
--id exampleString

Example output
The example response to a request for a deployable architecture configuration draft.
{
"id" : "293c3c36-a094-4115-a12b-de0a9ca39be5",
"definition" : {
"name" : "env-stage",
"description" : "The stage environment configuration.",
"locator_id" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global",
"inputs" : {
"account_id" : "ref:/configs/account-stage/inputs/account_id",
"resource_group" : "stage",
"access_tags" : [ "env:stage" ],
"logdna_name" : "The name of the LogDNA stage service instance.",
"sysdig_name" : "The name of the SysDig stage service instance."
}
},
"is_draft" : true,
"version" : 2,
"outputs" : [ {
"name" : "resource_group_id"
}, {
"name" : "logdna_id"
}, {
"name" : "sysdig_id"
} ],
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"schematics" : {
"workspace_crn" : "crn:v1:staging:public:schematics:us-south:a/38acaf4469814090a4e675dc0c317a0d:95ad49de-ab96-4e7d-a08c45c38aa448e6:workspace:us-south.workspace.service.e0106139"
},
"state" : "validated",
"update_available" : true,

Running secure workloads 345

"needs_attention_state" : [ ],
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/b0c44146-1ef6-40c2-82ba74d51149770a",
"deployment_mode" : "project_deployed"
}

ibmcloud project config-deploy
Deploy a project's configuration. This operation is asynchronous and can be tracked by using the

get project configuration API with full metadata.

$ ibmcloud project config-deploy --project-id PROJECT-ID --id ID

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .

Example
$ ibmcloud project config-deploy \
--project-id exampleString \
--id exampleString

Example output
The example response to a request for a deployable architecture configuration draft.
{
"id" : "293c3c36-a094-4115-a12b-de0a9ca39be5",
"definition" : {
"name" : "env-stage",
"description" : "The stage environment configuration.",
"locator_id" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global",
"inputs" : {
"account_id" : "ref:/configs/account-stage/inputs/account_id",
"resource_group" : "stage",
"access_tags" : [ "env:stage" ],
"logdna_name" : "The name of the LogDNA stage service instance.",
"sysdig_name" : "The name of the SysDig stage service instance."
}
},
"is_draft" : true,
"version" : 2,
"outputs" : [ {
"name" : "resource_group_id"
}, {
"name" : "logdna_id"
}, {
"name" : "sysdig_id"
} ],
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},

Running secure workloads 346

"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"schematics" : {
"workspace_crn" : "crn:v1:staging:public:schematics:us-south:a/38acaf4469814090a4e675dc0c317a0d:95ad49de-ab96-4e7d-a08c45c38aa448e6:workspace:us-south.workspace.service.e0106139"
},
"state" : "validated",
"update_available" : true,
"needs_attention_state" : [ ],
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/b0c44146-1ef6-40c2-82ba74d51149770a",
"deployment_mode" : "project_deployed"
}

ibmcloud project config-undeploy
Undeploy a project's configuration resources. The operation undeploys all the resources that are deployed with the specific configuration. You can track it
by using the get project configuration API with full metadata.
$ ibmcloud project config-undeploy --project-id PROJECT-ID --id ID

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .

Example
$ ibmcloud project config-undeploy \
--project-id exampleString \
--id exampleString

Example output
The example response to a request for a deployable architecture configuration draft.
{
"id" : "293c3c36-a094-4115-a12b-de0a9ca39be5",
"definition" : {
"name" : "env-stage",
"description" : "The stage environment configuration.",
"locator_id" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global",
"inputs" : {
"account_id" : "ref:/configs/account-stage/inputs/account_id",
"resource_group" : "stage",
"access_tags" : [ "env:stage" ],
"logdna_name" : "The name of the LogDNA stage service instance.",
"sysdig_name" : "The name of the SysDig stage service instance."
}
},
"is_draft" : true,
"version" : 2,
"outputs" : [ {
"name" : "resource_group_id"

Running secure workloads 347

}, {
"name" : "logdna_id"
}, {
"name" : "sysdig_id"
} ],
"project" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "iaas-infra-prestage-env"
},
"crn" : "crn:v1:staging:public:project:us-south:a/06580c923e40314421d3b6cb40c01c68:cfbf9050-ab8e-ac97-b01b-ab5af830be8a::",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"schematics" : {
"workspace_crn" : "crn:v1:staging:public:schematics:us-south:a/38acaf4469814090a4e675dc0c317a0d:95ad49de-ab96-4e7d-a08c45c38aa448e6:workspace:us-south.workspace.service.e0106139"
},
"state" : "validated",
"update_available" : true,
"needs_attention_state" : [ ],
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/configs/b0c44146-1ef6-40c2-82ba74d51149770a",
"deployment_mode" : "project_deployed"
}

ibmcloud project config-sync
Sync a project configuration by analyzing the associated pipeline runs and Schematics workspace logs to get the configuration back to a working state.
$ ibmcloud project config-sync --project-id PROJECT-ID --id ID [--schematics SCHEMATICS | --schematics-workspace-crn SCHEMATICSWORKSPACE-CRN]

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--schematics ( SchematicsWorkspace)

A Schematics workspace to use for deploying this deployable architecture.

If you are importing data from an existing Schematics workspace that is not backed by cart, then you must provide a

locator_id . If you are

using a Schematics workspace that is backed by cart, a locator_id is not required because the Schematics workspace has one.
There are 3 scenarios:
1. If only a locator_id is specified, a new Schematics workspace is instantiated with that locator_id .
2. If only a schematics workspace_crn is specified, a 400 is returned if a locator_id is not found in the existing schematics workspace.
3. If both a Schematics workspace_crn and a locator_id are specified, a 400 code is returned if the specified locator_id does not
agree with the locator_id in the existing Schematics workspace.
For more information, see Creating workspaces and importing your Terraform template . This JSON option can instead be provided by setting individual
fields with other options. It is mutually exclusive with those options.
$ Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a `@`, for
example `--schematics=@path/to/file.json`.
Running secure workloads 348

--schematics-workspace-crn (string)

An IBM Cloud resource name that uniquely identifies a resource. This option provides a value for a sub-field of the JSON option 'schematics'. It is
mutually exclusive with that option.
The maximum length is 512 characters. The minimum length is 4 characters. The value must match the regular expression /(?!\\s)
(?!.*\\s$)^(crn)[^'" <>{}\s\x00-\x1F]*/`.

Examples
$ ibmcloud project config-sync \
--project-id exampleString \
--id exampleString \
--schematics '{"workspace_crn": "crn:v1:staging:public:schematics:us-south:a/38acaf4469814090a4e675dc0c317a0d:95ad49de-ab964e7d-a08c-45c38aa448e6:workspace:us-south.workspace.service.e0106139"}'

Alternatively, granular options are available for the sub-fields of JSON string options:
$ ibmcloud project config-sync \
--project-id exampleString \
--id exampleString \
--schematics-workspace-crn crn:v1:staging:public:project:us-south:a/4e1c48fcf8ac33c0a2441e4139f189ae:bf40ad13-b107-446a-8286c6d576183bb1::

ibmcloud project config-resources
List resources that are deployed by a configuration.
$ ibmcloud project config-resources --project-id PROJECT-ID --id ID

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .

Example
$ ibmcloud project config-resources \
--project-id exampleString \
--id exampleString

Example output
The example response to a request to get project configuration resources.
{
"resources" : [ {
"resource_crn" : "crn:v1:staging:public:toolchain:us-south:a/4e1c48fcf8ac33c0a2441e4139f189ae:bf40ad13-b107-446a-8286c6d576183bb1::",
"resource_name" : "toolchain_instance",
"resource_type" : "ibm_cd_toolchain",

Running secure workloads 349

"resource_tainted" : false,
"resource_group_name" : ""
}, {
"resource_crn" : "crn:v1:staging:public:cloud-object-storage:global:a/4e1c48fcf8ac33c0a2441e4139f189ae:bf40ad13-b107-446a8286-c6d576183bb1::",
"resource_name" : "cos_bucket_instance",
"resource_type" : "ibm_cos_bucket",
"resource_tainted" : false,
"resource_group_name" : ""
} ],
"resources_count" : 2
}

ibmcloud project stack-definition-create
Experimental

Defines inputs at the stack level that users need to configure along with input values at the member level. These values are included in the catalog entry
when the deployable architecture stack is exported to a private catalog. They are required for the deployable architecture stack to deploy. You can add a
reference to a value, or add the value explicitly at the member level.
$ ibmcloud project stack-definition-create --project-id PROJECT-ID --id ID [--stack-definition STACK-DEFINITION | --stackdefinition-inputs STACK-DEFINITION-INPUTS --stack-definition-outputs STACK-DEFINITION-OUTPUTS]

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--stack-definition ( StackDefinitionBlockPrototype )

The definition block for a stack definition. This JSON option can instead be provided by setting individual fields with other options. It is mutually
exclusive with those options.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --stack-

definition=@path/to/file.json .
--stack-definition-inputs ( StackDefinitionInputVariable[])

Defines the inputs that users need to configure at the stack level. These inputs are included in the catalog entry when the deployable architecture
stack is exported to a private catalog. This option provides a value for a sub-field of the JSON option 'stack-definition'. It is mutually exclusive with
that option.
The maximum length is 100 items. The minimum length is 0 items.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --stack-

definition-inputs=@path/to/file.json .
--stack-definition-outputs ( StackDefinitionOutputVariable[])

The outputs associated with this stack definition. This option provides a value for a sub-field of the JSON option 'stack-definition'. It is mutually
exclusive with that option.
The maximum length is 100 items. The minimum length is 0 items.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --stack-

definition-outputs=@path/to/file.json .

Running secure workloads 350

Examples
$ ibmcloud project stack-definition-create \
--project-id exampleString \
--id exampleString \
--stack-definition '{"inputs": [{"name": "region", "type": "string", "description": "exampleString", "default": "us-south",
"required": true, "hidden": false}], "outputs": [{"name": "vpc_cluster_id", "value": "cluster_id"}]}'

Alternatively, granular options are available for the sub-fields of JSON string options:
$ ibmcloud project stack-definition-create \
--project-id exampleString \
--id exampleString \
--stack-definition-inputs '[stackDefinitionInputVariable]' \
--stack-definition-outputs '[stackDefinitionOutputVariable]'

Example output
Sample response from a create stack template operation.
{
"id" : "293c3c36-a094-4115-a12b-de0a9ca6678a",
"stack_definition" : {
"inputs" : [ {
"name" : "region",
"type" : "string",
"required" : true,
"default" : "us-south",
"hidden" : false
}, {
"name" : "resource_group",
"type" : "string",
"default" : "Default"
} ],
"outputs" : [ {
"name" : "vpc_cluster_id",
"value" : "cluster_id"
} ],
"members" : [ {
"name" : "foundation-deployable-architecture",
"version_locator" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global",
"inputs" : [ {
"name" : "region",
"value" : "us-south"
}, {
"name" : "cluster_name",
"value" : "foundation-cluster"
} ]
}, {
"name" : "middleware-architecture",
"version_locator" : "01e1a9ad-534b-4ab9-996a-b8f2a8653d5c.4d86732e-04b9-4dab-bfdc-5b514d86ecd8",
"inputs" : [ {
"name" : "kube_version",
"value" : 1.29
} ]
} ]
},
"state" : "draft",
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"configuration" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "stack-bottom-up-example"
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/template"
}

Running secure workloads 351

ibmcloud project stack-definition
Experimental

Retrieve the stack definition that is associated to the configuration.
$ ibmcloud project stack-definition --project-id PROJECT-ID --id ID

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .

Example
$ ibmcloud project stack-definition \
--project-id exampleString \
--id exampleString

Example output
Sample response from a create stack template operation.
{
"id" : "293c3c36-a094-4115-a12b-de0a9ca6678a",
"stack_definition" : {
"inputs" : [ {
"name" : "region",
"type" : "string",
"required" : true,
"default" : "us-south",
"hidden" : false
}, {
"name" : "resource_group",
"type" : "string",
"default" : "Default"
} ],
"outputs" : [ {
"name" : "vpc_cluster_id",
"value" : "cluster_id"
} ],
"members" : [ {
"name" : "foundation-deployable-architecture",
"version_locator" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global",
"inputs" : [ {
"name" : "region",
"value" : "us-south"
}, {
"name" : "cluster_name",
"value" : "foundation-cluster"
} ]
}, {
"name" : "middleware-architecture",
"version_locator" : "01e1a9ad-534b-4ab9-996a-b8f2a8653d5c.4d86732e-04b9-4dab-bfdc-5b514d86ecd8",
"inputs" : [ {
"name" : "kube_version",
"value" : 1.29
} ]
Running secure workloads 352

} ]
},
"state" : "draft",
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"configuration" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "stack-bottom-up-example"
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/template"
}

ibmcloud project stack-definition-update
Experimental

Update the stack definition that is associated with the configuration.
$ ibmcloud project stack-definition-update --project-id PROJECT-ID --id ID [--stack-definition STACK-DEFINITION | --stackdefinition-inputs STACK-DEFINITION-INPUTS --stack-definition-outputs STACK-DEFINITION-OUTPUTS]

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--stack-definition ( StackDefinitionBlockPrototype )

The definition block for a stack definition. This JSON option can instead be provided by setting individual fields with other options. It is mutually
exclusive with those options.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --stack-

definition=@path/to/file.json .
--stack-definition-inputs ( StackDefinitionInputVariable[])

Defines the inputs that users need to configure at the stack level. These inputs are included in the catalog entry when the deployable architecture
stack is exported to a private catalog. This option provides a value for a sub-field of the JSON option 'stack-definition'. It is mutually exclusive with
that option.
The maximum length is 100 items. The minimum length is 0 items.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --stack-

definition-inputs=@path/to/file.json .
--stack-definition-outputs ( StackDefinitionOutputVariable[])

The outputs associated with this stack definition. This option provides a value for a sub-field of the JSON option 'stack-definition'. It is mutually
exclusive with that option.
The maximum length is 100 items. The minimum length is 0 items.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --stack-

definition-outputs=@path/to/file.json .

Running secure workloads 353

Examples
$ ibmcloud project stack-definition-update \
--project-id exampleString \
--id exampleString \
--stack-definition '{"inputs": [{"name": "region", "type": "string", "description": "exampleString", "default": "eu-gb",
"required": true, "hidden": false}], "outputs": [{"name": "exampleString", "value": "exampleString"}]}'

Alternatively, granular options are available for the sub-fields of JSON string options:
$ ibmcloud project stack-definition-update \
--project-id exampleString \
--id exampleString \
--stack-definition-inputs '[stackDefinitionInputVariable]' \
--stack-definition-outputs '[stackDefinitionOutputVariable]'

Example output
Sample response from a patch stack template operation.
{
"id" : "293c3c36-a094-4115-a12b-de0a9ca6678a",
"stack_definition" : {
"inputs" : [ {
"name" : "region",
"type" : "string",
"required" : true,
"default" : "eu-gb",
"hidden" : false
} ],
"outputs" : [ {
"name" : "vpc_cluster_id",
"value" : "cluster_id"
} ],
"members" : [ {
"name" : "foundation-deployable-architecture",
"version_locator" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global",
"inputs" : [ {
"name" : "cluster_name",
"value" : "foundation-cluster"
} ]
} ]
},
"state" : "draft",
"created_at" : "2023-02-22T19:51:23.253Z",
"modified_at" : "2023-02-22T19:51:23.253Z",
"configuration" : {
"id" : "cfbf9050-ab8e-ac97-b01b-ab5af830be8a",
"definition" : {
"name" : "stack-bottom-up-example"
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a"
},
"href" : "https://projects.api.cloud.ibm.com/v1/projects/cfbf9050-ab8e-ac97-b01b-ab5af830be8a/template"
}

ibmcloud project stack-definition-export
Experimental

Exports the deployable architecture stack to a private catalog. All member deployable architectures within the stack must be validated and deployed
before the stack is exported. The stack definition must also exist before the stack is exported. You can export the stack as a new product, or as a new
version of an existing product.
$ ibmcloud project stack-definition-export --project-id PROJECT-ID --id ID [--settings SETTINGS | --settings-catalog-id
SETTINGS-CATALOG-ID --settings-target-version SETTINGS-TARGET-VERSION --settings-variation SETTINGS-VARIATION --settings-label
SETTINGS-LABEL --settings-tags SETTINGS-TAGS --settings-product-id SETTINGS-PRODUCT-ID]

Running secure workloads 354

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--settings ( StackDefinitionExportRequest)

The payload for the private catalog export request. This JSON option can instead be provided by setting individual fields with other options. It is
mutually exclusive with those options.
Provide a JSON string option or specify a JSON file to read from by providing a filepath option that begins with a

@ , for example --

settings=@path/to/file.json .
--settings-catalog-id (string)

The catalog ID to publish. This option provides a value for a sub-field of the JSON option 'settings'. It is mutually exclusive with that option.
The maximum length is 36 characters. The value must match regular expression /^[\\-0-9a-zA-Z]+$/ .
--settings-target-version (string)

The server value of this new version of the product. This option provides a value for a sub-field of the JSON option 'settings'. It is mutually exclusive
with that option.
The maximum length is 60 characters. The minimum length is 5 characters. The value must match regular expression /^(0|[1-9]\\d*)\\.(0|
[1-9]\\d*)\\.(0|[1-9]\\d*)(?:-((?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\.(?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?
(?:\\+([0-9a-zA-Z-]+(?:\\.[0-9a-zA-Z-]+)*))?$/ .
--settings-variation (string)

The variation of this new version of the product. This option provides a value for a sub-field of the JSON option 'settings'. It is mutually exclusive with
that option.
The maximum length is 128 characters. The value must match regular expression /^[a-zA-Z0-9][a-zA-Z0-9-_ ]*$/ .
--settings-label (string)

The product label. This option provides a value for a sub-field of the JSON option 'settings'. It is mutually exclusive with that option.
The maximum length is 128 characters. The value must match regular expression /^[a-zA-Z0-9][a-zA-Z0-9-_ ]*$/ .
--settings-tags ([]string)

Tags associated with the catalog product. This option provides a value for a sub-field of the JSON option 'settings'. It is mutually exclusive with that
option.
The list items must match regular expression /^[a-zA-Z0-9][a-zA-Z0-9-_]*$/ . The maximum length is 10 items. The minimum length is 0
items.
--settings-product-id (string)

The product ID to publish. This option provides a value for a sub-field of the JSON option 'settings'. It is mutually exclusive with that option.
The maximum length is 36 characters. The value must match regular expression /^[\\-0-9a-zA-Z]+$/ .

Examples
$ ibmcloud project stack-definition-export \
--project-id exampleString \
--id exampleString \
--settings '{"catalog_id": "01e1a9ad-534b-4ab9-996a-b8f2a8653d5c", "target_version": "exampleString", "variation":
Running secure workloads 355

"exampleString", "label": "Stack Deployable Architecture", "tags": ["exampleString","anotherTestString"]}'

Alternatively, granular options are available for the sub-fields of JSON string options:
$ ibmcloud project stack-definition-export \
--project-id exampleString \
--id exampleString \
--settings-catalog-id exampleString \
--settings-target-version exampleString \
--settings-variation exampleString \
--settings-label exampleString \
--settings-tags exampleString,anotherTestString

Example output
Sample response from exporting a stack definition to the private catalog
{
"catalog_id" : "01e1a9ad-534b-4ab9-996a-b8f2a8653d5c",
"product_id" : "b60b5876-d074-478a-ac73-f979898c527b",
"version_locator" : "01e1a9ad-534b-4ab9-996a-b8f2a8653d5c.f9f73bdb-5c7d-4ea6-82ef-9debc6340df8",
"kind" : "terraform",
"format" : "stack"
}

ibmcloud project config-versions
Retrieve a list of previous and current versions of a project configuration in a specific project.
$ ibmcloud project config-versions --project-id PROJECT-ID --id ID

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .

Example
$ ibmcloud project config-versions \
--project-id exampleString \
--id exampleString

Example output
The example response to a request to list project configuration drafts.
{
"versions" : [ {
"definition" : {
"locator_id" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global"
},
"version" : 1,
"state" : "approved",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/db268db0-160b-4911-8f93-89659000a927/configs/293c3c36-a094-4115a12b-de0a9ca39be5/versions/1"
}, {

Running secure workloads 356

"definition" : {
"locator_id" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global"
},
"version" : 2,
"state" : "validated",
"href" : "https://projects.api.cloud.ibm.com/v1/projects/db268db0-160b-4911-8f93-89659000a927/configs/293c3c36-a094-4115a12b-de0a9ca39be5/versions/2"
} ]
}

ibmcloud project config-version
Retrieve a specific version of a configuration in a project.
$ ibmcloud project config-version --project-id PROJECT-ID --id ID --version VERSION

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--version (int64)

The configuration version. Required.

Example
$ ibmcloud project config-version \
--project-id exampleString \
--id exampleString \
--version 38

ibmcloud project config-version-delete
Delete a configuration version by specifying the project ID.
$ ibmcloud project config-version-delete --project-id PROJECT-ID --id ID --version VERSION

Command options
--project-id (string)

The unique project ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--id (string)

The unique configuration ID. Required.
The maximum length is 128 characters. The value must match regular expression /^[\\.\\-0-9a-zA-Z]+$/ .
--version (int64)

The configuration version. Required.

Running secure workloads 357

Example
$ ibmcloud project config-version-delete \
--project-id exampleString \
--id exampleString \
--version 38

Example output
The example response to a request to delete a configuration.
{
"id" : "293c3c36-a094-4115-a12b-de0a9ca39be5"
}

Schema examples
The following schema examples represent the data that you need to specify for a command option. These examples model the data structure and include
placeholder values for the expected value type. When you run a command, replace these values with the values that apply to your environment as
appropriate.

EnvironmentDefinitionPropertiesPatch
The following example shows the format of the EnvironmentDefinitionPropertiesPatch object.

{
"description" : "The environment development.",
"name" : "development",
"authorizations" : {
"trusted_profile_id" : "Profile-9ac10c5c-195c-41ef-b465-68a6b6dg5f12",
"method" : "trusted_profile",
"api_key" : "exampleString"
},
"inputs" : {
"anyKey" : "anyValue"
},
"compliance_profile" : {
"id" : "some-profile-id",
"instance_id" : "some-instance-id",
"instance_location" : "us-south",
"attachment_id" : "some-attachment-id",
"profile_name" : "some-profile-name"
}
}

EnvironmentDefinitionRequiredProperties
The following example shows the format of the EnvironmentDefinitionRequiredProperties object.

{
"description" : "The environment development.",
"name" : "development",
"authorizations" : {
"trusted_profile_id" : "Profile-9ac10c5c-195c-41ef-b465-68a6b6dg5f12",
"method" : "trusted_profile",
"api_key" : "exampleString"
},
"inputs" : {
"anyKey" : "anyValue"
},
"compliance_profile" : {
"id" : "some-profile-id",
"instance_id" : "some-instance-id",
"instance_location" : "us-south",
"attachment_id" : "some-attachment-id",
"profile_name" : "some-profile-name"

Running secure workloads 358

}
}

EnvironmentPrototype[]
The following example shows the format of the EnvironmentPrototype[] object.

[ {
"definition" : {
"description" : "exampleString",
"name" : "exampleString",
"authorizations" : {
"trusted_profile_id" : "exampleString",
"method" : "api_key",
"api_key" : "exampleString"
},
"inputs" : {
"anyKey" : "anyValue"
},
"compliance_profile" : {
"id" : "exampleString",
"instance_id" : "exampleString",
"instance_location" : "us-south",
"attachment_id" : "exampleString",
"profile_name" : "exampleString"
}
}
} ]

ProjectComplianceProfile
The following example shows the format of the ProjectComplianceProfile object.

{
"id" : "some-profile-id",
"instance_id" : "some-instance-id",
"instance_location" : "us-south",
"attachment_id" : "some-attachment-id",
"profile_name" : "some-profile-name"
}

ProjectConfigAuth
The following example shows the format of the ProjectConfigAuth object.

{
"trusted_profile_id" : "Profile-9ac10c5c-195c-41ef-b465-68a6b6dg5f12",
"method" : "trusted_profile",
"api_key" : "exampleString"
}

ProjectConfigDefinitionPatch
The following example shows the format of the ProjectConfigDefinitionPatch object.

{
"compliance_profile" : {
"id" : "exampleString",
"instance_id" : "exampleString",
"instance_location" : "us-south",
"attachment_id" : "exampleString",
"profile_name" : "exampleString"
},
"locator_id" : "exampleString",

Running secure workloads 359

"description" : "exampleString",
"name" : "env-stage",
"environment_id" : "exampleString",
"authorizations" : {
"trusted_profile_id" : "exampleString",
"method" : "api_key",
"api_key" : "exampleString"
},
"inputs" : {
"anyKey" : "anyValue"
},
"settings" : {
"anyKey" : "anyValue"
}
}

ProjectConfigDefinitionPrototype
The following example shows the format of the ProjectConfigDefinitionPrototype object.

{
"compliance_profile" : {
"id" : "exampleString",
"instance_id" : "exampleString",
"instance_location" : "us-south",
"attachment_id" : "exampleString",
"profile_name" : "exampleString"
},
"locator_id" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global",
"description" : "The stage environment configuration.",
"name" : "env-stage",
"environment_id" : "exampleString",
"authorizations" : {
"trusted_profile_id" : "exampleString",
"method" : "api_key",
"api_key" : "exampleString"
},
"inputs" : {
"anyKey" : "anyValue"
},
"settings" : {
"anyKey" : "anyValue"
}
}

ProjectConfigPrototype[]
The following example shows the format of the ProjectConfigPrototype[] object.

[ {
"definition" : {
"compliance_profile" : {
"id" : "exampleString",
"instance_id" : "exampleString",
"instance_location" : "us-south",
"attachment_id" : "exampleString",
"profile_name" : "exampleString"
},
"locator_id" : "1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global",
"description" : "The stage account configuration.",
"name" : "account-stage",
"environment_id" : "exampleString",
"authorizations" : {
"trusted_profile_id" : "exampleString",
"method" : "api_key",
"api_key" : "exampleString"
},
"inputs" : {
Running secure workloads 360

"anyKey" : "anyValue"
},
"settings" : {
"anyKey" : "anyValue"
}
},
"schematics" : {
"workspace_crn" : "crn:v1:staging:public:project:us-south:a/4e1c48fcf8ac33c0a2441e4139f189ae:bf40ad13-b107-446a-8286c6d576183bb1::"
}
} ]

ProjectPatchDefinitionBlock
The following example shows the format of the ProjectPatchDefinitionBlock object.

{
"name" : "acme-microservice",
"destroy_on_delete" : true,
"auto_deploy" : true,
"description" : "A microservice to deploy on top of ACME infrastructure.",
"monitoring_enabled" : true
}

ProjectPrototypeDefinition
The following example shows the format of the ProjectPrototypeDefinition object.

{
"name" : "acme-microservice",
"destroy_on_delete" : true,
"description" : "A microservice to deploy on top of ACME infrastructure.",
"auto_deploy" : false,
"monitoring_enabled" : false
}

SchematicsWorkspace
The following example shows the format of the SchematicsWorkspace object.

{
"workspace_crn" : "crn:v1:staging:public:project:us-south:a/4e1c48fcf8ac33c0a2441e4139f189ae:bf40ad13-b107-446a-8286c6d576183bb1::"
}

StackDefinitionBlockPrototype
Experimental

The following example shows the format of the StackDefinitionBlockPrototype object.

{
"inputs" : [ {
"name" : "region",
"type" : "string",
"description" : "exampleString",
"default" : "us-south",
"required" : true,
"hidden" : false
} ],
"outputs" : [ {
"name" : "vpc_cluster_id",
"value" : "cluster_id"
} ]

Running secure workloads 361

}

StackDefinitionExportRequest
Experimental

The following example shows the format of the StackDefinitionExportRequest object.

{
"catalog_id" : "01e1a9ad-534b-4ab9-996a-b8f2a8653d5c",
"target_version" : "exampleString",
"variation" : "exampleString",
"label" : "Stack Deployable Architecture",
"tags" : [ "exampleString", "anotherExampleString" ]
}

Other relevant commands for IBM Cloud projects
The following commands are not a part of the projects CLI plug-in, but you can use them to complete project-related tasks, such as attaching tags to a
project. This list is not exhaustive of all of the relevant commands that are available to use with projects. Rather, this list is a starting point for you to explore
other commands that you can use with projects.
Important: Some of the following commands might require the installation of their specific plug-ins before you can run them.
Run ibmcloud resource tag-attach to attach tags to a project:
$ ibmcloud resource tag-attach --tag-names TAG --resource-id PROJECT-CRN

Run ibmcloud resource search to retrieve all of the resources in an account created by configurations in a project:
$ ibmcloud resource search "service_tags:\"schematics::project_id:PROJECT_ID\""

Run ibmcloud schematics logs to retrieve the log files for a Schematics workspace:
$ ibmcloud schematics logs --id WORKSPACE_ID [--act-id ACTION_ID]

Project CLI change log
In this change log, you can learn about the latest changes, improvements, and updates for the Project CLI.

Version 0.0.37
Version 0.0.37 of the CLI was released on 3 April 2024.
In this release, the following changes impact the pagination of listing commands. For more information, see the

pagination section of the Projects API

docs. The in-line option --start was renamed to --token for all listing commands. For example, the project list command now uses --token
instead of --start as an option.
Listing commands return 10 records by default if the page size is not specified by the

--limit option. Alternatively, the --all-pages option returns

every record available.
Added experimental commands to support stacking deployable architectures.

Version 0.0.25
Version 0.0.25 of the CLI was released on 6 November 2023.
In this release, the create and update JSON properties match the get JSON properties with separation between the server-controlled attributes and
the user-supplied attributes. The commands are normalized so that they follow a regular pattern. Terminology was also aligned to use validate ,
deploy , and undeploy .

Updated the following commands:
All commands that impact configurations now begin with config instead of project .
Running secure workloads 362

The project create , project update , config-create , and config-update commands now use the definition construct to replace individual
parameters like name and description .
The project config-install command is replaced by the config-deploy command.
The project config-uninstall command is replaced by the config-undeploy command.
The project list-config-drafts command is replaced by the config-versions command.
The project config-draft-get command is replaced by the config-version-get command.
Added the following commands:
The config-version-delete command deletes a version of a configuration.
The environment-create command creates an environment.
The environment-update command edits an environment.
The environment-delete command deletes an environment.
The environment command returns an environment.
The environments command returns all environments.

Searching and managing the IBM Cloud catalog (ibmcloud catalog)
Use the following commands from the IBM Cloud® Command Line Interface to manage the IBM Cloud catalog entries, query templates, runtimes, and
geolocations of data centers.
Note: You can use extra CLI commands and capabilities for catalogs. Use the Catalogs management CLI plug-in to manage your private catalogs
and onboard new private software. For more information, see the Catalogs management CLI plug-in.

ibmcloud catalog entry
Get a catalog entry:
ibmcloud catalog entry ID [--children] [--global]

Command options
--children
Get all children for the catalog entry
--global
Operate in global scope

Examples
Get entry with ID a0ef1-d3b4j0 :
ibmcloud catalog entry 'a0ef1-d3b4j0'

ibmcloud catalog entry-create
Create a catalog entry (catalog admin of an account only):
ibmcloud catalog entry-create [-c PARAMETERS_AS_JSON] [-p, --parent PARENT] [--global]

Command options
-p, --parent
Parent ID of the object
-c

Running secure workloads 363

Valid JSON object that contains catalog-specific configuration parameters, provided either inline or in a file. For a list of supported configuration
parameters, see the documentation for the particular catalog entry.
--global
Operate in global scope

Examples
Create resource from JSON file with parent ID a0ef1-d3b4j0 :
ibmcloud catalog entry-create -c @entry.json -p 'a0ef1-d3b4j0'

ibmcloud catalog entry-update
Update an existing catalog entry (catalog admin or editor of an account only):
ibmcloud catalog entry-update ID [-c PARAMETERS_AS_JSON] [--global]

Command options
-c
Valid JSON object that contains catalog-specific configuration parameters, provided either inline or in a file. For a list of supported configuration
parameters, see the documentation for the particular catalog entry.
--global
Operate in global scope

Examples
Update resource j402-dnf1i from JSON file:
ibmcloud catalog entry-update 'j402-dnf1i' -c update

ibmcloud catalog entry-delete
Delete a catalog entry(catalog admin of an account only)
ibmcloud catalog entry-delete ID [--global]

Command options
--global
Operate in global scope

Examples
Delete resource j402-dnf1i :
ibmcloud catalog delete `j402-dnf1i`

ibmcloud catalog entry-visibility
Get the visibility for a catalog entry(catalog admin of an account only)
ibmcloud catalog entry-visibility ID [--global]

Running secure workloads 364

Command options
--global
Operate in global scope

Examples
Get visibility of resource j402-dnf1i in global scope:
ibmcloud catalog entry-visibility 'j402-dnf1i' --global

ibmcloud catalog entry-visibility-set
Update the visibility of an existing catalog entry(catalog admin of an account only):
ibmcloud catalog entry-visibility-set ID [--includes-add LIST] [--includes-remove LIST] [--excludes-add LIST] [--excludes-remove
LIST] [--owner ID or Email] [--restrict] [--unrestrict] [-c PARAMETERS_AS_JSON] [--global]

Command options
--includes-add
Adding an account (or list of comma-separated accounts) to the includes list, granting visibility to the entry. Email or Account GUIDs are acceptable.
--includes-remove
Removing an account (or list of comma-separated accounts) from the includes list, revoking visibility to the entry. Email or Account GUIDs are
acceptable.
--excludes-add
Adding an account (or list of comma-separated accounts) to the excludes list. Email or Account GUIDs are acceptable.
--excludes-remove
Removing an account (or list of comma-separated accounts) from the excludes list, revoking visibility to the entry. If the account was set by global
admins, the account admins can't remove the account. Email or Account GUIDs are acceptable.
--owner
Changing the owner of an object. Email or Account GUIDs are acceptable.
--restrict
Changing the restriction of the visibility object to 'Private'.
--unrestrict
Changing the restriction of the visibility object to 'Public'.
-c
Valid JSON object that contains catalog-specific configuration parameters, provided either inline or in a file. For a list of supported configuration
parameters, see the documentation for the particular catalog entry.
--global
Operate in global scope

Examples
Set visibility of resource j402-dnf1i from JSON file:
ibmcloud catalog entry-visibility-set 'j402-dnf1i' -c @visibility.json

ibmcloud catalog service-marketplace
Running secure workloads 365

List service offerings in the marketplace:
ibmcloud catalog service-marketplace [--rc] [--global]

Command options
--rc
Show RC compatible services only
--global
Operate in global scope

Examples
Show service offerings in global scope:
ibmcloud catalog service-marketplace --global

ibmcloud catalog service
View details of a service in the catalog, including a description, tags, compatibility information, and available plans.
$ ibmcloud catalog service NAME_OR_ID [--global]

Command options
--global
Operate in a global scope

Examples
Show details of the container-kubernetes service:
ibmcloud catalog service container-kubernetes

ibmcloud catalog templates
View the boilerplate templates on IBM Cloud.
$ ibmcloud catalog templates [-d]

Command options
-d (optional)
If the -d option is specified, the description of each template is also displayed. Otherwise, only the ID and name of each template is shown.

ibmcloud catalog template
View the detailed information of a specified boilerplate template.
ibmcloud catalog template TEMPLATE_ID

Command options
Running secure workloads 366

TEMPLATE_ID (required)
The ID of the boilerplate template. Use ibmcloud templates to view all templates' IDs.

Examples
View details of the template mobileBackendStarter :
ibmcloud catalog template mobileBackendStarter

ibmcloud catalog locations
Get a choice subset of regions in your choice of format.
ibmcloud catalog locations [-i, --id ID] [-k, --kind KIND] [--col COLUMNS] [--global] [--csv]

Command options
-i, --id
Specify geography by id.
-k, --kind
Get a list of entries for the specified kind.
--col
Specify more columns for the table. Currently, "group", "provider", and "tags".
--global
Operate in a global scope.
--csv
Output CSV file

ibmcloud catalog runtime
View the details of a runtime. This command is only available for public cloud.
ibmcloud catalog runtime RUNTIME_ID

Examples
Show details of runtime "nodejsHelloWorld":
ibmcloud catalog runtime nodejsHelloWorld

ibmcloud catalog runtimes
List all runtimes. This command is only available for public cloud.
ibmcloud catalog runtimes [-d]

Command options
-d
Show the description of each runtime

Running secure workloads 367

Examples
List all runtimes along with their descriptions:
ibmcloud catalog runtimes -d

Working with resources and resource groups (ibmcloud resource)
A resource group is a way for you to organize your account resources in customizable groupings. Use the following commands from the IBM Cloud®
Command Line Interface to manage IBM Cloud resources in a resource group.

ibmcloud resource groups
List resource groups.
ibmcloud resource groups [--default]

Command options
--default
Get the default group of the current account.

Examples
List all resource groups under the currently targeted account:
ibmcloud resource groups

List the default group of currently targeted account:
ibmcloud resource groups --default

ibmcloud resource group
Show details of a resource group
ibmcloud resource group NAME [--id]

Command options
NAME (required)
Name of the resource group
--id
Show ID only

Examples
Show resource group example-group :
ibmcloud resource group example-group

Show only ID of resource group example-group :
ibmcloud resource group example-group --id

Running secure workloads 368

ibmcloud resource group-create
Create a resource group:
ibmcloud resource group-create NAME

Command options
NAME (required)
Name of the resource group

Examples
Create a resource group example-group :
ibmcloud resource group-create example-group

ibmcloud resource group-update
Update an existing resource group
ibmcloud resource group-update NAME [-n, --name NEW_NAME] [-f, --force]

Command options
NAME (required)
Name of the target resource group
-n, --name
New name of the resource group
-f, --force
Force update without confirmation

Examples
Rename resource group example-group to trial-group :
ibmcloud resource group-update example-group -n trial-group

ibmcloud resource group-delete
Delete an existing resource group
ibmcloud resource group-delete NAME [-f, --force]

Command options
NAME (required)
Name of the target resource group
-f, --force
Force deletion without confirmation

Running secure workloads 369

Examples
Delete resource group example-group :
ibmcloud resource group-delete example-group -f

ibmcloud resource quotas
List all quota definitions.
ibmcloud resource quotas

Examples
List all quota definitions:
ibmcloud resource quotas

ibmcloud resource quota
Show details of a quota definition.
ibmcloud resource quota NAME

Command options
NAME (required)
Name of the quota

Examples
Show details of quota free :
ibmcloud resource quota free

ibmcloud resource service-instances
List service instances.
ibmcloud resource service-instances [--service-name SERVICE_NAME] [--location LOCATION] [--type INSTANCE_TYPE] [-g RESOURCE_GROUP
| --all-resource-groups] [--long] [--limit LIMIT] [--offset OFFSET] [--output FORMAT] [-q, --quiet]

Command options
--service-name SERVICE_NAME
Name of belonging to service
--location LOCATION
Filter by location
--type INSTANCE_TYPE
Type of instances. The service_instance type is used if not specified. Use all to list all types of instances.
-g RESOURCE_GROUP
Resource group name
--all-resource-groups
Query all resource groups

Running secure workloads 370

--long
Show more fields in output
--limit LIMIT
Number of resources to return
--offset OFFSET
Starting resource position number
--output FORMAT
Specify the output format. Only JSON is supported now.
-q, --quiet
Suppress verbose output.

Examples
List service instances of service test-service :
$ ibmcloud resource service-instances --service-name test-service

List next page of service instances with page size of 10
ibmcloud resource service-instances --offset 1 --limit 10

ibmcloud resource service-instance
Show details of a service instance.
ibmcloud resource service-instance (NAME|ID) [--location LOCATION] [--id]

Command options
NAME (required), exclusive with ID
Name of the service instance
ID (required), exclusive with NAME
ID of the service instance
--location
Filter by location
--id
Display the ID of the service instance

Examples
Show details of service instance my-service-instance :
ibmcloud resource service-instance my-service-instance

ibmcloud resource service-instance-create
Create a service instance.
ibmcloud resource service-instance-create NAME (SERVICE_NAME | SERVICE_ID) SERVICE_PLAN_NAME LOCATION [-d, --deployment
DEPLOYMENT_NAME] [-p, --parameters @JSON_FILE | JSON_STRING ] [-g RESOURCE_GROUP] [--service-endpoints SERVICE_ENDPOINTS_TYPE] [-allow-cleanup] [--lock] [--subscription SUBSCRIPTION_ID]

Running secure workloads 371

Command options
NAME (required)
Name of the service instance
SERVICE_NAME or SERVICE_ID (required)
Name or ID of the service. To list service offerings, use the

ibmcloud catalog service-marketplace command.

SERVICE_PLAN_NAME or SERVICE_PLAN_ID (required)
Name or ID of the service plan
LOCATION (required)
Target location or environment to create the service instance
-d, --deployment DEPLOYMENT_NAME
Name of the deployment
-p, --parameters @JSONFILE or JSON_STRING
JSON file or JSON string of parameters to create service instance
-g RESOURCE_GROUP
Resource group name
--service-endpoints SERVICE_ENDPOINTS_TYPE
Types of the service endpoints. Possible values are 'public', 'private', 'public-and-private'. The default value for service endpoints is the type that is
configured by the service in IBM Cloud®.
--allow-cleanup
Whether the service instance should be deleted (cleaned up) during the processing of a region instance delete call
--lock
Whether to create the service instance with locked state
--subscription
Subscription ID associated with this service and plan

Examples
Create a service instance that is named my-service-instance that uses service plan test-service-plan of service test-service on location eugb :
ibmcloud resource service-instance-create my-service-instance test-service test-service-plan eu-gb

ibmcloud resource service-instance-update
Update service instance.
ibmcloud resource service-instance-update ( NAME | ID ) [-n, --name NEW_NAME] [--service-plan-id SERVICE_PLAN_ID] [-p, -parameters @JSON_FILE | JSON_STRING ] [-g RESOURCE_GROUP] [--service-endpoints SERVICE_ENDPOINTS_TYPE] [-f, --force]

Command options
Name (required)
Name of the service instance, exclusive with ID
ID (required)
ID of the service instance, exclusive with NAME
-n, --name NEW_NAME
New service instance name
Running secure workloads 372

--service-plan-id SERVICE_PLAN_ID
New Service Plan ID
-p, --parameters @JSON_FILE | JSON_STRING
JSON file or JSON string of parameters to create service instance
-g RESOURCE_GROUP
Resource group name
--service-endpoints SERVICE_ENDPOINTS_TYPE
Types of the service endpoints. Possible values are 'public', 'private', 'public-and-private'.
-f, --force
Force update without confirmation

Examples
Update service instance my-service-instance , change its name to new-service-instance :
ibmcloud resource service-instance-update my-service-instance -n new-service-instance

ibmcloud resource service-instance-delete
Delete the service instance. If provisioning is in progress, the command attempts to cancel the provisioning process. Some services might not support
cancellation.
ibmcloud resource service-instance-delete (NAME|ID) [-f, --force] [--recursive]

Command options
Name (required)
Name of the service instance, exclusive with ID
ID (required)
ID of the service instance, exclusive with NAME
-f, --force
Force deletion without confirmation
--recursive
Delete all belonging resources

Examples
Delete resource service-instance my-service-instance :
ibmcloud resource service-instance-delete my-service-instance

ibmcloud resource service-instance-lock
Lock service instance.
ibmcloud resource service-instance-lock ( NAME | ID ) [-g RESOURCE_GROUP] [-f, --force]

Command options
Name (required)

Running secure workloads 373

Name of the service instance, exclusive with ID
ID (required)
ID of the service instance, exclusive with NAME
-g RESOURCE_GROUP
Resource group name
-f, --force
Force locking without confirmation

Examples
Lock resource service-instance my-service-instance :
ibmcloud resource service-instance-lock my-service-instance

ibmcloud resource service-instance-unlock
Unlock the service instance.
ibmcloud resource service-instance-unlock ( NAME | ID ) [-g RESOURCE_GROUP] [-f, --force]

Command options
Name (required)
Name of the service instance, exclusive with ID
ID (required)
ID of the service instance, exclusive with NAME
-g RESOURCE_GROUP
Resource group name
-f, --force
Force locking without confirmation

Examples
Unlock resource service-instance my-service-instance :
ibmcloud resource service-instance-unlock my-service-instance

ibmcloud resource service-keys
List service keys of service instance.
ibmcloud resource service-keys [ --instance-id ID | --instance-name NAME ]

Command options
--instance-id
Service Instance ID
--instance-name
Service Instance Name

Running secure workloads 374

Examples
List service keys of service instance my-service-instance :
ibmcloud resource service-keys --instance-name my-service-instance

ibmcloud resource service-key
Displays the details of any number of service keys, where the first n characters of the service key name matches the supplied KEY_NAME.
ibmcloud resource service-key (NAME | ID) [-g RESOURCE_GROUP] [--id]

Command options
NAME
Name of the key
ID
ID of the key
-g
Resource group name
--id
Display the ID of the service key. This option is exclusive with '--output'.
-g RESOURCE_GROUP
Resource group name

Examples
Show details of service keys my-service-key :
ibmcloud resource service-key my-service-key

Show details of service key with ID crn:v1:bluemix:public:cloudantnosqldb:us-south:a/537860630a5ba7115be954e8d5aa5689:cc2a6d6c-8f5e4038-b975-b09b51d1d8dc:resource-key:9057f12e-fbf5-421d-8865-764422217a79 :
ibmcloud resource service-key crn:v1:bluemix:public:cloudantnosqldb:us-south:a/537860630a5ba7115be954e8d5aa5689:cc2a6d6c-8f5e4038-b975-b09b51d1d8dc:resource-key:9057f12e-fbf5-421d-8865-764422217a79

ibmcloud resource service-key-create
Create a service key.
ibmcloud resource service-key-create NAME [ROLE_NAME] ( --instance-id SERVICE_INSTANCE_ID | --instance-name
SERVICE_INSTANCE_NAME) [--service-id SERVICE_ID] [-p, --parameters @JSON_FILE | JSON_TEXT] [-g RESOURCE_GROUP] [--serviceendpoint SERVICE_ENDPOINT_TYPE] [-f, --force] [-f, --force] [-q, --quiet]

Command options
NAME (required)
Name of the key.
ROLE_NAME (optional)
Name of the IAM service role. The specified role cannot be one of the default platform roles. You can verify the eligibility of any role for use with this
option by running ibmcloud iam roles --service <your-service> and checking that serviceRole appears in the role's CRN.
--instance-id SERVICE_INSTANCE_ID

Running secure workloads 375

Service instance ID.
--instance-name SERVICE_INSTANCE_NAME
Service instance name.
--service-id SERVICE_ID
Name or UUID of the service ID, which the role belongs to. Can be set only when

ROLE_NAME is omitted or is set to None .

-p, --parameters @JSON_FILE | JSON_TEXT
Parameters JSON file or JSON string.
-g RESOURCE_GROUP
Resource group name.
--service-endpoint SERVICE_ENDPOINT_TYPE
Type of the service endpoint. Possible values are 'public' or 'private'.
--output FORMAT (optional)
Specify the output format. Only JSON is supported.
-f, --force
Force creation without confirmation
-q, --quite
Suppress verbose output.

Examples
Create a service key named my-service-key with role Administrator for service instance my-service-instance :
ibmcloud resource service-key-create my-service-key Administrator --instance-name my-service-instance

Create a service key named my-service-key without any role for a non-iam-enabled service instance my-service-instance :
ibmcloud resource service-key-create my-service-key --instance-name my-service-instance

ibmcloud resource service-key-update
Update a service key.
ibmcloud resource service-key-update ( NAME | ID ) [-n, --name NEW_NAME] [-g RESOURCE_GROUP] [-f, --force]

Command options
NAME | ID
Name or ID of the key
-n, --name NEW_NAME
New name of the key
-g RESOURCE_GROUP
ID of the resource group to which the key belongs
-f, --force
Force update without confirmation

Examples
Update a service key named my-service-key , give it a new name my-service-key-2 :

Running secure workloads 376

ibmcloud resource service-key-update my-service-key -n my-service-key-2

ibmcloud resource service-key-delete
Delete a service key.
ibmcloud resource service-key-delete ( KEY_NAME | KEY_ID ) [-f, --force]

Command options
KEY_NAME | KEY_ID
Name of the key or the ID of the key
-f, --force
Force deletion without confirmation

Examples
Delete service key my-service-key :
ibmcloud resource service-key-delete my-service-key

ibmcloud resource search
Search resources by using Lucene query syntax.
ibmcloud resource search LUCENE_QUERY [-o, --offset OFFSET] [-l, --limit LIMIT] [-s, --sort-by (name, family, region, type,
crn)] [-p, --provider PROVIDER] [-ir, --is-reclaimed (false, true, any)] [--output FORMAT]

Command options
-ir, --is-reclaimed
Search for account resources that have been reclaimed. However, by default the search returns only active resources. You can set is-reclaimed to
any to search for resources whether they are reclaimed or not. Set this option to true to apply the search criteria only to reclaimed resources. Set
this option to false to search only for active resources. false is the default behavior.
-o, -offset
Starting resource position number
-l, -limit
Number of resources to return, up to a maximum of 10000.
-s, --sort-by
Property to sort by. Accepted values are name , family , region , type , crn .
-p, --provider
Display classic infrastructure resources. The only supported value is classic-infrastructure .

Searchable attributes
You can search for many attributes to scope your search. A few examples are:

name
The user-defined name of the resource.
region

Running secure workloads 377

The geographical location where the resource is provisioned. For example: us-south, us-east, au-syd, eu-gb, eu-de, and jp-tok.
service_name
The name of the service as it appears in the Name column of the output of 'ibmcloud catalog service-marketplace'.
creation_date
The date on which the resource is created.
modification_date
The last modification date of the resource.

For the complete list of attributes that you can search for, see Searching for resources.

Examples
Search for Resource Controller resources in the specified location (that is, in us-south region):
ibmcloud resource search "region:us-south AND family:resource_controller"

Search for resource groups with name default:
ibmcloud resource search "name:default AND type:resource-group"

Search for a resource with the specified Cloud Resource Name (CRN):
ibmcloud resource search "crn:\"crn:v1:bluemix:public:cloudantnosqldb:us-south:s/4948af7e-cc78-4321-998a-e549dd5e9210:41a031cde9e5-4c46-975d-9e4a6391322e:cf-service-instance:\""

Search for a resource with the specified tag:
ibmcloud resource search "tags:\"mykey:myvalue\""

Search for Classic Infrastructure Virtual Guest resource with the specified id (only with -p classic-infrastructure):
ibmcloud resource search "id:12345678 _objectType:SoftLayer_Virtual_Guest"

Search for Classic Infrastructure Hardware resource with the specified tag name (only with -p classic-infrastructure):
ibmcloud resource search "tagReferences.tag.name:name _objectType:SoftLayer_Hardware"

ibmcloud resource subscription
Show details of a subscription.
ibmcloud resource subscription SUBSCRIPTION_ID

Command options
SUBSCRIPTION_ID (required)
SUBSCRIPTION_ID field of a subscription

Examples
Show details of subscription my-subscription-id :
ibmcloud resource subscription my-subscription-id

ibmcloud resource subscriptions
Running secure workloads 378

List subscriptions for your account
ibmcloud resource subscriptions [--output FORMAT]

Command options
--output value
Specify the output format. Only JSON is supported now.

ibmcloud resource tags
List all tags in your billing account
ibmcloud resource tags [-o, --offset OFFSET] [-l, --limit LIMIT]

[-p, --provider classic-infrastructure] [-d, --details true] [-

a, --attached true] [--output FORMAT] [--tag-type TAG_TYPE] [--account-id ACCOUNT_ID]

Command options
--offset value, -o value
Starting resource position number (default: 0).
--limit value, -l value
Number of resources to return (maximum 1000) (default: 100).
--provider value, -p value
Display Classic Infrastructure resources, the only value that is allowed is: classic-infrastructure. Use it for resources of type SoftLayer_Hardware,
SoftLayer_Network_Application_Delivery_Controller, SoftLayer_Network_Subnet_IpAddress or SoftLayer_Network_Vlan.
--details value, -d value
Show additional attributes for each tag, only value allowed is true.
--attached value, -a value
Show only filtered tags attached to a resource, only value allowed is true.
--tag-type value
Type of the tag. Only allowed values are: user, service, or access (default value : user).
--account-id value
The ID of the account that owns the tags that you want to list (required if tag-type is set to service).
--output value
Specify the output format. Only JSON is supported now.
-q, --quiet
Suppress verbose output.

ibmcloud resource tag-create
Create an access management tag:
ibmcloud resource tag-create --tag-names TAG_NAMES

Command options
--tag-names value
Comma-separated list of tag names.
Running secure workloads 379

-q, --quiet
Suppress verbose output.

This command is only valid for access management tags. For example:
Run the following command to create the access management tag project:myproject :
ibmcloud resource tag-create —tag-names “project:myproject”

ibmcloud resource tag-attach
Attach one or more tags to a resource:
ibmcloud resource tag-attach --tag-names TAG_NAMES (--resource-name NAME | --resource-id RESOURCE_ID ) [--resource-type
RESOURCE_TYPE] [--tag-type TAG_TYPE] [--account-id ACCOUNT_ID] [--replace] [--update]

Command options
--tag-names value
Comma-separated list of tag names.
--resource-name value
The name of the resource on which the tags must be attached.
--resource-id value
CRN of the resource on which the tags should be attached (for Classic Infrastructure resource, it is the ID of the resource).
--resource-type value
Type of the tag. Only allowed values are: user, service or access (default value : user).
--tag-type value
The type of the tag. The only allowed values are user or service . The default value is user .
--account-id value
The ID of the account that owns the resources to be tagged (required if tag-type is set to service).
--replace
The list of tag names replaces the current list of tag names that are attached to the resource.
--update
The tag names in the format key:value will be updated. The option has no effect on tag names that are not in that format.
-q, --quiet
Suppress verbose output.

Examples
To attach the user tag MyTag to a Kubernetes cluster named MyCluster , first look for the CRN of the cluster you would like to tag:
ibmcloud resource search 'type:k8\-cluster AND name:MyCluster'

Take note of the CRN, which is a string similar to the following example:
crn:v1:bluemix:public:containers-kubernetes:us-south:a/a27a4741a57dcf5c965939adb66fe1c7:a46242e638ca47b09f10e9a3cbe5687a::

To attach the tag, run the following command:
ibmcloud resource tag-attach --tag-names MyTag --resource-id rn:v1:bluemix:public:containers-kubernetes:ussouth:a/a27a4741a57dcf5c965939adb66fe1c7:a46242e638ca47b09f10e9a3cbe5687a::

Running secure workloads 380

To attach the user tag MyTag to a resource named MyResource :
ibmcloud resource tag-attach --tag-name MyTag --resource-name

'MyResource'

To attach the user tag MyTag to a classic infrastructure virtual guest named MyVM , first look for the ID of the virtual guest you would like to tag:
ibmcloud resource search 'fullyQualifiedDomainName:MyVM

Take a note of the ID, which is a string similar to

_objectType:SoftLayer_Virtual_Guest' -p classic-infrastructure

48373549 .

To attach the tag, run the following command:
ibmcloud resource tag-attach --tag-names MyTag --resource-id 48373549 --resource-type SoftLayer_Virtual_Guest

To attach the access management tag project:myproject , that you previously created, to an instance of IBM Cloud Object Storage called
Project data , run the following command:
ibmcloud resource tag-attach --tag-names "project:myproject" --resource-name Project data -—tag-type access

To update to production the value of the env user tag on a resource named MyResource run the following command:
ibmcloud resource tag-attach --tag-names 'env:production' --resource-name 'MyResource' --update

To update to production the value of the env access management tag on a resource named MyResource run the following command:
ibmcloud resource tag-attach --tag-names 'env:production' --resource-name 'MyResource' --update --tag-type access

To replace all user tags of MyResource with a new set of tags tag1 , tag2 , and tag3 run the following command:
ibmcloud resource tag-attach --tag-names 'tag1,tag2,tag3' --resource-name 'MyResource' --replace

To replace all access management tags of MyResource with the tag compliance:hipaa run the following command:
ibmcloud resource tag-attach --tag-names 'compliance:hipaa' --resource-name 'MyResource' --replace --tag-type access

ibmcloud resource tag-detach
Detaching one or more tags from a resource:
ibmcloud resource tag-detach --tag-names TAG_NAMES (--resource-name NAME | --resource-id RESOURCE_ID ) [--resource-type
RESOURCE_TYPE] [--tag-type TAG_TYPE] [--account-id ACCOUNT_ID]

Command options
--tag-names value
Comma-separated list of tag names.
--resource-name value
The name of the resource on which the tags should be attached.
--resource-id value
CRN of the resource on which the tags should be attached (for Classic Infrastructure resource, it is the ID of the resource).
--resource-type value
Resource type on which the tags should be attached (required for Classic Infrastructure resource of type SoftLayer_Hardware,
SoftLayer_Network_Application_Delivery_Controller, SoftLayer_Network_Subnet_IpAddress or SoftLayer_Network_Vlan only).
--tag-type value
Type of the tag. Only allowed values are: user, service, or access (default value : user).
--account-id value

Running secure workloads 381

The ID of the account that owns the resources to be detached (required if tag-type is set to service).
-q, --quiet
Suppress verbose output.

Examples
To detach the user tag MyTag from a Kubernetes cluster named MyCluster , first look for the CRN of the cluster you would like to detach the tag
from:
ibmcloud resource search 'type:k8\-cluster AND name:MyCluster'

Take note of the CRN, which is a string similar to the following example:
crn:v1:bluemix:public:containers-kubernetes:us-south:a/a27a4741a57dcf5c965939adb66fe1c7:a46242e638ca47b09f10e9a3cbe5687a::

To detach the tag, run the following command:
ibmcloud resource tag-detach --tag-names MyTag --resource-id rn:v1:bluemix:public:containers-kubernetes:ussouth:a/a27a4741a57dcf5c965939adb66fe1c7:a46242e638ca47b09f10e9a3cbe5687a::

To detach the user tag MyTag to a resource named MyResource :
ibmcloud resource tag-detach --tag-name MyTag --resource-name 'MyResource'

To detach the user tag MyTag to a classic infrastructure virtual guest named MyVM , first look for the ID of the virtual guest you would like to detach
the tag from:
ibmcloud resource search 'fullyQualifiedDomainName:MyVM

Take a note of the ID, which is a string similar to

_objectType:SoftLayer_Virtual_Guest' -p classic-infrastructure

48373549 .

To detach the tag, run the following command:
ibmcloud resource tag-detach --tag-names MyTag --resource-id 48373549 --resource-type SoftLayer_Virtual_Guest

To detach the access management tag project:myproject from an instance of IBM Cloud Object Storage called Project data , run the following
command:
ibmcloud resource tag-detach --tag-names "project:myproject" --resource-name Project data -—tag-type access

To detach the env:value tag from MyResource , regardless of its value, run the following command:
ibmcloud resource tag-detach --tag-names 'env:*' —resource-name 'MyResource'

To detach all tags from MyResource run the following command:
ibmcloud resource tag-detach --tag-names '*' —resource-name 'MyResource'

ibmcloud resource tag-delete
Delete a tag:
ibmcloud resource tag-delete (--tag-name TAG_NAME | -a, --all

[-f, --force]) [-p, --provider PROVIDER] [--tag-type TAG_TYPE] [--

account-id ACCOUNT_ID]

Command options
--tag-name value
Tag name to be deleted.
Running secure workloads 382

--provider value, -p value
Delete the tag in the specified provider (the only supported value is classic-infrastructure). Use it for resources of type SoftLayer_Hardware,
SoftLayer_Network_Application_Delivery_Controller, SoftLayer_Network_Subnet_IpAddress or SoftLayer_Network_Vlan.
--tag-type value
Type of the tag. Only allowed values are: user, service, or access (default value : user).
account-id value
The ID of the account that owns the tags to be deleted (required if tag-type is set to service).
--force, -f
Delete the tags without confirmation.
--all, -a
Delete all tags that are not attached to any resources.
-q, --quiet
Suppress verbose output.

A tag can be deleted only if it isn't attached to any resource.

Examples
To delete the user tag MyTag from the account:
ibmcloud resource tag-delete --tag-name "MyTag"

To delete the access management tag project:myproject from the account:
ibmcloud resource tag-delete --tag-name "project:myproject" --tag-type access

To delete all unused user tags from the account:
ibmcloud resource tag-delete -a

To delete all unused access management tags from the account:
ibmcloud resource tag-delete -a --tag-type access

ibmcloud resource reclamations
List reclaimed resources that can be restored or deleted:
ibmcloud resource reclamations [--resource-instance-id INSTANCE_ID]

Command options
--resource-instance-id
The globally unique ID (GUID) of the resource instance

Examples
List all resource reclamations:
ibmcloud resource reclamations

List resource reclamations of a particular service instance:
ibmcloud resource reclamations --resource-instance-id abcd1234-ef56-486e-b293-22d6c7eb6699
Running secure workloads 383

ibmcloud resource reclamation
Show details of a resource reclamation:
ibmcloud resource reclamation RECLAMATION_ID

Command options
RECLAMATION_ID
Resource reclamation ID

Examples
Show details of a resource reclamation:
ibmcloud resource reclamation daf12d343ef

ibmcloud resource reclamation-restore
Restore a reclaimed resource so that the resource is available again:
ibmcloud resource reclamation-restore ID [--comment COMMENT]

Command options
ID
ID of the resource reclamation
--comment
Comments about the action

Examples
Restore a resource reclamation with ID d9fendfwlw :
ibmcloud resource reclamation-restore "d9fendfwlw"

Restore a resource reclamation with ID d9fendfwlw , leave a comment of need to use for another 3 months , and show JSON output:
ibmcloud resource reclamation-restore "d9fendfwlw" --comment "need to use for another 3 months" --output JSON

ibmcloud resource reclamation-delete
Delete a reclaimed resource so that the resource can no longer be restored:
ibmcloud resource reclamation-delete ID [--comment COMMENT] [--f, --force]

Command options
ID
ID of the resource reclamation
--comment
Comments about the action

Running secure workloads 384

-f, --force
Force deletion without confirmation

Examples
Delete a resource reclamation with ID d9fendfwlw :
ibmcloud resource reclamation-delete "d9fendfwlw"

Delete a resource reclamation with ID d9fendfwlw and leave a comment of no longer needed without confirmation:
ibmcloud resource reclamation-delete "d9fendfwlw" --comment "no longer needed" -f

Running secure workloads 385

Getting help and support
If you experience an issue or have questions, you can use the following resources before you open a support case.
Review the FAQs about projects in the product documentation.
Review the troubleshooting documentation for projects to troubleshoot and resolve common issues.
Check the status of the IBM Cloud platform and resources by going to the Status page.
Review Stack Overflow to see whether other users experienced the same problem. When you ask a question, tag the question with

projects , so

that it's seen by the IBM Cloud development teams.
If you still can't resolve the problem, you can open a support case. For more information, see

Creating support cases. And, if you're looking to provide

feedback, see Submitting feedback.

Running secure workloads 386

Known issues and limitations
Known issues and limitations include configuration management, user access to projects, and identity and access management (IAM) limits.
Note: To review the default IAM limits for your enterprise, see Enterprise limits. To review the default limits for an account, see IBM Cloud IAM
limits.

Authorization
To work in a project, users must have access to the IBM Cloud Projects service, the resource group for the project, and IBM Cloud® Schematics. For more
information about access, see Assigning users access to projects .
Authorizing projects to deploy to a target account is managed by passing an API key into the deployable architecture. Projects can be directly authorized
by using a trusted profile, but trusted profiles are not currently supported by all services. API keys will continue to be supported , but a trusted profile is the
preferred method for authorizing deployment to target accounts.

Configuration management
Configurations can be added, deleted, and renamed. Moving a configuration between projects must be done manually by editing

project.json

documents on both projects. If there are multiple configurations in a project, they can be organized only by naming conventions.

Cost estimate
Cost estimation is available for deployable architectures in the IBM Cloud catalog. Depending on the deployable architecture, a starting cost is estimated
based on the available data. This estimated amount is subject to change as the architecture is customized within a project, and it does not include all
resources, usage, licenses, fees, discounts, or taxes. For more information, see Estimating architecture costs in a project.

API, SDK, and Terraform
The projects API, SDK, and Terraform functionalities are beta for this release. Beta products are made solely available for evaluation and testing purposes.
There are no warranties, SLAs, or support provided and beta products are not intended for production use.

Access policy version limitations
As of 25 January 2023, IAM supports two versions of the IAM Policy Management API:

/v2/policies and /v1/policies . v1/polices allows for string

comparisons against attributes in the subject and resources of a policy. v2/polices introduces a new schema that provides backwards functional
compatibility while allowing for more complex comparisons and operators and time based conditions.

String comparisons
The following table lists the string comparison operators that you can use to build access policies with

/v2/policies syntax. For more information about

each version, see Comparing /v1/policies and /v2/policies syntax. For example use cases of the operators, see Resource attribute-based conditions.
Important: You can have up to 10 conditions and nesting up to 2 levels.

Operator

Description

stringEquals

Case-sensitive string comparison. Boolean or number values are converted into a string before comparison.

stringMatch

Case-sensitive string match is performed between the pattern and the target string by using either an asterisk ( *), question
mark ( ?), both, or none (same as literal value). An asterisk ( *) represents any sequence of zero or more characters in the
string, and a question mark (?) represents any single character. You can also express an asterisk * and question mark ? as a
literal value by enclosing each within two sets of curly brackets {{}}.

stringExists

Boolean where true indicates that the string must be present and can be empty. false indicates that the string must not be
present.

stringEqualsAnyOf

Case-sensitive exact string matching any of the strings in an array of strings. Limit of 10 values.

Running secure workloads 387

stringMatchAnyOf

Case-sensitive string matching any of the strings in an array of strings. The string values can include either an asterisk ( *),
question mark (?), both, or none (same as literal value). An asterisk ( *) represents any sequence of zero or more characters in
the string, and a question mark (?) represents any single character. You can also express an asterisk * and question mark ? as
a literal value by enclosing each within two sets of curly brackets {{}}. Limit of 10 values.
The string comparison operators available for conditions in access policies.

For example, the following statement contains an operator element that uses stringEquals to specify that the account ID and service name must
exactly match the value element. The statement also contains an operator element that uses stringMatch to specify a naming pattern for Event
Streams topics that you might use to organize access to those specific resources. This way, you can assign one policy to all topics in your account that
begin with messagehub-topic-dev .
"resource": {
"attributes": [
{
"operator": "stringEquals",
"value": "0aeab68aabd14d89bd72e4330150710a0",
"key": "accountId"
},
{
"value": "messagehub",
"operator": "stringEquals",
"key": "serviceName"
},
{
"value": "messagehub-topic-dev*",
"operator": "stringMatch",
"key": "resource"
}
]
},

Note: Authorization policies are currently only supported in /v1/policies .

Checking a policy version in the console
Time-based and resource attribute-based conditions for IAM access policies use /v2/policies syntax. Policies that use /v1/policies syntax aren't
eligible to add time-based and resource attribute-based conditions. To update /v1/policies to /v2/policies by using the API, see Updating
/v1/policies to /v2/policies with conditions by using the API . To check whether you can add these conditions to an existing policy in the console,

complete the following steps.
1. Go to Manage > Access (IAM).
2. Select Users, Trusted profiles, Service IDs, or Access groups, depending on the policy you want to check.
3. Select a specific users, trusted profile, service ID, or access group.
4. Go to Access > Access policies.
5. Click on a policy. /v1/policies are indicated by the following notification:
Conditions unavailable for v1 policies
6. (Optional) To add conditions to a policy that uses /v1/policies syntax, delete the original policy and create a new one. In the console, new policies
use /v2/policies syntax.

Updating /v1/policies to /v2/policies with conditions by using the API
Policies that use /v1/policies syntax aren't eligible to add time-based and resource attribute-based conditions. To update the version, you can use the
PUT /v2/policies/{id} with the V1 ID and any conditions you want to include. For more information, see /v2/policies.

Comparing /v1/policies and /v2/policies syntax
The policy in each example grants a user access to the Billing service with the Editor role. The

/v2/policies example includes temporary time-based

conditions, indicated by the "conditions" parameter.

Running secure workloads 388

Tip: When editing, creating, and deleting policies, use the corresponding API version.

/v1/policies
{
"type": "access",
"roles": [
{
"role_id": "crn:v1:bluemix:public:iam::::role:Editor"
}
],
"resources": [
{
"attributes": [
{
"name": "accountId",
"value": "000c49bc2724a07000010b1da94c4d0"
},
{
"name": "serviceName",
"value": "billing"
}
]
}
],
"subjects": [
{
"attributes": [
{
"name": "iam_id",
"value": "IBMid-00000AV0S0"
}
]
}
]
}

Note: When you list policies with /v1/policies the API returns /v1/ and a placeholder policy for each /v2/ policy that's in the account. For
more information, see /v1/policies returns a placeholder for /v2/ policies the account

/v2/policies
{
"type": "access",
"control": {
"grant": {
"roles": [
{
"role_id": "crn:v1:bluemix:public:iam::::role:Editor"
}
]
}
},
"resource": {
"attributes": [
{
"operator": "stringEquals",
"value": "000c49bc2724a07000010b1da94c4d0",
"key": "accountId"
},
{
"value": "billing",
"operator": "stringEquals",
"key": "serviceName"
}
]
},
Running secure workloads 389

"rule": {
"operator": "and",
"conditions": [
{
"key": "{{environment.attributes.current_date_time}}",
"operator": "dateTimeGreaterThanOrEquals",
"value": "2023-01-01T09:00:00+00:00"
},
{
"key": "{{environment.attributes.current_date_time}}",
"operator": "dateTimeLessThanOrEquals",
"value": "2023-01-06T17:59:59+00:00"
}
]
},
"pattern": "time-based-conditions:once",
"subject": {
"attributes": [
{
"key": "iam_id",
"operator": "stringEquals",
"value": "IBMid-00000AV0S0"
}
]
}
}

/v1/policies returns a placeholder for /v2/ policies
When you list policies with /v1/policies the API returns /v1/ and a placeholder policy for each /v2/ policy that's in the account. The placeholders
indicate the existence of additional policies in the account while abiding by the /v1/ schema. To see the full content of a /v2/ policy, list policies by
using /v2/policies or retrieve the individual policy by using GET: v2/policies/<ID> . For example, see the following placeholder policy:
{
"id": "33b901fa-8ec5-4432-a2e6-24b6a212c20a",
"type": "access",
"description": "**This is a unsupported policy version placeholder, to view the full content, please call GET with provided
href**",
"subjects": [{
"attributes": [{
"name": "iam_id",
"value": "unsupported version"
}]
}],
"roles": [{
"role_id": "crn:v1:bluemix:public:iam::::role:UnsupportedVersion",
"display_name": "Unsupported Version",
"description": "**This is a unsupported policy version placeholder, to view the full content, please call GET with provided
href**"
}],
"resources": [{
"attributes": [{
"name": "accountId",
"value": "000c49bc2724a07000010b1da94c4d0"
}]
}],
"href": "https://iam.cloud.ibm.com/v2/policies/88b901fa-6ec5-888-a2e6-24b6a212c20a"
}

Drift detection limits
Schematics and Terraform can detect a drift only between a changed resource and the specific configuration that created that resource during deployment.
The service can’t detect drift in reused or referenced resources.
For example, in a specific scenario, configuration config-1 created a Cloud Object Storage instance during deployment. Later, you deployed
configurations config-2 and config-3 , and they reused the same Cloud Object Storage instance. When you renamed the resource, drift was detected
only between config-1 and the renamed Cloud Object Storage instance. config-2 and config-3 failed the drift detection job because drift can be
detected only between a configuration and the resource that it created, not reused.

Running secure workloads 390

For more information, see Managing drift.

Running secure workloads 391

FAQ about projects
FAQs for IBM Cloud® projects might include questions about support options, configurations, access to projects, and cost estimation.

What are IBM Cloud projects?
As an enterprise, you use projects to ensure that the configuration of your deployable architecture is always compliant, cost effective, and secure. Projects
are a named collection of configurations that are used to manage related resources and Infrastructure as Code (IaC) deployments across accounts.

How do I add users to my project?
To add a user to a project, they must be a member of your account with correct IAM access roles assigned.
To assign access to the IBM Cloud Projects service, complete the following steps:
1. In the IBM Cloud console, click Manage > Access (IAM), and then select Users.
2. Click the user or access group that you want to assign access, then go to Access > Assign access.
3. For the service, select Project. Then, click Next.
4. Scope the access to All resources or Specific resources. Then, click Next.
5. Select any combination of roles or permissions, and click Review.
6. Click Add to add your policy configuration to your policy summary.
7. Click Assign.
In addition, users must be assigned the Editor and Manager role on the Schematics service and the Viewer role on the resource group for the project.

How do I estimate project costs?
During the validation process, the starting costs for the project are estimated. You can view the cost details associated with the project from the validation
modal after your changes to the configuration are saved and validated.

Who has access to my project?
Any user that is a member of your account that is assigned access to the IBM Cloud Projects service, Schematics, and the resource group for your project
can access your project.

Running secure workloads 392

Troubleshooting projects
Why can't I access a project?
You try to find a project that you created or a project that you thought you had access to from the Projects page in the console, but it isn't listed.

What’s happening
A project that you expected to find in the console from the Menu

> Projects page isn't included in your list of projects.

Why it’s happening
Your project might have been deleted by another member of your team, or you don't have the required level of access to view projects.

How to fix it
Make sure that you have the correct access to view projects. For more information, see Assigning users access to projects . If your project was deleted,
create a new one. If you have the IBM Cloud® Activity Tracker service set up for your account, you can use that to audit events for a project , including
project deletions.

Why can't I create a project?
You try to create a project from the Projects page in the console, but you encounter an error.

What’s happening
When you click Create from the Projects page in the console, you encounter this error:
Additional access required

Why it’s happening
You don't have the required level of access to create a project.

How to fix it
Assign yourself access, or request access from your account administrator. For more information, see Assigning users access to projects .

Why can't I delete my project?
You tried to delete a project, but it doesn't delete successfully.

What’s happening
The project displays a Needs attention alert and a message displays on the Activity tab that states that the project deletion failed.

Why it’s happening
One of the reasons a project might not delete successfully is due to an issue with the project tooling services.

How to fix it
Project tooling is required to delete a project. If an error occurs with the project tooling service, you can’t delete the project. Try again later or contact IBM
Cloud Support.

Why can't I deploy my changes to a configuration?
If you're unable to deploy changes to a configuration, you might need an Editor to approve your changes.

What’s happening
You can edit and save changes to a configuration, but you can't deploy them.

Why it’s happening
Running secure workloads 393

After you save changes to a configuration, they must be validated. Then, a user who is assigned to the Editor role for projects must approve the changes
before they can be deployed.

How to fix it
Contact an Editor on your team to approve the changes to the configuration. Contact your account administrator if you need Editor access to the IBM Cloud
Projects service. For more information, see Assigning users access to projects .

Why can't I validate my configuration?
You tried to validate changes to a configuration in a project, but an error prevented the validation from completing.

What’s happening
You tried to validate changes to a configuration in a project, but the following error displays:
Unable to validate your configuration.

Why it’s happening
An availability issue occurred, which prevented validation.
A problem occurred with the project's authentication method. The API key that is used in a secret might have been deleted, or the trusted profile
was not set up properly. For more information, go to Defining an authentication menthod .
If the error message provides information about a Schematics cart order failure with a status code

403 , then access is not granted between the IBM

Cloud Projects service and other IBM Cloud services. For more information, go to Granting access between the IBM Cloud Projects service and other
IBM Cloud services.
A service might have been down during the validation. Check the Status page for the service, and try to validate your configuration again when the
service is back up.
A timeout might have occurred during the validation, which caused a failure. Try validating your configuration again.
If the error message provides information about a bad request or parameters , you might need to edit your input values, then validate your
configuration again.

How do I address a failed validation when using projects?
You tried to validate changes to a configuration in a project, but the validation failed.

What’s happening
The project displays a Needs attention alert and a message displays on the Activity tab that states that the validation failed.

Why it’s happening
An issue occurred with the configuration during the validation process. You can't deploy your changes until issues are resolved. Go to the needs attention
widget on the Overview tab and select Changes failed validation to view more information about the failure.
If the plan failed, it likely means that a required input value, such as an authentication method, hasn't been supplied yet. Or, one of the provided
inputs isn't valid. The plan can also fail if the deployable architecture that your configuration is based on is invalid. Determine the exact problem from
the logs, and update the input values if needed. If the logs indicate an error with the Terraform version, your settings in IBM Cloud® Schematics
might need to be updated. For more information, see How do I update my Terraform version?
If the compliance check failed, the deployment is not compliant with the compliance profile. The failure might be caused by input values or because
of compliance issues with the current version of the deployable architecture that you're configuring. Review which controls failed and adjust the
inputs or update the deployable architecture until the validation is successful. If it's necessary, an administrator can override and approve changes
that failed due to the Code Risk Analyzer scan.

How do I address a failed deployment when using projects?
You tried to deploy a configuration from a project, but the deployment failed, preventing a successful deployment to your target environment.

What’s happening
The project displays a Needs attention alert and a message displays on the Activity tab that states that the deployment failed.
Running secure workloads 394

Why it’s happening
The changes that you made to your resources failed to deploy. Go to the needs attention widget on the Overview tab and select Changes failed to deploy
to view more information about the failure.
Lack of permissions: Ensure that the project has sufficient privileges in the target account.
Invalid input value: Check the logs for details.
Duplicate input values: Some input values, like an Object Storage bucket name or IP address, must be unique. Undeploy the existing resource, or
modify your input values to be unique.
Timeout: If the deployment runs too long, it might time out and cause a failure. Try deploying the configuration again.
A service was down during the deployment: Check the Schematics logs for 400 or 500 errors that indicate a problem with the service. Check the
Status page for the service, and try to deploy again when the service is back up. For more information on the 500 errors in Schematics, see Why am
I getting 5xx errors in Schematics?
Reaching a quota limit: Ensure that sufficient quota space is available in the account. For example, you can have only one instance of a service that
uses a Lite plan.
Manual changes were made to the account that conflict with the deployable architecture. We recommend avoiding manual changes to the account
during a deployment.

Why were my resources not destroyed when I undeployed a configuration?
You tried to undeploy a configuration, but it failed.

What’s happening
The project displays a Needs attention alert and a message displays on the Activity tab that states that the configuration failed to undeploy.

Why it’s happening
Go to the needs attention widget on the Overview tab and select Failed to undeploy to view the Schematics logs, which provide more information about
the failure.
Permissions for the API Key or trusted profile were changed: For more information about the required access for trusted profiles, see

Using trusted

profiles to authorize projects.
A service was down when you tried to undeploy a configuration: Check the Status page for the service, and try to undeploy the configuration again
when the service is back up.
The deployable architecture that your configuration is based on contains bugs that caused a failure when you tried to undeploy it.
Though not recommended, some resources might need to be destroyed one by one in the Schematics resource list. For more information, see
Undeploying resources created by projects .

How do I update my Terraform version?
If you try to validate a configuration, and the validation fails due to a plan failure, you might need to edit the settings in your IBM Cloud® Schematics
workspace.

What’s happening
You tried to validate a configuration, but the validation failed due to a plan failure. In the Schematics logs, you see the following error:
Error: Unsupported Terraform Core version

Why it’s happening
Schematics is using a version of Terraform that is no longer supported.

How to fix it
Update the settings of the Schematics workspace to use a supported Terraform version.
Complete the following steps:
1. From the projects list, select a project.
2. Go to the Configurations tab, and select a deployable architecture configuration.
3. Select the Workspace URL to open the Schematics logs.
Running secure workloads 395

4. Click Settings.
5. In the Details section, select Update for the Offering version to update the Terraform version that your workspace is using.

Why can't I view my project resources?
Some or all resources aren't listed on the Resources tab in a configuration.

What’s happening
You open a configuration and go to Resources. Some or all of the resources you expected to see aren't included in the list of resources.

Why it’s happening
If your configuration's deployment was successful, but some resources are missing from the Resources tab, they might have been destroyed individually
from the IBM Cloud® Schematics workspace. If your configuration failed to deploy, some resources might have been created, but not all of the resources
that are needed for a full deployment.

How to fix it
Undeploy the configuration and try deploying your configuration again.

Why are my resources tainted?
When you view your resource list, there are resources with a tainted status.

What’s happening
A resource that you deployed is marked as tainted.

Why it’s happening
Terraform marks a resource that isn't fully functional as tainted. This might be due to a provisioning error, or because Terraform is unable to determine if
the resources were successfully or partially created.
Terraform will delete and re-create the resource at the start of the next deployment. You can manually remove the taint status by deleting the resource and
re-creating it.

How to fix it
For more information, see Managing resources with Schematics.

Running secure workloads 396

© Copyright IBM Corporation 2025
IBM Corporation
New Orchard Road
Armonk, NY 10504
Produced in the United States of America
2025-04-15
IBM, the IBM logo, and ibm.com are trademarks or registered trademarks of
International Business Machines Corp., registered in many jurisdictions
worldwide. Other product and service names might be trademarks of IBM or
other companies. A current list of IBM trademarks is available on the web at
https://www.ibm.com/legal/copytrade.
This document is current as of the initial date of publication and may be changed
by IBM at any time. Not all offerings are available in every country in which IBM
operates.
THE INFORMATION IN THIS DOCUMENT IS PROVIDED "AS IS" WITHOUT ANY
WARRANTY, EXPRESS OR IMPLIED, INCLUDING WITHOUT ANY WARRANTIES
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND ANY
WARRANTY OR CONDITION OF NON-INFRINGEMENT.
IBM products are warranted according to the terms and conditions of the
agreements under which they are provided.

